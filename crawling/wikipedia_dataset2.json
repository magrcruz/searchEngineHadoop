[
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo",
        "titulo": "Algoritmo",
        "contenido": "en matematicas, logica, ciencias de la computacion y disciplinas relacionadas, un algoritmo (probablemente del latin tardio algorithmus, y este del arabe clasico hisabu lgubar, que significa «calculo mediante cifras arabigas»)​ es un conjunto de instrucciones o reglas definidas y no-ambiguas, ordenadas y finitas que permite, tipicamente, solucionar un problema, realizar un computo, procesar datos y llevar a cabo otras tareas o actividades.​ dado un estado inicial y una entrada, siguiendo los pasos sucesivos se llega a un estado final y se obtiene una solucion. los algoritmos son el objeto de estudio de la algoritmia.​  en la vida cotidiana, se emplean algoritmos frecuentemente para resolver problemas determinados. algunos ejemplos son los manuales de usuario, que muestran algoritmos para usar un aparato, o las instrucciones que recibe un trabajador de su patron. algunos ejemplos en matematica son el algoritmo de multiplicacion, para calcular el producto, el algoritmo de la division para calcular el cociente de dos numeros, el algoritmo de euclides para obtener el maximo comun divisor de dos enteros positivos, o el metodo de gauss para resolver un sistema de ecuaciones lineales.  en terminos de programacion, un algoritmo es una secuencia de pasos logicos que permiten solucionar un problema.  en general, no existe ningun consenso definitivo en cuanto a la definicion formal de algoritmo. muchos autores los señalan como listas de instrucciones para resolver un calculo o un problema abstracto, es decir, que un numero finito de pasos convierten los datos de un problema (entrada) en una solucion (salida).​​​​​​ sin embargo, cabe notar que algunos algoritmos no tienen necesariamente que terminar o resolver un problema en particular. por ejemplo, una version modificada de la criba de eratostenes, que nunca termine de calcular numeros primos, no deja de ser un algoritmo.​  a lo largo de la historia, varios autores han tratado de definir formalmente los algoritmos utilizando modelos matematicos. esto lo hizo alonzo church en 1936 con el concepto de \"calculabilidad efectiva\" basada en su calculo lambda y por alan turing basandose en la maquina de turing. los dos enfoques son equivalentes, en el sentido de que se pueden resolver exactamente los mismos problemas con ambos enfoques.​​ no obstante, estos modelos estan sujetos a un tipo particular de datos, como son numeros, simbolos o graficas mientras que, en general, los algoritmos funcionan sobre una vasta cantidad de estructuras de datos.​​ en general, la parte comun en todas las definiciones se puede resumir en las siguientes tres propiedades, siempre y cuando no consideremos algoritmos paralelos:​  en resumen, un algoritmo es cualquier cosa que funcione paso a paso, donde cada paso se pueda describir sin ambiguedad y sin hacer referencia a una computadora en particular, y ademas tiene un limite fijo en cuanto a la cantidad de datos que se pueden leer/escribir en un solo paso.  esta amplia definicion abarca tanto a algoritmos practicos como aquellos que solo funcionan en teoria, por ejemplo, el metodo de newton y la eliminacion de gauss-jordan funcionan, al menos en principio, con numeros de precision infinita; sin embargo, no es posible programar la precision infinita en una computadora, y no por ello dejan de ser algoritmos.​ en particular es posible considerar una cuarta propiedad que puede usarse para validar la tesis de church-turing, de que toda funcion calculable se puede programar en una maquina de turing (o equivalentemente, en un lenguaje de programacion suficientemente general):​  los algoritmos pueden ser expresados de muchas maneras, incluyendo al lenguaje natural, pseudocodigo, diagramas de flujo y lenguajes de programacion entre otros. las descripciones en lenguaje natural tienden a ser ambiguas y extensas. el usar pseudocodigo y diagramas de flujo evita muchas ambiguedades del lenguaje natural. dichas expresiones son formas mas estructuradas para representar algoritmos; no obstante, se mantienen independientes de un lenguaje de programacion especifico.  la descripcion de un algoritmo suele hacerse en tres niveles:  tambien es posible incluir un teorema que demuestre que el algoritmo es correcto, un analisis de complejidad o ambos.  los diagramas de flujo son descripciones graficas de algoritmos; usan simbolos conectados con flechas para indicar la secuencia de instrucciones y estan regidos por iso.  los diagramas de flujo se emplean para representar algoritmos pequeños, ya que abarcan mucho espacio y su construccion es laboriosa. por su facilidad de lectura se utilizan como introduccion a los algoritmos, descripcion de un lenguaje y descripcion de procesos a personas ajenas a la computacion.  el pseudocodigo (falso lenguaje, el prefijo pseudo significa falso) es una descripcion de alto nivel de un algoritmo que emplea una mezcla de lenguaje natural con algunas convenciones sintacticas propias de lenguajes de programacion, como asignaciones, ciclos y condicionales, aunque no esta regido por ningun estandar.  el pseudocodigo esta pensado para facilitar a las personas el entendimiento de un algoritmo y, por lo tanto, puede omitir detalles irrelevantes que son necesarios en una implementacion. programadores diferentes suelen utilizar convenciones distintas, que pueden estar basadas en la sintaxis de lenguajes de programacion concretos. sin embargo, el pseudocodigo, en general, es comprensible sin necesidad de conocer o usar un entorno de programacion especifico, y es a la vez suficientemente estructurado para que su implementacion se pueda hacer directamente a partir de el.  asi, el pseudocodigo cumple con las funciones antes mencionadas para representar algo abstracto, los protocolos son los lenguajes para la programacion. busque fuentes mas precisas para tener mayor comprension del tema.  la teoria de automatas y la teoria de funciones recursivas proveen modelos matematicos que formalizan el concepto de algoritmo. los modelos mas comunes son la maquina de turing, maquina de registro y funciones μ-recursivas. estos modelos son tan precisos como un lenguaje maquina, careciendo de expresiones coloquiales o ambiguedad; sin embargo, se mantienen independientes de cualquier computadora y de cualquier implementacion.  muchos algoritmos se han ideado para implementarse en un programa. no obstante, los algoritmos pueden ser implementados en otros medios, como una red neuronal, un circuito electrico o un aparato mecanico y electrico. algunos algoritmos incluso se diseñan especialmente para implementarse usando lapiz y papel. el algoritmo de multiplicacion tradicional, el algoritmo de euclides, la criba de eratostenes y muchas formas de resolver la raiz cuadrada son solo algunos ejemplos.  son elementos que toman valores especificos de un tipo de datos concreto. la declaracion de una variable puede realizarse comenzando con var. principalmente, existen dos maneras de otorgar valores iniciales a variables:  ejemplo:  la estructura secuencial es aquella en la que una accion sigue a otra en secuencia. las operaciones se suceden de tal modo que la salida de una es la entrada de la siguiente y asi sucesivamente hasta el fin del proceso. la asignacion de esto consiste en el paso de valores o resultados a una zona de la memoria. dicha zona sera reconocida con el nombre de la variable que recibe el valor. la asignacion se puede clasificar de la siguiente forma:  un ejemplo de estructura secuencial, como obtener el area de un triangulo:  un algoritmo se puede concebir como una funcion que transforma los datos de un problema (entrada) en los datos de una solucion (salida). mas aun, los datos se pueden representar a su vez como secuencias de bits, y en general, de simbolos cualesquiera.​​​ como cada secuencia de bits representa a un numero natural (vease sistema binario), entonces los algoritmos son en esencia funciones de los numeros naturales en los numeros naturales que si se pueden calcular. es decir que todo algoritmo calcula una funcion f : n → n \\to \\mathbb {n} } donde cada numero natural es la codificacion de un problema o de una solucion.  en ocasiones los algoritmos son susceptibles de nunca terminar, por ejemplo, cuando entran a un bucle infinito. cuando esto ocurre, el algoritmo nunca devuelve ningun valor de salida, y podemos decir que la funcion queda indefinida para ese valor de entrada. por esta razon se considera que los algoritmos son funciones parciales, es decir, no necesariamente definidas en todo su dominio de definicion.  cuando una funcion puede ser calculada por medios algoritmicos, sin importar la cantidad de memoria que ocupe o el tiempo que se tarde, se dice que dicha funcion es computable. no todas las funciones entre secuencias datos son computables. el problema de la parada es un ejemplo.  como medida de la eficiencia de un algoritmo, se suelen estudiar los recursos (memoria y tiempo) que consume el algoritmo. el analisis de algoritmos se ha desarrollado para obtener valores que de alguna forma indiquen (o especifiquen) la evolucion del gasto de tiempo y memoria en funcion del tamaño de los valores de entrada.  el analisis y estudio de los algoritmos es una disciplina de las ciencias de la computacion y, en la mayoria de los casos, su estudio es completamente abstracto sin usar ningun tipo de lenguaje de programacion ni cualquier otra implementacion; por eso, en ese sentido, comparte las caracteristicas de las disciplinas matematicas. asi, el analisis de los algoritmos se centra en los principios basicos del algoritmo, no en los de la implementacion particular. una forma de plasmar (o algunas veces \"codificar\") un algoritmo es escribirlo en pseudocodigo o utilizar un lenguaje muy simple tal como lexico, cuyos codigos pueden estar en el idioma del programador.  algunos escritores restringen la definicion de algoritmo a procedimientos que deben acabar en algun momento, mientras que otros consideran procedimientos que podrian ejecutarse eternamente sin pararse, suponiendo el caso en el que existiera algun dispositivo fisico que fuera capaz de funcionar eternamente. en este ultimo caso, la finalizacion con exito del algoritmo no se podria definir como la terminacion de este con una salida satisfactoria, sino que el exito estaria definido en funcion de las secuencias de salidas dadas durante un periodo de vida de la ejecucion del algoritmo. por ejemplo, un algoritmo que verifica que hay mas ceros que unos en una secuencia binaria infinita debe ejecutarse siempre para que pueda devolver un valor util. si se implementa correctamente, el valor devuelto por el algoritmo sera valido, hasta que evalue el siguiente digito binario. de esta forma, mientras evalua la siguiente secuencia podran leerse dos tipos de señales: una señal positiva (en el caso de que el numero de ceros sea mayor que el de unos) y una negativa en caso contrario. finalmente, la salida de este algoritmo se define como la devolucion de valores exclusivamente positivos si hay mas ceros que unos en la secuencia y, en cualquier otro caso, devolvera una mezcla de señales positivas y negativas.  el problema consiste en encontrar el maximo de un conjunto de numeros. para un ejemplo mas complejo vease algoritmo de euclides.  dado un conjunto finito c de numeros, se tiene el problema de encontrar el numero mas grande. sin perdida de generalidad se puede asumir que dicho conjunto no es vacio y que sus elementos estan numerados como c 0 , c 1 , … , c n ,c_{1},\\dots ,c_{n}} .  es decir, dado un conjunto c = { c 0 , c 1 , … , c n } ,c_{1},\\dots ,c_{n}\\}} se pide encontrar m tal que x ≤ m para todo elemento x que pertenece al conjunto c .  para encontrar el elemento maximo, se asume que el primer elemento ( c 0 } ) es el maximo; luego, se recorre el conjunto y se compara cada valor con el valor del maximo numero encontrado hasta ese momento. en el caso de que un elemento sea mayor que el maximo, se asigna su valor al maximo. cuando se termina de recorrer la lista, el maximo numero que se ha encontrado es el maximo de todo el conjunto.  el algoritmo puede ser escrito de una manera mas formal en el siguiente pseudocodigo:  funcion max( c )  sobre la notacion:  en lenguaje c++: ",
        "snippet": "En matemáticas, lógica, ciencias de la computación y disciplinas relacionadas, un algoritmo (probablemente del latín tardío algorithmus, y este del árabe clásico ḥisābu lḡubār, que significa «cálculo mediante cifras arábigas»)[1]​ es un conjunto de instrucciones o reglas definidas y no-ambiguas, ordenadas y finitas que permite, típicamente, solucionar un problema, realizar un cómputo, procesar datos y llevar a cabo otras tareas o actividades.[1]​ Dado un estado inicial y una entrada, siguiendo los pasos sucesivos se llega a un estado final y se obtiene una solución. Los algoritmos son el objeto de estudio de la algoritmia.[2]​",
        "enlaces_salientes": [
            "/wiki/Algoritmo",
            "/wiki/Algoritmo",
            "/wiki/Algoritmo",
            "/wiki/Logaritmo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Ada_Lovelace",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Lat%C3%ADn_tard%C3%ADo",
            "/wiki/%C3%81rabe_cl%C3%A1sico",
            "/wiki/Empleador",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/C%C3%A1lculo",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/C%C3%A1lculo",
            "/wiki/Problema_abstracto",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Alonzo_Church",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Alan_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Grafo",
            "/wiki/Estructura_de_datos",
            "/wiki/Algoritmo_paralelo",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Lenguaje_natural",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Diagramas_de_flujo",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Teorema",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Organizaci%C3%B3n_Internacional_para_la_Estandarizaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Lenguaje_m%C3%A1quina",
            "/wiki/Programa_(computaci%C3%B3n)",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Formas_de_resolver_la_ra%C3%ADz_cuadrada",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Camino_hamiltoniano",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Problema_abstracto",
            "/wiki/Bit",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Sistema_binario",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Bucle_infinito",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Dominio_de_definici%C3%B3n",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Problema_de_la_parada",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Ciencias_de_la_computacion",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Lexico",
            "/wiki/C%C3%B3digo_binario",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Conjunto",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/C%2B%2B",
            "/wiki/Algoritmo_de_ordenamiento",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Algoritmo_voraz",
            "/wiki/Algoritmos_paralelos",
            "/wiki/Algoritmo_probabil%C3%ADstico",
            "/wiki/Algoritmo_determin%C3%ADstico",
            "/wiki/Algoritmo_no_determin%C3%ADstico",
            "/wiki/Divide_y_vencer%C3%A1s",
            "/wiki/Metaheur%C3%ADsticas",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica_(computaci%C3%B3n)",
            "/wiki/Ramificaci%C3%B3n_y_acotaci%C3%B3n",
            "/wiki/Vuelta_atr%C3%A1s",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/Complejidad_computacional",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_Nassi-Shneiderman",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Ciencias_de_la_Computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Complejidad_computacional",
            "/wiki/Gobierno_por_algoritmos",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Inteligencia_artificial",
            "/wiki/Investigaci%C3%B3n_operativa",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Programaci%C3%B3n",
            "/wiki/ISBN",
            "/wiki/Thomas_H._Cormen",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISBN",
            "/wiki/Rivest,_R._L.",
            "/wiki/Gilles_Brassard",
            "/wiki/Knuth,_D._E",
            "/wiki/TeX",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/George_Boolos",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Alonzo_Church",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/Alonzo_Church",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/G%C3%B6del",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/Emil_Post",
            "/wiki/ISBN",
            "/wiki/Gottfried_Leibniz",
            "/wiki/George_Boole",
            "/wiki/Gottlob_Frege",
            "/wiki/Georg_Cantor",
            "/wiki/David_Hilbert",
            "/wiki/John_von_Neumann",
            "/wiki/Joseph-Marie_Jacquard",
            "/wiki/Babbage",
            "/wiki/Ada_Lovelace",
            "/wiki/Claude_Shannon",
            "/wiki/Howard_Aiken",
            "/wiki/Digital_object_identifier",
            "/wiki/Bibcode",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Andrew_Hodges",
            "/wiki/Simon_and_Schuster",
            "/wiki/Bibcode",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Stephen_Kleene",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Stephen_Kleene",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Donald_Knuth",
            "/wiki/ISBN",
            "/wiki/Donald_Knuth",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/A.A._Markov",
            "/wiki/Marvin_Minsky",
            "/wiki/ISBN",
            "/wiki/Emil_Post",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/United_States_Patent_and_Trademark_Office",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Medical_Subject_Headings",
            "/wiki/Descriptores_en_Ciencias_de_la_Salud"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo",
        "titulo": "Algoritmo",
        "contenido": "en matematicas, logica, ciencias de la computacion y disciplinas relacionadas, un algoritmo (probablemente del latin tardio algorithmus, y este del arabe clasico hisabu lgubar, que significa «calculo mediante cifras arabigas»)​ es un conjunto de instrucciones o reglas definidas y no-ambiguas, ordenadas y finitas que permite, tipicamente, solucionar un problema, realizar un computo, procesar datos y llevar a cabo otras tareas o actividades.​ dado un estado inicial y una entrada, siguiendo los pasos sucesivos se llega a un estado final y se obtiene una solucion. los algoritmos son el objeto de estudio de la algoritmia.​  en la vida cotidiana, se emplean algoritmos frecuentemente para resolver problemas determinados. algunos ejemplos son los manuales de usuario, que muestran algoritmos para usar un aparato, o las instrucciones que recibe un trabajador de su patron. algunos ejemplos en matematica son el algoritmo de multiplicacion, para calcular el producto, el algoritmo de la division para calcular el cociente de dos numeros, el algoritmo de euclides para obtener el maximo comun divisor de dos enteros positivos, o el metodo de gauss para resolver un sistema de ecuaciones lineales.  en terminos de programacion, un algoritmo es una secuencia de pasos logicos que permiten solucionar un problema.  en general, no existe ningun consenso definitivo en cuanto a la definicion formal de algoritmo. muchos autores los señalan como listas de instrucciones para resolver un calculo o un problema abstracto, es decir, que un numero finito de pasos convierten los datos de un problema (entrada) en una solucion (salida).​​​​​​ sin embargo, cabe notar que algunos algoritmos no tienen necesariamente que terminar o resolver un problema en particular. por ejemplo, una version modificada de la criba de eratostenes, que nunca termine de calcular numeros primos, no deja de ser un algoritmo.​  a lo largo de la historia, varios autores han tratado de definir formalmente los algoritmos utilizando modelos matematicos. esto lo hizo alonzo church en 1936 con el concepto de \"calculabilidad efectiva\" basada en su calculo lambda y por alan turing basandose en la maquina de turing. los dos enfoques son equivalentes, en el sentido de que se pueden resolver exactamente los mismos problemas con ambos enfoques.​​ no obstante, estos modelos estan sujetos a un tipo particular de datos, como son numeros, simbolos o graficas mientras que, en general, los algoritmos funcionan sobre una vasta cantidad de estructuras de datos.​​ en general, la parte comun en todas las definiciones se puede resumir en las siguientes tres propiedades, siempre y cuando no consideremos algoritmos paralelos:​  en resumen, un algoritmo es cualquier cosa que funcione paso a paso, donde cada paso se pueda describir sin ambiguedad y sin hacer referencia a una computadora en particular, y ademas tiene un limite fijo en cuanto a la cantidad de datos que se pueden leer/escribir en un solo paso.  esta amplia definicion abarca tanto a algoritmos practicos como aquellos que solo funcionan en teoria, por ejemplo, el metodo de newton y la eliminacion de gauss-jordan funcionan, al menos en principio, con numeros de precision infinita; sin embargo, no es posible programar la precision infinita en una computadora, y no por ello dejan de ser algoritmos.​ en particular es posible considerar una cuarta propiedad que puede usarse para validar la tesis de church-turing, de que toda funcion calculable se puede programar en una maquina de turing (o equivalentemente, en un lenguaje de programacion suficientemente general):​  los algoritmos pueden ser expresados de muchas maneras, incluyendo al lenguaje natural, pseudocodigo, diagramas de flujo y lenguajes de programacion entre otros. las descripciones en lenguaje natural tienden a ser ambiguas y extensas. el usar pseudocodigo y diagramas de flujo evita muchas ambiguedades del lenguaje natural. dichas expresiones son formas mas estructuradas para representar algoritmos; no obstante, se mantienen independientes de un lenguaje de programacion especifico.  la descripcion de un algoritmo suele hacerse en tres niveles:  tambien es posible incluir un teorema que demuestre que el algoritmo es correcto, un analisis de complejidad o ambos.  los diagramas de flujo son descripciones graficas de algoritmos; usan simbolos conectados con flechas para indicar la secuencia de instrucciones y estan regidos por iso.  los diagramas de flujo se emplean para representar algoritmos pequeños, ya que abarcan mucho espacio y su construccion es laboriosa. por su facilidad de lectura se utilizan como introduccion a los algoritmos, descripcion de un lenguaje y descripcion de procesos a personas ajenas a la computacion.  el pseudocodigo (falso lenguaje, el prefijo pseudo significa falso) es una descripcion de alto nivel de un algoritmo que emplea una mezcla de lenguaje natural con algunas convenciones sintacticas propias de lenguajes de programacion, como asignaciones, ciclos y condicionales, aunque no esta regido por ningun estandar.  el pseudocodigo esta pensado para facilitar a las personas el entendimiento de un algoritmo y, por lo tanto, puede omitir detalles irrelevantes que son necesarios en una implementacion. programadores diferentes suelen utilizar convenciones distintas, que pueden estar basadas en la sintaxis de lenguajes de programacion concretos. sin embargo, el pseudocodigo, en general, es comprensible sin necesidad de conocer o usar un entorno de programacion especifico, y es a la vez suficientemente estructurado para que su implementacion se pueda hacer directamente a partir de el.  asi, el pseudocodigo cumple con las funciones antes mencionadas para representar algo abstracto, los protocolos son los lenguajes para la programacion. busque fuentes mas precisas para tener mayor comprension del tema.  la teoria de automatas y la teoria de funciones recursivas proveen modelos matematicos que formalizan el concepto de algoritmo. los modelos mas comunes son la maquina de turing, maquina de registro y funciones μ-recursivas. estos modelos son tan precisos como un lenguaje maquina, careciendo de expresiones coloquiales o ambiguedad; sin embargo, se mantienen independientes de cualquier computadora y de cualquier implementacion.  muchos algoritmos se han ideado para implementarse en un programa. no obstante, los algoritmos pueden ser implementados en otros medios, como una red neuronal, un circuito electrico o un aparato mecanico y electrico. algunos algoritmos incluso se diseñan especialmente para implementarse usando lapiz y papel. el algoritmo de multiplicacion tradicional, el algoritmo de euclides, la criba de eratostenes y muchas formas de resolver la raiz cuadrada son solo algunos ejemplos.  son elementos que toman valores especificos de un tipo de datos concreto. la declaracion de una variable puede realizarse comenzando con var. principalmente, existen dos maneras de otorgar valores iniciales a variables:  ejemplo:  la estructura secuencial es aquella en la que una accion sigue a otra en secuencia. las operaciones se suceden de tal modo que la salida de una es la entrada de la siguiente y asi sucesivamente hasta el fin del proceso. la asignacion de esto consiste en el paso de valores o resultados a una zona de la memoria. dicha zona sera reconocida con el nombre de la variable que recibe el valor. la asignacion se puede clasificar de la siguiente forma:  un ejemplo de estructura secuencial, como obtener el area de un triangulo:  un algoritmo se puede concebir como una funcion que transforma los datos de un problema (entrada) en los datos de una solucion (salida). mas aun, los datos se pueden representar a su vez como secuencias de bits, y en general, de simbolos cualesquiera.​​​ como cada secuencia de bits representa a un numero natural (vease sistema binario), entonces los algoritmos son en esencia funciones de los numeros naturales en los numeros naturales que si se pueden calcular. es decir que todo algoritmo calcula una funcion f : n → n \\to \\mathbb {n} } donde cada numero natural es la codificacion de un problema o de una solucion.  en ocasiones los algoritmos son susceptibles de nunca terminar, por ejemplo, cuando entran a un bucle infinito. cuando esto ocurre, el algoritmo nunca devuelve ningun valor de salida, y podemos decir que la funcion queda indefinida para ese valor de entrada. por esta razon se considera que los algoritmos son funciones parciales, es decir, no necesariamente definidas en todo su dominio de definicion.  cuando una funcion puede ser calculada por medios algoritmicos, sin importar la cantidad de memoria que ocupe o el tiempo que se tarde, se dice que dicha funcion es computable. no todas las funciones entre secuencias datos son computables. el problema de la parada es un ejemplo.  como medida de la eficiencia de un algoritmo, se suelen estudiar los recursos (memoria y tiempo) que consume el algoritmo. el analisis de algoritmos se ha desarrollado para obtener valores que de alguna forma indiquen (o especifiquen) la evolucion del gasto de tiempo y memoria en funcion del tamaño de los valores de entrada.  el analisis y estudio de los algoritmos es una disciplina de las ciencias de la computacion y, en la mayoria de los casos, su estudio es completamente abstracto sin usar ningun tipo de lenguaje de programacion ni cualquier otra implementacion; por eso, en ese sentido, comparte las caracteristicas de las disciplinas matematicas. asi, el analisis de los algoritmos se centra en los principios basicos del algoritmo, no en los de la implementacion particular. una forma de plasmar (o algunas veces \"codificar\") un algoritmo es escribirlo en pseudocodigo o utilizar un lenguaje muy simple tal como lexico, cuyos codigos pueden estar en el idioma del programador.  algunos escritores restringen la definicion de algoritmo a procedimientos que deben acabar en algun momento, mientras que otros consideran procedimientos que podrian ejecutarse eternamente sin pararse, suponiendo el caso en el que existiera algun dispositivo fisico que fuera capaz de funcionar eternamente. en este ultimo caso, la finalizacion con exito del algoritmo no se podria definir como la terminacion de este con una salida satisfactoria, sino que el exito estaria definido en funcion de las secuencias de salidas dadas durante un periodo de vida de la ejecucion del algoritmo. por ejemplo, un algoritmo que verifica que hay mas ceros que unos en una secuencia binaria infinita debe ejecutarse siempre para que pueda devolver un valor util. si se implementa correctamente, el valor devuelto por el algoritmo sera valido, hasta que evalue el siguiente digito binario. de esta forma, mientras evalua la siguiente secuencia podran leerse dos tipos de señales: una señal positiva (en el caso de que el numero de ceros sea mayor que el de unos) y una negativa en caso contrario. finalmente, la salida de este algoritmo se define como la devolucion de valores exclusivamente positivos si hay mas ceros que unos en la secuencia y, en cualquier otro caso, devolvera una mezcla de señales positivas y negativas.  el problema consiste en encontrar el maximo de un conjunto de numeros. para un ejemplo mas complejo vease algoritmo de euclides.  dado un conjunto finito c de numeros, se tiene el problema de encontrar el numero mas grande. sin perdida de generalidad se puede asumir que dicho conjunto no es vacio y que sus elementos estan numerados como c 0 , c 1 , … , c n ,c_{1},\\dots ,c_{n}} .  es decir, dado un conjunto c = { c 0 , c 1 , … , c n } ,c_{1},\\dots ,c_{n}\\}} se pide encontrar m tal que x ≤ m para todo elemento x que pertenece al conjunto c .  para encontrar el elemento maximo, se asume que el primer elemento ( c 0 } ) es el maximo; luego, se recorre el conjunto y se compara cada valor con el valor del maximo numero encontrado hasta ese momento. en el caso de que un elemento sea mayor que el maximo, se asigna su valor al maximo. cuando se termina de recorrer la lista, el maximo numero que se ha encontrado es el maximo de todo el conjunto.  el algoritmo puede ser escrito de una manera mas formal en el siguiente pseudocodigo:  funcion max( c )  sobre la notacion:  en lenguaje c++: ",
        "snippet": "En matemáticas, lógica, ciencias de la computación y disciplinas relacionadas, un algoritmo (probablemente del latín tardío algorithmus, y este del árabe clásico ḥisābu lḡubār, que significa «cálculo mediante cifras arábigas»)[1]​ es un conjunto de instrucciones o reglas definidas y no-ambiguas, ordenadas y finitas que permite, típicamente, solucionar un problema, realizar un cómputo, procesar datos y llevar a cabo otras tareas o actividades.[1]​ Dado un estado inicial y una entrada, siguiendo los pasos sucesivos se llega a un estado final y se obtiene una solución. Los algoritmos son el objeto de estudio de la algoritmia.[2]​",
        "enlaces_salientes": [
            "/wiki/Algoritmo",
            "/wiki/Algoritmo",
            "/wiki/Algoritmo",
            "/wiki/Logaritmo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Ada_Lovelace",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Lat%C3%ADn_tard%C3%ADo",
            "/wiki/%C3%81rabe_cl%C3%A1sico",
            "/wiki/Empleador",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/C%C3%A1lculo",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/C%C3%A1lculo",
            "/wiki/Problema_abstracto",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Alonzo_Church",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Alan_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Grafo",
            "/wiki/Estructura_de_datos",
            "/wiki/Algoritmo_paralelo",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Lenguaje_natural",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Diagramas_de_flujo",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Teorema",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Organizaci%C3%B3n_Internacional_para_la_Estandarizaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Lenguaje_m%C3%A1quina",
            "/wiki/Programa_(computaci%C3%B3n)",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Formas_de_resolver_la_ra%C3%ADz_cuadrada",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Camino_hamiltoniano",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Problema_abstracto",
            "/wiki/Bit",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Sistema_binario",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Bucle_infinito",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Dominio_de_definici%C3%B3n",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Problema_de_la_parada",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Ciencias_de_la_computacion",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Lexico",
            "/wiki/C%C3%B3digo_binario",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Conjunto",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/C%2B%2B",
            "/wiki/Algoritmo_de_ordenamiento",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Algoritmo_voraz",
            "/wiki/Algoritmos_paralelos",
            "/wiki/Algoritmo_probabil%C3%ADstico",
            "/wiki/Algoritmo_determin%C3%ADstico",
            "/wiki/Algoritmo_no_determin%C3%ADstico",
            "/wiki/Divide_y_vencer%C3%A1s",
            "/wiki/Metaheur%C3%ADsticas",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica_(computaci%C3%B3n)",
            "/wiki/Ramificaci%C3%B3n_y_acotaci%C3%B3n",
            "/wiki/Vuelta_atr%C3%A1s",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/Complejidad_computacional",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_Nassi-Shneiderman",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Ciencias_de_la_Computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Complejidad_computacional",
            "/wiki/Gobierno_por_algoritmos",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Inteligencia_artificial",
            "/wiki/Investigaci%C3%B3n_operativa",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Programaci%C3%B3n",
            "/wiki/ISBN",
            "/wiki/Thomas_H._Cormen",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISBN",
            "/wiki/Rivest,_R._L.",
            "/wiki/Gilles_Brassard",
            "/wiki/Knuth,_D._E",
            "/wiki/TeX",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/George_Boolos",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Alonzo_Church",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/Alonzo_Church",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/G%C3%B6del",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/Emil_Post",
            "/wiki/ISBN",
            "/wiki/Gottfried_Leibniz",
            "/wiki/George_Boole",
            "/wiki/Gottlob_Frege",
            "/wiki/Georg_Cantor",
            "/wiki/David_Hilbert",
            "/wiki/John_von_Neumann",
            "/wiki/Joseph-Marie_Jacquard",
            "/wiki/Babbage",
            "/wiki/Ada_Lovelace",
            "/wiki/Claude_Shannon",
            "/wiki/Howard_Aiken",
            "/wiki/Digital_object_identifier",
            "/wiki/Bibcode",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Andrew_Hodges",
            "/wiki/Simon_and_Schuster",
            "/wiki/Bibcode",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Stephen_Kleene",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Stephen_Kleene",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Donald_Knuth",
            "/wiki/ISBN",
            "/wiki/Donald_Knuth",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/A.A._Markov",
            "/wiki/Marvin_Minsky",
            "/wiki/ISBN",
            "/wiki/Emil_Post",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/United_States_Patent_and_Trademark_Office",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Medical_Subject_Headings",
            "/wiki/Descriptores_en_Ciencias_de_la_Salud"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo",
        "titulo": "Algoritmo",
        "contenido": "en matematicas, logica, ciencias de la computacion y disciplinas relacionadas, un algoritmo (probablemente del latin tardio algorithmus, y este del arabe clasico hisabu lgubar, que significa «calculo mediante cifras arabigas»)​ es un conjunto de instrucciones o reglas definidas y no-ambiguas, ordenadas y finitas que permite, tipicamente, solucionar un problema, realizar un computo, procesar datos y llevar a cabo otras tareas o actividades.​ dado un estado inicial y una entrada, siguiendo los pasos sucesivos se llega a un estado final y se obtiene una solucion. los algoritmos son el objeto de estudio de la algoritmia.​  en la vida cotidiana, se emplean algoritmos frecuentemente para resolver problemas determinados. algunos ejemplos son los manuales de usuario, que muestran algoritmos para usar un aparato, o las instrucciones que recibe un trabajador de su patron. algunos ejemplos en matematica son el algoritmo de multiplicacion, para calcular el producto, el algoritmo de la division para calcular el cociente de dos numeros, el algoritmo de euclides para obtener el maximo comun divisor de dos enteros positivos, o el metodo de gauss para resolver un sistema de ecuaciones lineales.  en terminos de programacion, un algoritmo es una secuencia de pasos logicos que permiten solucionar un problema.  en general, no existe ningun consenso definitivo en cuanto a la definicion formal de algoritmo. muchos autores los señalan como listas de instrucciones para resolver un calculo o un problema abstracto, es decir, que un numero finito de pasos convierten los datos de un problema (entrada) en una solucion (salida).​​​​​​ sin embargo, cabe notar que algunos algoritmos no tienen necesariamente que terminar o resolver un problema en particular. por ejemplo, una version modificada de la criba de eratostenes, que nunca termine de calcular numeros primos, no deja de ser un algoritmo.​  a lo largo de la historia, varios autores han tratado de definir formalmente los algoritmos utilizando modelos matematicos. esto lo hizo alonzo church en 1936 con el concepto de \"calculabilidad efectiva\" basada en su calculo lambda y por alan turing basandose en la maquina de turing. los dos enfoques son equivalentes, en el sentido de que se pueden resolver exactamente los mismos problemas con ambos enfoques.​​ no obstante, estos modelos estan sujetos a un tipo particular de datos, como son numeros, simbolos o graficas mientras que, en general, los algoritmos funcionan sobre una vasta cantidad de estructuras de datos.​​ en general, la parte comun en todas las definiciones se puede resumir en las siguientes tres propiedades, siempre y cuando no consideremos algoritmos paralelos:​  en resumen, un algoritmo es cualquier cosa que funcione paso a paso, donde cada paso se pueda describir sin ambiguedad y sin hacer referencia a una computadora en particular, y ademas tiene un limite fijo en cuanto a la cantidad de datos que se pueden leer/escribir en un solo paso.  esta amplia definicion abarca tanto a algoritmos practicos como aquellos que solo funcionan en teoria, por ejemplo, el metodo de newton y la eliminacion de gauss-jordan funcionan, al menos en principio, con numeros de precision infinita; sin embargo, no es posible programar la precision infinita en una computadora, y no por ello dejan de ser algoritmos.​ en particular es posible considerar una cuarta propiedad que puede usarse para validar la tesis de church-turing, de que toda funcion calculable se puede programar en una maquina de turing (o equivalentemente, en un lenguaje de programacion suficientemente general):​  los algoritmos pueden ser expresados de muchas maneras, incluyendo al lenguaje natural, pseudocodigo, diagramas de flujo y lenguajes de programacion entre otros. las descripciones en lenguaje natural tienden a ser ambiguas y extensas. el usar pseudocodigo y diagramas de flujo evita muchas ambiguedades del lenguaje natural. dichas expresiones son formas mas estructuradas para representar algoritmos; no obstante, se mantienen independientes de un lenguaje de programacion especifico.  la descripcion de un algoritmo suele hacerse en tres niveles:  tambien es posible incluir un teorema que demuestre que el algoritmo es correcto, un analisis de complejidad o ambos.  los diagramas de flujo son descripciones graficas de algoritmos; usan simbolos conectados con flechas para indicar la secuencia de instrucciones y estan regidos por iso.  los diagramas de flujo se emplean para representar algoritmos pequeños, ya que abarcan mucho espacio y su construccion es laboriosa. por su facilidad de lectura se utilizan como introduccion a los algoritmos, descripcion de un lenguaje y descripcion de procesos a personas ajenas a la computacion.  el pseudocodigo (falso lenguaje, el prefijo pseudo significa falso) es una descripcion de alto nivel de un algoritmo que emplea una mezcla de lenguaje natural con algunas convenciones sintacticas propias de lenguajes de programacion, como asignaciones, ciclos y condicionales, aunque no esta regido por ningun estandar.  el pseudocodigo esta pensado para facilitar a las personas el entendimiento de un algoritmo y, por lo tanto, puede omitir detalles irrelevantes que son necesarios en una implementacion. programadores diferentes suelen utilizar convenciones distintas, que pueden estar basadas en la sintaxis de lenguajes de programacion concretos. sin embargo, el pseudocodigo, en general, es comprensible sin necesidad de conocer o usar un entorno de programacion especifico, y es a la vez suficientemente estructurado para que su implementacion se pueda hacer directamente a partir de el.  asi, el pseudocodigo cumple con las funciones antes mencionadas para representar algo abstracto, los protocolos son los lenguajes para la programacion. busque fuentes mas precisas para tener mayor comprension del tema.  la teoria de automatas y la teoria de funciones recursivas proveen modelos matematicos que formalizan el concepto de algoritmo. los modelos mas comunes son la maquina de turing, maquina de registro y funciones μ-recursivas. estos modelos son tan precisos como un lenguaje maquina, careciendo de expresiones coloquiales o ambiguedad; sin embargo, se mantienen independientes de cualquier computadora y de cualquier implementacion.  muchos algoritmos se han ideado para implementarse en un programa. no obstante, los algoritmos pueden ser implementados en otros medios, como una red neuronal, un circuito electrico o un aparato mecanico y electrico. algunos algoritmos incluso se diseñan especialmente para implementarse usando lapiz y papel. el algoritmo de multiplicacion tradicional, el algoritmo de euclides, la criba de eratostenes y muchas formas de resolver la raiz cuadrada son solo algunos ejemplos.  son elementos que toman valores especificos de un tipo de datos concreto. la declaracion de una variable puede realizarse comenzando con var. principalmente, existen dos maneras de otorgar valores iniciales a variables:  ejemplo:  la estructura secuencial es aquella en la que una accion sigue a otra en secuencia. las operaciones se suceden de tal modo que la salida de una es la entrada de la siguiente y asi sucesivamente hasta el fin del proceso. la asignacion de esto consiste en el paso de valores o resultados a una zona de la memoria. dicha zona sera reconocida con el nombre de la variable que recibe el valor. la asignacion se puede clasificar de la siguiente forma:  un ejemplo de estructura secuencial, como obtener el area de un triangulo:  un algoritmo se puede concebir como una funcion que transforma los datos de un problema (entrada) en los datos de una solucion (salida). mas aun, los datos se pueden representar a su vez como secuencias de bits, y en general, de simbolos cualesquiera.​​​ como cada secuencia de bits representa a un numero natural (vease sistema binario), entonces los algoritmos son en esencia funciones de los numeros naturales en los numeros naturales que si se pueden calcular. es decir que todo algoritmo calcula una funcion f : n → n \\to \\mathbb {n} } donde cada numero natural es la codificacion de un problema o de una solucion.  en ocasiones los algoritmos son susceptibles de nunca terminar, por ejemplo, cuando entran a un bucle infinito. cuando esto ocurre, el algoritmo nunca devuelve ningun valor de salida, y podemos decir que la funcion queda indefinida para ese valor de entrada. por esta razon se considera que los algoritmos son funciones parciales, es decir, no necesariamente definidas en todo su dominio de definicion.  cuando una funcion puede ser calculada por medios algoritmicos, sin importar la cantidad de memoria que ocupe o el tiempo que se tarde, se dice que dicha funcion es computable. no todas las funciones entre secuencias datos son computables. el problema de la parada es un ejemplo.  como medida de la eficiencia de un algoritmo, se suelen estudiar los recursos (memoria y tiempo) que consume el algoritmo. el analisis de algoritmos se ha desarrollado para obtener valores que de alguna forma indiquen (o especifiquen) la evolucion del gasto de tiempo y memoria en funcion del tamaño de los valores de entrada.  el analisis y estudio de los algoritmos es una disciplina de las ciencias de la computacion y, en la mayoria de los casos, su estudio es completamente abstracto sin usar ningun tipo de lenguaje de programacion ni cualquier otra implementacion; por eso, en ese sentido, comparte las caracteristicas de las disciplinas matematicas. asi, el analisis de los algoritmos se centra en los principios basicos del algoritmo, no en los de la implementacion particular. una forma de plasmar (o algunas veces \"codificar\") un algoritmo es escribirlo en pseudocodigo o utilizar un lenguaje muy simple tal como lexico, cuyos codigos pueden estar en el idioma del programador.  algunos escritores restringen la definicion de algoritmo a procedimientos que deben acabar en algun momento, mientras que otros consideran procedimientos que podrian ejecutarse eternamente sin pararse, suponiendo el caso en el que existiera algun dispositivo fisico que fuera capaz de funcionar eternamente. en este ultimo caso, la finalizacion con exito del algoritmo no se podria definir como la terminacion de este con una salida satisfactoria, sino que el exito estaria definido en funcion de las secuencias de salidas dadas durante un periodo de vida de la ejecucion del algoritmo. por ejemplo, un algoritmo que verifica que hay mas ceros que unos en una secuencia binaria infinita debe ejecutarse siempre para que pueda devolver un valor util. si se implementa correctamente, el valor devuelto por el algoritmo sera valido, hasta que evalue el siguiente digito binario. de esta forma, mientras evalua la siguiente secuencia podran leerse dos tipos de señales: una señal positiva (en el caso de que el numero de ceros sea mayor que el de unos) y una negativa en caso contrario. finalmente, la salida de este algoritmo se define como la devolucion de valores exclusivamente positivos si hay mas ceros que unos en la secuencia y, en cualquier otro caso, devolvera una mezcla de señales positivas y negativas.  el problema consiste en encontrar el maximo de un conjunto de numeros. para un ejemplo mas complejo vease algoritmo de euclides.  dado un conjunto finito c de numeros, se tiene el problema de encontrar el numero mas grande. sin perdida de generalidad se puede asumir que dicho conjunto no es vacio y que sus elementos estan numerados como c 0 , c 1 , … , c n ,c_{1},\\dots ,c_{n}} .  es decir, dado un conjunto c = { c 0 , c 1 , … , c n } ,c_{1},\\dots ,c_{n}\\}} se pide encontrar m tal que x ≤ m para todo elemento x que pertenece al conjunto c .  para encontrar el elemento maximo, se asume que el primer elemento ( c 0 } ) es el maximo; luego, se recorre el conjunto y se compara cada valor con el valor del maximo numero encontrado hasta ese momento. en el caso de que un elemento sea mayor que el maximo, se asigna su valor al maximo. cuando se termina de recorrer la lista, el maximo numero que se ha encontrado es el maximo de todo el conjunto.  el algoritmo puede ser escrito de una manera mas formal en el siguiente pseudocodigo:  funcion max( c )  sobre la notacion:  en lenguaje c++: ",
        "snippet": "En matemáticas, lógica, ciencias de la computación y disciplinas relacionadas, un algoritmo (probablemente del latín tardío algorithmus, y este del árabe clásico ḥisābu lḡubār, que significa «cálculo mediante cifras arábigas»)[1]​ es un conjunto de instrucciones o reglas definidas y no-ambiguas, ordenadas y finitas que permite, típicamente, solucionar un problema, realizar un cómputo, procesar datos y llevar a cabo otras tareas o actividades.[1]​ Dado un estado inicial y una entrada, siguiendo los pasos sucesivos se llega a un estado final y se obtiene una solución. Los algoritmos son el objeto de estudio de la algoritmia.[2]​",
        "enlaces_salientes": [
            "/wiki/Algoritmo",
            "/wiki/Algoritmo",
            "/wiki/Algoritmo",
            "/wiki/Logaritmo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Ada_Lovelace",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Lat%C3%ADn_tard%C3%ADo",
            "/wiki/%C3%81rabe_cl%C3%A1sico",
            "/wiki/Empleador",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/C%C3%A1lculo",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/C%C3%A1lculo",
            "/wiki/Problema_abstracto",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Alonzo_Church",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Alan_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Grafo",
            "/wiki/Estructura_de_datos",
            "/wiki/Algoritmo_paralelo",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Lenguaje_natural",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Diagramas_de_flujo",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Teorema",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Organizaci%C3%B3n_Internacional_para_la_Estandarizaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Lenguaje_m%C3%A1quina",
            "/wiki/Programa_(computaci%C3%B3n)",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Formas_de_resolver_la_ra%C3%ADz_cuadrada",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Camino_hamiltoniano",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Problema_abstracto",
            "/wiki/Bit",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Sistema_binario",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Bucle_infinito",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Dominio_de_definici%C3%B3n",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Problema_de_la_parada",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Ciencias_de_la_computacion",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Lexico",
            "/wiki/C%C3%B3digo_binario",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Conjunto",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/C%2B%2B",
            "/wiki/Algoritmo_de_ordenamiento",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Algoritmo_voraz",
            "/wiki/Algoritmos_paralelos",
            "/wiki/Algoritmo_probabil%C3%ADstico",
            "/wiki/Algoritmo_determin%C3%ADstico",
            "/wiki/Algoritmo_no_determin%C3%ADstico",
            "/wiki/Divide_y_vencer%C3%A1s",
            "/wiki/Metaheur%C3%ADsticas",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica_(computaci%C3%B3n)",
            "/wiki/Ramificaci%C3%B3n_y_acotaci%C3%B3n",
            "/wiki/Vuelta_atr%C3%A1s",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/Complejidad_computacional",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_Nassi-Shneiderman",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Ciencias_de_la_Computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Complejidad_computacional",
            "/wiki/Gobierno_por_algoritmos",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Inteligencia_artificial",
            "/wiki/Investigaci%C3%B3n_operativa",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Programaci%C3%B3n",
            "/wiki/ISBN",
            "/wiki/Thomas_H._Cormen",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISBN",
            "/wiki/Rivest,_R._L.",
            "/wiki/Gilles_Brassard",
            "/wiki/Knuth,_D._E",
            "/wiki/TeX",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/George_Boolos",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Alonzo_Church",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/Alonzo_Church",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/G%C3%B6del",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/Emil_Post",
            "/wiki/ISBN",
            "/wiki/Gottfried_Leibniz",
            "/wiki/George_Boole",
            "/wiki/Gottlob_Frege",
            "/wiki/Georg_Cantor",
            "/wiki/David_Hilbert",
            "/wiki/John_von_Neumann",
            "/wiki/Joseph-Marie_Jacquard",
            "/wiki/Babbage",
            "/wiki/Ada_Lovelace",
            "/wiki/Claude_Shannon",
            "/wiki/Howard_Aiken",
            "/wiki/Digital_object_identifier",
            "/wiki/Bibcode",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Andrew_Hodges",
            "/wiki/Simon_and_Schuster",
            "/wiki/Bibcode",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Stephen_Kleene",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Stephen_Kleene",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Donald_Knuth",
            "/wiki/ISBN",
            "/wiki/Donald_Knuth",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/A.A._Markov",
            "/wiki/Marvin_Minsky",
            "/wiki/ISBN",
            "/wiki/Emil_Post",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/United_States_Patent_and_Trademark_Office",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Medical_Subject_Headings",
            "/wiki/Descriptores_en_Ciencias_de_la_Salud"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo",
        "titulo": "Algoritmo",
        "contenido": "en matematicas, logica, ciencias de la computacion y disciplinas relacionadas, un algoritmo (probablemente del latin tardio algorithmus, y este del arabe clasico hisabu lgubar, que significa «calculo mediante cifras arabigas»)​ es un conjunto de instrucciones o reglas definidas y no-ambiguas, ordenadas y finitas que permite, tipicamente, solucionar un problema, realizar un computo, procesar datos y llevar a cabo otras tareas o actividades.​ dado un estado inicial y una entrada, siguiendo los pasos sucesivos se llega a un estado final y se obtiene una solucion. los algoritmos son el objeto de estudio de la algoritmia.​  en la vida cotidiana, se emplean algoritmos frecuentemente para resolver problemas determinados. algunos ejemplos son los manuales de usuario, que muestran algoritmos para usar un aparato, o las instrucciones que recibe un trabajador de su patron. algunos ejemplos en matematica son el algoritmo de multiplicacion, para calcular el producto, el algoritmo de la division para calcular el cociente de dos numeros, el algoritmo de euclides para obtener el maximo comun divisor de dos enteros positivos, o el metodo de gauss para resolver un sistema de ecuaciones lineales.  en terminos de programacion, un algoritmo es una secuencia de pasos logicos que permiten solucionar un problema.  en general, no existe ningun consenso definitivo en cuanto a la definicion formal de algoritmo. muchos autores los señalan como listas de instrucciones para resolver un calculo o un problema abstracto, es decir, que un numero finito de pasos convierten los datos de un problema (entrada) en una solucion (salida).​​​​​​ sin embargo, cabe notar que algunos algoritmos no tienen necesariamente que terminar o resolver un problema en particular. por ejemplo, una version modificada de la criba de eratostenes, que nunca termine de calcular numeros primos, no deja de ser un algoritmo.​  a lo largo de la historia, varios autores han tratado de definir formalmente los algoritmos utilizando modelos matematicos. esto lo hizo alonzo church en 1936 con el concepto de \"calculabilidad efectiva\" basada en su calculo lambda y por alan turing basandose en la maquina de turing. los dos enfoques son equivalentes, en el sentido de que se pueden resolver exactamente los mismos problemas con ambos enfoques.​​ no obstante, estos modelos estan sujetos a un tipo particular de datos, como son numeros, simbolos o graficas mientras que, en general, los algoritmos funcionan sobre una vasta cantidad de estructuras de datos.​​ en general, la parte comun en todas las definiciones se puede resumir en las siguientes tres propiedades, siempre y cuando no consideremos algoritmos paralelos:​  en resumen, un algoritmo es cualquier cosa que funcione paso a paso, donde cada paso se pueda describir sin ambiguedad y sin hacer referencia a una computadora en particular, y ademas tiene un limite fijo en cuanto a la cantidad de datos que se pueden leer/escribir en un solo paso.  esta amplia definicion abarca tanto a algoritmos practicos como aquellos que solo funcionan en teoria, por ejemplo, el metodo de newton y la eliminacion de gauss-jordan funcionan, al menos en principio, con numeros de precision infinita; sin embargo, no es posible programar la precision infinita en una computadora, y no por ello dejan de ser algoritmos.​ en particular es posible considerar una cuarta propiedad que puede usarse para validar la tesis de church-turing, de que toda funcion calculable se puede programar en una maquina de turing (o equivalentemente, en un lenguaje de programacion suficientemente general):​  los algoritmos pueden ser expresados de muchas maneras, incluyendo al lenguaje natural, pseudocodigo, diagramas de flujo y lenguajes de programacion entre otros. las descripciones en lenguaje natural tienden a ser ambiguas y extensas. el usar pseudocodigo y diagramas de flujo evita muchas ambiguedades del lenguaje natural. dichas expresiones son formas mas estructuradas para representar algoritmos; no obstante, se mantienen independientes de un lenguaje de programacion especifico.  la descripcion de un algoritmo suele hacerse en tres niveles:  tambien es posible incluir un teorema que demuestre que el algoritmo es correcto, un analisis de complejidad o ambos.  los diagramas de flujo son descripciones graficas de algoritmos; usan simbolos conectados con flechas para indicar la secuencia de instrucciones y estan regidos por iso.  los diagramas de flujo se emplean para representar algoritmos pequeños, ya que abarcan mucho espacio y su construccion es laboriosa. por su facilidad de lectura se utilizan como introduccion a los algoritmos, descripcion de un lenguaje y descripcion de procesos a personas ajenas a la computacion.  el pseudocodigo (falso lenguaje, el prefijo pseudo significa falso) es una descripcion de alto nivel de un algoritmo que emplea una mezcla de lenguaje natural con algunas convenciones sintacticas propias de lenguajes de programacion, como asignaciones, ciclos y condicionales, aunque no esta regido por ningun estandar.  el pseudocodigo esta pensado para facilitar a las personas el entendimiento de un algoritmo y, por lo tanto, puede omitir detalles irrelevantes que son necesarios en una implementacion. programadores diferentes suelen utilizar convenciones distintas, que pueden estar basadas en la sintaxis de lenguajes de programacion concretos. sin embargo, el pseudocodigo, en general, es comprensible sin necesidad de conocer o usar un entorno de programacion especifico, y es a la vez suficientemente estructurado para que su implementacion se pueda hacer directamente a partir de el.  asi, el pseudocodigo cumple con las funciones antes mencionadas para representar algo abstracto, los protocolos son los lenguajes para la programacion. busque fuentes mas precisas para tener mayor comprension del tema.  la teoria de automatas y la teoria de funciones recursivas proveen modelos matematicos que formalizan el concepto de algoritmo. los modelos mas comunes son la maquina de turing, maquina de registro y funciones μ-recursivas. estos modelos son tan precisos como un lenguaje maquina, careciendo de expresiones coloquiales o ambiguedad; sin embargo, se mantienen independientes de cualquier computadora y de cualquier implementacion.  muchos algoritmos se han ideado para implementarse en un programa. no obstante, los algoritmos pueden ser implementados en otros medios, como una red neuronal, un circuito electrico o un aparato mecanico y electrico. algunos algoritmos incluso se diseñan especialmente para implementarse usando lapiz y papel. el algoritmo de multiplicacion tradicional, el algoritmo de euclides, la criba de eratostenes y muchas formas de resolver la raiz cuadrada son solo algunos ejemplos.  son elementos que toman valores especificos de un tipo de datos concreto. la declaracion de una variable puede realizarse comenzando con var. principalmente, existen dos maneras de otorgar valores iniciales a variables:  ejemplo:  la estructura secuencial es aquella en la que una accion sigue a otra en secuencia. las operaciones se suceden de tal modo que la salida de una es la entrada de la siguiente y asi sucesivamente hasta el fin del proceso. la asignacion de esto consiste en el paso de valores o resultados a una zona de la memoria. dicha zona sera reconocida con el nombre de la variable que recibe el valor. la asignacion se puede clasificar de la siguiente forma:  un ejemplo de estructura secuencial, como obtener el area de un triangulo:  un algoritmo se puede concebir como una funcion que transforma los datos de un problema (entrada) en los datos de una solucion (salida). mas aun, los datos se pueden representar a su vez como secuencias de bits, y en general, de simbolos cualesquiera.​​​ como cada secuencia de bits representa a un numero natural (vease sistema binario), entonces los algoritmos son en esencia funciones de los numeros naturales en los numeros naturales que si se pueden calcular. es decir que todo algoritmo calcula una funcion f : n → n \\to \\mathbb {n} } donde cada numero natural es la codificacion de un problema o de una solucion.  en ocasiones los algoritmos son susceptibles de nunca terminar, por ejemplo, cuando entran a un bucle infinito. cuando esto ocurre, el algoritmo nunca devuelve ningun valor de salida, y podemos decir que la funcion queda indefinida para ese valor de entrada. por esta razon se considera que los algoritmos son funciones parciales, es decir, no necesariamente definidas en todo su dominio de definicion.  cuando una funcion puede ser calculada por medios algoritmicos, sin importar la cantidad de memoria que ocupe o el tiempo que se tarde, se dice que dicha funcion es computable. no todas las funciones entre secuencias datos son computables. el problema de la parada es un ejemplo.  como medida de la eficiencia de un algoritmo, se suelen estudiar los recursos (memoria y tiempo) que consume el algoritmo. el analisis de algoritmos se ha desarrollado para obtener valores que de alguna forma indiquen (o especifiquen) la evolucion del gasto de tiempo y memoria en funcion del tamaño de los valores de entrada.  el analisis y estudio de los algoritmos es una disciplina de las ciencias de la computacion y, en la mayoria de los casos, su estudio es completamente abstracto sin usar ningun tipo de lenguaje de programacion ni cualquier otra implementacion; por eso, en ese sentido, comparte las caracteristicas de las disciplinas matematicas. asi, el analisis de los algoritmos se centra en los principios basicos del algoritmo, no en los de la implementacion particular. una forma de plasmar (o algunas veces \"codificar\") un algoritmo es escribirlo en pseudocodigo o utilizar un lenguaje muy simple tal como lexico, cuyos codigos pueden estar en el idioma del programador.  algunos escritores restringen la definicion de algoritmo a procedimientos que deben acabar en algun momento, mientras que otros consideran procedimientos que podrian ejecutarse eternamente sin pararse, suponiendo el caso en el que existiera algun dispositivo fisico que fuera capaz de funcionar eternamente. en este ultimo caso, la finalizacion con exito del algoritmo no se podria definir como la terminacion de este con una salida satisfactoria, sino que el exito estaria definido en funcion de las secuencias de salidas dadas durante un periodo de vida de la ejecucion del algoritmo. por ejemplo, un algoritmo que verifica que hay mas ceros que unos en una secuencia binaria infinita debe ejecutarse siempre para que pueda devolver un valor util. si se implementa correctamente, el valor devuelto por el algoritmo sera valido, hasta que evalue el siguiente digito binario. de esta forma, mientras evalua la siguiente secuencia podran leerse dos tipos de señales: una señal positiva (en el caso de que el numero de ceros sea mayor que el de unos) y una negativa en caso contrario. finalmente, la salida de este algoritmo se define como la devolucion de valores exclusivamente positivos si hay mas ceros que unos en la secuencia y, en cualquier otro caso, devolvera una mezcla de señales positivas y negativas.  el problema consiste en encontrar el maximo de un conjunto de numeros. para un ejemplo mas complejo vease algoritmo de euclides.  dado un conjunto finito c de numeros, se tiene el problema de encontrar el numero mas grande. sin perdida de generalidad se puede asumir que dicho conjunto no es vacio y que sus elementos estan numerados como c 0 , c 1 , … , c n ,c_{1},\\dots ,c_{n}} .  es decir, dado un conjunto c = { c 0 , c 1 , … , c n } ,c_{1},\\dots ,c_{n}\\}} se pide encontrar m tal que x ≤ m para todo elemento x que pertenece al conjunto c .  para encontrar el elemento maximo, se asume que el primer elemento ( c 0 } ) es el maximo; luego, se recorre el conjunto y se compara cada valor con el valor del maximo numero encontrado hasta ese momento. en el caso de que un elemento sea mayor que el maximo, se asigna su valor al maximo. cuando se termina de recorrer la lista, el maximo numero que se ha encontrado es el maximo de todo el conjunto.  el algoritmo puede ser escrito de una manera mas formal en el siguiente pseudocodigo:  funcion max( c )  sobre la notacion:  en lenguaje c++: ",
        "snippet": "En matemáticas, lógica, ciencias de la computación y disciplinas relacionadas, un algoritmo (probablemente del latín tardío algorithmus, y este del árabe clásico ḥisābu lḡubār, que significa «cálculo mediante cifras arábigas»)[1]​ es un conjunto de instrucciones o reglas definidas y no-ambiguas, ordenadas y finitas que permite, típicamente, solucionar un problema, realizar un cómputo, procesar datos y llevar a cabo otras tareas o actividades.[1]​ Dado un estado inicial y una entrada, siguiendo los pasos sucesivos se llega a un estado final y se obtiene una solución. Los algoritmos son el objeto de estudio de la algoritmia.[2]​",
        "enlaces_salientes": [
            "/wiki/Algoritmo",
            "/wiki/Algoritmo",
            "/wiki/Algoritmo",
            "/wiki/Logaritmo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Ada_Lovelace",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Lat%C3%ADn_tard%C3%ADo",
            "/wiki/%C3%81rabe_cl%C3%A1sico",
            "/wiki/Empleador",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/C%C3%A1lculo",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/C%C3%A1lculo",
            "/wiki/Problema_abstracto",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Alonzo_Church",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Alan_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Grafo",
            "/wiki/Estructura_de_datos",
            "/wiki/Algoritmo_paralelo",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Lenguaje_natural",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Diagramas_de_flujo",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Teorema",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Organizaci%C3%B3n_Internacional_para_la_Estandarizaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Lenguaje_m%C3%A1quina",
            "/wiki/Programa_(computaci%C3%B3n)",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Formas_de_resolver_la_ra%C3%ADz_cuadrada",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Camino_hamiltoniano",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Problema_abstracto",
            "/wiki/Bit",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Sistema_binario",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Bucle_infinito",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Dominio_de_definici%C3%B3n",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Problema_de_la_parada",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Ciencias_de_la_computacion",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Lexico",
            "/wiki/C%C3%B3digo_binario",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Conjunto",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/C%2B%2B",
            "/wiki/Algoritmo_de_ordenamiento",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Algoritmo_voraz",
            "/wiki/Algoritmos_paralelos",
            "/wiki/Algoritmo_probabil%C3%ADstico",
            "/wiki/Algoritmo_determin%C3%ADstico",
            "/wiki/Algoritmo_no_determin%C3%ADstico",
            "/wiki/Divide_y_vencer%C3%A1s",
            "/wiki/Metaheur%C3%ADsticas",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica_(computaci%C3%B3n)",
            "/wiki/Ramificaci%C3%B3n_y_acotaci%C3%B3n",
            "/wiki/Vuelta_atr%C3%A1s",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/Complejidad_computacional",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_Nassi-Shneiderman",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Ciencias_de_la_Computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Complejidad_computacional",
            "/wiki/Gobierno_por_algoritmos",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Inteligencia_artificial",
            "/wiki/Investigaci%C3%B3n_operativa",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Programaci%C3%B3n",
            "/wiki/ISBN",
            "/wiki/Thomas_H._Cormen",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISBN",
            "/wiki/Rivest,_R._L.",
            "/wiki/Gilles_Brassard",
            "/wiki/Knuth,_D._E",
            "/wiki/TeX",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/George_Boolos",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Alonzo_Church",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/Alonzo_Church",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/G%C3%B6del",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/Emil_Post",
            "/wiki/ISBN",
            "/wiki/Gottfried_Leibniz",
            "/wiki/George_Boole",
            "/wiki/Gottlob_Frege",
            "/wiki/Georg_Cantor",
            "/wiki/David_Hilbert",
            "/wiki/John_von_Neumann",
            "/wiki/Joseph-Marie_Jacquard",
            "/wiki/Babbage",
            "/wiki/Ada_Lovelace",
            "/wiki/Claude_Shannon",
            "/wiki/Howard_Aiken",
            "/wiki/Digital_object_identifier",
            "/wiki/Bibcode",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Andrew_Hodges",
            "/wiki/Simon_and_Schuster",
            "/wiki/Bibcode",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Stephen_Kleene",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Stephen_Kleene",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Donald_Knuth",
            "/wiki/ISBN",
            "/wiki/Donald_Knuth",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/A.A._Markov",
            "/wiki/Marvin_Minsky",
            "/wiki/ISBN",
            "/wiki/Emil_Post",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/United_States_Patent_and_Trademark_Office",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Medical_Subject_Headings",
            "/wiki/Descriptores_en_Ciencias_de_la_Salud"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Logaritmo",
        "titulo": "Logaritmo",
        "contenido": "no  la base tiene que ser positiva y distinta de 1.  cuando la base es 10, esta no se pone, y se escribe como log ⁡ n = x y cuando es e }\\,} se escribe como ln ⁡ n = x  asi, el logaritmo de 1000 en base 10 es 3, porque 10 al cubo vale 1000:  de la misma manera que la operacion opuesta de la suma es la resta y la de la multiplicacion la division, el calculo de logaritmos o logaritmacion es la operacion inversa a la exponenciacion de la base del logaritmo.  para representar la operacion de logaritmo en una determinada base se escribe la abreviatura log y como subindice la base, y despues el numero cuyo logaritmo se desea hallar o expresar. por ejemplo, 35=243, luego log3243=5. cuando se sobreentiende la base, se puede omitir.  los logaritmos fueron introducidos por john napier a principios del siglo xvii como un medio de simplificacion de los calculos y fueron prontamente adoptados por cientificos, ingenieros, banqueros y otros para realizar operaciones facil y rapidamente, usando reglas de calculo y tablas de logaritmos. estos dispositivos se basan en el hecho, importante en si mismo —por identidades logaritmicas—, de que el logaritmo de un producto es la suma de los logaritmos de los factores:  la nocion actual de los logaritmos proviene de leonhard euler, quien los conecto con la funcion exponencial en el siglo xviii y tambien introdujo el numero de euler (representado por la letra e) como base de los logaritmos naturales.  los logaritmos, que hacen posible transformar una multiplicacion en una suma, una division en una resta, una potencia en un producto y una raiz en una division, tuvieron gran importancia porque simplificaban los calculos numericos; hoy en dia, con las calculadoras y los ordenadores, las operaciones con logaritmos han cambiado sustancialmente.​  logaritmacion es el proceso de hallar el exponente al cual fue elevada la base para obtener un numero.  dado un numero real (argumento x), la funcion logaritmo le asigna el exponente n (o potencia) a la que un numero fijo b (base) se ha de elevar para obtener dicho argumento. es la funcion inversa de b a la potencia n. esta funcion se escribe como: n = logb x, lo que permite obtener n.​   log b ⁡ x = n ⇔ b n = x x=n\\quad \\leftrightarrow \\ \\quad b^{n}=x\\,}  que se lee como: logaritmo en base b de x es igual a n si y solo si b elevado a la n da por resultado x.  para que la definicion sea valida, no todas las bases y numeros son posibles, la base b tiene que ser positiva y distinta de 1 (b> 0 y b = 1), x tiene que ser un numero positivo (x > 0) y n puede ser cualquier numero real (n ∈ r).​  asi, en la expresion 102 = 100, el logaritmo en base 10 de 100 es 2, y se escribe como log10 100 = 2.  los logaritmos, independientemente de la base elegida, cumplen una serie de propiedades comunes que los caracterizan. asi, el logaritmo de su base es siempre 1; logb b = 1 ya que b1 = b. el logaritmo de 1 es cero (independientemente de la base); logb 1=0 ya que b0 = 1.  si b es entero (z) y el numero real a se encuentra dentro del intervalo 0 <  a < 1, entonces logb a da un valor negativo o se dice que es un logaritmo negativo. es evidente, ya que si el logaritmo de 1 es cero, entonces valores reales menores que uno seran negativos por ser la funcion logaritmica estrictamente creciente y cuyo recorrido es (-∞, +∞). tambien usando la identidad logaritmica logb(x/y)=logb x - logb y; puesto que a pertenece al intervalo 0 <  a < 1, su inverso a-1 sera mayor que uno, con lo que logb(a)=logb(1/a-1) = logb 1 - logb(a-1)= -logb(a-1). lo cual puede resumirse asi: sea b ∈ z  ∧ 0<a<1 ⇒ logb(a)= -c.  los numeros negativos no tienen logaritmo en el cuerpo de los reales r, ya que cualquiera que sea el exponente n, se tendra siempre que bn sera mayor que cero, bn > 0; en consecuencia, no hay ningun valor real de n que pueda satisfacer bn = x cuando x sea menor que 0. sin embargo, este obstaculo se puede salvar, ampliando el dominio de definicion al cuerpo de los numeros complejos c, pudiendo calcular logaritmos de numeros negativos usando el logaritmo complejo o recurriendo a la formula de euler.  las potencias consecutivas de una base forman una progresion geometrica y la de los exponentes una progresion aritmetica. por ejemplo, las potencias de 2 son 1,2,4,8,16,32,64,…, etc., y sus exponentes seran 0, 1, 2, 3, 4, …, etc., ya que 20 = 1, 21 = 2, 22 = 4, 23 = 8, y 24 = 16, etc., luego log2 1 = 0, log2 2 = 1, log2 4 = 2, log2 8 = 3 y log2 16 = 4, etc.  en esta parte se destaca la capacidad operativa del uso de logaritmos en el sentido de operaciones coligadas; mediante logaritmos, una operacion se convierte en otra operacion de menor nivel. por ejemplo, un producto de n factores se reduce a una adicion de n sumandos.  ciertamente, las siguientes proposiciones funcionan como identidades para los valores de su dominio de definicion. sin embargo, el exito de la invencion y uso de los logaritmos, justamente, radico en poder convertir productos en sumas; cocientes en restas; potencia en producto y raiz de grado n en un cociente. este hecho permite decir que, en su momento, el uso de logaritmos produjo un cambio revolucionario en los calculos, empleados en la astronomia, navegacion y matematica financiera aplicada a la banca y los negocios colaterales.​ los logaritmos mantienen ciertas identidades aritmeticas muy utiles a la hora de realizar calculos:  en realidad la tercera y cuarta identidad son equivalentes, sin mas que hacer:  entre los logaritmos mas utilizados se encuentra el logaritmo natural, cuya base es e, base 10 (logaritmo comun), base 2 (logaritmo binario), o en base indefinida (logaritmo indefinido). la eleccion de un determinado numero como base de los logaritmos no es crucial, ya que, todos son proporcionales entre si. es util la siguiente formula que define al logaritmo de x en base b (suponiendo que b, x, y k son numeros reales positivos y que tanto b como k son diferentes de 1):  en la que k es cualquier base valida. si hacemos k=x, obtendremos:  el logaritmo mas ampliamente utilizado es el natural, ya que tiene multitud de aplicaciones en fisica, matematicas, ingenieria y en ciencias en general. tambien es bastante utilizado el logaritmo decimal, que se indica como log ⁡ ( x ) , en ciencias que hacen uso de las matematicas, como la quimica en la medida de la acidez (denominada ph) y en fisica en magnitudes como la medida de la luminosidad (candela), de intensidad de sonido (db), de la energia de un terremoto (escala sismologica de richter), etc. en informatica se usa el logaritmo en base 2 la mayoria de veces.  un estudio mas profundo de los logaritmos requiere el concepto de funcion. un ejemplo es la funcion que produce la x-esima potencia de b para cualquier numero real x, donde la base (o raiz) b es un numero fijo. esta funcion se escribe como  para garantizar la definicion de logaritmos, es necesario demostrar que para la ecuacion exponencial  existe una unica solucion x , asumiendo que y es positivo y que b es positivo y distinto de 1. una demostracion de este hecho requiere del teorema del valor intermedio del calculo elemental.​ este teorema establece que una funcion continua que produce dos valores m y n tambien produce cualquier valor que se encuentre entre m y n. una funcion es continua si esta no «salta», esto es, si su grafico puede ser escrito sin levantar el lapiz del papel.  esta propiedad se puede demostrar que se cumple para la funcion f(x) = bx. puesto que f toma arbitrariamente valores grandes positivos y valores pequeños positivos, cualquier numero y > 0 que se encuentra entre f(x0) y f(x1) para un adecuado x0 y x1. por lo tanto, el teorema del valor intermedio asegura que la ecuacion f(x) = y tiene una solucion. mas aun, hay unicamente una solucion para esta ecuacion, puesto que la funcion f es estrictamente creciente (para b > 1), o estrictamente decreciente (para 0 < b < 1).​  la unica solucion x es el logaritmo de y en la base b, logb(y). la funcion que asigna a cada y su logaritmo se llama funcion logaritmo o funcion logaritmica (o logaritmo a secas).  la formula para el logaritmo de una potencia dice en particular que para cualquier numero x,  en lenguaje llano, tomando la x-esima potencia de b y luego el base-b logaritmo se vuelve a obtener x. de modo contrario, dado un numero positivo y, la formula  dice que tomando primero el logaritmo y despues exponenciando se vuelve a obtener y. asi, las dos maneras posibles de combinar (o componer) logaritmos y exponenciales vuelve a dar el numero original. por lo tanto, el logaritmo en base b es la funcion inversa de f(x) = bx.​  las funciones inversas estan intimamente relacionadas con las funciones originales. sus graficos se corresponden el uno con el otro mediante el intercambio de las coordenadas x e y (o por reflexion sobre la linea diagonal x = y), como se muestra en la figura de la derecha: un punto (t, u = bt) sobre el grafico de f proporciona un punto (u, t = logbu) sobre el grafico del logaritmo y viceversa.  como consecuencia, logb(x) tiende a + infinito (se hace mas grande que cualquier numero dado) si x aproxima a + infinito, siempre que b sea mayor que 1. en ese caso, logb(x) es un funcion creciente. para b < 1, logb(x) tiende a menos infinito en lugar de a infinito. cuando x se aproxima a cero, logb(x) tiende a menos infinito para b > 1 (a mas infinito cuando b < 1, respectivamente). en cualquier caso, y para todo valor apropiado de la base b, la grafica de la funcion logaritmica corta al eje de las abscisas en el punto (1,0).  las propiedades analiticas de las funciones pasan a sus inversas.​ asi, como f(x) = bx es una funcion continua y diferenciable, tambien lo sera logb(y). toscamente hablando, una funcion continua es diferenciable si su grafico no tiene «trazos puntiagudos». mas aun, como la derivada de f(x) evaluada en ln(b)bx por las propiedades de la funcion exponencial, la regla de la cadena implica que la derivada de logb(x) es dada por​​   d d x log b ⁡ ( x ) = 1 x ln ⁡ ( b ) . }{}x}}\\log _{b}(x)={x\\ln(b)}}.}  esto es, la pendiente de la tangente que toca el grafico del logaritmo en base-b en el punto (x, logb(x)) es igual a 1/(x ln(b)). en particular, la derivada de ln(x) es 1/x, lo que implica que la integral indefinida de 1/x es ln(x) + c.la derivada con un argumento funcional generalizado f(x) es   d d x ln ⁡ ( f ( x ) ) = f ′ ( x ) f ( x ) . }{}x}}\\ln(f(x))={f(x)}}.}  el cociente del miembro derecho es denominado derivada logaritmica de f. calcular f'(x) por medio de la derivada de ln(f(x)) se conoce como diferenciacion logaritmica.​ la integral indefinida del logaritmo natural ln(x) es:​   ∫ ln ⁡ ( x ) d x = x ln ⁡ ( x ) − x + c . }x=x\\ln(x)-x+c.}  formulas relacionadas, tales como integrales indefinidas de logaritmos en otras bases pueden ser obtenidas de esta ecuacion usando el cambio de bases.​  el logaritmo natural de t concuerda con la integral de 1/x dx desde 1 a t:  en otras palabras, ln(t) es igual al area entre el eje x y el grafico de la funcion 1/x, recorrido desde x = 1 a x = t (figura a la derecha). esto es una consecuencia del teorema fundamental del calculo y del hecho de que la derivada de ln(x) sea 1/x. el miembro de la derecha de esta ecuacion puede servir con una definicion para el logaritmo natural. las formulas del producto y potencias de logaritmo pueden ser obtenidas de esta definicion.​ por ejemplo, la formula del producto ln(tu) = ln(t) + ln(u) se deduce como:  la igualdad (1) descompone la integral en dos partes, mientras que la igualdad (2) es un cambio de variable ( w = x/t). en la ilustracion de abajo, la descomposicion corresponde a dividir el area en las partes azul y amarilla. reescalando el area azul de la izquierda verticalmente mediante el factor t y contrayendo esta por el mismo factor horizontalmente no se cambia su tamaño. moviendola apropiadamente, el area de la grafica se ajusta a la funcion f(x) = 1/x de nuevo. por lo tanto, el area azul del termino izquierdo, que es la integral de f(x) desde t a tu es la misma que la de la integral desde 1 a u. esto justifica la igualdad (2) con otra demostracion geometrica mas.  la formula de la potencia ln(tr) = r ln(t) puede ser obtenida de manera similar:  la segunda igualdad usa los cambios de variable (integracion por sustitucion), w := x1/r.  la suma sobre los inversos de los numeros naturales,  es llamada serie armonica. esta estrechamente vinculada al logaritmo natural: cuando n tiende a infinito, la diferencia,  converge (es decir, se aproxima arbitrariamente cerca) a un numero conocido como constante de euler-mascheroni. esta relacion ayuda a analizar el rendimiento de algoritmos, como quicksort.​  el logaritmo es un ejemplo de funcion trascendente y desde un punto de vista teorico, el teorema de gelfond-schneider afirma que los logaritmos suelen tomar valores «dificiles». la declaracion formal se basa en la nocion de numeros algebraicos, que incluye a todos los numeros racionales, pero tambien numeros tales como la raiz cuadrada de 2 o  numeros complejos que no son algebraicos son llamados transcendentes;​ por ejemplo, π y e son dos de esos numeros. casi todos los numeros complejos son trascendentes. usando estas nociones, el teorema de gelfond–scheider declara que dados dos numeros algebraicos a y b, logb(a) es, o un numero trascendente, o un numero racional p / q (en cuyo caso aq = bp, de manera que, para empezar, a y b estaban estrechamente relacionados).​  los logaritmos son faciles de calcular en algunos casos, tales como log10(1000) = 3. en general, los logaritmos pueden ser calculados usando series de potencias o la media aritmetico-geometrica, o ser obtenidos de una tabla de logaritmos precalculada que proporciona una precision fijada.​​ el metodo de newton, un metodo iterativo para resolver ecuaciones aproximadamente, puede ser usado tambien para calcular el logaritmo, porque su funcion inversa, la funcion exponencial, puede ser calculada eficientemente.​ usando tablas de referencias, metodos como cordic pueden ser usados para calcular logaritmos si las unicas operaciones disponibles son la adicion y el desplazamiento de bits.​​ mas aun, el algoritmo del logaritmo binario calcula lb(x) recursivamente basado en la repeticion cuadratica de x, aprovechando la relacion  para cualquier numero real z que satisfaga 0 < z < 2, la siguiente serie de potencias se cumple:[nb 1]​​  esta es una manera rapida de decir que ln(z) puede ser aproximado a un valor mas y mas preciso mediante las siguientes expresiones:  por ejemplo, con z = 1.5 la tercera aproximacion obtiene 0.4167, que es alrededor de 0.011 mayor que ln(1.5) = 0.405465. esta serie aproxima ln(z) con precision arbitraria, siempre que el numero de sumandos sea lo suficientemente grande. en calculo elemental, ln(z) es por tanto, el limite de la serie. esta es la serie de taylor del logaritmo natural en z = 1. la serie de taylor de ln z proporciona una particular aproximacion util de ln(1+z) cuando z es pequeño, |z| << 1, puesto que  por ejemplo, con z = 0,1 el primer orden de aproximacion da ln(1,1) ≈ 0.1, que es menor del 5 % del valor correcto 0,0953.  otra serie esta basada en la funcion argumento de tangente hiperbolica:  para cualquier numero real z > 0.[nb 2]​​ usando la notacion sumatorio esta tambien puede ser escrita como  esta serie se puede obtener de la serie de taylor anterior. converge mas rapido que la serie de taylor, especialmente si z es cercano a 1. por ejemplo, para  , los tres primeros terminos de la segunda serie aproximan ln(1,5) con un error del entorno de 3×10−6. la rapida convergencia para z cercano a 1 puede ser tomada como una ventaja de la siguiente manera.: da una aproximacion de baja exactitud y ≈ ln(z) y calculando  el logaritmo de z es:  cuando mejor es la aproximacion inicial y, mas cerca esta a de 1, asi que su logaritmo puede ser calculado eficientemente. a puede ser calculado usando la serie exponencial, que converge rapidamente siempre que y no sea demasiado grande. calculando el logaritmo de un z mayor, puede ser reducido a valores mas pequeños que z mediante la escritura z = a · 10b, asi que ln(z) = ln(a) + b · ln(10).  un metodo intimamente relacionado puede ser utilizado para calcular el logaritmo de enteros. de la serie anterior, se deduce que:  si el logaritmo de un entero grande n es conocido, entonces esta serie obtiene una veloz serie convergente para log(n+1).  la media aritmetico-geometrica da aproximaciones con gran precision del logaritmo natural. ln(x) es aproximado con una precision de 2−p (o p bits precisos) mediante la siguiente formula (dada por carl friedrich gauss):​​  aqui m denota la media aritmetico-geometrica. se puede obtener mediante el calculo repetido de la media (media aritmetica) y de la raiz cuadrada del producto de dos numeros (media geometrica). mas aun, m es escogido tal que  ambas, media aritmetico-geometrica y las constantes π y ln(2) pueden ser calculadas mediante series convergentes muy rapidas.  es posible extender el concepto de logaritmo mas alla de los reales positivos.  para enteros b y x, el numero log b ⁡ ( x ) (x)\\,} es irracional (no puede representarse como el cociente de dos enteros) si b o x tienen un factor primo que el otro no tiene.  el logaritmo natural de un numero real positivo esta bien definido y es un numero real. sin embargo, generalizar el logaritmo natural a numeros reales negativos solo puede hacerse introduciendo numeros complejos.  sin embargo, al igual que sucede el logaritmo de numeros complejos la eleccion de logaritmo de un numero negativo no es unica, aunque la eleccion hecha es la mas frecuentemente usada para extender el logaritmo a numeros reales negativos.  el logaritmo natural de un numero complejo z es otro numero complejo b = ln(z) que sea solucion de la ecuacion:  (*) z = e b \\;\\,}  la ecuacion anterior no tiene solucion unica. de hecho, tiene un numero infinito de soluciones, aunque todas ellas son faciles de encontrar. dado un numero complejo z escrito en forma polar, una solucion posible de la ecuacion (*) es b0:   b 0 = ln ⁡ ρ + i θ con z = ρ e i θ =\\ln \\rho +i\\theta \\qquad }\\ z=\\rho e^{i\\theta }\\,}  puede comprobarse que esta no es la unica solucion, sino que para cualquier valor k ∈ z \\,} resulta que el numero complejo bk, definido a continuacion, tambien es solucion:   b k = ln ⁡ ρ + i θ + 2 π k i ⇒ e b k = ρ e i θ ⋅ e 2 π k i = z =\\ln \\rho +i\\theta +2\\pi ki\\qquad \\rightarrow e^{b_{k}}=\\rho e^{i\\theta }\\cdot e^{2\\pi ki}=z\\,}  de hecho cada valor particular de k define una superficie de riemann.  un logaritmo en base imaginaria es un logaritmo que tiene como base i (la unidad imaginaria). este tipo de logaritmos se puede resolver facilmente con la formula:   log i ⁡ ( z ) = 2 ln ⁡ ( z ) i π . (z)={{2\\ln(z)} \\over i\\pi }.\\,}  donde z es cualquier numero complejo excepto 0. sin embargo, cabe señalar que la formula anterior solo es una de las posibles soluciones ya que la ecuacion:   i λ = z =z\\,}  admite no solo la solucion dada anteriormente sino que cualquier x de la forma:   λ = 2 i π ln ⁡ ( z ) + 4 k = log i ⁡ ( z ) + 4 k , k ∈ z {i\\pi }}\\ln(z)+4k=\\log _{i}(z)+4k,\\qquad k\\in \\mathbb {z} \\,}  tambien es solucion.  una matriz b es logaritmo de una matriz dada a si la exponenciacion de b es a:   e b = a =a\\,}  a diferencia de la exponenciacion de matrices, el logaritmo de una matriz real puede no estar definido siempre. en el caso de una matriz diagonalizable es necesario que logaritmo este definido para todos y cada uno de los autovalores o valores propios de la matriz. en ese caso el logaritmo de la matriz esta definido y es logaritmo de una matriz con autovalores positivos es otra matriz real. si el 0 es un autovalor de la matriz, entonces su logaritmo no esta definido.  si el logaritmo esta definido sobre el espectro o conjunto de autovalores y estos incluyen algun numero negativo, aun asi es posible definir una matriz logaritmo (en forma similar a como se definen los logaritmos de numeros negativos o complejos), aunque no resulta unica.  en el caso de una matriz no diagonalizable, este proceso es mas complicado, ya que requiere encontrar primero su forma canonica de jordan.  los logaritmos discretos son los analogos en teoria de grupos de los logaritmos ordinarios. en particular, un logaritmo ordinario loga(b) es una solucion de la ecuacion ax = b sobre numeros reales o numeros complejos. de manera similar, si g y h son elementos de un grupo ciclico finito g, entonces una solucion x de la ecuacion gx = h es llamada logaritmo discreto en la base g de h en el grupo g.  si (g,·) es un grupo ciclico finito de orden n, donde · es el operador multiplicacion, si se escoge un generador g de g, entonces cada elemento h de g puede ser escrito como h = gk para algun entero k, de manera que la funcion  asigna a cada h la clase de equivalencia modulo n de k, esto es, todos los k que cumplan que h ≡ gk mod n.  este logaritmo tiene aplicaciones en criptografia, en especial en el metodo de intercambio de claves de diffie-hellman o en el sistema de elgamal.  el metodo de calculo mediante logaritmos fue propuesto por primera vez, publicamente, por john napier (latinizado neperus) en 1614, en su libro titulado mirifici logarithmorum canonis descriptio. joost burgi, un matematico y relojero suizo al servicio del duque de hesse-kassel, concibio por primera vez los logaritmos; sin embargo, publico su descubrimiento cuatro años despues que napier. la inicial resistencia a la utilizacion de logaritmos fue cambiada por kepler, por el entusiasta apoyo de su publicacion y la impecable y clara explicacion de como funcionaban.  este metodo contribuyo al avance de la ciencia, y especialmente de la astronomia, facilitando la resolucion de calculos muy complejos. los logaritmos fueron utilizados habitualmente en geodesia, navegacion maritima y otras ramas de la matematica aplicada, antes de la llegada de las calculadoras y computadoras. ademas de la utilidad en el calculo, los logaritmos tambien ocuparon un importante lugar en las matematicas mas avanzadas; el logaritmo natural presenta una solucion para el problema de la cuadratura de un sector hiperbolico ideado por gregoire de saint-vincent en 1647.  napier no uso una base tal como ahora se entiende pero, sus logaritmos, como factor de escala, funcionaban de manera eficaz con base 1/e. para los propositos de interpolacion y facilidad de calculo, eran utiles para hallar la relacion r en una serie geometrica tendente a 1. napier escogio r = 1 - 10−7 = 0,999999 (burgi eligio r = 1 + 10−4 = 1,0001). los logaritmos originales de napier no tenian log 1 = 0, sino log 107 = 0. asi, si n es un numero y l es el logaritmo, napier calcula: n = 107(1 − 10−7)l. donde (1 − 10−7)107 es aproximadamente 1/e, haciendo l/107 equivalente a log1/e n/107. vease logaritmo neperiano.  inicialmente, napier llamo «numeros artificiales» a los logaritmos y «numeros naturales» a los antilogaritmos. mas tarde, napier usa la palabra logaritmo en el sentido de un numero que indica una proporcion: λογος (logos) el sentido de proporcion, y αρθμος (arithmos) significado numero, y se define, literalmente, como «un numero que indica una relacion o proporcion». se refiere a la proposicion que fue hecha por napier en su «teorema fundamental», que establece que la diferencia de dos logaritmos determina la relacion de los numeros a los cuales corresponden, de manera que una progresion aritmetica de logaritmos corresponde a una progresion geometrica de numeros. el termino antilogaritmo fue introducido a finales del siglo xvii y, aunque nunca se utilizo ampliamente en matematicas, perduro en muchas tablas, hasta que cayo en desuso.   ",
        "snippet": "No",
        "enlaces_salientes": [
            "/wiki/Logaritmo",
            "/wiki/Logaritmo",
            "/wiki/Logaritmo",
            "/wiki/Algoritmo",
            "/wiki/Gr%C3%A1fica_de_una_funci%C3%B3n",
            "/wiki/Funci%C3%B3n_real",
            "/wiki/John_Napier",
            "/wiki/Dominio_de_definici%C3%B3n",
            "/wiki/Codominio",
            "/wiki/Conjunto_imagen",
            "/wiki/Funci%C3%B3n_biyectiva",
            "/wiki/Funci%C3%B3n_c%C3%B3ncava",
            "/wiki/Funci%C3%B3n_mon%C3%B3tona",
            "/wiki/Funci%C3%B3n_trascendente",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Derivada",
            "/wiki/Funci%C3%B3n_inversa",
            "/wiki/L%C3%ADmite_matem%C3%A1tico",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/N%C3%BAmero_e",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Exponencial",
            "/wiki/Suma",
            "/wiki/Resta",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/C%C3%A1lculo",
            "/wiki/Operaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Exponenciaci%C3%B3n",
            "/wiki/John_Napier",
            "/wiki/Siglo_XVII",
            "/wiki/Regla_de_c%C3%A1lculo",
            "/wiki/Tabla_de_logaritmos",
            "/wiki/Identidades_logar%C3%ADtmicas",
            "/wiki/Producto_(matem%C3%A1ticas)",
            "/wiki/Suma",
            "/wiki/Leonhard_Euler",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/Siglo_XVIII",
            "/wiki/N%C3%BAmero_e",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Suma",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Resta",
            "/wiki/Potenciaci%C3%B3n",
            "/wiki/Radicaci%C3%B3n",
            "/wiki/Calculadora",
            "/wiki/Ordenador",
            "/wiki/Funci%C3%B3n_inversa",
            "/wiki/Intervalo_(matem%C3%A1ticas)",
            "/wiki/Imagen_de_una_funci%C3%B3n",
            "/wiki/Inverso_multiplicativo",
            "/wiki/Cuerpo_(matem%C3%A1ticas)",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Dominio_de_definici%C3%B3n",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/Logaritmo_complejo",
            "/wiki/F%C3%B3rmula_de_Euler",
            "/wiki/Progresi%C3%B3n_geom%C3%A9trica",
            "/wiki/Progresi%C3%B3n_aritm%C3%A9tica",
            "/wiki/Potencias_de_2",
            "/wiki/Logaritmo_binario",
            "/wiki/Identidades_logar%C3%ADtmicas",
            "/wiki/Logaritmo_natural",
            "/wiki/N%C3%BAmero_e",
            "/wiki/Logaritmo_com%C3%BAn",
            "/wiki/Logaritmo_binario",
            "/wiki/F%C3%ADsica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Ciencia",
            "/wiki/Logaritmo_decimal",
            "/wiki/PH",
            "/wiki/Candela",
            "/wiki/Intensidad_de_sonido",
            "/wiki/Decibelio",
            "/wiki/Escala_sismol%C3%B3gica_de_Richter",
            "/wiki/Funci%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/Ra%C3%ADz_de_una_funci%C3%B3n",
            "/wiki/Ecuaci%C3%B3n_exponencial",
            "/wiki/Teorema_del_valor_intermedio",
            "/wiki/C%C3%A1lculo",
            "/wiki/Funci%C3%B3n_continua",
            "/wiki/Funci%C3%B3n_mon%C3%B3tona",
            "/wiki/Reflexi%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/Funci%C3%B3n_compuesta",
            "/wiki/Funci%C3%B3n_inversa",
            "/wiki/Gr%C3%A1fica_de_una_funci%C3%B3n",
            "/wiki/L%C3%ADmite_de_una_sucesi%C3%B3n",
            "/wiki/Funci%C3%B3n_mon%C3%B3tona",
            "/wiki/Funci%C3%B3n_diferenciable",
            "/wiki/Derivada",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/Regla_de_la_cadena",
            "/wiki/Pendiente_(matem%C3%A1ticas)",
            "/wiki/Tangente_(geometr%C3%ADa)",
            "/wiki/Integral_indefinida",
            "/wiki/Derivada_logar%C3%ADtmica",
            "/wiki/Diferenciaci%C3%B3n_logar%C3%ADtmica",
            "/wiki/Lista_de_integrales_de_funciones_logar%C3%ADtmicas",
            "/wiki/Logaritmo_natural",
            "/wiki/Integral",
            "/wiki/Teorema_fundamental_del_c%C3%A1lculo",
            "/wiki/Integraci%C3%B3n_por_sustituci%C3%B3n",
            "/wiki/Serie_arm%C3%B3nica_(matem%C3%A1ticas)",
            "/wiki/Infinito",
            "/wiki/Convergencia_(matem%C3%A1ticas)",
            "/wiki/Constante_de_Euler-Mascheroni",
            "/wiki/Quicksort",
            "/wiki/Funci%C3%B3n_trascendente",
            "/wiki/Teorema_de_Gelfond-Schneider",
            "/wiki/N%C3%BAmero_algebraico",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/Ra%C3%ADz_cuadrada_de_2",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/Numero_trascendente",
            "/wiki/Serie_de_potencias",
            "/wiki/Media_aritm%C3%A9tico-geom%C3%A9trica",
            "/wiki/Tabla_de_logaritmos",
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/CORDIC",
            "/wiki/Logaritmo_binario",
            "/wiki/Recursi%C3%B3n",
            "/wiki/Serie_de_Taylor",
            "/wiki/Serie_de_potencias",
            "/wiki/Serie_matem%C3%A1tica",
            "/wiki/L%C3%ADmite_matem%C3%A1tico",
            "/wiki/Funci%C3%B3n_hiperb%C3%B3lica#Inversas_de_las_funciones_hiperbólicas",
            "/wiki/Sumatorio",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/Media_aritm%C3%A9tico-geom%C3%A9trica",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/Media_aritm%C3%A9tica",
            "/wiki/Media_geom%C3%A9trica",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/N%C3%BAmero_irracional",
            "/wiki/Factorizaci%C3%B3n",
            "/wiki/Logaritmo_complejo",
            "/wiki/Superficie_de_Riemann",
            "/wiki/Logaritmo_en_base_imaginaria",
            "/wiki/N%C3%BAmero_complejo#Unidad_imaginaria",
            "/wiki/N%C3%BAmero_complejo#Unidad_imaginaria",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/Logaritmo_de_una_matriz",
            "/wiki/Exponencial_de_matrices",
            "/wiki/Exponenciaci%C3%B3n",
            "/wiki/Matriz_diagonalizable",
            "/wiki/Autovalor",
            "/wiki/Espectro_de_un_operador",
            "/wiki/Forma_can%C3%B3nica_de_Jordan",
            "/wiki/Logaritmo_discreto",
            "/wiki/Logaritmo_discreto",
            "/wiki/Grupo_(matem%C3%A1ticas)",
            "/wiki/N%C3%BAmero_real",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/Grupo_c%C3%ADclico",
            "/wiki/Conjunto_finito",
            "/wiki/Grupo_c%C3%ADclico",
            "/wiki/Orden_(teor%C3%ADa_de_grupos)",
            "/wiki/Conjunto_generador_de_un_grupo",
            "/wiki/Aritm%C3%A9tica_modular#Clases_de_equivalencia_módulo_n",
            "/wiki/Diffie-Hellman",
            "/wiki/Cifrado_ElGamal",
            "/wiki/Historia_de_los_logaritmos",
            "/wiki/John_Napier",
            "/wiki/John_Napier",
            "/wiki/Joost_B%C3%BCrgi",
            "/wiki/Kepler",
            "/wiki/Astronom%C3%ADa",
            "/wiki/Geodesia",
            "/wiki/Navegaci%C3%B3n_mar%C3%ADtima",
            "/wiki/Computadora",
            "/wiki/Logaritmo_neperiano",
            "/wiki/Progresi%C3%B3n_aritm%C3%A9tica",
            "/wiki/Progresi%C3%B3n_geom%C3%A9trica",
            "/wiki/Identidades_logar%C3%ADtmicas",
            "/wiki/Cologaritmo",
            "/wiki/Logaritmo_binario",
            "/wiki/Logaritmo_natural",
            "/wiki/Logaritmo_neperiano",
            "/wiki/Logaritmo_decimal",
            "/wiki/Logaritmo_complejo",
            "/wiki/Logaritmo_en_base_imaginaria",
            "/wiki/Logaritmo_iterado",
            "/wiki/Logaritmo_discreto",
            "/wiki/Logaritmo_de_una_matriz",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/Neper",
            "/wiki/PH",
            "/wiki/Decibelio",
            "/wiki/Escala_logar%C3%ADtmica",
            "/wiki/Funci%C3%B3n_elemental",
            "/wiki/Funci%C3%B3n_algebraica",
            "/wiki/Potenciaci%C3%B3n",
            "/wiki/Funci%C3%B3n_polin%C3%B3mica",
            "/wiki/Funci%C3%B3n_racional",
            "/wiki/Radicaci%C3%B3n",
            "/wiki/Funci%C3%B3n_trascendente",
            "/wiki/Funci%C3%B3n_trigonom%C3%A9trica",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/ISBN",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/ISBN",
            "/wiki/Wolfram_Research",
            "/wiki/Morris_Kline",
            "/wiki/Dover_Publications",
            "/wiki/ISBN",
            "/wiki/John_Wiley_%26_Sons",
            "/wiki/ISBN",
            "/wiki/Mathematical_Reviews",
            "/wiki/Princeton_University_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/William_Kahan",
            "/wiki/Digital_object_identifier",
            "/wiki/Serge_Lang",
            "/wiki/Springer-Verlag",
            "/wiki/ISBN",
            "/wiki/Mathematical_Reviews",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Diagrama_de_flujo",
        "titulo": "Diagrama de flujo",
        "contenido": "el diagrama de flujo o flujograma o diagrama de actividades es la representacion grafica de un algoritmo o proceso. se utiliza en disciplinas como programacion, economia, procesos industriales y psicologia cognitiva.  en lenguaje unificado de modelado (uml), es un diagrama de actividades que representa los flujos de trabajo paso a paso. un diagrama de actividades muestra el flujo de control general.  en sysml el diagrama ha sido extendido para indicar flujos entre pasos que mueven elementos fisicos (p. ej., gasolina) o energia (p. ej., presion). los cambios adicionales permiten al diagrama soportar mejor flujos de comportamiento y datos continuos.  estos diagramas utilizan simbolos con significados definidos que representan los pasos del algoritmo, y representan el flujo de ejecucion mediante flechas que conectan los puntos de inicio y de fin del proceso.  las siguientes son acciones previas a la realizacion del diagrama de flujo:  los pasos a seguir para construir el diagrama de flujo son:  en uml 1.x, un diagrama de actividades es una variacion del diagrama de estado unl donde los \"estados\" representan operaciones, y las transiciones representan las actividades que ocurren cuando la operacion se termina.  el diagrama de mensajes de uml 2.0, mientras que es similar en aspecto al diagrama de actividades uml 1.x, ahora tiene semanticas basadas en redes de petri. en uml 2.0, el diagrama general de interaccion esta basado en el diagrama de actividades. el diagrama de actividad es una forma especial de diagrama de estado usado para modelar una secuencia de acciones y condiciones tomadas dentro de un proceso.  la especificacion del lenguaje de notificacion unificado (unl) define un diagrama de actividad como:  el proposito del diagrama de actividad es modelar un proceso de flujo de trabajo (workflow) y/o modelar operaciones.  una operacion es un servicio proporcionado por un objeto, que esta disponible a traves de una interfaz.  una interfaz es un grupo de operaciones relacionadas con la semantica.  1.-segun gomez cejas, guillermo. año 1997:  2.-segun chiavenato, idalberto. año 1993:  3.-segun gomez rondon, francisco. año 1995:  el instituto nacional estadounidense de estandares (ansi, por su siglas en ingles) establecio estandares para los diagramas de flujo y sus simbolos en los años 1960s.​ la organizacion internacional de normalizacion (iso, por sus siglas en ingles) adopto los simbolos ansi en 1970.​ el estandar actual, iso 5807, fue revisado en 1985.​  se trata de la mas comun y practica entre todas las clases de diagramas de flujo. describe el flujo de informacion en un ente u organizacion, sus procesos, sistemas administrativos y de control. permite la impresion visual de los procedimientos y una clara y logica interpretacion.  segun la normativa, el flujo presupuesto es de izquierda a derecha y de arriba hacia abajo, siendo optativo el uso de flechas. cuando el sentido es invertido (de derecha a izquierda o de abajo hacia arriba), es obligatorio el uso de la flecha.​  la paternidad del diagrama de flujo es en principio algo difusa. el metodo estructurado para documentar graficamente un proceso como un flujo de pasos sucesivos y alternativos, el \"proceso de diagrama de flujo\", fue expuesto por frank gilbreth, en la sociedad americana de ingenieros mecanicos (asme), en 1921, bajo el enunciado de \"proceso de graficas-primeros pasos para encontrar el mejor modo\". estas herramientas de gilbreth rapidamente encontraron sitio en los programas de ingenieria industrial.  al principio de los 30, un ingeniero industrial, allan h. mogensen comenzo la formacion de personas de negocios en lake placid, nueva york, incluyendo el uso del diagrama de flujo. art spinanger, asistente a las clases de mogesen, utilizo las herramientas en su trabajo en procter & gamble, donde desarrollo su “programa metodico de cambios por etapas”. otro asistente al grupo de graduados en 1944, ben s. graham, director de ingenieria de formcraft standard register corporation, adapto la grafica de flujo de procesos al tratamiento de la informacion en su empresa. y desarrollo la grafica del proceso de multiples flujos en multiples pantallas, documentos, y sus relaciones. en 1947, asme adopto un conjunto de simbolos derivados de la obra original de gilbreth como norma asme para los graficos de procesos (preparada mishad, ramsan y raiaan).  sin embargo, segun explica douglas hartree fueron originalmente herman goldstine y john von neumann quienes desarrollaron el diagrama de flujo (inicialmente llamado \"diagrama\") para planificar los programas de ordenador. las tablas de programacion original de flujo de goldstine y von neumann, aparecen en un informe no publicado, \"planificacion y codificacion de los problemas de un instrumento de computacion electronica, la parte ii, volumen 1 \"(1947), reproducido en las obras completas de von neumann.  inicialmente los diagramas de flujo resultaron un medio popular para describir algoritmos de computadora, y aun se utilizan con este fin. herramientas como los diagramas de actividad uml, pueden ser considerados como evoluciones del diagrama de flujo.  en la decada de 1970 la popularidad de los diagramas de flujo como metodo propio de la informatica disminuyo, con el nuevo hardware y los nuevos lenguajes de programacion de tercera generacion. y por otra parte se convirtieron en instrumentos comunes en el mundo empresarial. son una expresion concisa, legible y practica de algoritmos. actualmente se aplican en muchos campos del conocimiento, especialmente como simplificacion y expresion logica de procesos, etc.  actualmente existe una gran cantidad de software para la elaboracion de diagramas de flujo. a continuacion se listan los programas mas comunes para elaborar diagramas de flujo.  tambien existen aplicaciones que permiten que, una vez que un creador haya diseñado el diagrama de flujo, un usuario final lo utilice y, sobre la base de las opciones que vaya escogiendo, se le vayan mostrando las siguientes etapas hasta llegar a un resultado final. un ejemplo de este tipo de aplicaciones es iboske. ",
        "snippet": "El diagrama de flujo o flujograma o diagrama de actividades es la representación gráfica de un algoritmo o proceso. Se utiliza en disciplinas como programación, economía, procesos industriales y psicología cognitiva.",
        "enlaces_salientes": [
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/L%C3%A1mpara",
            "/wiki/Bucle_for",
            "/wiki/Gr%C3%A1fica",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Econom%C3%ADa",
            "/wiki/Proceso_de_fabricaci%C3%B3n",
            "/wiki/Psicolog%C3%ADa_cognitiva",
            "/wiki/Lenguaje_Unificado_de_Modelado",
            "/wiki/Flujo_de_trabajo",
            "/wiki/SysML",
            "/wiki/Red_de_Petri",
            "/wiki/Instituto_Nacional_Estadounidense_de_Est%C3%A1ndares",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/Estadio_(geometr%C3%ADa)",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/Paralelogramo",
            "/wiki/Campo_de_b%C3%A9isbol#Home_plate",
            "/wiki/Pent%C3%A1gono",
            "/wiki/%C3%93valo",
            "/wiki/Elipse",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/C%C3%ADrculo",
            "/wiki/Tri%C3%A1ngulo",
            "/wiki/Lake_Placid",
            "/wiki/Nueva_York",
            "/wiki/Herman_Goldstine",
            "/wiki/John_von_Neumann",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Ordenador",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Microsoft_Office",
            "/wiki/Microsoft_Word",
            "/wiki/Microsoft_Excel",
            "/wiki/Microsoft_PowerPoint",
            "/wiki/Microsoft_Visio",
            "/wiki/LibreOffice_Draw",
            "/wiki/GitMind",
            "/wiki/XMind",
            "/wiki/DRAKON",
            "/wiki/UML",
            "/wiki/Flujo_de_trabajo",
            "/wiki/Red_de_Petri",
            "/wiki/Diagrama_de_secuencia",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Resoluci%C3%B3n_de_problemas_de_programaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Estructuras_de_control",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Bucle_for",
            "/wiki/Bucle_while",
            "/wiki/Bucle_repetir",
            "/wiki/Bucle_infinito",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/National_Archives_and_Records_Administration",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Ada_Lovelace",
        "titulo": "Ada Lovelace",
        "contenido": "augusta ada king, condesa de lovelace (londres, 10 de diciembre de 1815-id., 27 de noviembre de 1852), registrada al nacer como augusta ada byron y conocida habitualmente como ada lovelace, fue una matematica y escritora britanica, celebre sobre todo por su trabajo acerca de la computadora mecanica de uso general de charles babbage, la denominada maquina analitica. fue la primera en reconocer que la maquina tenia aplicaciones mas alla del calculo puro y en haber publicado lo que se reconoce hoy como el primer algoritmo destinado a ser procesado por una maquina, por lo que se le considera como la primera programadora de ordenadores.​​​  lovelace fue la unica hija legitima del poeta lord byron y anna isabella noel byron. byron se separo de su esposa un mes despues del nacimiento de ada y dejo inglaterra para siempre cuatro meses despues. conmemoro la despedida en un poema que comienza: «¿es tu rostro como el de tu madre, mi bella hija? ¡ada! hija unica de mi casa y mi corazon».​ murio en la guerra de independencia de grecia cuando ada tenia ocho años.  dedujo y previo la capacidad de los ordenadores para ir mas alla de los simples calculos de numeros, mientras que otros, incluido el propio babbage, se centraron unicamente en estas capacidades.​  su posicion social y su educacion la llevaron a conocer a cientificos importantes como andrew crosse, sir david brewster, charles wheatstone, michael faraday y al novelista charles dickens, relaciones que aprovecho para llegar mas lejos en su educacion. entre estas relaciones se encuentra mary somerville, que fue su tutora durante un tiempo, ademas de amiga y estimulo intelectual.​ ada byron se referia a si misma como una cientifica poetisa y como analista (y metafisica).​​  a una edad temprana, su talento matematico la condujo a una relacion de amistad prolongada con el matematico ingles charles babbage, y concretamente con la obra de babbage sobre la maquina analitica.​ entre 1842 y 1843, tradujo un articulo del ingeniero militar italiano luigi menabrea sobre la maquina, que complemento con un amplio conjunto de notas propias, denominado simplemente notas. estas notas contienen lo que se considera como el primer programa de ordenador, esto es, un algoritmo codificado para que una maquina lo procese. las notas de lovelace son importantes en la historia de la computacion. otros historiadores rechazan esta perspectiva y señalan que las notas personales de babbage de los años 1836/1837 contienen los primeros programas para el motor.​ tambien desarrollo una vision de la capacidad de las computadoras para ir mas alla del mero calculo o el calculo de numeros, mientras que muchos otros, incluido el propio babbage, se centraron solo en esas capacidades. su mentalidad de 'ciencia poetica' la llevo a hacer preguntas sobre el motor analitico (como se muestra en sus notas) examinando como los individuos y la sociedad se relacionan con la tecnologia como una herramienta de colaboracion.  ada lovelace fue la unica hija legitima de anna isabella y del poeta lord byron,​ quien esperaba que su hijo fuera un niño y se sintio decepcionado cuando su esposa dio a luz a una niña. nacio el domingo 10 de diciembre de 1815. la niña lleva el nombre de la media hermana de byron, augusta leigh, y fue llamada ada por el propio byron. el 16 de enero de 1816, por orden de lord byron, lady byron se fue a la casa de sus padres en kirkby mallory (leicestershire) llevando a su hija de cinco semanas con ella. aunque la ley inglesa en ese momento otorgaba la custodia total de los hijos al padre en casos de separacion, lord byron no intento reclamar sus derechos parentales, pero solicito que su hermana lo mantuviera informado sobre el bienestar de ada. en abril de 1816 su padre abandono inglaterra huyendo de sus acreedores y del escandalo que se cernia sobre el por los rumores de incesto. meses mas tarde, annabella presento una demanda de separacion. durante los ocho años que lord byron estuvo fuera de su pais hasta su muerte escribia con frecuencia a augusta y preguntaba por la hija de ambos. a lovelace no se le mostro el retrato familiar de su padre hasta que cumplio 20 años.  lovelace no tuvo una relacion cercana con su madre. a menudo la dejaban al cuidado de su abuela materna judith, hon. lady milbanke, que la adoraba. sin embargo, debido a las actitudes sociales de la epoca, que favorecian al marido en cualquier separacion, con el bienestar de cualquier niño que actuara como mitigante, lady byron tuvo que presentarse como una madre amorosa para el resto de la sociedad. esto incluia escribir cartas de ansiedad a lady milbanke sobre el bienestar de su hija, con una nota de presentacion que decia que debia retener las cartas en caso de que tuviera que usarlas para mostrar preocupacion materna.  desde niña ada desperto el interes de una sociedad en la que se vivian continuos escandalos. su madre puso mucho empeño en protegerla, pero solo lo consiguio hasta cierto punto.  lady byron queria darle una educacion esmerada a su hija, muy parecida a la que ella misma habia recibido, pero mas exigente.​ ada no se podia relacionar con otros niños sin la previa aprobacion de su madre, por lo que la mayor parte de su infancia la paso sola o con adultos. su educacion empezo cuando era muy pequeña; a los cuatro años ya tenia preceptores e institutrices. a los ocho años (en 1824) la jornada normal de ada comenzaba con clase de musica a las 10:00 de la mañana, a las 11:15 tocaba lectura de frances, a las 11:30 clase de aritmetica, a las 13:30 hacia deberes, a las 15:15 musica otra vez y a las 16:30 finalizaba con ejercicios de frances. lady byron le impuso una disciplina estricta basada en un sistema de recompensas y castigos, y tambien buscando el estimulo intelectual con lecturas y relaciones con intelectuales. puso mucho empeño en que su hija aprendiera matematicas, disciplina que ella misma practicaba. en este contexto, ada conoce a la matematica y cientifica escocesa mary somerville, que durante un tiempo fue su tutora. somerville, en tanto que mujer cientifica, se convierte en un importante estimulo y gran influencia en su vida. ambas, alumna y tutora, comparten aficiones cientificas estableciendose entre ellas una gran complicidad.​  a medida que ada se iba haciendo mayor, su madre pasaba temporadas fuera de casa, en balnearios o en el campo.  tuvo mala salud, sufrio muchas de las infecciones infantiles y le dolia la cabeza frecuentemente. a los siete años contrajo una enfermedad grave, que la mantuvo postrada durante meses. a los catorce mantuvo reposo durante mas de un año debido al sarampion, lo cual hizo que dedicara largas horas al estudio y a la lectura.  cuando ada tenia 8 años se conocio la muerte de su padre en grecia, en abril de 1824. lady byron se intereso por estrechar lazos con su familia politica. el nuevo y sexto lord byron mantuvo una buena relacion con annabella; este tenia un hijo pequeño un año menor que ada. annabella indujo a ada a escribir una carta a su primo con la esperanza de unir de nuevo a la familia.​  en junio de 1826, ada, que entonces tenia diez años, viajo por primera vez fuera de inglaterra. partio con todo un grupo (en el que se incluia su madre) y el viaje duro 15 meses, durante los cuales ada disfruto de todo lo nuevo que veian sus ojos, de todo lo que escuchaba, descubria, etc. en el otoño de 1827 acabo su viaje y se instalaron directamente en bifrons, una mansion de campo muy alejada de la ciudad. en ese palacio no ocurria nada del interes de ada; ademas su madre estaba frecuentemente fuera de casa, asi que la niña se dedicaba a estudiar y a dejar volar su imaginacion. ese mismo año, ada empezo su formacion en matematicas. a los once años estaba obsesionada con la idea de volar; estaba decidida a inventar una maquina que le permitiera moverse por el aire. su primer paso, en febrero de 1828, fue construir alas. investigo diferentes materiales y tamaños. considero varios materiales para las alas: papel, seda de aceite, alambres y plumas. paso años estudiando la anatomia de las aves para determinar la proporcion correcta entre las alas y el cuerpo, y creando bocetos de su soñado proyecto. decidio escribir un libro, flyology, ilustrando, con placas, algunos de sus hallazgos. decidio que equipo necesitaria; por ejemplo, una brujula, para «atravesar el pais por el camino mas directo», para que pueda superar montañas, rios y valles. su ultimo paso fue integrar steam con el «arte de volar»\".  a principios de 1829 contrajo una enfermedad grave, posiblemente sarampion, que le causo paralisis en las piernas y la obligo a guardar cama hasta mediados de 1832. ese periodo la marco profundamente, pero siguio estudiando. el año de su recuperacion se mudo con su madre a fordhook manor, una mansion situada en ealing, una aldea a 12 km del centro de londres, muy popular entre la aristocracia londinense. durante este tiempo ada vivio su primer romance; se enamoro de un joven, hijo de john hamble, que la ayudaba con los estudios dos horas al dia. vivieron su historia de amor en secreto durante algun tiempo, pero, cuando lady byron se entero, prohibio al joven entrar en su casa y relacionarse con su hija.​  el año que cumplia dieciocho años, ada empezo a asistir a las fiestas de la alta sociedad londinense. en uno de sus primeros eventos conocio a charles babbage, la unica persona que compartiria su fascinacion por las cuestiones de mecanica. babbage tenia cuarenta y cuatro años en ese momento y era conocido, entre otras cosas, por el proyecto que tenia entre manos: una calculadora mecanica que funcionaba sin la ayuda de un humano, llamada la maquina diferencial.  en esos tiempos en inglaterra se hizo famoso un avanzado artilugio, el telar de seda de joseph marie jacquard, con el que ella estaba totalmente fascinada. le maravillaba la posibilidad de idear y construir maquinas, como la de jacquard, que permitieran al ser humano controlar procesos que anteriormente eran incontrolables o lo eran de una forma erratica.  ada y babbage se hicieron amigos. su relacion la estimulo intelectualmente; le ayudo a avanzar en sus especulaciones sobre el calculo hasta concebir una brillante idea: construir un telar de jacquard aplicado a los numeros, o en otras palabras: una computadora.  la maquina diferencial de babbage tenia todos los elementos que entusiasmaban a ada, y principalmente demostraba que un dia las maquinas harian posible volar. la amistad entre el cientifico y la joven duro toda su vida; se escribieron cartas hasta la muerte de ella.  en 1834 ada se relacionaba mucho con william king, al que lady byron habia encargado guiar a su hija moralmente; tambien se encargo de enseñarle matematicas. fue durante esas clases cuando ada se dio cuenta de que su pasion eran las matematicas. ya habia encontrado la disciplina a la que aplicar su extraordinaria inteligencia. el verano de ese año, ada y su madre recorrieron el norte de inglaterra, la zona industrial mas importante, visitando muchas fabricas, donde pudieron ver el telar de jacquard en funcionamiento. durante esa epoca, madre e hija se relacionaban mucho con mary somerville, la matematica mas famosa de su pais. otros conocidos incluyeron a los cientificos andrew crosse, sir david brewster , charles wheatstone, michael faraday y el autor charles dickens.  ada ya era una habitual de la corte victoriana y empezaba a asistir a diversos eventos en los que con frecuencia participaba en los bailes y encandilaba a muchos de sus asistentes, los cuales la describian como un ser encantador. sin embargo, john hobhouse, que habia sido amigo de su padre, fue una excepcion y la describio como «una joven estirada y demacrada pero con algun rasgo de su amigo, especialmente su boca». la descripcion fue hecha despues de su encuentro el 24 de febrero de 1834, en el que ada dejo claro a hobhouse que el no le gustaba, pero esta primera impresion no duro mucho tiempo y posteriormente se hicieron amigos.  en la primavera de 1835 ada conocio a william, lord king. el aristocrata era de una familia muy influyente desde el punto de vista politico, social, intelectual y religioso. poseia varias propiedades importantes y el titulo de lord tenia mas de un siglo de antiguedad, asi que lady byron aprobo su relacion. el 8 de julio de 1835 se casaron, convirtiendose ella en lady king. su residencia paso a ser una gran propiedad en ockham park (ockham, surrey), junto con otra en el fiordo de torridon y una mas en londres. paso su luna de miel en la mansion worthy, situada en asley combe (somerset), la cual habia sido construida en 1799 como un refugio de caza y que el propio king amplio con motivo de su luna de miel. posteriormente la casa se convertiria en su retiro de verano tras volver a ser ampliada.  el matrimonio tuvo tres hijos: byron, el heredero, nacido el 12 de mayo de 1836; anne isabella (llamada annabella, posteriormente lady anne blunt), nacida el 22 de septiembre de 1837; y ralph gordon, nacido el 2 de julio de 1839.  inmediatamente despues del nacimiento de annabella, lady king experimento «una dolorosa y prolongada enfermedad que tardo meses en curarse». entre 1843 y 1844 su madre le encargo a william benjamin carpenter la tarea de educar a los hijos de ada y de actuar como un «instructor moral» para su propia hija.  en 1837, william king paso de baron a vizconde de ockham y tomo otro titulo, el de conde de lovelace. a partir de ese momento, ada siempre firmaria como ada lovelace.  en sus primeros años de matrimonio ada fue muy feliz, pero la falta de ambicion de su marido acabo cansandola, por lo que se refugio de nuevo en las matematicas. decidio que necesitaba buscar un buen mentor que la guiara en su trabajo intelectual y en el verano de 1840 su madre le encontro uno: el famoso matematico y logico augustus de morgan. con su ayuda, ada progreso rapidamente, pero de morgan tuvo un problema como profesor. informo a lady byron de que su hija no se contentaba con aprender las lecciones como cualquier dama; sus preguntas iban mucho mas alla de lo que trataban en las clases y el no queria fomentar esa actitud. de morgan creia (como casi toda la sociedad en esos tiempos) que las mujeres no estaban hechas para estudiar los fundamentos de las matematicas ni de otras ciencias. las preguntas de ada, segun el, eran impropias de una mujer. en definitiva, le inquietaba que su alumna pensase como un hombre. pero lady byron y lord lovelace hicieron caso omiso de la advertencia del profesor y ella continuo con sus estudios.  durante este tiempo en el que se vio obligada a compaginar su faceta de esposa y madre, el intercambio epistolar con su antigua tutora y amiga, mary somerville, representan un gran desahogo para ada. en esta correspondencia lovelace hace participe a su amiga de su frustracion despues de la maternidad y de las dificultades para continuar con sus estudios.​  en 1841 la madre de ada les conto a su hija y a medora leigh que el padre de ambas era el propio lord byron, y el 27 de febrero ada le escribio a su madre: «no estoy ni siquiera sorprendida. de hecho, simplemente me ha confirmado aquello de lo que, por años, no tuve la mas minima duda, pero hubiera considerado impropio por mi parte el haberle insinuado de alguna manera lo que sospechaba». ada no culpo a su padre por la incestuosa relacion sino a augusta leigh: «me temo que ella es inherentemente mas malvada de lo que el fue nunca». esto no evito que la madre de ada intentara destruir la imagen que esta tenia de su padre, sino que la llevo a hacerlo con mayor intensidad. a pesar de lo que cambio su vida despues de casarse, ada y babbage mantuvieron su amistad; el los visitaba a ella y a su marido con frecuencia. en el otoño de 1840, babbage volvio de su estancia en italia preocupado por su proyecto; cada vez le parecia mas dificil llegar a construir el prototipo totalmente operativo de la maquina analitica (o diferencial). no tenia suficientes recursos para financiarla, pero era optimista porque un reconocido cientifico italiano iba a escribir un articulo sobre su proyecto.​  a lo largo de sus enfermedades, continuo su educacion. la obsesion de su madre de desarraigar cualquiera de las locuras de las que acuso a byron fue una de las razones por las que ada aprendio matematicas desde temprana edad. william frend, william king y mary somerville, la destacada investigadora y autora del siglo xix, la educaron en matematicas y ciencias. uno de sus tutores posteriores fue el matematico y logico augustus de morgan. a partir de 1832, cuando tenia diecisiete años, sus habilidades matematicas comenzaron a surgir, y su interes por las matematicas domino la mayor parte de su vida adulta. en una carta a lady byron, de morgan sugirio que la habilidad de su hija en matematicas podria llevarla a convertirse en «una investigadora matematica, quizas de eminencia de primer nivel».  lovelace a menudo cuestionaba suposiciones basicas integrando poesia y ciencia. mientras estudiaba calculo diferencial, le escribio a de morgan:  lovelace creia que la intuicion y la imaginacion eran criticas para la aplicacion efectiva de conceptos matematicos y cientificos. valoraba la metafisica tanto como las matematicas, y las veia como herramientas para explorar «los mundos invisibles que nos rodean».  en 1841, ada escribe a babbage una carta dejando claro que esta interesada en colaborar con el. a babbage le parecio bien la idea, asi ella empezo traduciendo el articulo del cientifico italiano, luigi federico menabrea. con la traduccion del texto ella tenia dos objetivos: dar a conocer el valioso trabajo de su amigo y cumplir su sueño de alcanzar una vida intelectual que la elevase por encima de las exigencias de la maternidad y el matrimonio.[cita requerida]  finalmente llamo a su trabajo notas, que consistia en su propio estudio sobre la maquina analitica, y como anexo, la traduccion del articulo del italiano. babbage la asesoro, pero ada fue enteramente la autora de ese trabajo.  ada dedica gran parte de su estudio a describir con un lenguaje muy tecnico como funcionaria la maquina analitica, pero tambien ofrece una serie de observaciones que dejan clara su aportacion teorica. ella distinguia con claridad entre datos y procesamiento; este pensamiento era revolucionario en su tiempo. ada aspiraba a crear la informatica, que ella llamaba la ciencia de las operaciones. se dio cuenta de las aplicaciones practicas de la maquina analitica y llego incluso a vislumbrar la posibilidad de digitalizar la musica. escribio en las notas: «supongamos, por ejemplo, que las relaciones fundamentales entre los sonidos, en el arte de la armonia, fueran susceptibles de tales expresiones y adaptaciones: la maquina podria componer piezas musicales todo lo largas y complejas que se quisiera». ada tenia una idea clara: la maquina analitica y el telar de jacquard vienen a hacer lo mismo. una frase clave donde se expresa esto es: «puede decirse que la primera teje dibujos algebraicos, del mismo modo que el telar de jacquard teje flores y hojas». ada expresa con claridad las tres funciones que podia cumplir el invento de babbage: procesar formulas matematicas expresadas con simbolos, hacer calculos numericos (su objetivo primordial) y dar resultados algebraicos en notacion literal.  babbage y ada concebian la maquina analitica de manera muy distinta. al primero no le interesaban demasiado sus consecuencias practicas. a ada, por el contrario, le obsesionaban las aplicaciones del invento. ella fue la primera en intuir lo que el invento de babbage significaba para el progreso tecnologico. entendio que la tecnologia utilizada en el telar de jacquard y en la maquina analitica podia aplicarse a todo proceso que implicara tratar datos: de este modo abria camino a una nueva ciencia, la de la computacion de la informacion.​  en 1840 charles babbage viajo a italia para explicar el concepto de la maquina analitica en la universidad de turin. entre la audiencia se encontraba el ingeniero militar y matematico luigi menabrea, quien publicara mas tarde las notas de la conferencia, en frances. a ada se le pidio que hiciera la traduccion de lo escrito por menabrea al ingles, y al hacerlo, añadio un apendice mas extenso que fue un articulo en si mismo, consistiendo en siete notas etiquetadas alfabeticamente de la a a la g. las notas de ada se publicaron en la revista scientific memoir en septiembre de 1843, con el titulo de «sketch of the analytical engine invented by charles babbage»,​ que firmo con sus iniciales a. a. l.  en estas notas, ada escribio:  este algoritmo para calcular los numeros de bernoulli, una serie de fracciones con diferentes aplicaciones en matematicas, se ha considerado por muchos como el primer programa/algoritmo de la historia. consecuentemente, muchos perfiles de la figura de ada lovelace lo celebran como la primera persona programadora de la historia. sin embargo, se ha mantenido durante años la controversia sobre el grado de participacion de babbage en la confeccion de las notas de lovelace. es una controversia complicada debido al hecho de que se ha tomado, en los ultimos años, la contribucion de ada como \"una cuestion de genero\"​ y a la atencion creciente de la promocion de las mujeres en ciencia, tecnologia, ingenieria y matematicas (stem).​  actualmente esta probado que fue babbage la primera persona que hizo lo que se entiende como un programa, ya que escribio algoritmos parecidos entre 6 y 7 años antes de la publicacion del articulo de lovelace en 1843. existen 24 de tales 'programas' y tienen caracteristicas identicas a los de la nota g de lovelace. la idea general de que ella escribio el primer programa de ordenador de la historia es solo un mito​ tratandose en realidad de un trabajo en equipo con babbage.​  en cambio, la aportacion de ada a la informatica fue incluso aun mas importante: con una vision mas amplia que la de babbage, dedujo y previo la capacidad de las maquinas para ir mas alla de los simples calculos de numeros. ada vio las aplicaciones practicas de la maquina, y creyo acertadamente que en el futuro podria incluso componer musica y hacer graficos:   fue la primera persona en darse cuenta de que los numeros almacenados dentro de la maquina analitica podian representar otras cosas mas alla de la magnitud de dichos numeros, es decir, el caracter simbolico de la representacion numerica interna de la maquina. tambien aporto una primera idea de lo que seria el software:   (las palabras en cursiva son de la propia ada).  actualmente se podria decir que ada lovelace fue la primera ingeniera del software,​ algo mas importante que ser programadora, pues ella estudio, desarrollo y creo la documentacion sobre un determinado sistema de procesamiento automatico.  desde un punto de vista moderno, como se entiende lo que significa ser un programador (el que usa un lenguaje intermedio para comunicarle a un ordenador que interprete y ejecute una serie de ordenes), el primero fue alan turing, al desarrollar su maquina de turing. ademas, existen grandes diferencias entre el desarrollo de babbage/lovelace con el de turing: mientras que la maquina analitica era una maquina de proposito especifico (el motor diferencial), la de turing era programable de uso general.​  babbage y ada desarrollaron la gran idea de separar operaciones y datos de la maquinaria, y que las operaciones se pudieran codificar en tarjetas que dirigieran el comportamiento de la maquinaria. pero no fueron mas alla. la propuesta de turing es la de una maquina universal (es decir, una maquina que garantice la ejecucion de cualquier funcion que pueda ser descrita en terminos de la propia maquina), y una representacion uniforme de los datos y de las operaciones, almacenados ambos en la propia maquina.​  en sus notas, lovelace enfatizo la diferencia entre el motor analitico y las maquinas de calculo previas, en particular su capacidad de ser programado para resolver problemas de cualquier complejidad. se dio cuenta de que el potencial del dispositivo se extendia mucho mas alla del mero procesamiento numerico intensivo (number crunching). en sus notas, ella escribio:  este analisis fue un desarrollo importante de las ideas previas sobre las capacidades de los dispositivos informaticos y anticipo las implicaciones de la informatica moderna cien años antes de que se realizaran. walter isaacson atribuye la idea de lovelace sobre la aplicacion de la informatica a cualquier proceso basado en simbolos logicos a una observacion sobre textiles: «cuando vio algunos telares mecanicos que usaban tarjetas perforadas para dirigir el tejido de hermosos diseños, le recordo como la maquina de babbage usaba tarjetas perforadas para hacer calculos».[cita requerida] esta vision es considerada importante por escritores como betty toole y benjamin woolley, asi como por el programador john graham-cumming, cuyo proyecto plan 28 tiene el objetivo de construir la primera maquina analitica completa. de acuerdo con el historiador de informatica y especialista en babbage doron swade:  aunque a lovelace se la conoce como la primera programadora informatica, algunos biografos e historiadores de la informatica afirman lo contrario.  allan g. bromley, en el articulo de 1990 difference and analytical engines:  bruce collier, quien mas tarde escribio una biografia de babbage, escribio en su tesis de doctorado de la universidad de harvard de 1970 que lovelace «hizo una contribucion considerable para publicitar la maquina analitica, pero no hay evidencia de que haya avanzado en el diseño o la teoria de ninguna manera».  eugene eric kim y betty alexandra toole consideran «incorrecto» considerar a lovelace como el primer programador de computadoras, ya que babbage escribio los programas iniciales para su motor analitico, aunque la mayoria nunca se publico. bromley observa varias docenas de programas de muestra preparados por babbage entre 1837 y 1840, todos sustancialmente anteriores a las notas de lovelace. dorothy k. stein considera que las notas de lovelace son «mas un reflejo de la incertidumbre matematica del autor, los propositos politicos del inventor y, sobre todo, del contexto social y cultural en el que se escribio, que un plan para una investigacion cientifica».  en su libro, idea makers, stephen wolfram defiende las contribuciones de lovelace. aunque reconoce que babbage escribio varios algoritmos ineditos para analytical engine antes de las notas de lovelace, wolfram argumenta que «no hay nada tan sofisticado —o tan limpio— como el calculo de ada de los numeros de bernoulli. babbage ciertamente ayudo y comento el trabajo de ada, pero ella era definitivamente la conductora de eso». wolfram luego sugiere que el logro principal de lovelace fue destilar de la correspondencia de babbage «una exposicion clara de la operacion abstracta de la maquina, algo que babbage nunca hizo».  doron swade, un especialista en historia de la informatica conocido por su trabajo en babbage, analizo cuatro afirmaciones sobre lovelace durante una conferencia sobre el motor analitico de babbage:  segun el, solo el cuarto reclamo tenia «alguna sustancia en absoluto». explico que ada era solo una «principiante prometedora» en lugar de genio en matematicas, que comenzo a estudiar conceptos basicos de las matematicas cinco años despues de que babbage concibio el motor analitico por lo que no pudo haber hecho contribuciones importantes, y que ella solo publico el primer programa de computadora en vez de realmente escribirlo. pero esta de acuerdo con que ada fue la unica persona que vio el potencial del motor analitico como una maquina capaz de expresar entidades distintas de las cantidades.  a finales de la decada de 1840, ada se volvio adicta a las carreras de caballos y junto con algunos de sus amigos intentaron crear un modelo matematico que les ayudara a ganar grandes apuestas. el intento fue un absoluto fracaso, generandole a ada miles de libras de deuda y provocando que uno de los miembros del grupo la chantajeara con informar a su marido, cosa que finalmente se vio forzada a confesarle. en la ultima epoca de su vida paso continuos apuros economicos.​  en el verano de 1852, la salud de ada empeoro mucho, llevaba años padeciendo agotamiento nervioso y debilidad general, pero no fue hasta ese año que aparecieron los primeros sintomas del cancer de utero. la enfermedad duro varios meses, durante los cuales su madre tomo el control respecto a sus citas medicas y personales. por influencia de su madre, decidio dejar de ser materialista y adopto ideas religiosas​ que la llevaron a arrepentirse de su vida anterior.​  finalmente, fallecio a los treinta y seis años el 27 de noviembre de 1852, acompañada de lady byron y de william.  fue enterrada, a peticion suya, junto a su padre, en la parroquia del pueblo de hucknall torkard, en nottinghamshire, cerca de la abadia de newstead.​  sugirio el uso de tarjetas perforadas como metodo de entrada de informacion e instrucciones a la maquina analitica.​ ademas introdujo una notacion para escribir programas, principalmente basada en el dominio que ada tenia sobre el texto de luigi menabrea de 1842 (que comento personalmente completandolo con anotaciones que son mas extensas que el texto mismo) sobre el funcionamiento del telar de jacquard asi como de la maquina analitica de babbage. es reseñable ademas su mencion sobre la existencia de ceros o estado neutro en las tarjetas perforadas siendo que las tarjetas representaban para la maquina de babbage numeros decimales y no binarios (8 perforaciones equivaldrian entonces a 8 unidades).  tambien introdujo la posibilidad de que la maquina analitica no fuera solo capaz de realizar calculos matematicos, sino tambien de, entre muchas otras cosas, «producir arte» y componer musica, literatura... de hecho, afirmaba que el invento seria capaz de realizar cualquier cosa que se le pidiera, siempre y cuando supieramos como ordenarselo.​  el lenguaje de programacion ada, creado por el departamento de defensa de los estados unidos, fue nombrado asi en homenaje a ada lovelace. el manual de referencia del lenguaje fue aprobado el 10 de diciembre de 1980, y al estandar de defensa de los estados unidos para el lenguaje mil-std-1815 se le dio el numero del año de su nacimiento.  en 1981, la asociacion de mujeres en informatica inauguro su premio ada lovelace.​​ desde 1998, la british computer society (bcs) ha otorgado la medalla lovelace​ y en 2008 inicio una competencia anual para mujeres estudiantes.​ bcswomen patrocina el coloquio lovelace, una conferencia anual para mujeres universitarias. ada college es una universidad de educacion superior en tottenham hale, londres, centrada en las habilidades digitales.​  desde 1998, la british computer society ha premiado con la lovelace medal (medalla lovelace) en su nombre​ y en 2008 iniciaron una competicion anual para mujeres estudiantes de la informatica.​ en reino unido, el bcswomen lovelace colloquium —conferencia anual para universitarias— tambien lleva su nombre, ada lovelace.​  el dia de ada lovelace (ada lovelace day) es un evento anual celebrado el segundo martes de octubre​ cuyo objetivo es el de elevar el perfil de las mujeres en la ciencia, tecnologia, ingenieria y matematicas (las areas stem). pretende visibilizar, dar reconocimiento y apoyo a las mujeres que trabajan en alguno de estos ambitos, asi como a sus descubrimientos e invenciones, introducir a las mujeres mas jovenes en el mundo de la ciencia y la tecnologia y crear nuevos referentes femeninos. esta jornada internacional, que se empezo a celebrar en 2009 gracias a suw charman-anderson, cuenta con la organizacion de conferencias, talleres, concursos... en todo el mundo. el evento mas representativo es el ada lovelace day live!, celebrado en londres.​ los eventos han incluido wikipedia editatones con el objetivo de mejorar la representacion de las mujeres en wikipedia en terminos de articulos y editores para reducir la no intencionada brecha de genero en wikipedia.[cita requerida]  la iniciativa ada es una organizacion sin animo de lucro dedicada a incrementar la participacion y dedicacion de las mujeres en la cultura libre y en los movimientos open source.​  el edificio b de la escuela politecnica superior de la uam, en la que se imparten los grados de ingenieria informatica y de ingenieria de tecnologias y servicios de telecomunicacion, recibe el nombre de edificio b - ada lovelace. asi mismo, en la universidad de zaragoza se encuentra el edificio ada byron, en el que se imparten las mismas titulaciones que en el de la uam.​  el centro de computadoras en el pueblo de porlock, cerca de donde vivia lovelace, lleva su nombre. ada lovelace house​ es un edificio propiedad del consejo en kirkby-in-ashfield, nottinghamshire, cerca de donde lovelace paso su infancia; el edificio, que anteriormente albergaba las oficinas locales del consejo de distrito, ahora ofrece espacio de oficinas de alta calidad para una serie de empresas locales de nueva creacion.​​  tambien es la inspiracion e influencia de la academia ada developers en seattle, washington. la academia es una organizacion sin fines de lucro que busca aumentar la diversidad en tecnologia mediante la capacitacion de mujeres, personas trans y no binarias para ser ingenieros de software.​  en la universidad de malaga se encuentra el edificio de investigacion ada byron, inaugurado en 2014 y dedicado a la tecnologia informatica.​ el 10 de noviembre de 2009 una de las calles del parque tecnologico de gijon, en asturias, paso a llamarse ada byron en su honor.​  en 2014, la universidad de deusto entrega por primera vez un reconocimiento llamado premio ada byron a la mujer tecnologa, en honor a la informatica. este es un galardon que se concede a las mujeres tecnologas para visibilizar la trayectoria de los personajes femeninos en este ambito. las premiadas son mujeres que tienen como referencias a mujeres cientificas y tecnologas, que lleven siglos aportando al mundo tal y como la que da nombre al premio, ada byron.​  el premio ada byron destaca por valorar el empoderamiento de las mujeres tecnologas y su efecto positivo en el desarrollo y crecimiento sostenible a nivel mundial.  en 2017 fue lanzada la criptomoneda ada de cardano en su homenaje.  en 2018, the new york times publico un obituario tardio para ada lovelace.​  el 27 de julio de 2018, el senador ron wyden presento, en el senado de los estados unidos, la designacion del 9 de octubre de 2018 como dia nacional de ada lovelace: «para honrar la vida y las contribuciones de ada lovelace como una mujer lider en ciencias y matematicas». la resolucion (s.res.592)​ fue considerada y acordada sin enmiendas y con un preambulo por consentimiento unanime.  en la universidad del rosario, en bogota, colombia, se encuentra la sala lovelace, en su honor, del programa de matematicas aplicadas y ciencias de la computacion. se trata de una sala de computacion moderna donde se ven cursos de programacion, algoritmos, estructuras de datos, entre otros.​  en el 197º aniversario de su nacimiento, google le dedico su google doodle.​​ el doodle muestra a lovelace trabajando en una formula entre imagenes que muestran la evolucion de los ordenadores.​  el poeta uruguayo eduardo galeano le dedico el capitulo «las edades de ada», en su libro espejosː una historia casi universal (2009), destacando su papel de pionera al ser la primera programadora de la historia.​  el bicentenario del nacimiento de ada lovelace se celebro con una serie de eventos, que incluyen ada lovelace day: celebrating the achievements of women in science, technology, engineering and maths.​  exposiciones especiales fueron exhibidas por el museo de ciencias de londres, inglaterra y la biblioteca weston (parte de la biblioteca bodleian) en oxford (inglaterra).  en el episodio «spyfall parte 2»' de la temporada 12 de la serie doctor who, «la doctor» se encuentra con la pionera en informatica ada lovelace.  se han localizado seis copias de la primera edicion de 1843 de sketch of the analytical engine con las notas de ada lovelace. tres se llevan a cabo en la universidad de harvard, uno en la universidad de oklahoma y uno en la academia de la fuerza aerea de los estados unidos. el 20 de julio de 2018, la sexta copia se vendio en una subasta a un comprador anonimo por £ 95,000. un facsimil digital de una de las copias en la biblioteca de la universidad de harvard esta disponible en linea. ",
        "snippet": "Augusta Ada King, condesa de Lovelace (Londres, 10 de diciembre de 1815-íd., 27 de noviembre de 1852), registrada al nacer como Augusta Ada Byron y conocida habitualmente como Ada Lovelace, fue una matemática y escritora británica, célebre sobre todo por su trabajo acerca de la computadora mecánica de uso general de Charles Babbage, la denominada máquina analítica. Fue la primera en reconocer que la máquina tenía aplicaciones más allá del cálculo puro y en haber publicado lo que se reconoce hoy como el primer algoritmo destinado a ser procesado por una máquina, por lo que se le considera como la primera programadora de ordenadores.[2]​[3]​[4]​",
        "enlaces_salientes": [
            "/wiki/Ada_Lovelace",
            "/wiki/Ada_Lovelace",
            "/wiki/Ada_Lovelace",
            "/wiki/Antoine_Claudet",
            "/wiki/Londres",
            "/wiki/Reino_Unido_de_Gran_Breta%C3%B1a_e_Irlanda",
            "/wiki/Marylebone",
            "/wiki/Reino_Unido",
            "/wiki/C%C3%A1ncer_uterino",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Lord_Byron",
            "/wiki/Anna_Isabella_Noel_Byron",
            "/wiki/Mary_Somerville",
            "/wiki/Augustus_De_Morgan",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Programador",
            "/wiki/Poeta",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Inventor",
            "/wiki/Traductor",
            "/wiki/Escritor",
            "/wiki/Ingeniero",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Londres",
            "/wiki/10_de_diciembre",
            "/wiki/1815",
            "/wiki/27_de_noviembre",
            "/wiki/1852",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Escritora",
            "/wiki/Computadora",
            "/wiki/Charles_Babbage",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Algoritmo",
            "/wiki/Programador",
            "/wiki/Ordenador",
            "/wiki/Lord_Byron",
            "/wiki/Anna_Isabella_Noel_Byron",
            "/wiki/Guerra_de_independencia_de_Grecia",
            "/wiki/David_Brewster",
            "/wiki/Charles_Wheatstone",
            "/wiki/Michael_Faraday",
            "/wiki/Charles_Dickens",
            "/wiki/Mary_Somerville",
            "/wiki/Luigi_Menabrea",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Alfred_d%27Orsay",
            "/wiki/Anna_Isabella_Noel_Byron",
            "/wiki/Lord_Byron",
            "/wiki/Leicestershire",
            "/wiki/Mary_Somerville",
            "/wiki/Balneario",
            "/wiki/Sarampi%C3%B3n",
            "/wiki/Flyology",
            "/wiki/Charles_Babbage",
            "/wiki/M%C3%A1quina_diferencial",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Mary_Somerville",
            "/wiki/David_Brewster",
            "/wiki/Charles_Wheatstone",
            "/wiki/Michael_Faraday",
            "/wiki/Charles_Dickens",
            "/wiki/Fiordo_de_Torridon",
            "/wiki/Luna_de_miel",
            "/wiki/William_Benjamin_Carpenter",
            "/wiki/Augustus_De_Morgan",
            "/wiki/Italia",
            "/wiki/Mary_Somerville",
            "/wiki/Augustus_De_Morgan",
            "/wiki/Metaf%C3%ADsica",
            "/wiki/Luigi_Federico_Menabrea",
            "/wiki/Scientific_Memoirs_by_Officers_of_the_Medical_and_Sanitary_Departments_of_the_Government_of_India",
            "/wiki/N%C3%BAmero_de_Bernoulli",
            "/wiki/CTIM",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Lenguaje_formal",
            "/wiki/Software",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Programador",
            "/wiki/Alan_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Materialismo",
            "/wiki/Nottinghamshire",
            "/wiki/Tarjetas_perforadas",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Ada_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Departamento_de_Defensa_de_los_Estados_Unidos",
            "/wiki/Asociaci%C3%B3n_de_Mujeres_en_Computaci%C3%B3n",
            "/wiki/British_Computer_Society",
            "/wiki/British_Computer_Society",
            "/wiki/Medalla",
            "/wiki/STEM",
            "/wiki/Londres",
            "/wiki/Brecha_de_g%C3%A9nero_en_Wikipedia",
            "/wiki/Ada_Initiative",
            "/wiki/Escuela_Polit%C3%A9cnica_Superior_(Universidad_Aut%C3%B3noma_de_Madrid)",
            "/wiki/Universidad_Aut%C3%B3noma_de_Madrid",
            "/wiki/Universidad_de_Zaragoza",
            "/wiki/Porlock",
            "/wiki/Universidad_de_Deusto",
            "/wiki/Premio_Ada_Byron",
            "/wiki/Ada_(moneda_digital)",
            "/wiki/The_New_York_Times",
            "/wiki/Ron_Wyden",
            "/wiki/Senado_de_los_Estados_Unidos",
            "/wiki/Google",
            "/wiki/Google_Doodle",
            "/wiki/Eduardo_Galeano",
            "/wiki/Espejos_(libro)",
            "/wiki/Aniversario",
            "/wiki/Universidad_de_Oxford",
            "/wiki/Museo_de_Ciencias_de_Londres",
            "/wiki/Biblioteca_Bodleian",
            "/wiki/Oxford",
            "/wiki/Spyfall",
            "/wiki/Doctor_Who",
            "/wiki/ISBN",
            "/wiki/Mujeres_en_inform%C3%A1tica",
            "/wiki/Mujeres_en_campos_de_CTIM",
            "/wiki/Microsiervos_(blog)",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Matem%C3%A1ticas",
        "titulo": "Matemáticas",
        "contenido": "las matematicas ​​​ (del latin mathematica, y este del griego μαθηματκα, transliterado como mathematika, derivado de μαθημα, tr. mathema (conocimiento) son una ciencia formal que surgio del estudio de las figuras geometricas y la aritmetica con numeros. hoy en dia se suele aceptar que la matematica es una ciencia que investiga patrones.​​​​​  las ciencias naturales han hecho un uso extensivo de la matematica para explicar diversos fenomenos observables, tal como lo expreso eugene paul wigner (premio nobel de fisica en 1963):  galileo galilei, en la misma linea, lo habia expresado asi:  mediante la abstraccion y el uso de la logica en el razonamiento, la matematica ha evolucionado basandose en el calculo y las mediciones, junto con el estudio sistematico de la forma y el movimiento de los objetos fisicos.​ las matematicas, desde sus comienzos, han tenido un fin practico.  las explicaciones que se apoyaban en la logica aparecieron por primera vez con la matematica helenica, especialmente con los elementos de euclides.​ la matematica siguio desarrollandose, con continuas interrupciones, hasta que en el renacimiento las innovaciones matematicas interactuaron con los nuevos descubrimientos cientificos. como consecuencia, hubo una aceleracion en la investigacion que continua hasta la actualidad.  hoy dia, la matematica se usa en todo el mundo como una herramienta esencial en muchos campos, entre los que se encuentran las ciencias naturales,​ las ciencias aplicadas, las humanidades,​​​ la medicina​ y las ciencias sociales,​​​ e incluso disciplinas que, aparentemente, no estan vinculadas con ella, como la musica​ (por ejemplo, en cuestiones de resonancia armonica, cuerda vibrante,​​ etc.) y la literatura.​ las matematicas aplicadas, rama de la matematica destinada a la aplicacion del conocimiento matematico a otros ambitos, inspiran y hacen uso de los nuevos descubrimientos matematicos y, en ocasiones, conducen al desarrollo de nuevas disciplinas. los matematicos​ tambien participan en la matematica pura, sin tener en cuenta la aplicacion de esta ciencia, aunque las aplicaciones practicas de la matematica pura suelen ser descubiertas con el paso del tiempo.  las matematicas son una de las ciencias mas antiguas. florecio primero antes de la antiguedad en mesopotamia,​ en cuanto a la geometria​, india y china, y mas tarde en la antiguedad en grecia y el helenismo. de ahi data la orientacion hacia la tarea de \"demostracion puramente logica\" y la primera axiomatizacion, a saber, la geometria euclidiana​. en la edad media sobrevivio de forma independiente en el primer humanismo de las universidades y en el mundo arabe.  a principios de la era moderna, francois viete introdujo variables y rene descartes inauguro un enfoque computacional de la geometria​​​  mediante el uso de coordenadas. la consideracion de las tasas de cambio (fluxion)​ asi como la descripcion de las tangentes y la determinacion de los contenidos de las superficies (cuadratura)​ condujeron al calculo infinitesimal​ de gottfried wilhelm leibniz e isaac newton​. la mecanica de newton y su ley de la gravitacion fueron tambien una fuente de orientacion de problemas matematicos como el problema de los tres cuerpos​​​ en los siglos siguientes.  otro de los principales problemas de la primera epoca moderna fue la solucion de ecuaciones algebraicas cada vez mas complicadas. para hacer frente a esto, niels henrik abel y evariste galois desarrollaron el concepto de grupo, que describe las relaciones entre las simetrias de un objeto.​​ el algebra mas reciente y, en particular, la geometria algebraica pueden considerarse como una profundizacion de estas investigaciones.  una idea entonces nueva en el intercambio de cartas entre blaise pascal y pierre de fermat en 1654 acerca del problema de los juegos de azar,​​​ aunque  existian otras soluciones discutibles como las de cardano, quien intento matematizarlas. pierre-simon laplace hace un recuento de los diferentes logros hasta 1812 cuando publica su ensayo filosofico sobre las posibilidades.​ las nuevas ideas y metodos conquistaron muchos campos. pero durante siglos, la teoria clasica de la probabilidad se dividio en escuelas separadas. los intentos de definir explicitamente el termino «probabilidad» solo tuvieron exito para casos especiales. solo la publicacion del libro de texto de andrei kolmogorov en 1933 los fundamentos de la teoria de la  probabilidad ​ completo el desarrollo de los fundamentos de la teoria moderna de la probabilidad.  en el transcurso del siglo xix, el calculo infinitesimal​ encontro su forma actual de rigor gracias a los trabajos de augustin-louis cauchy y karl weierstrass. la teoria de conjuntos​ desarrollada por georg cantor hacia finales del siglo xix es tambien indispensable en la matematica actual, aunque las paradojas del concepto ingenuo de conjuntos dejaron claro, en un primer momento, la incierta base sobre la que se asentaban las matematicas.​  el desarrollo de la primera mitad del siglo xx estuvo influenciado por la lista de 23 problemas matematicos​ de david hilbert. uno de los problemas fue el intento de axiomatizar completamente las matematicas; al mismo tiempo, se hicieron grandes esfuerzos de abstraccion, es decir, el intento de reducir los objetos a sus propiedades esenciales. asi, emmy noether desarrollo los fundamentos del algebra moderna,​ felix hausdorff desarrollo la topologia general como el estudio de los espacios topologicos, stefan banach desarrollo probablemente el concepto mas importante del analisis funcional, el espacio de banach que lleva su nombre. un nivel de abstraccion aun mayor, un marco comun para la consideracion de construcciones similares de diferentes areas de las matematicas, fue finalmente creado por la introduccion de la teoria de categorias por samuel eilenberg y saunders mac lane.  la palabra «matematica» (del griego μαθηματκα mathematika, «cosas que se aprenden») viene del griego antiguo μαθημα (mathema), que quiere decir «campo de estudio o instruccion». las matematicas requieren un esfuerzo de instruccion o aprendizaje, refiriendose a areas del conocimiento que solo pueden entenderse tras haber sido instruido en las mismas, como la astronomia. «el arte matematica» (μαθηματκη τεχνη, mathematike tekhne) se contrapondria en esto a la musica, «el arte de las musas» (μουσκη τεχνη, mousike techne), que seria un arte, como la poesia, retorica​​ y similares, que se puede apreciar directamente, «que se puede entender sin haber sido instruido».​ aunque el termino ya era usado por los pitagoricos (matematikoi) en el siglo vi a. c., alcanzo su significado mas tecnico y reducido de «estudio matematico» en los tiempos de aristoteles (siglo iv a. c.). su adjetivo es μαθηματκος (mathematikos), «relacionado con el aprendizaje», lo cual, de manera similar, vino a significar «matematico». en particular, μαθηματκη τεχνη (mathematike tekhne; en latin ars mathematica), significa «el arte matematica».  la forma mas usada es el plural matematicas (cuyo acortamiento, en algunos paises,  es «mates»​​), que tiene el mismo significado que el singular​ y viene de la forma latina mathematica (ciceron), basada en el plural en griego τα μαθηματκα (ta mathematika), usada por aristoteles y que significa, a grandes rasgos, «todas las cosas matematicas». algunos autores, sin embargo, hacen uso de la forma singular del termino; tal es el caso de bourbaki, en el tratado elementos de matematica (elements de mathematique, 1940), destaca la uniformidad de este campo aportada por la vision axiomatica moderna, aunque tambien hace uso de la forma plural como en elements d'histoire des mathematiques (1969),​ posiblemente sugiriendo que es bourbaki quien finalmente realiza la unificacion de las matematicas.​ asi mismo, en el escrito l'architecture des mathematiques (1948)  plantea el tema en la seccion «¿matematicas, singular o plural?» donde defiende la unicidad conceptual de la matematica aunque hace uso de la forma plural en dicho escrito.​​​​  establecer definiciones claras y precisas es el fundamento de la matematica, aunque encontrar  una definicion unica para ella es improbable.​ se muestran algunas reflexiones de reconocidos autores:  el caracter epistemologico y cientifico de la matematica ha sido ampliamente discutido. en la practica, la matematica se emplea para estudiar relaciones cuantitativas, estructuras, relaciones geometricas y las magnitudes variables. los matematicos buscan patrones,​​​​ formulan nuevas conjeturas e intentan alcanzar la verdad matematica mediante deducciones rigurosas. estas les permiten establecer los axiomas y las definiciones apropiados para dicho fin.​​ algunas definiciones clasicas restringen las matematicas al razonamiento sobre cantidades,​ aunque solo una parte de la matematica actual usa numeros,​ predominando el analisis logico de construcciones abstractas no cuantitativas.  existe cierta discusion acerca de si los objetos matematicos, como los numeros​ y puntos, realmente existen o simplemente provienen de la imaginacion humana. el matematico benjamin peirce definio las matematicas como «la ciencia que señala las conclusiones necesarias».​ por otro lado:  se ha discutido el caracter cientifico de las matematicas debido a que sus procedimientos y resultados poseen una firmeza e inevitabilidad inexistentes en otras disciplinas como pueden ser la fisica, la quimica o la biologia. asi, la matematica seria tautologica, infalible y a priori, mientras que otras, como la geologia o la fisiologia, serian falibles y a posteriori. son estas caracteristicas lo que hace dudar de colocarse en el mismo rango que las disciplinas antes citadas. john stuart mill afirmaba:  asi, los matematicos pueden descubrir nuevos procedimientos para resolver integrales o teoremas, pero se muestran incapaces de descubrir un suceso que ponga en duda el teorema de pitagoras​​  o cualquier otro, como si sucede constantemente con las ciencias de la naturaleza.​  la matematica puede ser entendida como ciencia; si es asi debiera señalarse su objeto y su metodo. sin embargo, algunos plantean que la matematica es un lenguaje formal, seguro, eficiente, aplicable al entendimiento de la naturaleza, tal como indico galileo; ademas muchos fenomenos de caracter social, otros de caracter biologico​ o geologico, pueden ser estudiados mediante la aplicacion de ecuaciones diferenciales,​​ calculo de probabilidades o teoria de conjunto.​ precisamente, el avance de la fisica y de la quimica ha exigido la invencion de nuevos conceptos, instrumentos y metodos en la matematica, sobre todo en el analisis real, analisis complejo y el analisis matricial.​  es muy posible que el arte de calcular​​​ haya sido desarrollado antes incluso que la escritura,​​ relacionado fundamentalmente con la contabilidad y la administracion de bienes, el comercio, en la agrimensura y, posteriormente, en la astronomia.  actualmente, todas las ciencias aportan problemas que son estudiados por matematicos, al mismo tiempo que aparecen nuevos problemas dentro de las propias matematicas. por ejemplo, el fisico richard feynman propuso la integral de caminos como fundamento de la mecanica cuantica, combinando el razonamiento matematico y el enfoque de la fisica, pero todavia, no se ha logrado una definicion plenamente satisfactoria en terminos matematicos. igualmente, la teoria de cuerdas, una teoria cientifica en desarrollo que trata de unificar las cuatro fuerzas fundamentales de la fisica, sigue inspirando a las mas modernas matematicas.​  algunas matematicas solo son relevantes en el area en la que estaban inspiradas y son aplicadas para otros problemas en ese campo. sin embargo, a menudo las matematicas inspiradas en un area concreta resultan utiles en muchos ambitos, y se incluyen dentro de los conceptos matematicos generales aceptados. el notable hecho de que incluso la matematica mas pura habitualmente tiene aplicaciones practicas es lo que eugene paul wigner ha definido como «la irrazonable eficacia de las matematicas en las ciencias naturales».​​  como en la mayoria de las areas de estudio, la explosion de los conocimientos en la era cientifica ha llevado a la especializacion de las matematicas. hay una importante distincion entre las matematicas puras y las matematicas aplicadas. la mayoria de los matematicos que se dedican a la investigacion se centran unicamente en una de estas areas y, a veces, la eleccion se realiza cuando comienzan su licenciatura. varias areas de las matematicas aplicadas se han fusionado con otras areas tradicionalmente fuera de las matematicas y se han convertido en disciplinas independientes, como pueden ser la estadistica, la investigacion de operaciones o la informatica.  aquellos que sienten predileccion por las matematicas, consideran que prevalece un aspecto estetico que define a la mayoria de las matematicas. muchos matematicos hablan de la elegancia de la matematica, su intrinseca estetica y su belleza interna. en general, uno de sus aspectos mas valorados es la simplicidad. hay belleza en una simple y contundente demostracion, como la demostracion de euclides​ de la existencia de infinitos numeros primos, y en un elegante analisis numerico que acelera el calculo, asi como en la transformada rapida de fourier. godfrey harold hardy en a mathematician's apology ​ (apologia de un matematico) expreso la conviccion de que estas consideraciones esteticas son, en si mismas, suficientes para justificar el estudio de las matematicas puras. los matematicos con frecuencia se esfuerzan por encontrar demostraciones de los teoremas que son especialmente elegantes, el excentrico matematico paul erdos se refiere a este hecho como la busqueda de pruebas de el libro en el que dios ha escrito sus demostraciones favoritas.​​ la popularidad de la matematica recreativa​​​​ es otra señal que nos indica el placer que produce resolver las preguntas matematicas.  la mayor parte de la notacion​ matematica que se utiliza hoy en dia no se invento hasta el siglo xviii.​​ antes de eso, las matematicas eran escritas con palabras, un minucioso proceso que limitaba el avance matematico. en el siglo xviii, euler, fue responsable de muchas de las notaciones empleadas en la actualidad. la notacion​ moderna hace que las matematicas sean mucho mas facil para los profesionales, pero para los principiantes resulta complicada. la notacion reduce las matematicas al maximo, hace que algunos simbolos​ contengan una gran cantidad de informacion. al igual que la notacion musical, la notacion matematica moderna tiene una sintaxis estricta y codifica la informacion que seria dificil de escribir de otra manera.  el lenguaje matematico tambien puede ser dificil para los principiantes. palabras tales como o y solo tienen significados mas precisos que en lenguaje cotidiano. ademas, palabras como abierto y cuerpo tienen significados matematicos muy concretos. la jerga matematica, o lenguaje matematico, incluye terminos tecnicos como homeomorfismo o integrabilidad. la razon que explica la necesidad de utilizar la notacion y la jerga es que el lenguaje matematico requiere mas precision que el lenguaje cotidiano. los matematicos se refieren a esta precision en el lenguaje y en la logica como el «rigor».  el rigor es una condicion indispensable que debe tener una demostracion matematica. los matematicos quieren que sus teoremas a partir de los axiomas sigan un razonamiento sistematico. esto sirve para evitar teoremas erroneos, basados en intuiciones falibles, que se han dado varias veces en la historia de esta ciencia.​ el nivel de rigor previsto en las matematicas ha variado con el tiempo: los griegos buscaban argumentos detallados, pero en tiempos de isaac newton los metodos empleados eran menos rigurosos. los problemas inherentes de las definiciones que newton utilizaba dieron lugar a un resurgimiento de un analisis cuidadoso y a las demostraciones oficiales del siglo xix. ahora, los matematicos continuan apoyandose entre ellos mediante demostraciones asistidas por ordenador.​  un axioma se interpreta tradicionalmente como una «verdad evidente», pero esta concepcion es problematica. en el ambito formal, un axioma no es mas que una cadena de simbolos, que tiene un significado intrinseco solo en el contexto de todas las formulas derivadas de un sistema axiomatico.  carl friedrich gauss se referia a la matematica como «la reina de las ciencias».​ tanto en el latin original scientiarum regina, asi como en aleman konigin der wissenschaften, la palabra ciencia debe ser interpretada como (campo de) conocimiento. si se considera que la ciencia es el estudio del mundo fisico, entonces las matematicas, o por lo menos las matematicas puras, no son una ciencia.  muchos filosofos creen que las matematicas no son experimentalmente falsables y, por ende, no son una ciencia segun la definicion de karl popper.​ no obstante, en la decada de 1930 una importante labor en la logica matematica demuestra que las matematicas no pueden reducirse a la logica​ y karl popper llego a la conclusion de que «la mayoria de las teorias matematicas son, como las de fisica y biologia, hipotetico-deductivas. por lo tanto, las matematicas puras se han vuelto mas cercanas a las ciencias naturales​ cuyas hipotesis son conjeturas, asi ha sido hasta ahora».​ otros pensadores, en particular imre lakatos, han solicitado una version de falsacionismo​​ para las propias matematicas.​  una vision alternativa es que determinados campos cientificos (como la fisica teorica) son matematicas con axiomas que pretenden corresponder a la realidad. de hecho, el fisico teorico, john michael ziman, propone que la ciencia es «conocimiento publico» y, por tanto, incluye a las matematicas.​ en cualquier caso, las matematicas tienen mucho en comun con distintos campos de las ciencias fisicas, especialmente la exploracion de las consecuencias logicas de las hipotesis. la intuicion​ y la experimentacion tambien desempeñan un papel importante en la formulacion de conjeturas tanto en las matematicas como en las otras ciencias. las matematicas experimentales siguen ganando representacion dentro de las matematicas. el calculo​ y simulacion​ estan jugando un papel cada vez mayor tanto en las ciencias como en las matematicas, atenuando la objecion de que las matematicas no se sirven del metodo cientifico. en 2002 stephen wolfram propuso, en su libro​ un nuevo tipo de ciencia, que la matematica computacional merece ser explorada empiricamente como un campo cientifico.  las opiniones de los matematicos sobre este asunto son muy variadas. muchos matematicos consideran que llamar a su campo ciencia es minimizar la importancia de su perfil estetico, ademas supone negar su historia dentro de las siete artes liberales. otros consideran que hacer caso omiso de su conexion con las ciencias supone ignorar la evidente conexion entre las matematicas y sus aplicaciones en la ciencia y la ingenieria, que ha impulsado considerablemente el desarrollo de las matematicas. otro asunto de debate, que guarda cierta relacion con el anterior, es si la matematica fue creada (como el arte) o descubierta (como la ciencia). este es uno de los muchos temas de incumbencia de la filosofia de las matematicas.  los premios matematicos se mantienen generalmente separados de sus equivalentes en la ciencia. el mas prestigioso premio dentro de las matematicas es la medalla fields,​ fue instaurado en 1936 y se concede cada cuatro años. a menudo se le considera el equivalente del premio nobel para la ciencia. otros premios son el premio wolf en matematica, creado en 1978, que reconoce los logros en vida de los matematicos, y el premio abel, otro gran premio internacional, que se introdujo en 2003. estos dos ultimos se conceden por un excelente trabajo, que puede ser una investigacion innovadora o la solucion de un problema pendiente en un campo determinado. una famosa lista de esos 23 problemas sin resolver​, denominada los «problemas de hilbert», fue recopilada en 1900 por el matematico aleman david hilbert. esta lista ha alcanzado gran popularidad entre los matematicos y, al menos, nueve de los problemas ya han sido resueltos. una nueva lista de siete problemas fundamentales, titulada «problemas del milenio», se publico en 2000. la solucion de cada uno de los problemas sera recompensada con 1 millon de dolares. curiosamente, tan solo uno (la hipotesis de riemann) aparece en ambas listas.  la sociedad matematica americana distingue unas 5.000 ramas distintas de matematica.​ en una subdivision escolarizada de la matematica se distinguen cinco areas de estudio basicas: la cantidad, la estructura, el espacio, el cambio y la variabilidad que se corresponden con la aritmetica, el algebra, la geometria, el calculo, la probabilidad y estadistica. como señalaba richard courant​ «es posible seguir una ruta directa a partir de los elementos fundamentales hasta puntos avanzados» para que puedan divisarse las directrices de la matematica como ciencia. ademas, hay ramas de las matematicas conectadas a otros campos, por ejemplo la logica, teoria de conjuntos y las matematicas aplicadas entre muchas otras tal como indica la sociedad matematica americana.​  2ei4π⁄3  el concepto «matematica aplicada» se refiere a aquellos metodos y herramientas matematicas que pueden ser utilizados en el analisis o resolucion de problemas pertenecientes al area de las ciencias basicas o aplicadas.  muchos metodos matematicos han resultado efectivos en el estudio de problemas en fisica, quimica, biologia,​ medicina,​ ciencias sociales,​ ingenieria, economia,​ finanzas, ecologia entre otras.  sin embargo, una posible diferencia es que en matematica aplicada se procura el desarrollo de la matematica «hacia afuera», es decir su aplicacion o transferencia hacia el resto de las areas. y en menor grado «hacia dentro» o sea, hacia el desarrollo de la matematica misma. este ultimo seria el caso de la matematica pura o matematica elemental.  la matematica aplicada se usa con frecuencia en distintas areas tecnologicas para modelado,​​ simulacion​ y optimizacion de procesos o fenomenos,​ como el tunel de viento o el diseño de experimentos.  la estadistica es la rama de la matematica que estudia la variabilidad, asi como el proceso aleatorio que la genera siguiendo leyes de probabilidad.​ es un conocimiento fundamental para la investigacion cientifica en algunos campos de la tecnologia, como informatica e ingenieria, y de las ciencias facticas,​ como economia,​ genetica, sociologia,​ psicologia,​ medicina,​ contabilidad, etc. en ocasiones, estas areas de conocimiento necesitan aplicar tecnicas estadisticas durante su proceso de investigacion factual, con el fin de obtener nuevos conocimientos basados en la experimentacion y en la observacion, precisando para ello recolectar, organizar, presentar y analizar un conjunto de datos numericos y, a partir de ellos y de un marco teorico, hacer las inferencias apropiadas.​​​​​  se consagra en forma directa al gran problema universal de como tomar decisiones inteligentes y acertadas en condiciones de incertidumbre. la estadistica descriptiva sirve como fuente de instruccion en los niveles basicos de estadistica aplicada a las ciencias facticas​ y, por tanto, los conceptos manejados y las tecnicas empleadas suelen ser presentadas de la forma mas simple y clara posibles. ",
        "snippet": "Las matemáticas [2]​[3]​[4]​ (del latín mathematĭca, y este del griego μαθηματικά, transliterado como mathēmatiká, derivado de μάθημα, tr. máthēma (conocimiento) son una ciencia formal que surgió del estudio de las figuras geométricas y la aritmética con números. Hoy en día se suele aceptar que la matemática es una ciencia que investiga patrones.[5]​[6]​[7]​[8]​[9]​",
        "enlaces_salientes": [
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Papiro_de_Ahmes",
            "/wiki/Ahmes_(escriba)",
            "/wiki/Gregor_Reisch",
            "/wiki/Algorista",
            "/wiki/Euclides",
            "/wiki/Comp%C3%A1s_(instrumento)",
            "/wiki/Rafael_Sanzio",
            "/wiki/La_escuela_de_Atenas",
            "/wiki/Lat%C3%ADn",
            "/wiki/Griego_antiguo",
            "/wiki/Romanizaci%C3%B3n_del_griego",
            "/wiki/Conocimiento",
            "/wiki/Ciencias_formales",
            "/wiki/Figura_geom%C3%A9trica",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Ciencias_naturales",
            "/wiki/Eugene_Paul_Wigner",
            "/wiki/Galileo_Galilei",
            "/wiki/L%C3%B3gica",
            "/wiki/Razonamiento",
            "/wiki/C%C3%A1lculo",
            "/wiki/Medici%C3%B3n",
            "/wiki/Forma_(figura)",
            "/wiki/Movimiento_(f%C3%ADsica)",
            "/wiki/Matem%C3%A1tica_hel%C3%A9nica",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Euclides",
            "/wiki/Renacimiento",
            "/wiki/Ciencias_naturales",
            "/wiki/Ciencias_aplicadas",
            "/wiki/Humanidades",
            "/wiki/Medicina",
            "/wiki/Ciencias_sociales",
            "/wiki/M%C3%BAsica",
            "/wiki/Cuerda_vibrante",
            "/wiki/Matem%C3%A1tica_aplicada",
            "/wiki/Historia_de_las_matem%C3%A1ticas",
            "/wiki/Antig%C3%BCedad",
            "/wiki/Mesopotamia",
            "/wiki/India",
            "/wiki/Historia_de_China",
            "/wiki/Helenismo",
            "/wiki/Axiomatizaci%C3%B3n",
            "/wiki/Geometr%C3%ADa_euclidiana",
            "/wiki/Edad_Media",
            "/wiki/Era_moderna",
            "/wiki/Fran%C3%A7ois_Vi%C3%A8te",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Coordenadas",
            "/wiki/C%C3%A1lculo_infinitesimal#Modernidad",
            "/wiki/Cuadratura_(geometr%C3%ADa)",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Isaac_Newton",
            "/wiki/Mec%C3%A1nica_cl%C3%A1sica",
            "/wiki/Ley_de_gravitaci%C3%B3n_universal",
            "/wiki/Problema_de_los_tres_cuerpos",
            "/wiki/Niels_Henrik_Abel",
            "/wiki/%C3%89variste_Galois",
            "/wiki/Grupo_(matem%C3%A1tica)",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa_algebraica",
            "/wiki/Blaise_Pascal",
            "/wiki/Pierre_de_Fermat",
            "/wiki/Pierre-Simon_Laplace",
            "/wiki/Andr%C3%A9i_Kolmog%C3%B3rov",
            "/wiki/Rigor_matem%C3%A1tico",
            "/wiki/Augustin_Louis_Cauchy",
            "/wiki/Karl_Weierstra%C3%9F",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Georg_Cantor",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/David_Hilbert",
            "/wiki/Emmy_Noether",
            "/wiki/Felix_Hausdorff",
            "/wiki/Topolog%C3%ADa",
            "/wiki/Espacios_topol%C3%B3gicos",
            "/wiki/Stefan_Banach",
            "/wiki/An%C3%A1lisis_funcional",
            "/wiki/Espacio_de_Banach",
            "/wiki/Teor%C3%ADa_de_categor%C3%ADas",
            "/wiki/Samuel_Eilenberg",
            "/wiki/Saunders_Mac_Lane",
            "/wiki/Astronom%C3%ADa",
            "/wiki/Musa",
            "/wiki/Ret%C3%B3rica",
            "/wiki/Pitag%C3%B3ricos",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Marco_Tulio_Cicer%C3%B3n",
            "/wiki/Nicolas_Bourbaki",
            "/wiki/Elementos_de_matem%C3%A1tica",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Mathesis_Universalis",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/David_Hilbert",
            "/wiki/Finitismo",
            "/wiki/Benjamin_Peirce",
            "/wiki/Bertrand_Russell",
            "/wiki/John_David_Barrow",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/Espacio_m%C3%A9trico",
            "/wiki/C%C3%A1lculo",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Conjetura",
            "/wiki/Verdad",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Rigor",
            "/wiki/Axioma",
            "/wiki/Definici%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Definici%C3%B3n",
            "/wiki/Punto_(geometr%C3%ADa)",
            "/wiki/Benjamin_Peirce",
            "/wiki/Albert_Einstein",
            "/wiki/F%C3%ADsica",
            "/wiki/Qu%C3%ADmica",
            "/wiki/Biolog%C3%ADa",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/A_priori_y_a_posteriori",
            "/wiki/Geolog%C3%ADa",
            "/wiki/Fisiolog%C3%ADa",
            "/wiki/John_Stuart_Mill",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Teorema",
            "/wiki/Teorema_de_Pit%C3%A1goras",
            "/wiki/Ciencias",
            "/wiki/Naturaleza",
            "/wiki/Teorema_de_Pit%C3%A1goras",
            "/wiki/%C3%81baco",
            "/wiki/Calculadora",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Suma",
            "/wiki/Resta",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Galileo_Galilei",
            "/wiki/Isaac_Newton",
            "/wiki/Gottfried_Leibniz",
            "/wiki/C%C3%A1lculo",
            "/wiki/Contabilidad",
            "/wiki/Comercio",
            "/wiki/Agrimensura",
            "/wiki/Astronom%C3%ADa",
            "/wiki/F%C3%ADsico",
            "/wiki/Richard_Feynman",
            "/wiki/Integral_de_caminos_(mec%C3%A1nica_cu%C3%A1ntica)",
            "/wiki/Mec%C3%A1nica_cu%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_cuerdas",
            "/wiki/Interacciones_fundamentales",
            "/wiki/Eugene_Paul_Wigner",
            "/wiki/Ciencias_Naturales",
            "/wiki/Matem%C3%A1ticas_puras",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Licenciatura",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Investigaci%C3%B3n_de_operaciones",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Est%C3%A9tica",
            "/wiki/Belleza",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/N%C3%BAmero_primo",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Transformada_r%C3%A1pida_de_Fourier",
            "/wiki/Godfrey_Harold_Hardy",
            "/wiki/Apolog%C3%ADa_de_un_matem%C3%A1tico",
            "/wiki/Paul_Erd%C5%91s",
            "/wiki/Matem%C3%A1tica_recreativa",
            "/wiki/Notaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Leonhard_Euler",
            "/wiki/Siglo_XVIII",
            "/wiki/Leonhard_Euler",
            "/wiki/Notaci%C3%B3n_musical",
            "/wiki/Infinito",
            "/wiki/Lenguaje",
            "/wiki/Conjunto_abierto",
            "/wiki/Cuerpo_(matem%C3%A1ticas)",
            "/wiki/Jerga",
            "/wiki/Homeomorfismo",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Rigor",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Teorema",
            "/wiki/Isaac_Newton",
            "/wiki/Siglo_XIX",
            "/wiki/Axioma",
            "/wiki/Sistema_axiom%C3%A1tico",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/Ciencia",
            "/wiki/F%C3%ADsico",
            "/wiki/Matem%C3%A1ticas_puras",
            "/wiki/Falsacionismo",
            "/wiki/Karl_Popper",
            "/wiki/A%C3%B1os_1930",
            "/wiki/F%C3%ADsica",
            "/wiki/Biolog%C3%ADa",
            "/wiki/M%C3%A9todo_hipot%C3%A9tico-deductivo",
            "/wiki/Hip%C3%B3tesis_(l%C3%B3gica)",
            "/wiki/Imre_Lakatos",
            "/wiki/Falsacionismo",
            "/wiki/F%C3%ADsica_te%C3%B3rica",
            "/wiki/Axiomas",
            "/wiki/John_Michael_Ziman",
            "/wiki/Ciencias_f%C3%ADsicas",
            "/wiki/Intuici%C3%B3n",
            "/wiki/Experimentaci%C3%B3n",
            "/wiki/Conjeturas",
            "/wiki/C%C3%A1lculo",
            "/wiki/M%C3%A9todo_cient%C3%ADfico",
            "/wiki/Stephen_Wolfram",
            "/wiki/Un_nuevo_tipo_de_ciencia",
            "/wiki/Matem%C3%A1tica_computacional",
            "/wiki/Est%C3%A9tico",
            "/wiki/Artes_liberales",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Debate",
            "/wiki/Filosof%C3%ADa_de_la_matem%C3%A1tica",
            "/wiki/Medalla_Fields",
            "/wiki/Premio_Nobel",
            "/wiki/Premio_Abel",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/David_Hilbert",
            "/wiki/Problemas_del_milenio",
            "/wiki/Hip%C3%B3tesis_de_Riemann",
            "/wiki/%C3%81reas_de_las_matem%C3%A1ticas",
            "/wiki/Sociedad_Matem%C3%A1tica_Americana",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/C%C3%A1lculo",
            "/wiki/Probabilidad",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Richard_Courant",
            "/wiki/L%C3%B3gica",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Matem%C3%A1ticas_puras",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/N%C3%BAmero_real",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/Combinatoria",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Teor%C3%ADa_de_grupos",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Teor%C3%ADa_del_orden",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Trigonometr%C3%ADa",
            "/wiki/Geometr%C3%ADa_diferencial",
            "/wiki/Topolog%C3%ADa",
            "/wiki/Fractal",
            "/wiki/Teor%C3%ADa_de_la_medida",
            "/wiki/C%C3%A1lculo",
            "/wiki/C%C3%A1lculo_vectorial",
            "/wiki/Ecuaci%C3%B3n_diferencial",
            "/wiki/Sistema_din%C3%A1mico",
            "/wiki/Teor%C3%ADa_del_caos",
            "/wiki/An%C3%A1lisis_complejo",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Ciencias_f%C3%A1cticas",
            "/wiki/F%C3%ADsica_matem%C3%A1tica",
            "/wiki/Mec%C3%A1nica_de_fluidos",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Teor%C3%ADa_de_la_probabilidad",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Matem%C3%A1tica_financiera",
            "/wiki/Teor%C3%ADa_de_juegos",
            "/wiki/Biolog%C3%ADa_matem%C3%A1tica",
            "/wiki/Qu%C3%ADmica_matem%C3%A1tica",
            "/wiki/Econom%C3%ADa_matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_control",
            "/wiki/Belleza_matem%C3%A1tica",
            "/wiki/Filosof%C3%ADa_de_las_matem%C3%A1ticas",
            "/wiki/Fundamentos_de_las_matem%C3%A1ticas",
            "/wiki/Matem%C3%A1ticas_y_arquitectura",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Olimpiada_Internacional_de_Matem%C3%A1tica",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Euclides",
            "/wiki/Keith_Devlin",
            "/wiki/ISBN",
            "/wiki/Mate_(infusi%C3%B3n)",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Demostraci%C3%B3n_inv%C3%A1lida",
            "/wiki/Teorema_de_los_cuatro_colores",
            "/wiki/ISBN",
            "/wiki/Constante_macabra",
            "/wiki/Funci%C3%B3n_gaussiana",
            "/wiki/Eric_Temple_Bell",
            "/wiki/Albert_Einstein",
            "/wiki/Benjamin_Peirce",
            "/wiki/Karl_Popper",
            "/wiki/Wolfgang_Sartorius_von_Waltershausen",
            "/wiki/Wolfgang_Sartorius_von_Waltershausen",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Historical_Dictionary_of_Switzerland",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Medical_Subject_Headings"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/L%C3%B3gica",
        "titulo": "Lógica",
        "contenido": "la logica es una rama de la filosofia​ de caracter interdisciplinario, entendida como la ciencia formal que estudia los principios de la  demostracion y la inferencia valida,​ las falacias, las paradojas y la nocion de verdad.​  la logica se divide en varias categorias segun su campo de estudio. la logica filosofica estudia el concepto y la definicion, la enunciacion o proposicion y la argumentacion utilizando los metodos y resultados de la logica moderna para el estudio de problemas filosoficos. la logica matematica estudia la inferencia mediante sistemas formales como la logica proposicional, la logica de primer orden y la logica modal. la logica informal se enfoca en el desarrollo linguistico de los razonamientos y sus falacias. la logica computacional es la aplicacion de la logica matematica a las ciencias de la computacion.  los origenes de la logica se remontan a la edad antigua, con brotes independientes en china, india y grecia. desde entonces, la logica tradicionalmente se considera una rama de la filosofia, pero en el siglo xx la logica ha pasado a ser principalmente la logica matematica, y por lo tanto ahora tambien se considera parte de las matematicas, e incluso una ciencia formal independiente.  no existe un acuerdo universal sobre la definicion exacta o los limites de la logica.​​​ sin embargo, el ambito de la logica (interpretada en sentido amplio) incluye:  historicamente, la logica se ha estudiado principalmente en filosofia desde la antiguedad, en matematicas desde mediados del siglo xix y en informatica desde mediados del siglo xx. mas recientemente, la logica tambien se ha estudiado en linguistica y en ciencias cognitivas. en general, la logica sigue siendo un area de estudio fuertemente interdisciplinaria.  la palabra «logica» deriva del griego antiguo λογκη logike, que significa «dotada de razon, intelectual, dialectica, argumentativa» y que a su vez viene de λογος (logos), «palabra, pensamiento, idea, argumento, razon o principio».​​[i]​  en el lenguaje cotidiano, expresiones como «logica» o «pensamiento logico» aportan tambien un sentido alrededor de un «pensamiento lateral» comparado, haciendo los contenidos de la afirmacion coherentes con un contexto, bien sea del discurso o de una teoria de la ciencia, o simplemente con las creencias o evidencias transmitidas por la tradicion cultural.  del mismo modo existe el concepto sociologico y cultural de logica como por ejemplo «logica deportiva», que en general, podriamos considerar como «logica cotidiana» - tambien conocida como «logica del sentido comun».  en estas areas la «logica» suele tener una referencia linguistica en la pragmatica.  un argumento en este sentido tiene su «logica» cuando resulta convincente, razonable y claro; en definitiva cuando cumple una funcion de eficacia. la habilidad de pensar y expresar un argumento asi corresponde a la retorica, cuya relacion con la verdad es una relacion probable.  la inferencia es el proceso por el cual se derivan conclusiones a partir de premisas o hipotesis iniciales.​ cuando una conclusion se sigue de sus premisas o hipotesis de partida, por medio de deducciones logicas validas, se dice que las premisas implican la conclusion.  la inferencia es el objeto de estudio tradicional de la logica, asi como la vida es el objeto de estudio de la biologia. la logica investiga los fundamentos por los cuales algunas inferencias son aceptables, y otras no. cuando una inferencia es aceptable, lo es por su estructura logica y no por el contenido especifico del argumento o el lenguaje utilizado (retorica). por esto se construyen sistemas logicos que capturan los factores relevantes de las deducciones que aparecen en el lenguaje natural.​  tradicionalmente, se distinguen tres clases de inferencias: las deducciones, las inducciones y las abducciones, aunque a veces se cuenta a la abduccion como un caso especial de induccion.​ las inducciones se estudian desde la logica inductiva y el problema de la induccion. las deducciones, en cambio, son estudiadas por la mayor parte de la logica contemporanea.​  en logica, la validez es una propiedad que tienen los argumentos cuando las premisas implican la conclusion. si la conclusion es una consecuencia logica de las premisas, se dice que el argumento es deductivamente valido.​ algunos consideran estas dos nociones identicas y usan ambos terminos indistintamente. otros, sin embargo, consideran que puede haber argumentos que no sean deductivamente validos, como las inducciones. en cualquier caso, de las inducciones a veces se dice que son buenas o malas, en vez de validas o invalidas.  ejemplos de argumentos deductivamente validos son los siguientes:  para que un argumento sea lo que le da principalmente la validez a un argumento es la seguridad con lo que lo dice la persona y que tenga razon con lo que dice deductivamente valido, no es necesario que las premisas o la conclusion sean verdaderas. solo se requiere que la conclusion sea una consecuencia logica de las premisas. la logica formal exige unicamente una relacion condicional entre las premisas y la conclusion. esto es: que si las premisas son verdaderas, entonces la conclusion tambien lo es (esta es la caracterizacion semantica de la nocion de consecuencia logica); o alternativamente: que la conclusion sea deducible de las premisas conforme a las reglas de un sistema logico (esta es la caracterizacion sintactica de la nocion de consecuencia logica). si un argumento, ademas de ser valido, tiene premisas verdaderas, entonces se dice que es solido.  en logica, una falacia (del latin fallacia ‘engaño’) es un argumento que parece valido, pero no lo es.​​ algunas falacias se cometen intencionadamente para persuadir o manipular a los demas, mientras que otras se cometen sin intencion debido a descuidos o ignorancia. en ocasiones las falacias pueden ser muy sutiles y persuasivas, por lo que se debe poner mucha atencion para detectarlas.​  que un argumento sea falaz no implica que sus premisas o su conclusion sean falsas ni que sean verdaderas. un argumento puede tener premisas y conclusion verdaderas y aun asi ser falaz. lo que hace falaz a un argumento es la invalidez del argumento en si. de hecho, inferir que una proposicion es falsa porque el argumento que la contiene por conclusion es falaz es en si una falacia conocida como argumento ad logicam.​  el estudio de las falacias se remonta por lo menos hasta aristoteles, quien en sus refutaciones sofisticas identifico y clasifico trece clases de falacias.​ desde entonces se han agregado a la lista cientos de otras falacias y se han propuesto varios sistemas de clasificacion.​  el uso de la palabra verdad abarca asimismo la honestidad, la buena fe y la sinceridad humana en general; tambien el acuerdo de los conocimientos con las cosas que se afirman como realidades: los hechos o la cosa en particular;​ y, finalmente, la relacion de los hechos o las cosas en su totalidad en la constitucion del todo, el universo.​  las cosas son verdaderas cuando son «fiables», fieles porque cumplen lo que ofrecen.​​  el termino no tiene una unica definicion en la que esten de acuerdo la mayoria de los estudiosos y las teorias sobre la verdad continuan siendo ampliamente debatidas. hay posiciones diferentes acerca de cuestiones como:  este articulo procura introducir las principales interpretaciones y perspectivas, tanto historicas como actuales, acerca de este concepto.  la pregunta por la verdad es y ha sido objeto de debate entre teologos, filosofos y logicos a lo largo de los siglos considerandose un tema concerniente al alma y al estudio de una llamada psicologia racional dentro del campo de la filosofia.  en la actualidad es un tema de investigacion cientifica asi como de fundamentacion filosofica:​  el lenguaje, tambien llamada logica simbolica, logica teoretica, logica formal o logistica,​ es el estudio formal y simbolico de la logica y su aplicacion a algunas areas de la matematica y la ciencia. comprende la aplicacion de las tecnicas de la logica formal a la construccion y el desarrollo de las matematicas y el razonamiento matematico, y conversamente la aplicacion de tecnicas matematicas a la representacion y el analisis de la logica formal. la investigacion en logica matematica ha jugado un papel crucial en el estudio de los fundamentos de las matematicas.  la logica matematica estudia la inferencia mediante la construccion de sistemas formales como la logica proposicional, la logica de primer orden o la logica modal. estos sistemas capturan las caracteristicas esenciales de las inferencias validas en los lenguajes naturales, pero al ser estructuras formales susceptibles de analisis matematico, permiten realizar demostraciones rigurosas sobre ellas.  la logica matematica se suele dividir en cuatro areas: teoria de modelos, teoria de la demostracion, teoria de conjuntos y teoria de la computabilidad. la teoria de la demostracion y la teoria de modelos fueron el fundamento de la logica matematica. la teoria de conjuntos se origino en el estudio del infinito por georg cantor y ha sido la fuente de muchos de los temas mas desafiantes e importantes de la logica matematica, desde el teorema de cantor, el axioma de eleccion y la cuestion de la independencia de la hipotesis del continuo, al debate moderno sobre grandes axiomas cardinales. la logica matematica tiene estrechas conexiones con las ciencias de la computacion. la teoria de la computabilidad captura la idea de la computacion en terminos logicos y aritmeticos. sus logros mas clasicos son la indecidibilidad del entscheidungsproblem de alan turing y su presentacion de la tesis de church-turing. hoy en dia, la teoria de la computabilidad se ocupa principalmente del problema mas refinado de las clases de complejidad (¿cuando es un problema eficientemente solucionable?) y de la clasificacion de los grados de insolubilidad.  la logica matematica tambien estudia las definiciones de nociones y objetos matematicos basicos como conjuntos, numeros, demostraciones y algoritmos. la logica matematica estudia las reglas de deduccion formales, las capacidades expresivas de los diferentes lenguajes formales y las propiedades metalogicas de los mismos.  en un nivel elemental, la logica proporciona reglas y tecnicas para determinar si es o no valido un argumento dado dentro de un determinado sistema formal. en un nivel avanzado, la logica matematica se ocupa de la posibilidad de axiomatizar las teorias matematicas, de clasificar su capacidad expresiva, y desarrollar metodos computacionales utiles en sistemas formales. la teoria de la demostracion y la matematica inversa son dos de los razonamientos mas recientes de la logica matematica abstracta. debe señalarse que la logica matematica se ocupa de sistemas formales que pueden no ser equivalentes en todos sus aspectos, por lo que la logica matematica no es un metodo para descubrir verdades del mundo fisico real, sino solo una fuente posible de modelos logicos aplicables a teorias cientificas, muy especialmente a la matematica convencional.  la logica computacional es la misma logica matematica aplicada al contexto de las ciencias de la computacion. su uso es fundamental en varios niveles: en los circuitos computacionales, en la programacion logica y en el analisis y optimizacion (de recursos temporales y espaciales) de algoritmos.  la logica se extiende al corazon de la informatica a medida que surge como una disciplina: el trabajo de alan turing sobre el entscheidungsproblem seguido del trabajo de kurt godel sobre  teoremas incompletos. la nocion de la computadora de uso general que surgio de este trabajo fue de gran importancia para los diseñadores de la maquinaria informatica en la decada de 1940.  en los años 50 y 60, investigaciones predijeron que, cuando el conocimiento humano se pudiera expresar usando la logica con notaciones matematicas, seria posible crear una maquina capaz de razonar o una inteligencia artificial. esto fue mas dificil de lo esperado a causa de la complejidad del razonamiento humano. en la logica de programacion, un programa consiste en una coleccion de axiomas y reglas. los sistemas de programacion logicos (como prolog) calculan las consecuencias de los axiomas y las reglas organizadas para responder a una consulta.  hoy en dia, la logica es extensamente aplicada en los campos de inteligencia artificial y de ciencias de computacion, y estos campos proporcionan una rica fuente de problemas en la logica formal e informal. la teoria de la argumentacion es un buen ejemplo de como la logica esta siendo aplicada a la inteligencia artificial. el sistema de clasificacion computacional acm, en particular, considera:  entendida en un sentido estricto, la logica filosofica es el area de la filosofia que estudia la aplicacion de metodos logicos a problemas filosoficos, a menudo en forma de sistemas logicos extendidos como la logica modal. algunos teoricos conciben la logica filosofica en un sentido mas amplio como el estudio del alcance y la naturaleza de la logica en general. en este sentido, la logica filosofica puede considerarse identica a la filosofia de la logica, que incluye temas adicionales como la definicion de la logica o la discusion de los conceptos fundamentales de la logica. el presente articulo trata la logica filosofica en el sentido estricto, en el que constituye un campo de investigacion dentro de la filosofia de la logica.  un tema importante para la logica filosofica es la cuestion de como clasificar la gran variedad de sistemas logicos no clasicos, muchos de los cuales son de origen bastante reciente. una forma de clasificacion que se encuentra a menudo en la literatura es distinguir entre logicas extendidas y logicas desviadas. la logica misma puede definirse como el estudio de la inferencia valida. la logica clasica es la forma dominante de la logica y articula reglas de inferencia de acuerdo con intuiciones logicas compartidas por muchos, como el principio del tercero excluido, la eliminacion de la doble negacion y la bivalencia de la verdad.  las logicas extendidas son sistemas logicos que se basan en la logica clasica y sus reglas de inferencia, pero la extienden a nuevos campos introduciendo nuevos simbolos logicos y las correspondientes reglas de inferencia que rigen estos simbolos. en el caso de la logica modal aletica, estos nuevos simbolos se utilizan para expresar no solo lo que es verdadero simpliciter, sino tambien lo que es posible o necesariamente verdadero. a menudo se combina con la semantica de los mundos posibles, que sostiene que una proposicion es posiblemente verdadera si es verdadera en algun mundo posible, mientras que es necesariamente verdadera si es verdadera en todos los mundos posibles. la logica deontica pertenece a la etica y proporciona un tratamiento formal de las nociones eticas, como la obligacion y el permiso. la logica temporal formaliza las relaciones temporales entre proposiciones. esto incluye ideas como si algo es verdadero en algun momento o todo el tiempo y si es verdadero en el futuro o en el pasado. la logica epistemica pertenece a la epistemologia. puede usarse para expresar no solo lo que es el caso, sino tambien lo que alguien cree o sabe que es el caso. sus reglas de inferencia articulan lo que se desprende del hecho de que alguien tiene estos tipos de estados mentales. las logicas de orden superior no aplican directamente la logica clasica a ciertos subcampos nuevos dentro de la filosofia, sino que la generalizan al permitir la cuantificacion no solo sobre individuos sino tambien sobre predicados.  el organon fue el conjunto de trabajos de aristoteles sobre logica, constituyendo los primeros analiticos el primer trabajo explicito de logica formal, introduciendo la silogistica.​ las partes de la logica silogistica, tambien conocida con el nombre de logica de terminos, son el analisis de los juicios en proposiciones que consisten en dos terminos que estan relacionados por una de un numero fijo de relaciones, y la expresion de inferencias mediante silogismos que consisten en dos proposiciones que comparten un termino comun como premisa, y una conclusion que es una proposicion que involucra los dos terminos no relacionados de las premisas.  la obra de aristoteles fue considerada en la epoca clasica y a partir de la epoca medieval en europa y oriente medio como la imagen misma de un sistema totalmente elaborado. sin embargo, no fue el unico: los estoicos propusieron un sistema de logica proposicional que fue estudiado por los logicos medievales. tambien el problema de la generalidad multiple fue reconocido en la epoca medieval. no obstante, no se consideraba que los problemas de la logica silogistica necesitaran soluciones revolucionarias.  hoy en dia, algunos academicos afirman que el sistema de aristoteles es generalmente visto como algo que tiene poco mas que valor historico (aunque hay algun interes actual en la ampliacion de la logica de terminos), considerado como obsoleto por el advenimiento de la logica proposicional y el calculo de predicados. otros utilizan a aristoteles en la teoria de la argumentacion para ayudar a desarrollar y cuestionar criticamente los «esquemas de argumentacion» que se utilizan en la inteligencia artificial y en los argumentos  legales.  un calculo o logica proposicional (tambien un calculo sentencial) es un sistema formal en el que las formulas que representan proposiciones pueden formarse combinando  proposiciones atomicas (normalmente representadas con p, q, etc.) utilizando  conectivos logicos ( a n d , → , ∨ , ≡ , ∼ , etc.); estas proposiciones y conectivas son los unicos elementos de un calculo proposicional estandar.​ a diferencia de la logica de predicados o la logica silogistica, donde los sujetos y predicados individuales (que no tienen valores de verdad) son la unidad mas pequeña, la logica proposicional toma proposiciones completas con valores de verdad como su componente mas basico.​ los cuantificadores (por ejemplo, p a r a t o d o s o e x i s t e ) se incluyen en el calculo proposicional extendido, pero solo cuantifican sobre proposiciones completas, no sobre sujetos o predicados individuales.​ una logica proposicional dada es un sistema de prueba formal con reglas que establecen que formulas bien formadas de un lenguaje dado son \"teoremas\" demostrandolos a partir de axiomas que se asumen sin prueba.​  en el lenguaje, la modalidad se ocupa del fenomeno de que las subpartes de una oracion pueden tener su semantica modificada por verbos especiales o particulas modales. por ejemplo, \"vamos a los juegos puede modificarse para dar \"debemos ir a los juegos', y \"podemos ir a los juegos y quizas \"iremos a los juegos. de forma mas abstracta, podriamos decir que la modalidad afecta a las circunstancias en las que damos por satisfecha una afirmacion. la confusion de la modalidad se conoce como falacia modal.  la logica de aristoteles se ocupa en gran parte de la teoria de la logica no modalizada. aunque, hay pasajes en su obra, como el famoso argumento de la batalla naval en sobre la interpretacion § 9, que ahora se ven como anticipaciones de la logica modal y su conexion con la potencialidad y el tiempo, el primer sistema formal de logica modal fue desarrollado por avicena, que finalmente desarrollo una teoria de la \"temporal modalizada\" silogistica.​  aunque el estudio de la necesidad y la posibilidad siguio siendo importante para los filosofos, apenas se produjeron innovaciones logicas hasta las historicas investigaciones de c. i. lewis en 1918, quien formulo una familia de axiomatizaciones rivales de la  modalidades aleatorias. su trabajo desato un torrente de nuevos trabajos sobre el tema, ampliando los tipos de modalidad tratados para incluir la logica deontica y la logica epistemica.  el trabajo seminal de arthur prior aplico el mismo lenguaje formal para tratar la logica temporal y preparo el camino para la union de los dos temas. saul kripke descubrio (contemporaneamente con prior) su teoria de la semantica de kripke, que revoluciono la tecnologia formal disponible para los logicos modales y dio una nueva teoria de grafos forma de ver la modalidad que ha impulsado muchas aplicaciones en linguistica computacional y informatica, como la logica dinamica.  la logica de predicados es el termino generico para los sistemas formales simbolicos como la logica de primer orden, la logica de segundo orden, la logica de muchos ordenes y la logica infinitaria.  proporciona una cuenta de  cuantificadores lo suficientemente general para expresar un amplio conjunto de argumentos que ocurren en el lenguaje natural. por ejemplo, la famosa paradoja del barbero de bertrand russell, \"hay un hombre que afeita a todos y solo a los hombres que no se afeitan a si mismos\", puede formalizarse mediante la sentencia ( ∃ x ) ( hombre ( x ) ∧ ( ∀ y ) ( hombre ( y ) → ( afeita ( x , y ) ↔ ¬ afeitan ( y , y ) ) }(x)\\wedge (\\forall y)(}(y)\\rightarrow (}(x,y)\\leftrightarrow \\neg }(y,y))} , utilizando el predicado no logico hombre ( x ) }(x)} para indicar que x es un hombre, y la relacion no logica afeita ( x , y ) }(x,y)} para indicar que x afeita a y; todos los demas simbolos de las formulas son logicos, y expresan el cuantificadores universal y existencial, la conjuncion, el implicacion, la  negacion y el bicondicional.  mientras que la logica silogistica aristotelica especifica un pequeño numero de formas que puede adoptar la parte relevante de los juicios implicados, la logica de predicados permite analizar las oraciones en sujeto y argumento de varias formas adicionales, permitiendo a la logica de predicados resolver el problema de la generalidad multiple que habia dejado perplejos a los logicos medievales.  el desarrollo de la logica de predicados suele atribuirse a gottlob frege, a quien tambien se le atribuye el merito de ser uno de los fundadores de la filosofia analitica, pero la formulacion de la logica de predicados mas utilizada hoy en dia es la logica de primer orden presentada en principios de logica matematica por david hilbert y wilhelm ackermann en 1928. la generalidad analitica de la logica de predicados permitio la formalizacion de las matematicas, impulso la investigacion de la teoria de conjuntos y permitio el desarrollo del enfoque de alfred tarski sobre la teoria de modelos. proporciona la base de la logica matematica moderna.  el sistema original de logica de predicados de frege era de segundo orden, en lugar de primer orden. la logica de segundo orden es defendida de manera mas prominente (contra las criticas de willard van orman quine y otros) por george boolos y stewart shapiro.  las logicas discutidas anteriormente son todas \"bivalentes\" o \"de dos valores\"; es decir, se entienden de forma mas natural como la division de las proposiciones en verdaderas y falsas. los sistemas de logica no clasica son aquellos que rechazan varias reglas de la logica clasica.  hegel desarrollo su propia logica dialectica que amplio la logica trascendental de kant pero tambien la devolvio a la tierra asegurando que ni en el cielo ni en la tierra, ni en el mundo de la mente ni en el de la naturaleza, existe en ninguna parte un \"o\" abstracto como el que sostiene el entendimiento. todo lo que existe es concreto, con diferencia y oposicion en si mismo.​  en 1910, nicolai a. vasiliev amplio la ley del medio excluido y la ley de la contradiccion y propuso la ley del cuarto excluido y la logica tolerante a la contradiccion.​ a principios del siglo xx, jan łukasiewicz investigo la ampliacion de los valores tradicionales de verdadero/falso para incluir un tercer valor, \"posible\" (o indeterminado, una hipotesis) inventando asi la logica ternaria, la primera logica plurivalente de la tradicion occidental.​ una modificacion menor de la logica ternaria fue introducida posteriormente en un modelo de logica ternaria de hermanos propuesto por stephen cole kleene. el sistema de kleene difiere de la logica de łukasiewicz con respecto a un resultado de la implicacion. el primero supone que el operador de implicacion entre dos hipotesis produce una hipotesis.  desde entonces se han ideado logicas como la logica difusa con un numero infinito de \"grados de verdad\", representados por un numero real entre 0 y 1.​  la logica intuicionista fue propuesta por l.e.j. brouwer como la logica correcta para razonar sobre las matematicas, basandose en su rechazo del principio del tercero excluido como parte de su intuicionismo. brouwer rechazo la formalizacion en matematicas, pero su alumno arend heyting estudio la logica intuicionista formalmente, al igual que gerhard gentzen. la logica intuicionista es de gran interes para los informaticos, ya que es una logica intuicionista y ve muchas aplicaciones, como la extraccion de programas verificados a partir de pruebas y la influencia en el diseño de lenguajes de programacion a traves de la  correspondencia formula-como-tipos.  la logica modal no es condicional de verdad, por lo que a menudo se ha propuesto como una logica no clasica. sin embargo, la logica modal se formaliza normalmente con el principio del medio excluido, y su semantica relacional es bivalente, por lo que esta inclusion es discutible.  la historia de la logica documenta el desarrollo de la logica en varias culturas y tradiciones a lo largo de la historia. aunque muchas culturas han empleado intrincados sistemas de razonamiento, e, incluso, el pensamiento logico estaba ya implicito en babilonia en algun sentido, la logica como analisis explicito de los metodos de razonamiento ha recibido un tratamiento sustancial solo originalmente en tres tradiciones: la antigua china, la antigua india y la antigua grecia.  aunque las dataciones exactas son inciertas, particularmente en el caso de la india, es probable que la logica emergiese en las tres sociedades hacia el siglo iv a. c. el tratamiento formalmente sofisticado de la logica proviene de la tradicion griega, especialmente del organon aristotelico, cuyos logros serian desarrollados por los logicos islamicos y, luego, por los logicos de la edad media europea. el descubrimiento de la logica india entre los especialistas britanicos en el siglo xviii influyo tambien en la logica moderna.  ¿cual es el estatus epistemologico de la leyes de la logica? ¿que tipo de argumento es apropiado para criticar los supuestos principios de la logica? en un influyente articulo titulado \"¿es empirica la logica?\"​ hilary putnam, basandose en una sugerencia de w. v. quine, argumento que en general los hechos de la logica proposicional tienen un estatus epistemologico similar al de los hechos sobre el universo fisico, por ejemplo como las leyes de la mecanica o de la relatividad general, y en particular que lo que los fisicos han aprendido sobre la mecanica cuantica proporciona un caso convincente para abandonar ciertos principios familiares de la logica clasica: si queremos ser realistas sobre los fenomenos fisicos descritos por la teoria cuantica, entonces debemos abandonar el principio de distributividad, sustituyendo la logica clasica por la logica cuantica propuesta por garrett birkhoff y john von neumann.​  otro trabajo del mismo nombre de michael dummett sostiene que el deseo de realismo de putnam exige la ley de la distributividad.​ la distributividad de la logica es esencial para que el realista entienda como las proposiciones son verdaderas del mundo de la misma manera que ha argumentado que lo es el principio de bivalencia. de este modo, la pregunta \"¿es la logica empirica?\" puede verse como una respuesta natural a la controversia fundamental en metafisica sobre  realismo versus antirrealismo.  la nocion de implicacion formalizada en la logica clasica no se traduce comodamente al lenguaje natural por medio de \"si ... entonces ...\", debido a una serie de problemas denominados paradojas de la implicacion material.  la primera clase de paradojas involucra contrafactuales, tales como si la luna esta hecha de queso verde, entonces 2+2=5, que son desconcertantes porque el lenguaje natural no soporta el principio de explosion. la eliminacion de esta clase de paradojas fue la razon de la formulacion de c. i. lewis de la implicacion estricta, que finalmente condujo a logicas mas radicalmente revisionistas como la logica relevante.  la segunda clase de paradojas involucra premisas redundantes, sugiriendo falsamente que conocemos el sucesor debido al antecedente: asi, \"si ese hombre es elegido, la abuelita morira\" es materialmente verdadero ya que la abuelita es mortal, independientemente de las perspectivas de eleccion del hombre. tales oraciones violan la  maxima griceana de relevancia, y pueden ser modeladas por logicas que rechazan el principio de monotonicidad de la implicacion, como la logica de la relevancia.  georg wilhelm friedrich hegel fue profundamente critico con cualquier nocion simplificada del principio de no contradiccion. se baso en la idea de gottfried wilhelm leibniz de que esta ley de la logica requiere tambien un fundamento suficiente para especificar desde que punto de vista (o tiempo) se dice que algo no puede contradecirse. un edificio, por ejemplo, se mueve y no se mueve; el terreno para lo primero es nuestro sistema solar y para lo segundo la tierra. en la dialectica hegeliana, la ley de la no-contradiccion, de la identidad, se apoya ella misma en la diferencia y, por tanto, no es afirmable de forma independiente.  en estrecha relacion con las cuestiones que surgen de las paradojas de la implicacion esta la sugerencia de que la logica debe tolerar la  inconsistencia. la logica relevante y la logica paraconsistente son los enfoques mas importantes aqui, aunque las preocupaciones son diferentes: una consecuencia clave de la logica clasica y de algunos de sus rivales, como la logica intuicionista, es que respetan el principio de explosion, lo que significa que la logica colapsa si es capaz de derivar una contradiccion. graham priest, el principal defensor del dialeteismo, ha argumentado a favor de la paraconsistencia sobre la base de que existen, de hecho, contradicciones verdaderas.​  la vena filosofica de varios tipos de escepticismo contiene muchos tipos de duda y rechazo de las diversas bases sobre las que descansa la logica, como la idea de forma logica, la inferencia correcta o el significado, lo que a veces lleva a la conclusion de que no hay verdades logicas. esto contrasta con los puntos de vista habituales en el escepticismo filosofico, donde la logica dirige la indagacion esceptica para dudar de los saberes recibidos, como en la obra de sexto empirico.  friedrich nietzsche proporciona un fuerte ejemplo del rechazo de la base habitual de la logica: su rechazo radical de la idealizacion le llevo a rechazar la verdad como un \"... ejercito movil de metaforas, metonimias y antropomorfismos-en resumen ... metaforas que estan desgastadas y sin poder sensual; monedas que han perdido sus imagenes y ahora importan solo como metal, ya no como monedas\".​ su rechazo de la verdad no le llevo a rechazar por completo la idea de la inferencia o la logica, sino que sugirio que \"la logica [llego] a existir en la cabeza del hombre [a partir] de la ilogica, cuyo reino originalmente debe haber sido inmenso. innumerables seres que hicieron inferencias de una manera diferente a la nuestra perecieron\".​ asi, existe la idea de que la inferencia logica tiene una utilidad como herramienta para la supervivencia humana, pero que su existencia no respalda la existencia de la verdad, ni tiene una realidad mas alla de lo instrumental: \"tambien la logica se apoya en supuestos que no se corresponden con nada del mundo real\".​  esta posicion sostenida por nietzsche, sin embargo, ha sido sometida a un escrutinio extremo por varias razones. algunos filosofos, como jurgen habermas, afirman que su posicion es autorrefutante y acusan a nietzsche de no tener siquiera una perspectiva coherente, y mucho menos una teoria del conocimiento.​ georg lukacs, en su libro la destruccion de la razon, afirma que, \"si estudiaramos las afirmaciones de nietzsche en este ambito desde un angulo logico-filosofico, nos encontrariamos con un caos vertiginoso de las afirmaciones mas escabrosas, arbitrarias y violentamente incompatibles. \"​ bertrand russell describio las afirmaciones irracionales de nietzsche con \"es aficionado a expresarse de forma paradojica y con vistas a escandalizar a los lectores convencionales\" en su libro a history of western philosophy.​  error en la cita: existen etiquetas <ref> para un grupo llamado «lower-roman», pero no se encontro la etiqueta <references group=\"lower-roman\"/> correspondiente. ",
        "snippet": "La lógica es una rama de la filosofía[1]​ de carácter interdisciplinario, entendida como la ciencia formal que estudia los principios de la demostración y la inferencia válida,[2]​ las falacias, las paradojas y la noción de verdad.[3]​",
        "enlaces_salientes": [
            "/wiki/L%C3%B3gica",
            "/wiki/L%C3%B3gica",
            "/wiki/L%C3%B3gica",
            "/wiki/Modus_ponens",
            "/wiki/Regla_de_inferencia",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Interdisciplinario",
            "/wiki/Ciencia_formal",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Inferencia",
            "/wiki/Validez_l%C3%B3gica",
            "/wiki/Falacia",
            "/wiki/Paradoja",
            "/wiki/Verdad",
            "/wiki/L%C3%B3gica_filos%C3%B3fica",
            "/wiki/Concepto",
            "/wiki/Definici%C3%B3n",
            "/wiki/Enunciaci%C3%B3n",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Argumento",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Sistemas_formales",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/L%C3%B3gica_informal",
            "/wiki/Ling%C3%BC%C3%ADstico",
            "/wiki/Razonamiento",
            "/wiki/Falacias",
            "/wiki/L%C3%B3gica_computacional",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Edad_Antigua",
            "/wiki/Rep%C3%BAblica_Popular_China",
            "/wiki/India",
            "/wiki/Grecia",
            "/wiki/Argumento",
            "/wiki/Forma_l%C3%B3gica",
            "/wiki/Validez_(l%C3%B3gica)",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Razonamiento_inductivo",
            "/wiki/Argumento",
            "/wiki/Falacia",
            "/wiki/Paradoja",
            "/wiki/Sintaxis",
            "/wiki/Sem%C3%A1ntica",
            "/wiki/Lenguajes_formales",
            "/wiki/Significado_(filosof%C3%ADa)",
            "/wiki/Denotaci%C3%B3n",
            "/wiki/Verdad",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Siglo_XIX",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Siglo_XX",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Ciencias_cognitivas",
            "/wiki/Griego_antiguo",
            "/wiki/L%C3%B3gos",
            "/wiki/Palabra",
            "/wiki/Pensamiento",
            "/wiki/Idea",
            "/wiki/Argumento",
            "/wiki/Raz%C3%B3n",
            "/wiki/Principio",
            "/wiki/Discurso",
            "/wiki/Teor%C3%ADa",
            "/wiki/Ciencia",
            "/wiki/Creencia",
            "/wiki/Evidencia_(filosof%C3%ADa)",
            "/wiki/Tradici%C3%B3n",
            "/wiki/Cultura",
            "/wiki/Sociolog%C3%ADa",
            "/wiki/Pragm%C3%A1tica",
            "/wiki/Eficacia",
            "/wiki/Ret%C3%B3rica",
            "/wiki/Probabilidad",
            "/wiki/Inferencia",
            "/wiki/Inferencia",
            "/wiki/Premisa",
            "/wiki/Vida",
            "/wiki/Biolog%C3%ADa",
            "/wiki/Estructura_(l%C3%B3gica)",
            "/wiki/Ret%C3%B3rica",
            "/wiki/Sistema_formal",
            "/wiki/Lenguaje_natural",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Razonamiento_inductivo",
            "/wiki/Razonamiento_abductivo",
            "/wiki/L%C3%B3gica_inductiva",
            "/wiki/Problema_de_la_inducci%C3%B3n",
            "/wiki/Inteligencia_artificial",
            "/wiki/Operador",
            "/wiki/Sistema_experto",
            "/wiki/Validez_(l%C3%B3gica)",
            "/wiki/Validez_(l%C3%B3gica)",
            "/wiki/Argumento_(l%C3%B3gica)",
            "/wiki/Premisa",
            "/wiki/Implicaci%C3%B3n",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Consecuencia_l%C3%B3gica",
            "/wiki/Razonamiento_inductivo",
            "/wiki/Necesario",
            "/wiki/Verdad",
            "/wiki/Consecuencia_l%C3%B3gica",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Sistema_l%C3%B3gico",
            "/wiki/Solidez",
            "/wiki/Constante_l%C3%B3gica",
            "/wiki/Falacia",
            "/wiki/Falacia",
            "/wiki/Lat%C3%ADn",
            "/wiki/Argumento",
            "/wiki/Validez_(l%C3%B3gica)",
            "/wiki/Intencionalidad",
            "/wiki/Persuasi%C3%B3n",
            "/wiki/Premisa",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Argumento_ad_logicam",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Refutaciones_sof%C3%ADsticas",
            "/wiki/Pol%C3%ADtica",
            "/wiki/Ret%C3%B3rica",
            "/wiki/Derecho",
            "/wiki/Ciencia",
            "/wiki/Religi%C3%B3n",
            "/wiki/Periodismo",
            "/wiki/Mercadotecnia",
            "/wiki/Cine",
            "/wiki/Paradoja",
            "/wiki/Cubo_imposible",
            "/wiki/Paradoja",
            "/wiki/Lat%C3%ADn",
            "/wiki/Sentido_com%C3%BAn",
            "/wiki/Principio_de_no_contradicci%C3%B3n",
            "/wiki/Sofisma",
            "/wiki/Validez_(l%C3%B3gica)",
            "/wiki/Premisa",
            "/wiki/Ret%C3%B3rica",
            "/wiki/Pensamiento",
            "/wiki/Ciencia",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Verdad",
            "/wiki/Alfred_Stevens",
            "/wiki/Crono",
            "/wiki/Mentira",
            "/wiki/Envidia",
            "/wiki/Fran%C3%A7ois_Lemoyne",
            "/wiki/Verdad",
            "/wiki/Afirmaci%C3%B3n",
            "/wiki/Ciencia",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Honestidad",
            "/wiki/Principio_de_buena_fe",
            "/wiki/Conocimiento",
            "/wiki/Afirmaci%C3%B3n",
            "/wiki/Realidad",
            "/wiki/Hecho_cient%C3%ADfico",
            "/wiki/Cosa_(ontolog%C3%ADa)",
            "/wiki/Totalidad",
            "/wiki/Universal_(metaf%C3%ADsica)",
            "/wiki/Teor%C3%ADa",
            "/wiki/Condici%C3%B3n_(l%C3%B3gica)",
            "/wiki/Definici%C3%B3n",
            "/wiki/Innatismo",
            "/wiki/Revelaci%C3%B3n",
            "/wiki/Experiencia",
            "/wiki/Entendimiento",
            "/wiki/Raz%C3%B3n",
            "/wiki/Subjetividad",
            "/wiki/Objetividad",
            "/wiki/Relativismo",
            "/wiki/Absoluto_(metaf%C3%ADsica)",
            "/wiki/Afirmaci%C3%B3n",
            "/wiki/Propiedad_(l%C3%B3gica)",
            "/wiki/Interpretaci%C3%B3n",
            "/wiki/Perspectiva",
            "/wiki/Teolog%C3%ADa",
            "/wiki/Filosof%C3%ADa",
            "/wiki/L%C3%B3gico",
            "/wiki/Alma",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Teor%C3%ADa_de_la_justificaci%C3%B3n",
            "/wiki/Cognitivismo",
            "/wiki/Conocimiento",
            "/wiki/Evidencia_(filosof%C3%ADa)",
            "/wiki/Creencia",
            "/wiki/Validez_(epistemolog%C3%ADa)",
            "/wiki/Teor%C3%ADa_de_la_justificaci%C3%B3n",
            "/wiki/Validez_(l%C3%B3gica)",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Antropolog%C3%ADa_filos%C3%B3fica",
            "/wiki/Mentira",
            "/wiki/Certeza",
            "/wiki/Duda",
            "/wiki/Historiograf%C3%ADa",
            "/wiki/Cultura",
            "/wiki/Ciencia",
            "/wiki/Conocimiento",
            "/wiki/Validez_(epistemolog%C3%ADa)",
            "/wiki/Charles_Sanders_Peirce",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Ciencia",
            "/wiki/Fundamentos_de_las_matem%C3%A1ticas",
            "/wiki/Inferencia",
            "/wiki/Sistema_formal",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/Lenguaje_natural",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Georg_Cantor",
            "/wiki/Teorema_de_Cantor",
            "/wiki/Axioma_de_elecci%C3%B3n",
            "/wiki/Hip%C3%B3tesis_del_continuo",
            "/wiki/Axiomas",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Entscheidungsproblem",
            "/wiki/Alan_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Definici%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Conjunto",
            "/wiki/N%C3%BAmero",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Algoritmo",
            "/wiki/Metal%C3%B3gica",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Razonamiento",
            "/wiki/L%C3%B3gica_computacional",
            "/wiki/L%C3%B3gica_computacional",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Circuito_de_conmutaci%C3%B3n",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Algoritmo",
            "/wiki/Alan_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Teoremas_incompletos_de_G%C3%B6del",
            "/wiki/Inteligencia_artificial",
            "/wiki/Prolog",
            "/wiki/Teor%C3%ADa_de_la_argumentaci%C3%B3n",
            "/wiki/L%C3%B3gica_de_Hoare",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/Cl%C3%A1usulas_de_Horn",
            "/wiki/L%C3%B3gica_de_descripci%C3%B3n",
            "/wiki/L%C3%B3gica_simb%C3%B3lica",
            "/wiki/L%C3%B3gica_filos%C3%B3fica",
            "/wiki/L%C3%B3gica_filos%C3%B3fica",
            "/wiki/Filosof%C3%ADa",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/Filosof%C3%ADa_de_la_l%C3%B3gica",
            "/wiki/L%C3%B3gica_no_cl%C3%A1sica",
            "/wiki/Inferencia",
            "/wiki/Validez_(l%C3%B3gica)",
            "/wiki/L%C3%B3gica_cl%C3%A1sica",
            "/wiki/Reglas_de_inferencia",
            "/wiki/Principio_del_tercero_excluido",
            "/wiki/Eliminaci%C3%B3n_de_la_doble_negaci%C3%B3n",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Mundo_posible",
            "/wiki/L%C3%B3gica_de%C3%B3ntica",
            "/wiki/%C3%89tica",
            "/wiki/Obligaci%C3%B3n_moral",
            "/wiki/L%C3%B3gica_temporal",
            "/wiki/L%C3%B3gica_epist%C3%A9mica",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/Estados_mentales",
            "/wiki/L%C3%B3gica_de_segundo_orden",
            "/wiki/Cuantificador",
            "/wiki/L%C3%B3gica_intuicionista",
            "/wiki/L%C3%B3gica_libre",
            "/wiki/L%C3%B3gica_plurivalente",
            "/wiki/L%C3%B3gica_paraconsistente",
            "/wiki/Principio_de_explosi%C3%B3n",
            "/wiki/L%C3%B3gica_relevante",
            "/wiki/Condicional_material",
            "/wiki/L%C3%B3gica_informal",
            "/wiki/L%C3%B3gica_informal",
            "/wiki/Argumento",
            "/wiki/A_posteriori",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Forma_l%C3%B3gica",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Howard_Kahane",
            "/wiki/L%C3%B3gica_aristot%C3%A9lica",
            "/wiki/Siglo_XV",
            "/wiki/Cuadro_de_oposici%C3%B3n_de_los_juicios",
            "/wiki/Organon",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Primeros_anal%C3%ADticos",
            "/wiki/L%C3%B3gica_de_t%C3%A9rminos",
            "/wiki/Silogismos",
            "/wiki/Estoicos",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/C%C3%A1lculo_de_predicados",
            "/wiki/Teor%C3%ADa_de_la_argumentaci%C3%B3n",
            "/wiki/Inteligencia_artificial",
            "/wiki/Derecho",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/Sentencia_at%C3%B3mica",
            "/wiki/Conectiva_l%C3%B3gica",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/Modalidad",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Sobre_la_interpretaci%C3%B3n",
            "/wiki/Avicena",
            "/wiki/L%C3%B3gica_temporal",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/C._I._Lewis",
            "/wiki/L%C3%B3gica_de%C3%B3ntica",
            "/wiki/L%C3%B3gica_epist%C3%A9mica",
            "/wiki/Arthur_Prior",
            "/wiki/L%C3%B3gica_temporal",
            "/wiki/Saul_Kripke",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Ling%C3%BC%C3%ADstica_computacional",
            "/wiki/Inform%C3%A1tica",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/Gottlob_Frege",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/L%C3%B3gica_de_segundo_orden",
            "/wiki/L%C3%B3gica_infinitaria",
            "/wiki/Cuantificador",
            "/wiki/Paradoja_del_barbero",
            "/wiki/Bertrand_Russell",
            "/wiki/Cuantificador",
            "/wiki/Conjunci%C3%B3n_l%C3%B3gica",
            "/wiki/Condicional_material",
            "/wiki/Negaci%C3%B3n_l%C3%B3gica",
            "/wiki/Bicondicional",
            "/wiki/Gottlob_Frege",
            "/wiki/Filosof%C3%ADa_anal%C3%ADtica",
            "/wiki/David_Hilbert",
            "/wiki/Wilhelm_Ackermann",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Alfred_Tarski",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/L%C3%B3gica_de_segundo_orden",
            "/wiki/Willard_Van_Orman_Quine",
            "/wiki/George_Boolos",
            "/wiki/Stewart_Shapiro",
            "/wiki/L%C3%B3gica_no_cl%C3%A1sica",
            "/wiki/Principio_de_bivalencia",
            "/wiki/L%C3%B3gica_no_cl%C3%A1sica",
            "/wiki/L%C3%B3gica_cl%C3%A1sica",
            "/wiki/Dial%C3%A9ctica_hegeliana",
            "/wiki/Immanuel_Kant",
            "/wiki/Nicolai_A._Vasiliev",
            "/wiki/Jan_%C5%81ukasiewicz",
            "/wiki/L%C3%B3gica_ternaria",
            "/wiki/L%C3%B3gica_plurivalente",
            "/wiki/Stephen_Cole_Kleene",
            "/wiki/Condicional_material",
            "/wiki/L%C3%B3gica_difusa",
            "/wiki/N%C3%BAmero_real",
            "/wiki/L%C3%B3gica_intuicionista",
            "/wiki/Principio_del_tercero_excluido",
            "/wiki/Intuicionismo",
            "/wiki/Arend_Heyting",
            "/wiki/Gerhard_Gentzen",
            "/wiki/L%C3%B3gica_intuicionista",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/Correspondencia_de_Curry-Howard",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/Historia_de_la_l%C3%B3gica",
            "/wiki/Historia_de_la_l%C3%B3gica",
            "/wiki/Babilonia",
            "/wiki/Antigua_China",
            "/wiki/Antigua_India",
            "/wiki/Antigua_Grecia",
            "/wiki/Organon",
            "/wiki/Edad_Media",
            "/wiki/Siglo_XVIII",
            "/wiki/L%C3%B3gica_aristot%C3%A9lica",
            "/wiki/Escuela_de_Megara",
            "/wiki/Estoicos",
            "/wiki/Ramon_Llull",
            "/wiki/Leibniz",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/C%C3%A1lculo",
            "/wiki/Gottlob_Frege",
            "/wiki/Bertrand_Russell",
            "/wiki/Whitehead",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Escuela_filos%C3%B3fica",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/L%C3%B3gica_cl%C3%A1sica",
            "/wiki/%C2%BFEs_emp%C3%ADrica_la_l%C3%B3gica%3F",
            "/wiki/Hilary_Putnam",
            "/wiki/W._V._Quine",
            "/wiki/Mec%C3%A1nica",
            "/wiki/Relatividad_general",
            "/wiki/Realismo_filos%C3%B3fico",
            "/wiki/L%C3%B3gica_cu%C3%A1ntica",
            "/wiki/Garrett_Birkhoff",
            "/wiki/John_von_Neumann",
            "/wiki/Michael_Dummett",
            "/wiki/Metaf%C3%ADsica",
            "/wiki/Antirrealismo",
            "/wiki/Paradojas_de_la_implicaci%C3%B3n_material",
            "/wiki/Paradojas_de_la_implicaci%C3%B3n_material",
            "/wiki/Principio_de_explosi%C3%B3n",
            "/wiki/C._I._Lewis",
            "/wiki/Implicaci%C3%B3n_estricta",
            "/wiki/L%C3%B3gica_relevante",
            "/wiki/Pragm%C3%A1tica_conversacional",
            "/wiki/Monotonicidad_de_la_implicaci%C3%B3n",
            "/wiki/L%C3%B3gica_paraconsistente",
            "/wiki/Georg_Wilhelm_Friedrich_Hegel",
            "/wiki/Principio_de_no_contradicci%C3%B3n",
            "/wiki/Gottfried_Wilhelm_Leibniz",
            "/wiki/Consistencia_(l%C3%B3gica)",
            "/wiki/L%C3%B3gica_relevante",
            "/wiki/L%C3%B3gica_paraconsistente",
            "/wiki/L%C3%B3gica_cl%C3%A1sica",
            "/wiki/L%C3%B3gica_intuicionista",
            "/wiki/Principio_de_explosi%C3%B3n",
            "/wiki/Graham_Priest",
            "/wiki/Dialeteismo",
            "/wiki/Verdades_l%C3%B3gicas",
            "/wiki/Escepticismo_filos%C3%B3fico",
            "/wiki/Sexto_Emp%C3%ADrico",
            "/wiki/Friedrich_Nietzsche",
            "/wiki/J%C3%BCrgen_Habermas",
            "/wiki/Gy%C3%B6rgy_Luk%C3%A1cs",
            "/wiki/Bertrand_Russell",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/L%C3%B3gica_de_segundo_orden",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/L%C3%B3gica_computacional",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/L%C3%B3gica_booleana",
            "/wiki/L%C3%B3gica_filos%C3%B3fica",
            "/wiki/L%C3%B3gica_cl%C3%A1sica",
            "/wiki/L%C3%B3gica_no_cl%C3%A1sica",
            "/wiki/L%C3%B3gica_informal",
            "/wiki/L%C3%B3gica_dial%C3%A9ctica",
            "/wiki/L%C3%B3gica_dox%C3%A1stica",
            "/wiki/L%C3%B3gica_de%C3%B3ntica",
            "/wiki/L%C3%B3gica_temporal",
            "/wiki/L%C3%B3gica_trivalente",
            "/wiki/L%C3%B3gica_epist%C3%A9mica",
            "/wiki/L%C3%B3gica_difusa",
            "/wiki/L%C3%B3gica_plurivalente",
            "/wiki/Metodolog%C3%ADa",
            "/wiki/M%C3%A9todo_cient%C3%ADfico",
            "/wiki/MC-14",
            "/wiki/Argumento",
            "/wiki/Raz%C3%B3n",
            "/wiki/Silogismo",
            "/wiki/Verdad",
            "/wiki/Apor%C3%ADa",
            "/wiki/Dialelo",
            "/wiki/Paradoja",
            "/wiki/Dicotom%C3%ADa",
            "/wiki/Ny%C4%81ya_(hinduismo)",
            "/wiki/Filosof%C3%ADa_de_la_l%C3%B3gica",
            "/wiki/Principio_de_no_contradicci%C3%B3n",
            "/wiki/Principio_de_identidad",
            "/wiki/Principio_del_tercero_excluido",
            "/wiki/Tertium_comparationis",
            "/wiki/Oxford_University_Press",
            "/wiki/ISBN",
            "/wiki/JSTOR",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Henry_Liddell",
            "/wiki/A_Greek%E2%80%93English_Lexicon",
            "/wiki/Oxford_University_Press",
            "/wiki/Perseus_Project",
            "/wiki/Online_Etymology_Dictionary",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/Cambridge_University_Press",
            "/wiki/Parm%C3%A9nides",
            "/wiki/Plat%C3%B3n",
            "/wiki/Hegel",
            "/wiki/Idealismo",
            "/wiki/Ferrater_Mora",
            "/wiki/F%C3%ADsica",
            "/wiki/Neurolog%C3%ADa",
            "/wiki/Evolucionismo",
            "/wiki/Gen%C3%A9tica",
            "/wiki/Biolog%C3%ADa",
            "/wiki/Etolog%C3%ADa",
            "/wiki/Psicolog%C3%ADa",
            "/wiki/Teeteto",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/Metodolog%C3%ADa",
            "/wiki/Investigaci%C3%B3n",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Encyclop%C3%A6dia_Britannica",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Jes%C3%BAs_Padilla_G%C3%A1lvez",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Nuel_Belnap",
            "/wiki/J%C3%B3zef_Maria_Boche%C5%84ski",
            "/wiki/J%C3%B3zef_Maria_Boche%C5%84ski",
            "/wiki/ISBN",
            "/wiki/Susan_Haack",
            "/wiki/Online_Etymology_Dictionary",
            "/wiki/David_Hilbert",
            "/wiki/Wilhelm_Ackermann",
            "/wiki/Online_Computer_Library_Center",
            "/wiki/Stanford_Encyclopedia_of_Philosophy",
            "/wiki/Edward_N._Zalta",
            "/wiki/ISBN",
            "/wiki/Henry_Liddell",
            "/wiki/A_Greek-English_Lexicon",
            "/wiki/Perseus_Project",
            "/wiki/Online_Computer_Library_Center",
            "/wiki/Alfred_North_Whitehead",
            "/wiki/Bertrand_Russell",
            "/wiki/Principia_Mathematica",
            "/wiki/Online_Computer_Library_Center",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Medical_Subject_Headings"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Ciencias_de_la_computaci%C3%B3n",
        "titulo": "Ciencias de la computación",
        "contenido": "las ciencias de la computacion o ciencias de la informatica son las ciencias formales que abarcan las bases teoricas de la informacion y la computacion, asi como su aplicacion en los sistemas informaticos.​​​ el cuerpo de conocimiento de las ciencias de la computacion es frecuentemente descrito como el estudio sistematico de los procesos algoritmicos que describen y transforman informacion: su teoria, analisis, diseño, eficiencia, implementacion, algoritmos sistematizados y aplicacion.​ en terminos mas especificos se trata del estudio sistematico de la factibilidad, estructura, expresion y mecanizacion de procedimientos metodicos (o algoritmos) que subyacen en la adquisicion, representacion, procesamiento, almacenamiento, comunicacion y acceso a la informacion. la informacion puede estar codificada en forma de bits en una memoria de computadora, o en algun otro objeto, como los genes y proteinas en una celula biologica.​  existen diversas ramas o disciplinas dentro de las ciencias de la computacion; algunos resaltan los resultados especificos del computo (como los graficos por computadora), mientras que otros (como la teoria de la complejidad computacional) se relacionan con propiedades de los algoritmos usados al realizar computo; y otros se enfocan en los problemas que requieren la implementacion de sistemas informaticos. por ejemplo, los estudios de la teoria de lenguajes de programacion describen un computo, mientras que la programacion de computadoras aplica lenguajes de programacion especificos para desarrollar una solucion a un problema computacional especifico. un computologo se especializa en teoria de la computacion y en el diseño e implementacion de sistemas computacionales.​  segun peter j. denning, la cuestion fundamental en que se basa la ciencia de la computacion es: «¿que puede ser (eficientemente) automatizado?».​  la historia de la ciencia de la computacion antecede a la invencion del computador digital moderno. antes de la decada de 1920, el termino computador se referia a un ser humano que realizaba calculos.​ los primeros cimientos de lo que se convertiria en ciencias de la computacion son anteriores a la invencion de la computadora digital moderna. se trataba de maquinas para el calculo de las tareas numericas fijas, como el abaco han existido desde la antiguedad, ayudando en calculos tales como la multiplicacion y la division. ademas, los algoritmos para realizar calculos han existido desde la antiguedad, incluso antes de que se crearan equipos de computacion sofisticados. los antiguos sanscritos tratadistas shulba sutras, o \"reglas de la cuerda\", es un libro de algoritmos escritos en 800 a. c. para la construccion de objetos geometricos como altares utilizando una clavija y cuerda, un precursor temprano del campo moderno de la geometria computacional.  blaise pascal diseño y construyo la primera calculadora mecanica de trabajo, la pascalina, en 1642.​ en 1673 gottfried leibniz creo una calculadora mecanica digital, llamada stepped reckoner.​ el puede ser considerado el primer computologo y teorico de la informacion, entre otras razones, porque fue el primero en documentar el sistema numerico binario. en 1820, charles xavier thomas de colmar lanzo la calculadora mecanica industrial​ cuando lanzo su simplificado aritmometro, que fue la primera maquina de calcular lo suficientemente fuerte y lo suficientemente fiable para ser usada a diario en un entorno industrial. charles babbage inicio el diseño de la primera calculadora automatica mecanica, su maquina diferencial, en 1822, que finalmente le dio la idea de la primera calculadora mecanica programable, su maquina analitica.​ el comenzo a desarrollar esta maquina en 1834 y en menos de dos años habia esbozado muchas de las caracteristicas mas destacadas del moderno equipo. un paso fundamental fue la adopcion de un sistema de tarjetas perforadas derivado del telar de jacquard​ haciendolo infinitamente programable.​ en 1843, durante la traduccion de un articulo frances sobre la maquina analitica, ada lovelace escribio, en una de las muchas notas que incluye el articulo, un algoritmo para calcular los numeros de bernoulli, que es considerado como el primer programa de ordenador.​ alrededor de 1885, herman hollerith invento la maquina tabuladora, que usaba tarjetas perforadas para procesar informacion estadistica; finalmente, su compañia se convirtio en parte de ibm. en 1937, cien años despues del sueño imposible de babbage, howard aiken fue convencido por ibm (que estaban manufacturando todo tipo de equipos de tarjetas perforadas y asi como la calculadora de negocio​) para desarrollar su calculadora programable gigante, el ascc/harvard mark i. se baso en la maquina analitica de babbage, que a su vez utiliza las tarjetas perforadas y una unidad central de calculo. cuando se termino de construir la maquina, algunas personas lo aclamaron como «el sueño de babbage hecho realidad».​  durante la decada de 1940, conforme se desarrollaban las nuevas y mas poderosas maquinas para computar, el termino computador se comenzo a utilizar para referirse a las maquinas y ya no a sus antecesores humanos.​ cuando se hizo evidente que las computadoras no solamente podrian utilizarse para realizar calculos matematicos, el campo de las ciencias de la computacion se amplio para estudiar computo en general. las ciencias de la computacion empezaron a establecerse como una disciplina academica distinta de las demas en la decada de 1950 y principios de 1960.​​ entonces surgio el primer programa de grado universitario del mundo, el cambridge diploma in computer science, del cambridge computer lab (departamento de ciencias de la computacion) de la universidad de cambridge, en 1953. el primer programa de grado universitario en ciencias de la informatica en estados unidos se formo en la universidad de purdue en 1962.​ desde que se dispone ordenadores practicos, muchas aplicaciones la de las ciencias de la computacion se convirtieron en diferentes areas de estudio en sus propios terminos.  aunque inicialmente muchos creyeron que era imposible que las computadoras en si mismas podrian constituir en realidad un campo cientifico de estudio, a finales de los años cincuenta se fue volviendo gradualmente aceptada entre la poblacion mayor academica.​​  la disciplina cientifica de las ciencias de la computacion nace a principios de 1940 con la confluencia de la teoria de algoritmos, logica matematica y la invencion del programa almacenado en una computadora electronica.​ ejemplos de esto son los trabajos de alan turing, alonzo church y kurt godel en 1930 acerca de los algoritmos y su trabajo en sistemas de reglas (vease calculo lambda, maquina de turing y problemas indecidibles), los algoritmos creados por augusta ada sesenta años antes, la computadora analogica construida por vannevar bush en 1920 y las computadoras electricas construidas por howard aiken y konrad zuse en 1930. los escritos de john von neumann dieron una profundidad intelectual considerable a esta disciplina emergente a mediados de la decada de 1940.  en 1960, habia suficientemente cuerpo de conocimiento que ameritaba la creacion de departamentos academicos y programas de grado universitario para esta disciplina.​ ibm es reconocida como la marca que formo parte de la revolucion de las ciencias de la computacion durante ese tiempo. ibm (abreviacion de international business machines) lanzo la ibm 704​ y mas tarde la ibm 709​ computadoras, que fueron ampliamente utilizadas durante el periodo de exploracion de este tipo de dispositivos. \"sin embargo, el trabajo con la ibm [equipo] era frustrante ... si te equivocas en una letra de alguna instruccion, el programa se arruinaria, y se tendria que empezar todo el proceso otra vez\".​ durante la decada de 1950, la disciplina de las ciencias de la computacion estaba en su etapa de desarrollo, y estos problemas eran algo comun.  el tiempo ha dado mejoras significativas en la capacidad de uso y la eficacia de la tecnologia de la computacion. la sociedad moderna ha presenciado un cambio significativo en los usuarios de la tecnologia en computo, de ser utilizada unicamente por expertos, profesionales y cientificos, a una base de usuarios que es casi omnipresente a la teoria con la cual se desarrollo y funciona este tipo de tecnologia. inicialmente, las computadoras eran bastante costosas, y era necesario un cierto grado de ayuda humana para el uso eficiente - en parte de operadores de computadoras profesionales. como la adopcion equipo se hizo mas generalizado y asequible, se necesitaba menos asistencia humana en el uso comun.  a pesar de su corto tiempo de ser una disciplina cientifica formal, las ciencias de la computacion han hecho un gran numero de contribuciones importantes a la ciencia y la sociedad –de hecho, junto con la electronica, es una ciencia fundacional de la epoca actual de la historia humana llamada era de la informacion y la revolucion de la informacion, visto como el tercer gran salto en el progreso tecnologico humano despues de la revolucion industrial (1750-1850) y la revolucion neolitica (8000-5000 a. c.).  estas contribuciones a la humanidad incluyen:  algunos cientificos de la computacion han argumentado a favor de la distincion de tres paradigmas diferentes en ciencias de la computacion. peter wegner ha argumentado que esos paradigmas son la ciencia, la tecnologia y las matematicas.​ el grupo de investigacion de peter denning argumento que son la abstraccion (modelado), y diseño. amnon h. eden lo describe como el «paradigma racionalista» (el cual trata a las ciencias de la computacion como una rama de las matematicas, la cual prevalece en ciencias de la computacion teorica y principalmente emplea el razonamiento deductivo), el paradigma tecnocratico (que podria ser encontrado en enfoques ingenieriles, mas prominente en la ingenieria de software) y el paradigma cientifico (que se enfoca a objetos relacionados con la computacion desde la perspectiva empirica de las ciencias naturales identificable en algunas ramas de la inteligencia artificial).  a pesar de su primera proposicion en 1956,​ la locucion «ciencias de la computacion» aparece en 1959 en un articulo de la revista communications of the acm (prestigiada publicacion cientifica destinada a lectores con experiencia en todos los ambitos de la computacion y los sistemas de informacion),​ en el cual louis fein discute sobre la creacion de una escuela de estudios de posgrado en ciencias computacionales analoga a la creacion de harvard business school en 1921,​ justificando el nombre con el argumento de que: como la ciencia administrativa, el tema o area de conocimiento puede ser aplicado, es de caracter interdisciplinario y que cuenta con las caracteristicas tipicas de una disciplina academica.​ sus esfuerzos y los de otros, como el analista numerico george forsythe, fueron recompensados: universidades pasaron a crear este tipo de programas de estudio, a partir de 1962 en purdue.​ a pesar del nombre de esta disciplina academica, una cantidad significativa de topicos en ciencias de la computacion no involucran el estudio de las computadoras, por esta razon muchos nombres alternativos han sido propuestos.​  algunos departamentos de universidades prefieren la locucion «ciencias de la computacion» para hacer enfasis en esta diferencia. el cientifico danes peter naur sugirio el termino datologia,​ para reflejar el hecho de que esta disciplina cientifica gira en torno a los datos y a al tratamiento de estos, mientras que no necesariamente involucra a las computadoras. la primera institucion cientifica en usar el termino fue el departamento de datologia de la universidad de copenhague, fundado en 1969, con peter naur como profesor de datologia. el termino es usado en paises escandinavos. en los primeros años de la computacion, un numero de terminus para los practicantes del campo de la computacion fueron propuestos en la revista communications of the acm – turingeniero, turologo, hombre de los diagramas de flujo, matematico meta-aplicado, y epistemologo aplicado.​ tres meses despues en esa misma publicacion cientifica, el termino computologo fue sugerido. el siguiente año en la misma publicacion surgio el termino hypologo.​ el termino computica tambien ha sido sugerido.​ en europa, terminos derivados de traducciones de la expresion \"automatic information\" (e.g. \"informazione automatica\" en italiano) or \"informacion y matematicas\" son frecuentemente usados, e.g. informatique (frances), informatik (aleman), informatica (italia, paises bajos), informatica (españa y portugal), informatika (lenguas eslavas) o pliroforiki (πληροφορκη, que significa informatica) en griego. palabras similares han sido adoptadas en algunos lugares del reino unido, por ejemplo en la universidad de edimburgo.​ pero estas no reflejan el aspecto de la computabilidad, por esta razon en un contexto de investigacion cientifica tanto academica como industrial el termino ciencias de la computacion es mayormente usado en publicaciones y conferencias cientificas.  como disciplina cientifica, las ciencias de la computacion abarca una gama de temas, desde los estudios teoricos de los algoritmos y los limites de la computacion a los problemas practicos de la implementacion de sistemas computacionales en hardware y software.​​ computing sciences acreditation board o la junta de acreditacion en ciencias de la computacion. –compuesta por representantes de la association for computing machinery (acm), y la sociedad de computacion ieee (ieee-cs)​– identifica cuatro areas que considera cruciales para la disciplina de ciencias de la computacion: teoria de la computacion, algoritmos y estructuras de datos, metodologia y lenguajes de programacion, y arquitectura de computadoras. ademas de estas cuatro areas, c.s.a.b. tambien identifica ambitos como la ingenieria de software, inteligencia artificial, redes de computadoras, sistemas de bases de datos, computacion paralela, computacion distribuida, la interaccion persona-computador, graficos por ordenador, sistemas operativos, calculo numerico y simbolico siendo importantes areas de las ciencias de la computacion.​  el campo mas amplio de la ciencia de la computacion teorica abarca tanto la teoria clasica de la computacion y una amplia gama de otros temas que se centran en los aspectos mas abstractos, logicos y matematicos de la computacion.  de acuerdo a peter j. denning, la pregunta fundamental en ciencias de la computacion es, «¿que puede ser eficientemente automatizado?»​ el estudio de la teoria de la computacion esta enfocado en responder preguntas fundamentales acerca de que puede ser computado y que cantidad de recursos son requeridos para ejecutar tales computos. en un esfuerzo por resolver esta pregunta, la teoria de la computabilidad examina que problemas computacionales se pueden resolver en varios modelos teoricos de computo. la segunda pregunta esta dirigida por la teoria de la complejidad computacional, que estudia los costos de tiempo y espacio asociados a diferentes enfoques para resolver una multitud de problemas computacionales.  el famoso problema \"¿p=np?\" es uno de los problemas del milenio,​ es un problema abierto en ciencias de la computacion.  la teoria de la informacion esta relacionada con la cuantificacion de la informacion. fue desarrollada por claude e. shannon para desarrollar los limites fundamentales del procesamiento de señales asi como sus operaciones, tales como compresion y almacenamiento de datos asi como la comunicacion de los datos de manera fiable.​ la teoria de codigos es un area de las matematicas que busca resolver el problema de detectar y corregir errores al momento de transmitir informacion.​ los codigos son usados para comprimir datos, criptografia y mas recientemente para la codificacion de redes. los codigos son estudiados para el proposito de diseñar metodos eficientes y seguros para la transmision de datos.  los algoritmos y las estructuras de datos son el estudio de metodos computacionales comunmente usados asi como su eficiencia computacional.  la teoria del lenguaje de programacion es una rama de las ciencias de la computacion que se ocupa del diseño, activacion, analisis, caracterizacion y clasificacion de los lenguaje de programacion y sus caracteristicas individuales, cae dentro de la disciplina de las ciencias de la computacion, tanto en dependencia de las matematicas y la linguistica. es un area de investigacion activa, con numerosas revistas academicas y conferencias especializadas en el tema.  los metodos formales son un tipo particular de la tecnica basada en las matematicas para la especificacion formal, desarrollo y verificacion formal de los sistemas de software y hardware. el uso de metodos formales para el diseño de soportes logico y fisico esta motivado por la expectativa de que, la realizacion de un analisis matematico adecuado puede contribuir a la fiabilidad y robustez de un diseño. estos forman una importante base teorica para la ingenieria de software, especialmente cuando esta involucrado la seguridad o robustez. los metodos formales son un complemento util para las pruebas de software, ya que ayudan a evitar errores y tambien pueden dar un marco para hacer pruebas. para su uso industrial, se requiere el apoyo de herramientas. sin embargo, el alto costo de la utilizacion de metodos formales significa que por lo general solo se utilizan en el desarrollo de sistemas criticos de alta integridad donde la vida o la seguridad es de muy alta importancia.  los metodos formales se describen mejor como la aplicacion de una amplia variedad de fundamentos teoricos de las ciencias de la computacion, en particular la logica computacional, lenguajes formales, teoria de automatas y semantica de lenguajes de programacion pero tambien areas como sistemas de tipos y tipos de datos algebraicos a problemas en la especificacion y verificacion de software y hardware.  las ciencias de la computacion aplicadas tratan de identificar ciertos aspectos conceptuales y teoricos de las ciencias de la informatica que pueden ser aplicados directamente para resolver problemas del mundo real.  esta rama de las ciencias de la computacion pretende o es requerida para la sintesis de procesos metaorientados tales como la resolucion de problemas, toma de decisiones, la adaptacion del medio ambiente, el aprendizaje y la comunicacion que se encuentran en los seres humanos y los animales. desde sus origenes en la cibernetica y en la conferencia de dartmouth (1956), la investigacion en inteligencia artificial (ia) ha sido necesariamente multidisciplinaria, aprovechando areas de especializacion, tales como las matematicas, la logica simbolica, la semiotica, la ingenieria electrica, la filosofia de la mente, la neurofisiologia, y la inteligencia social. la ia erroneamente es asociada en la mente popular con el desarrollo robotico, pero el principal campo de aplicacion practica ha sido como un componente integrado en las areas de desarrollo de programas informaticos que requieren la comprension y la modelacion computacional, tales como las finanzas y la economia, la mineria de datos y las ciencias fisicas. el termino fue acuñado por el cientifico de la computacion y matematico john mccarthy en 1955.  la arquitectura de computadores u organizacion de computadoras digitales es el diseño conceptual y la estructura operacional fundamental de un sistema computo. se centra en gran medida de la manera en que la unidad central de procesamiento realiza internamente y accede a las direcciones en la memoria.​ el campo involucra disciplinas de la ingenieria en computacion y la ingenieria electrica, la seleccion y la interconexion de los componentes fisicos para crear los equipos que cumplen funciones, de rendimiento, y costes.  analisis de rendimiento del equipo es el estudio del trabajo que fluye a traves de los equipos con el objetivo general de mejora de rendimiento y control de tiempo de respuesta, utilizando los recursos de manera eficiente, la eliminacion de los cuellos de botella, y la prediccion de rendimiento bajo cargas maximas previstas.​  la ciencia computacional (o computacion cientifica) es el campo de estudio que trata con la construccion de modelos matematicos y tecnicas de analisis cuantitativos, asi como el uso de computadoras para analizar y resolver problemas cientificos. en el uso practico, es tipicamente la aplicacion de simulacion por ordenador y otras formas de calculo a los problemas en diversas disciplinas cientificas.  esta rama de las ciencias de la computacion tiene como objetivo gestionar la conectividad entre redes (lan / wan) de computadoras a nivel mundial.  concurrencia es una propiedad de los sistemas en los que varios calculos estan ejecutando de forma simultanea, y, potencialmente, que interactuan entre si. un numero de modelos matematicos han sido desarrollados para el calculo concurrente general, incluyendo las redes de petri, calculos de proceso y del modelo de maquina de acceso aleatorio en paralelo. un sistema distribuido se extiende la idea de la simultaneidad en varios ordenadores conectados a traves de una red. las computadoras dentro del mismo sistema distribuido tienen su propia memoria privada, y la informacion es a menudo intercambiada entre si para lograr un objetivo comun.  una base de datos tiene la intencion de organizar, almacenar y recuperar grandes cantidades de datos de forma sencilla. bases de datos digitales se gestionan mediante sistemas de gestion de base de datos para almacenar, crear, mantener y consultar los datos, a traves de modelos de bases de datos y lenguajes de consulta. una base de datos es un conjunto de datos interrelacionados entre ellos mismos.  el campo estudia la estructura, algoritmos, comportamiento e interacciones de los sistemas naturales y artificiales que guardan, procesan, acceden a y comunican informacion. tambien desarrolla sus propios fundamentos conceptuales y teoricos y emplea fundamentos desarrollados en otros campos. una aplicacion moderna es el big data, que consiste en el procesamiento de un conjunto de datos (provenientes de fuentes como por ejemplo: transacciones comerciales, formularios web, imagenes, videos, correos electronicos, redes sociales, entre otros), los cuales son sometidos a herramientas informaticas de analisis que permiten extraer informacion valiosa para predecir comportamientos futuros y formular estrategias de toma decisiones.​  ingenieria de software consiste en el estudio del diseño, activacion y modificacion del software con la finalidad de asegurarse de que es de alta calidad, asequible, facil de mantener, y rapido de construir. es un enfoque sistematico para el diseño de software, que implica la aplicacion de practicas de ingenieria de software. los ingenieros de software comercian con la organizacion y analisis de software — no solo lidian con la creacion o fabricacion de un nuevo soporte logico, sino tambien con su mantenimiento y disposicion interna. se preve que esten entre las ocupaciones de mas rapido crecimiento entre 2008 y 2018. debido a la novedad de este subcampo, la educacion formal en ingenieria de software generalmente es parte de los planes de estudio de ciencias de la computacion, la gran mayoria de ingenieros de software tienen un grado academico en ciencias de la computacion sin tener relacion con la ingenieria.​  por ser una disciplina reciente, existen varias definiciones alternativas para la ciencia de la computacion. esta puede ser vista como una forma de ciencia, matematicas o una nueva disciplina que no puede ser categorizada siguiendo los modelos actuales.  las ciencias de la computacion frecuentemente se cruzan con otras areas de investigacion, tales como la fisica y la linguistica. pero es con las matematicas con las que se considera que tiene un grado mayor de relacion. eso es evidenciado por el hecho de que los primeros trabajos en el area fueran fuertemente influenciados por matematicos como kurt godel y alan turing. en la actualidad sigue habiendo un intercambio de ideas util entre ambos campos en areas como la logica matematica, la teoria de categorias, la teoria de dominios, el algebra y la geometria.  otro punto a destacar es que, a pesar de su nombre, las ciencias de la computacion raramente involucran el estudio mismo de las maquinas conocidas como computadoras. de hecho, el renombrado cientifico edsger dijkstra es muy citado por la frase «las ciencias de la computacion estan tan poco relacionadas con los ordenadores como la astronomia con los telescopios». la investigacion en ciencias de la computacion tambien suele relacionarse con otras disciplinas, como la ciencia cognitiva, la fisica (vease computacion cuantica), la linguistica, etc.  la relacion entre las ciencias de la computacion y la ingenieria de software es un tema muy discutido, por disputas sobre lo que realmente significa la lucion «ingenieria de software» y sobre como se define a las ciencias de la computacion. algunas personas creen que la ingenieria de software seria un subconjunto de las ciencias de la informatica. otras, tomando en cuenta la relacion entre otras disciplinas cientificas y de la ingenieria, creen que el principal objetivo de las ciencias de la computacion seria estudiar las propiedades del computo en general, mientras que el objetivo de la ingenieria de software seria diseñar computos especificos para lograr objetivos practicos, con lo que se convertiria en disciplinas diferentes. este punto de vista es el que sostiene, por ejemplo, parnas (1998). incluso hay otros que sostienen que no podria existir una ingenieria de software.  los aspectos academicos, politicos y de financiamiento en las areas de ciencias de la computacion tienden a verse influidos drasticamente por el criterio del departamento encargado de la investigacion y la educacion en cada universidad, que puede estar orientado a las matematica o a la ingenieria. los departamentos de ciencias de la computacion orientados a las matematicas teoricas suelen alinearse del lado de la computacion cientifica y las aplicaciones de calculo numerico.  la locucion «computacion cientifica», que no debe confundirse con ciencia de la computacion, designa a todas aquellas practicas destinadas a modelar, plantear experimentos y validar teorias cientificas sirviendose de medios informaticos. en estos casos la computacion es una mera herramienta y el esfuerzo se dirige a avanzar en los campos objetivo (fisica, biologia, mecanica de fluidos, radiotransmision...), mas que en la propia ciencia de la computacion.  finalmente, el publico en general algunas veces confunde la ciencia de la computacion con areas vocacionales que trabajan con computadoras o piensan que trata acerca de su propia experiencia con las computadoras, lo cual suele incluir actividades como los juegos, la navegacion web y el procesamiento de texto. sin embargo, el punto central de la ciencia de la computacion va mas alla de entender las propiedades de los programas que se emplean para ejecutar aplicaciones de software como juegos y navegadores web, y utiliza ese entendimiento para crear nuevos programas o mejorar los existentes.​     ",
        "snippet": "Las ciencias de la computación o ciencias de la informática son las ciencias formales que abarcan las bases teóricas de la información y la computación, así como su aplicación en los sistemas informáticos.[1]​[2]​[3]​ El cuerpo de conocimiento de las ciencias de la computación es frecuentemente descrito como el estudio sistemático de los procesos algorítmicos que describen y transforman información: su teoría, análisis, diseño, eficiencia, implementación, algoritmos sistematizados y aplicación.[4]​ En términos más específicos se trata del estudio sistemático de la factibilidad, estructura, expresión y mecanización de procedimientos metódicos (o algoritmos) que subyacen en la adquisición, representación, procesamiento, almacenamiento, comunicación y acceso a la información. La información puede estar codificada en forma de bits en una memoria de computadora, o en algún otro objeto, como los genes y proteínas en una célula biológica.[5]​",
        "enlaces_salientes": [
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Computaci%C3%B3n_gr%C3%A1fica",
            "/wiki/Interacci%C3%B3n_persona-computador",
            "/wiki/Ciencias_formales",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Sistemas_de_informaci%C3%B3n",
            "/wiki/Factibilidad",
            "/wiki/Estructura_de_datos",
            "/wiki/Expresi%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Algoritmos",
            "/wiki/Grafo",
            "/wiki/Proceso_(inform%C3%A1tica)",
            "/wiki/Dispositivo_de_almacenamiento_de_datos",
            "/wiki/Comunicaci%C3%B3n",
            "/wiki/Acceso",
            "/wiki/Informaci%C3%B3n",
            "/wiki/Bit",
            "/wiki/Gr%C3%A1ficos_por_computadora",
            "/wiki/Complejidad_computacional",
            "/wiki/Algoritmos",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Peter_J._Denning",
            "/wiki/Charles_Babbage",
            "/wiki/Turing_completo",
            "/wiki/Alan_Turing",
            "/wiki/Ada_Lovelace",
            "/wiki/Algoritmo",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Computadora_electr%C3%B3nica",
            "/wiki/A%C3%B1os_1920",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Blaise_Pascal",
            "/wiki/Pascalina",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Stepped_Reckoner",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Charles_Xavier_Thomas_de_Colmar",
            "/wiki/Calculadora_mec%C3%A1nica",
            "/wiki/Aritm%C3%B3metro",
            "/wiki/Charles_Babbage",
            "/wiki/M%C3%A1quina_diferencial",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Ada_Lovelace",
            "/wiki/Bernoulli",
            "/wiki/Herman_Hollerith",
            "/wiki/Tabuladora",
            "/wiki/IBM",
            "/wiki/Howard_Aiken",
            "/wiki/Harvard_Mark_I",
            "/wiki/A%C3%B1os_1940",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Universidad_de_Purdue",
            "/wiki/Disciplina_acad%C3%A9mica",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Alan_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/1930",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Problema_indecidible",
            "/wiki/Ada_Lovelace",
            "/wiki/Vannevar_Bush",
            "/wiki/Howard_Aiken",
            "/wiki/Konrad_Zuse",
            "/wiki/A%C3%B1os_1930",
            "/wiki/John_Von_Neumann",
            "/wiki/1960",
            "/wiki/IBM",
            "/wiki/Wehrmacht",
            "/wiki/M%C3%A1quina_Enigma",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Alan_Turing",
            "/wiki/Bletchley_Park",
            "/wiki/Disciplina_acad%C3%A9mica",
            "/wiki/Ciencia",
            "/wiki/Sociedad",
            "/wiki/Electr%C3%B3nica",
            "/wiki/Era_de_la_informaci%C3%B3n",
            "/wiki/Revoluci%C3%B3n_Industrial",
            "/wiki/Revoluci%C3%B3n_neol%C3%ADtica",
            "/wiki/Revoluci%C3%B3n_digital",
            "/wiki/Era_de_la_informaci%C3%B3n",
            "/wiki/Internet",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Problema_indecidible",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Criptolog%C3%ADa",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Computaci%C3%B3n_cient%C3%ADfica",
            "/wiki/Clase_de_complejidad",
            "/wiki/Proyecto_Genoma_Humano",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Folding@home",
            "/wiki/Plegamiento_de_prote%C3%ADnas",
            "/wiki/Computaci%C3%B3n_gr%C3%A1fica",
            "/wiki/Imagen_generada_por_computadora",
            "/wiki/Entretenimiento",
            "/wiki/Televisi%C3%B3n",
            "/wiki/Cine",
            "/wiki/Publicidad",
            "/wiki/Animaci%C3%B3n",
            "/wiki/Videojuegos",
            "/wiki/Simulaci%C3%B3n",
            "/wiki/Din%C3%A1mica_de_fluidos",
            "/wiki/SPICE",
            "/wiki/Circuito_integrado",
            "/wiki/Inteligencia_artificial",
            "/wiki/Peter_Wegner",
            "/wiki/Peter_J._Denning",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Ciencias_naturales",
            "/wiki/Inteligencia_artificial",
            "/wiki/Harvard_Business_School",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Peter_Naur",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/Lenguas_eslavas",
            "/wiki/Idioma_griego",
            "/wiki/Universidad_de_Edimburgo",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Disciplina_acad%C3%A9mica",
            "/wiki/Algoritmos",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/IEEE",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Algoritmos",
            "/wiki/Estructuras_de_datos",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Arquitectura_de_computadoras",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Inteligencia_artificial",
            "/wiki/Redes_de_computadoras",
            "/wiki/Bases_de_datos",
            "/wiki/Computaci%C3%B3n_paralela",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Interacci%C3%B3n_persona-computador",
            "/wiki/Gr%C3%A1ficos_por_ordenador",
            "/wiki/Sistemas_operativos",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/C%C3%A1lculo_simb%C3%B3lico",
            "/wiki/Ciencia_computacional_te%C3%B3rica",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Peter_J._Denning",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Clases_de_complejidad_P_y_NP",
            "/wiki/Problemas_del_milenio",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Claude_Shannon",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Transmisi%C3%B3n_de_datos",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Algoritmo",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Algoritmos",
            "/wiki/Estructuras_de_datos",
            "/wiki/Optimizaci%C3%B3n_combinatoria",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Teor%C3%ADa_de_tipos",
            "/wiki/Compiladores",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/M%C3%A9todos_formales",
            "/wiki/Especificaci%C3%B3n_formal",
            "/wiki/Verificaci%C3%B3n_formal",
            "/wiki/Lenguajes_formales",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Sem%C3%A1ntica_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Sistema_de_tipos",
            "/wiki/Inteligencia_artificial",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Visi%C3%B3n_artificial",
            "/wiki/Procesamiento_de_im%C3%A1genes",
            "/wiki/Reconocimiento_de_patrones",
            "/wiki/Ciencia_cognitiva",
            "/wiki/Miner%C3%ADa_de_datos",
            "/wiki/Computaci%C3%B3n_evolutiva",
            "/wiki/B%C3%BAsqueda_y_recuperaci%C3%B3n_de_informaci%C3%B3n",
            "/wiki/Representaci%C3%B3n_del_conocimiento",
            "/wiki/Procesamiento_de_lenguaje_natural",
            "/wiki/Rob%C3%B3tica",
            "/wiki/Arquitectura_de_computadoras",
            "/wiki/L%C3%B3gica_digital",
            "/wiki/Microarquitectura",
            "/wiki/Multiprocesamiento",
            "/wiki/Sistemas_operativos",
            "/wiki/Redes_de_computadoras",
            "/wiki/Sistema_de_gesti%C3%B3n_de_bases_de_datos",
            "/wiki/Seguridad_inform%C3%A1tica",
            "/wiki/Computaci%C3%B3n_ubicua",
            "/wiki/Arquitectura_de_software",
            "/wiki/Compiladores",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/F%C3%ADsica_computacional",
            "/wiki/Qu%C3%ADmica_computacional",
            "/wiki/Bioinform%C3%A1tica",
            "/wiki/Redes_de_computadoras",
            "/wiki/Red_de_%C3%A1rea_local",
            "/wiki/Red_de_%C3%A1rea_amplia",
            "/wiki/Computaci%C3%B3n_concurrente",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Bases_de_datos",
            "/wiki/Sistema_de_gesti%C3%B3n_de_bases_de_datos",
            "/wiki/Inform%C3%A1tica_en_salud",
            "/wiki/Inform%C3%A1tica_en_salud",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Software_m%C3%A9dico",
            "/wiki/Tecnolog%C3%ADas_sanitarias",
            "/wiki/Big_Data",
            "/wiki/Toma_de_decisiones",
            "/wiki/Ciencias_de_la_informaci%C3%B3n_(tecnolog%C3%ADa)",
            "/wiki/B%C3%BAsqueda_y_recuperaci%C3%B3n_de_informaci%C3%B3n",
            "/wiki/Representaci%C3%B3n_del_conocimiento",
            "/wiki/Procesamiento_de_lenguaje_natural",
            "/wiki/Interacci%C3%B3n_persona-computador",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Software",
            "/wiki/Categor%C3%ADa",
            "/wiki/F%C3%ADsica",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Alan_Turing",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_categor%C3%ADas",
            "/wiki/Teor%C3%ADa_de_dominios",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Edsger_Dijkstra",
            "/wiki/Ciencia_cognitiva",
            "/wiki/F%C3%ADsica",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Software",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Ciencias_de_la_informaci%C3%B3n_(tecnolog%C3%ADa)",
            "/wiki/Ingenier%C3%ADa_en_computaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Problema_de_la_cena_de_los_fil%C3%B3sofos",
            "/wiki/Problemas_no_resueltos_de_las_Ciencias_de_la_Computaci%C3%B3n",
            "/wiki/Mujeres_en_inform%C3%A1tica",
            "/wiki/Premio_Turing",
            "/wiki/Ciencia_web",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Peter_J._Denning",
            "/wiki/Princeton_University_Press",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Steven_Levy",
            "/wiki/ISBN",
            "/wiki/Hal_Abelson",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Donald_Knuth",
            "/wiki/Wayback_Machine",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/University_of_Cambridge",
            "/wiki/Bertrand_Meyer",
            "/wiki/CiteSeerX",
            "/wiki/Digital_Bibliography_%26_Library_Project",
            "/wiki/Universit%C3%A4t_Trier",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Historical_Dictionary_of_Switzerland",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Lat%C3%ADn_tard%C3%ADo",
        "titulo": "Latín tardío",
        "contenido": "el latin tardio (en latin: latinitas serior) es el nombre academico del latin escrito de la antiguedad tardia,​ datado habitualmente en el periodo entre los siglos iii y vi d. c.​​ y continuando hasta el siglo vii en iberia,​ es decir  entre las epocas del latin clasico y el latin medieval. los eruditos no estan de acuerdo exactamente cuando deberia terminar el latin clasico o deberia comenzar el latin medieval. sin embargo, el latin tardio se caracteriza (con variaciones y disputas) por un estilo identificable.  al ser un idioma escrito, el latin tardio no es lo mismo que el latin vulgar, que existia en epoca anterior. este ultimo sirvio como antepasado de las lenguas romances. aunque los autores del latin tardio emplean una mayor cantidad de vocabulario y construcciones del latin vulgar, sigue manteniendo en gran parte caracteristicas generales del latin clasico. algunos escritos del latin tardio son mas literarios y clasicos, pero otros se inclinan mas a lo  vernaculo. ademas, el latin tardio no es identico al latin patristico cristiano, utilizado en la teologia de los primeros padres cristianos. mientras que los escritos cristianos usaban un subconjunto del latin tardio, los paganos tambien escribieron extensamente en latin tardio, especialmente en la primera parte del periodo.  el latin tardio se formo cuando un gran numero de pueblos de habla no latina en la periferia del imperio eran subsumidos y asimilados, y con el surgimiento del cristianismo que introdujo una mayor division en la sociedad romana, creando una mayor necesidad de un lenguaje estandar para comunicarse entre diferentes registros socioeconomicos y regiones muy separadas del extenso imperio. un discurso nuevo y mas universal evoluciono a partir de varios elementos principales: latin clasico; latin cristiano, que contaba con un sermo humilis (habla ordinaria) en la dirigirse a la gente,​ y los diversos dialectos del latin vulgar.​   segun el linguista antoine meillet: \"sin que se modificara mucho la apariencia exterior de la lengua, el latin se convirtio en el transcurso de la epoca imperial en una nueva lengua. sirviendo como una especie de lengua franca para un gran imperio, el latin tendio a simplificarse, para mantenerse por encima de todo lo que tenia de ordinario \".​  los conceptos de latin tardio o antiguedad tardia no son modernos, aunque su origen permanece oscuro. un articulo en harper's new monthly magazine sobre la publicacion del lexicon of the latin language de andrews freund en 1850 menciona que el diccionario divide el latin en anteclasico, clasico, ciceroniano, augusto, post-augusto y postclasico o latin tardio,​​ lo que indica que el termino ya estaba en uso profesional por los clasicistas ingleses de principios del siglo xix. tambien se pueden encontrar ejemplos de uso vernaculo del termino desde el siglo xviii. el termino antiguedad tardia, que significa posclasico y premedieval, se habia difundido en ingles mucho antes de esa fecha.  la primera edicion de 1780 de la historia de la literatura romana de wilhelm sigismund teuffel definia un periodo temprano, la edad de oro, la edad de plata y luego pasa a definir otras edades primero por dinastia y luego por siglo. en las ediciones posteriores, subsumio todos los periodos bajo tres titulos: el primer periodo (latin arcaico), el segundo periodo (la edad de oro) y el tercer periodo, \"la edad imperial\", subdividido en la edad de plata, el siglo ii y los siglos iii-vi juntos, lo que fue un reconocimiento del latin tardio, ya que a veces se refiere a los escritos de esa epoca como \"tardios\". el concepto de latin imperial entraba a la literatura inglesa; la historia de la literatura romana de fowler lo menciona en 1903.​  sin embargo, la caracterizacion como \"imperial\" de este latin presenta problemas insolubles en el comienzo y el final del periodo. politicamente, el periodo augusto excluido es el paradigma de la imperialidad, pero su estilo no puede asociarse con el de la edad de plata ni con el latin tardio. por otra parte, en la italia del siglo vi, el imperio romano de occidente ya no existia sino el gobierno de reyes godos. por ello, el termino latin imperial fue abandonado por los historiadores de la literatura latina, aunque puede aparecer en obras marginales. la edad de plata se extendio un siglo y los ultimos cuatro siglos representan el latin tardio.  el bajo latin es un termino vago y a menudo peyorativo que puede referirse a cualquier latin posclasico desde el latin tardio hasta el latin renacentista, segun el autor. sus origenes son oscuros, pero la expresion latina media et infima latinitas aparecio en 1678 en el titulo de un glosario (para los estandares actuales un diccionario) de charles du fresne, señor du cange. la obra multivolumen tuvo muchas ediciones y ampliaciones de otros autores posteriores. el titulo varia un poco; el mas utilizado fue glossarium mediae et infimae latinitatis. ha sido traducido por expresiones de significados muy diferentes segun se entienda que significa medios, \"medio\" e infima, \"bajo\", en este contexto.  el termino medios esta firmemente conectado al latin medieval por la propia terminologia de cange expuesta en la praefatio,​ como scriptores mediae aetatis, \"escritores de la edad media\". el glosario de cange toma palabras de autores que van desde el periodo cristiano (latin tardio) hasta el latin renacentista, hasta el latin clasico si una palabra se origina alli. tanto media et infima latinitas puede referirse a una edad, que debe ser la edad media aun cubriendo todo el rango postclasico, o bien puede referirse a dos periodos consecutivos, infima latinitas y media latinitas. ambas interpretaciones tienen sus adeptos. ",
        "snippet": "El latín tardío (en latín: Latinitas serior) es el nombre académico del latín escrito de la antigüedad tardía,[1]​ datado habitualmente en el período entre los siglos III y VI d. C.[2]​[3]​ y continuando hasta el siglo VII en Iberia,[1]​ es decir entre las épocas del latín clásico y el latín medieval. Los eruditos no están de acuerdo exactamente cuándo debería terminar el latín clásico o debería comenzar el latín medieval. Sin embargo, el latín tardío se caracteriza (con variaciones y disputas) por un estilo identificable.",
        "enlaces_salientes": [
            "/wiki/Lat%C3%ADn_tard%C3%ADo",
            "/wiki/Lat%C3%ADn_tard%C3%ADo",
            "/wiki/Lat%C3%ADn_tard%C3%ADo",
            "/wiki/Agust%C3%ADn_de_Hipona",
            "/wiki/Siglo_III",
            "/wiki/Siglo_VI",
            "/wiki/Familia_de_lenguas",
            "/wiki/Lenguas_indoeuropeas",
            "/wiki/Lenguas_it%C3%A1licas",
            "/wiki/Lenguas_latino-faliscas",
            "/wiki/Lat%C3%ADn_cl%C3%A1sico",
            "/wiki/Sistema_de_escritura",
            "/wiki/Alfabeto_latino",
            "/wiki/Imperio_romano_de_Occidente",
            "/wiki/Imperio_romano_de_Oriente",
            "/wiki/Griego_koin%C3%A9",
            "/wiki/Imperio_galo",
            "/wiki/Reino_ostrogodo_de_Italia",
            "/wiki/Antig%C3%BCedad_Tard%C3%ADa",
            "/wiki/Invasiones_b%C3%A1rbaras",
            "/wiki/Lat%C3%ADn",
            "/wiki/Lat%C3%ADn",
            "/wiki/Antig%C3%BCedad_tard%C3%ADa",
            "/wiki/Iberia",
            "/wiki/Lat%C3%ADn_cl%C3%A1sico",
            "/wiki/Lat%C3%ADn_medieval",
            "/wiki/Lat%C3%ADn_vulgar",
            "/wiki/Lenguas_romances",
            "/wiki/Vern%C3%A1culo",
            "/wiki/Patr%C3%ADstica",
            "/wiki/Teolog%C3%ADa",
            "/wiki/Paganismo",
            "/wiki/Registro_ling%C3%BC%C3%ADstico",
            "/wiki/Lat%C3%ADn_vulgar",
            "/wiki/Antoine_Meillet",
            "/wiki/Lengua_franca",
            "/wiki/Antig%C3%BCedad_tard%C3%ADa",
            "/wiki/Lat%C3%ADn_arcaico",
            "/wiki/Gildas",
            "/wiki/Charles_du_Fresne,_se%C3%B1or_Du_Cange",
            "/wiki/Lat%C3%ADn_medieval",
            "/wiki/Lat%C3%ADn_cl%C3%A1sico",
            "/wiki/Constantino_I",
            "/wiki/Ausonio",
            "/wiki/Ambrosio_de_Mil%C3%A1n",
            "/wiki/Domicio_Ulpiano",
            "/wiki/Paulo_(jurista)",
            "/wiki/Herenio_Modestino",
            "/wiki/Censorino",
            "/wiki/Tertuliano",
            "/wiki/Pol%C3%A9mica",
            "/wiki/Herej%C3%ADa_en_el_catolicismo",
            "/wiki/Cipriano_de_Cartago",
            "/wiki/M%C3%A1rtir",
            "/wiki/Santo",
            "/wiki/Novaciano",
            "/wiki/Sereno_Samm%C3%B3nico",
            "/wiki/Comodiano",
            "/wiki/Lactancio",
            "/wiki/Amiano_Marcelino",
            "/wiki/Claudiano",
            "/wiki/Cayo_Julio_Solino",
            "/wiki/Nonio_Marcelo",
            "/wiki/Nemesiano",
            "/wiki/Floruit",
            "/wiki/%C3%81quila_Romano",
            "/wiki/Eumenio",
            "/wiki/Calcidio",
            "/wiki/Mario_Victorino",
            "/wiki/Arnobio_de_Sicca",
            "/wiki/Constantino_I",
            "/wiki/Nazario_(ret%C3%B3rico)",
            "/wiki/Juvenco",
            "/wiki/Nonio_Marcelo",
            "/wiki/Julio_F%C3%ADrmico_Materno",
            "/wiki/Elio_Donato",
            "/wiki/Paladio_de_Escocia",
            "/wiki/Aurelio_V%C3%ADctor",
            "/wiki/Eutropio_(historiador)",
            "/wiki/Ausonio",
            "/wiki/Claudio_Mamertino",
            "/wiki/Hilario_de_Poitiers",
            "/wiki/Ambrosio_de_Mil%C3%A1n",
            "/wiki/Lucifer_de_Cagliari",
            "/wiki/Prisciliano",
            "/wiki/Flavio_Sos%C3%ADpater_Carisio",
            "/wiki/Diomedes_Grammaticus",
            "/wiki/Avieno",
            "/wiki/Prisciano",
            "/wiki/Floruit",
            "/wiki/Ca%C3%ADda_del_Imperio_romano_de_Occidente",
            "/wiki/Panegyrici_Latini",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/%C3%81rabe_cl%C3%A1sico",
        "titulo": "Árabe clásico",
        "contenido": "el arabe clasico, tambien llamado arabe culto, en arabe العربيّة الفصحى y arabe coranico, es una variedad del idioma arabe. el arabe clasico es la forma de lengua arabe utilizada en los textos omeyas y abasies (siglos vii y ix). esta basado en los dialectos medievales de las tribus arabes. el arabe estandar moderno es descendiente directo del idioma usado modernamente a traves del mundo arabe, usado en la escritura y el idioma formal hablado, por ejemplo, discursos y transmisiones radiales. mientras que la estilistica y el lexis del arabe estandar moderno es distinto del arabe clasico, la morfologia y la sintaxis se han mantenido basicamente inalteradas. los dialectos vernaculares, sin embargo, han cambiado mas drasticamente. en el mundo arabe se hace poca distincion entre el arabe clasico y el estandar moderno, ambas son llamadas al-fusha (الفصحى) en arabe significando ¨la elocuente¨.  el origen del arabe clasico se encuentra en las partes norte y central de la peninsula arabiga y es distinto de las lenguas del arabe antiguo del sur las cuales fueron habladas en la parte sur de la peninsula, en el moderno yemen. el arabe clasico es la unica lengua sobreviviente de las lenguas del arabe antiguo del norte. la inscripcion mas antigua en arabe clasico data del 328 d. c. y se la conoce como la «inscripcion de namara». fue escrita en el alfabeto nabateo y encontrada al sur de siria en abril de 1901.  con la expansion del islam, el arabe clasico se convirtio en una lengua de importancia a nivel internacional y de devocion religiosa, ya que es la lengua en la que fue escrito el coran. su relacion con los dialectos modernos es similar a la relacion entre el latin y las lenguas romances o entre el idioma chino medio y el idioma chino.  en arabe suele llamarse al-luga al-‘arabiyya al-fusha اللغة العربيّة الفصحى, «la lengua arabe mas elocuente». esta basado en las modalidades hablada y literaria en uso en la region del hiyaz en el siglo vii. esta fijada originalmente por el coran y la poesia arabe preislamica.  paralelamente al uso literario y oficial del arabe clasico, se han desarrollado diferentes modalidades de arabe dialectal o arabe hablado que han convivido con el clasico en situacion de diglosia. existe discusion acerca de si estas variedades dialectales proceden de una transformacion del arabe clasico o si hay que buscar su origen directamente en dialectos preislamicos.  a partir del siglo xix, el arabe clasico ha dado lugar a una subvariedad que en ocasiones recibe el nombre de arabe culto moderno, arabe literal moderno o arabe estandar.  el arabe clasico pertenece a la familia de lenguas semiticas y por lo tanto guarda numerosas similitudes en pronunciacion y conjugacion con idiomas como el hebreo, arameo, acadio y amharico. su uso de vocales para modificar un grupo base de consonantes es similar al hebreo biblico.  por ejemplo:  el arabe pertenece a la familia de lenguas semiticas, una familia linguistica originaria de oriente medio, a la que tambien pertenecen el hebreo y el arameo. es de destacar que la escritura del arabe, conocida como alfabeto arabe, deriva muy directamente del alfabeto arameo. ninguno de estos dos alfabetos suelen transcribir usualmente las vocales breves (aunque si algunas largas). en el arabe clasico, y en particular para la compilacion del coran, se desarrollaron marcas especiales de puntuacion para señalar las vocales breves, indicadas sobre las lineas mediante una puntuacion especial. el arabe se escribe de derecha a izquierda.   ",
        "snippet": "El árabe clásico, también llamado árabe culto, en árabe العربيّة الفصحى y árabe coránico, es una variedad del idioma árabe. El árabe clásico es la forma de lengua árabe utilizada en los textos omeyas y abasíes (siglos VII y IX). Está basado en los dialectos medievales de las tribus árabes. El árabe estándar moderno es descendiente directo del idioma usado modernamente a través del mundo árabe, usado en la escritura y el idioma formal hablado, por ejemplo, discursos y transmisiones radiales. Mientras que la estilística y el lexis del árabe estándar moderno es distinto del árabe clásico, la morfología y la sintaxis se han mantenido básicamente inalteradas. Los dialectos vernaculares, sin embargo, han cambiado más drásticamente. En el mundo árabe se hace poca distinción entre el árabe clásico y el estándar moderno, ambas son llamadas al-fuṣḥā (الفصحى) en árabe significando ¨la elocuente¨.",
        "enlaces_salientes": [
            "/wiki/%C3%81rabe_cl%C3%A1sico",
            "/wiki/%C3%81rabe_cl%C3%A1sico",
            "/wiki/%C3%81rabe_cl%C3%A1sico",
            "/wiki/Idioma_%C3%A1rabe",
            "/wiki/%C3%81rabe_est%C3%A1ndar_moderno",
            "/wiki/Estil%C3%ADstica",
            "/wiki/Arabia",
            "/wiki/Yemen",
            "/wiki/Siria",
            "/wiki/Islam",
            "/wiki/Lenguas_romances",
            "/wiki/Chino_medio",
            "/wiki/Idioma_chino",
            "/wiki/Hiyaz",
            "/wiki/Siglo_VII",
            "/wiki/Cor%C3%A1n",
            "/wiki/%C3%81rabe_dialectal",
            "/wiki/Diglosia",
            "/wiki/Siglo_XIX",
            "/wiki/%C3%81rabe_est%C3%A1ndar_moderno",
            "/wiki/Idioma_hebreo",
            "/wiki/Idioma_arameo",
            "/wiki/Acadio",
            "/wiki/Amh%C3%A1rico",
            "/wiki/Lenguas_sem%C3%ADticas",
            "/wiki/Oriente_Medio",
            "/wiki/Idioma_hebreo",
            "/wiki/Idioma_arameo",
            "/wiki/Alfabeto_%C3%A1rabe",
            "/wiki/Alfabeto_arameo",
            "/wiki/Arabistas",
            "/wiki/Oxford_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Empleador",
        "titulo": "Empleador",
        "contenido": "empleador o patrono​ es, en un contrato de trabajo, la parte que provee pago de una remuneracion o salario. la otra parte del contrato se denomina «trabajador» o empleado.  el vocablo «empleador» esta originado en las relaciones laborales. el empleador es aquel que crea uno o varios puestos de trabajo y los ofrece con el fin de que sean ocupados por trabajadores bajo su mando, y a traves de un contrato laboral.  en algunas ocasiones se confunde «empleador» con «empresa», aunque estrictamente los terminos difieren considerablemente, porque la empresa tambien esta integrada por los trabajadores que pertenecen a ella, a la vez que la expresion incluye los activos de la misma y empleados jerarquico (gerentes y directores) que no son empleadores.  el termino «empleador» tambien se identifica con «capitalista» o «inversor». sin embargo ambos tambien registran diferencias notables, desde el momento que un capitalista o un inversor, suelen no conocer en detalle la gestion de las empresas en las que invierten, e incluso pueden ser personas sin capacidad juridica (niños, inhabilitados, etc.).  el empleador, a diferencia del trabajador, puede ser tanto una persona fisica como una persona juridica.  por definicion, la funcion primordial de un empleador es crear, mantener y ofrecer empleo, en el sentido de puestos de trabajo. ese empleo debe ser libre y decente.  las funciones economicas y sociales del empleador, pueden finalmente entrar en colision con las funciones del inversor o capitalista, cuyo objetivo principal no es crear y mantener puestos de trabajo, sino obtener una ganancia sobre el capital invertido. como en algunas ocasiones es posible obtener ganancia destruyendo empleo, las funciones de uno y otro, en este caso entran en conflicto. en muchas ocasiones el empleador y el inversor suelen ser la misma persona, o aquel depender de este.  como grupo de presion que puede alterar el funcionamiento de un mercado libre, son objeto del mismo recelo que los sindicatos de trabajadores para los teoricos de la liberalismo economico, desde adam smith.  su diferencia es notable con los gremios propios del antiguo regimen, donde al menos en apariencia los maestros compartian con oficiales e incluso aprendices los mismos intereses economicos.  por tanto, la patronal es una institucion que encuentra su razon de ser con el surgimiento de un empresario capitalista que tenga una clara conciencia de sus intereses, contrapuestos a los de los trabajadores; y que de algun modo debe salvar la contraposicion de intereses que la competencia de un mercado libre le hace tener con el resto de empresarios, y sobre todo le permita tener fuerza de negociacion o presion sobre los gobiernos, cuya actividad es vital para sus actividades y les proporciona la unidad de objetivos necesaria. ",
        "snippet": "Empleador o patrono[1]​ es, en un contrato de trabajo, la parte que provee pago de una remuneración o salario. La otra parte del contrato se denomina «trabajador» o empleado.",
        "enlaces_salientes": [
            "/wiki/Empleador",
            "/wiki/Empleador",
            "/wiki/Empleador",
            "/wiki/Contrato_de_trabajo",
            "/wiki/Salario",
            "/wiki/Trabajador",
            "/wiki/Relaciones_laborales",
            "/wiki/Empresa",
            "/wiki/Capitalista",
            "/wiki/Inversi%C3%B3n",
            "/wiki/Persona_f%C3%ADsica",
            "/wiki/Persona_jur%C3%ADdica",
            "/wiki/Puesto_de_trabajo",
            "/wiki/Trabajo_decente",
            "/wiki/Beneficio_econ%C3%B3mico",
            "/wiki/Patronal",
            "/wiki/Grupo_de_presi%C3%B3n",
            "/wiki/Mercado_libre",
            "/wiki/Sindicato",
            "/wiki/Trabajador",
            "/wiki/Liberalismo_econ%C3%B3mico",
            "/wiki/Adam_Smith",
            "/wiki/Gremio",
            "/wiki/Antiguo_R%C3%A9gimen",
            "/wiki/Maestro",
            "/wiki/Oficial_(oficio)",
            "/wiki/Aprendiz",
            "/wiki/Capitalista",
            "/wiki/Conciencia",
            "/wiki/Competencia_(econom%C3%ADa)",
            "/wiki/Negociaci%C3%B3n",
            "/wiki/Gobierno",
            "/wiki/Derecho_laboral",
            "/wiki/Empresa",
            "/wiki/Empleo",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Matem%C3%A1tica",
        "titulo": "Matemáticas",
        "contenido": "las matematicas ​​​ (del latin mathematica, y este del griego μαθηματκα, transliterado como mathematika, derivado de μαθημα, tr. mathema (conocimiento) son una ciencia formal que surgio del estudio de las figuras geometricas y la aritmetica con numeros. hoy en dia se suele aceptar que la matematica es una ciencia que investiga patrones.​​​​​  las ciencias naturales han hecho un uso extensivo de la matematica para explicar diversos fenomenos observables, tal como lo expreso eugene paul wigner (premio nobel de fisica en 1963):  galileo galilei, en la misma linea, lo habia expresado asi:  mediante la abstraccion y el uso de la logica en el razonamiento, la matematica ha evolucionado basandose en el calculo y las mediciones, junto con el estudio sistematico de la forma y el movimiento de los objetos fisicos.​ las matematicas, desde sus comienzos, han tenido un fin practico.  las explicaciones que se apoyaban en la logica aparecieron por primera vez con la matematica helenica, especialmente con los elementos de euclides.​ la matematica siguio desarrollandose, con continuas interrupciones, hasta que en el renacimiento las innovaciones matematicas interactuaron con los nuevos descubrimientos cientificos. como consecuencia, hubo una aceleracion en la investigacion que continua hasta la actualidad.  hoy dia, la matematica se usa en todo el mundo como una herramienta esencial en muchos campos, entre los que se encuentran las ciencias naturales,​ las ciencias aplicadas, las humanidades,​​​ la medicina​ y las ciencias sociales,​​​ e incluso disciplinas que, aparentemente, no estan vinculadas con ella, como la musica​ (por ejemplo, en cuestiones de resonancia armonica, cuerda vibrante,​​ etc.) y la literatura.​ las matematicas aplicadas, rama de la matematica destinada a la aplicacion del conocimiento matematico a otros ambitos, inspiran y hacen uso de los nuevos descubrimientos matematicos y, en ocasiones, conducen al desarrollo de nuevas disciplinas. los matematicos​ tambien participan en la matematica pura, sin tener en cuenta la aplicacion de esta ciencia, aunque las aplicaciones practicas de la matematica pura suelen ser descubiertas con el paso del tiempo.  las matematicas son una de las ciencias mas antiguas. florecio primero antes de la antiguedad en mesopotamia,​ en cuanto a la geometria​, india y china, y mas tarde en la antiguedad en grecia y el helenismo. de ahi data la orientacion hacia la tarea de \"demostracion puramente logica\" y la primera axiomatizacion, a saber, la geometria euclidiana​. en la edad media sobrevivio de forma independiente en el primer humanismo de las universidades y en el mundo arabe.  a principios de la era moderna, francois viete introdujo variables y rene descartes inauguro un enfoque computacional de la geometria​​​  mediante el uso de coordenadas. la consideracion de las tasas de cambio (fluxion)​ asi como la descripcion de las tangentes y la determinacion de los contenidos de las superficies (cuadratura)​ condujeron al calculo infinitesimal​ de gottfried wilhelm leibniz e isaac newton​. la mecanica de newton y su ley de la gravitacion fueron tambien una fuente de orientacion de problemas matematicos como el problema de los tres cuerpos​​​ en los siglos siguientes.  otro de los principales problemas de la primera epoca moderna fue la solucion de ecuaciones algebraicas cada vez mas complicadas. para hacer frente a esto, niels henrik abel y evariste galois desarrollaron el concepto de grupo, que describe las relaciones entre las simetrias de un objeto.​​ el algebra mas reciente y, en particular, la geometria algebraica pueden considerarse como una profundizacion de estas investigaciones.  una idea entonces nueva en el intercambio de cartas entre blaise pascal y pierre de fermat en 1654 acerca del problema de los juegos de azar,​​​ aunque  existian otras soluciones discutibles como las de cardano, quien intento matematizarlas. pierre-simon laplace hace un recuento de los diferentes logros hasta 1812 cuando publica su ensayo filosofico sobre las posibilidades.​ las nuevas ideas y metodos conquistaron muchos campos. pero durante siglos, la teoria clasica de la probabilidad se dividio en escuelas separadas. los intentos de definir explicitamente el termino «probabilidad» solo tuvieron exito para casos especiales. solo la publicacion del libro de texto de andrei kolmogorov en 1933 los fundamentos de la teoria de la  probabilidad ​ completo el desarrollo de los fundamentos de la teoria moderna de la probabilidad.  en el transcurso del siglo xix, el calculo infinitesimal​ encontro su forma actual de rigor gracias a los trabajos de augustin-louis cauchy y karl weierstrass. la teoria de conjuntos​ desarrollada por georg cantor hacia finales del siglo xix es tambien indispensable en la matematica actual, aunque las paradojas del concepto ingenuo de conjuntos dejaron claro, en un primer momento, la incierta base sobre la que se asentaban las matematicas.​  el desarrollo de la primera mitad del siglo xx estuvo influenciado por la lista de 23 problemas matematicos​ de david hilbert. uno de los problemas fue el intento de axiomatizar completamente las matematicas; al mismo tiempo, se hicieron grandes esfuerzos de abstraccion, es decir, el intento de reducir los objetos a sus propiedades esenciales. asi, emmy noether desarrollo los fundamentos del algebra moderna,​ felix hausdorff desarrollo la topologia general como el estudio de los espacios topologicos, stefan banach desarrollo probablemente el concepto mas importante del analisis funcional, el espacio de banach que lleva su nombre. un nivel de abstraccion aun mayor, un marco comun para la consideracion de construcciones similares de diferentes areas de las matematicas, fue finalmente creado por la introduccion de la teoria de categorias por samuel eilenberg y saunders mac lane.  la palabra «matematica» (del griego μαθηματκα mathematika, «cosas que se aprenden») viene del griego antiguo μαθημα (mathema), que quiere decir «campo de estudio o instruccion». las matematicas requieren un esfuerzo de instruccion o aprendizaje, refiriendose a areas del conocimiento que solo pueden entenderse tras haber sido instruido en las mismas, como la astronomia. «el arte matematica» (μαθηματκη τεχνη, mathematike tekhne) se contrapondria en esto a la musica, «el arte de las musas» (μουσκη τεχνη, mousike techne), que seria un arte, como la poesia, retorica​​ y similares, que se puede apreciar directamente, «que se puede entender sin haber sido instruido».​ aunque el termino ya era usado por los pitagoricos (matematikoi) en el siglo vi a. c., alcanzo su significado mas tecnico y reducido de «estudio matematico» en los tiempos de aristoteles (siglo iv a. c.). su adjetivo es μαθηματκος (mathematikos), «relacionado con el aprendizaje», lo cual, de manera similar, vino a significar «matematico». en particular, μαθηματκη τεχνη (mathematike tekhne; en latin ars mathematica), significa «el arte matematica».  la forma mas usada es el plural matematicas (cuyo acortamiento, en algunos paises,  es «mates»​​), que tiene el mismo significado que el singular​ y viene de la forma latina mathematica (ciceron), basada en el plural en griego τα μαθηματκα (ta mathematika), usada por aristoteles y que significa, a grandes rasgos, «todas las cosas matematicas». algunos autores, sin embargo, hacen uso de la forma singular del termino; tal es el caso de bourbaki, en el tratado elementos de matematica (elements de mathematique, 1940), destaca la uniformidad de este campo aportada por la vision axiomatica moderna, aunque tambien hace uso de la forma plural como en elements d'histoire des mathematiques (1969),​ posiblemente sugiriendo que es bourbaki quien finalmente realiza la unificacion de las matematicas.​ asi mismo, en el escrito l'architecture des mathematiques (1948)  plantea el tema en la seccion «¿matematicas, singular o plural?» donde defiende la unicidad conceptual de la matematica aunque hace uso de la forma plural en dicho escrito.​​​​  establecer definiciones claras y precisas es el fundamento de la matematica, aunque encontrar  una definicion unica para ella es improbable.​ se muestran algunas reflexiones de reconocidos autores:  el caracter epistemologico y cientifico de la matematica ha sido ampliamente discutido. en la practica, la matematica se emplea para estudiar relaciones cuantitativas, estructuras, relaciones geometricas y las magnitudes variables. los matematicos buscan patrones,​​​​ formulan nuevas conjeturas e intentan alcanzar la verdad matematica mediante deducciones rigurosas. estas les permiten establecer los axiomas y las definiciones apropiados para dicho fin.​​ algunas definiciones clasicas restringen las matematicas al razonamiento sobre cantidades,​ aunque solo una parte de la matematica actual usa numeros,​ predominando el analisis logico de construcciones abstractas no cuantitativas.  existe cierta discusion acerca de si los objetos matematicos, como los numeros​ y puntos, realmente existen o simplemente provienen de la imaginacion humana. el matematico benjamin peirce definio las matematicas como «la ciencia que señala las conclusiones necesarias».​ por otro lado:  se ha discutido el caracter cientifico de las matematicas debido a que sus procedimientos y resultados poseen una firmeza e inevitabilidad inexistentes en otras disciplinas como pueden ser la fisica, la quimica o la biologia. asi, la matematica seria tautologica, infalible y a priori, mientras que otras, como la geologia o la fisiologia, serian falibles y a posteriori. son estas caracteristicas lo que hace dudar de colocarse en el mismo rango que las disciplinas antes citadas. john stuart mill afirmaba:  asi, los matematicos pueden descubrir nuevos procedimientos para resolver integrales o teoremas, pero se muestran incapaces de descubrir un suceso que ponga en duda el teorema de pitagoras​​  o cualquier otro, como si sucede constantemente con las ciencias de la naturaleza.​  la matematica puede ser entendida como ciencia; si es asi debiera señalarse su objeto y su metodo. sin embargo, algunos plantean que la matematica es un lenguaje formal, seguro, eficiente, aplicable al entendimiento de la naturaleza, tal como indico galileo; ademas muchos fenomenos de caracter social, otros de caracter biologico​ o geologico, pueden ser estudiados mediante la aplicacion de ecuaciones diferenciales,​​ calculo de probabilidades o teoria de conjunto.​ precisamente, el avance de la fisica y de la quimica ha exigido la invencion de nuevos conceptos, instrumentos y metodos en la matematica, sobre todo en el analisis real, analisis complejo y el analisis matricial.​  es muy posible que el arte de calcular​​​ haya sido desarrollado antes incluso que la escritura,​​ relacionado fundamentalmente con la contabilidad y la administracion de bienes, el comercio, en la agrimensura y, posteriormente, en la astronomia.  actualmente, todas las ciencias aportan problemas que son estudiados por matematicos, al mismo tiempo que aparecen nuevos problemas dentro de las propias matematicas. por ejemplo, el fisico richard feynman propuso la integral de caminos como fundamento de la mecanica cuantica, combinando el razonamiento matematico y el enfoque de la fisica, pero todavia, no se ha logrado una definicion plenamente satisfactoria en terminos matematicos. igualmente, la teoria de cuerdas, una teoria cientifica en desarrollo que trata de unificar las cuatro fuerzas fundamentales de la fisica, sigue inspirando a las mas modernas matematicas.​  algunas matematicas solo son relevantes en el area en la que estaban inspiradas y son aplicadas para otros problemas en ese campo. sin embargo, a menudo las matematicas inspiradas en un area concreta resultan utiles en muchos ambitos, y se incluyen dentro de los conceptos matematicos generales aceptados. el notable hecho de que incluso la matematica mas pura habitualmente tiene aplicaciones practicas es lo que eugene paul wigner ha definido como «la irrazonable eficacia de las matematicas en las ciencias naturales».​​  como en la mayoria de las areas de estudio, la explosion de los conocimientos en la era cientifica ha llevado a la especializacion de las matematicas. hay una importante distincion entre las matematicas puras y las matematicas aplicadas. la mayoria de los matematicos que se dedican a la investigacion se centran unicamente en una de estas areas y, a veces, la eleccion se realiza cuando comienzan su licenciatura. varias areas de las matematicas aplicadas se han fusionado con otras areas tradicionalmente fuera de las matematicas y se han convertido en disciplinas independientes, como pueden ser la estadistica, la investigacion de operaciones o la informatica.  aquellos que sienten predileccion por las matematicas, consideran que prevalece un aspecto estetico que define a la mayoria de las matematicas. muchos matematicos hablan de la elegancia de la matematica, su intrinseca estetica y su belleza interna. en general, uno de sus aspectos mas valorados es la simplicidad. hay belleza en una simple y contundente demostracion, como la demostracion de euclides​ de la existencia de infinitos numeros primos, y en un elegante analisis numerico que acelera el calculo, asi como en la transformada rapida de fourier. godfrey harold hardy en a mathematician's apology ​ (apologia de un matematico) expreso la conviccion de que estas consideraciones esteticas son, en si mismas, suficientes para justificar el estudio de las matematicas puras. los matematicos con frecuencia se esfuerzan por encontrar demostraciones de los teoremas que son especialmente elegantes, el excentrico matematico paul erdos se refiere a este hecho como la busqueda de pruebas de el libro en el que dios ha escrito sus demostraciones favoritas.​​ la popularidad de la matematica recreativa​​​​ es otra señal que nos indica el placer que produce resolver las preguntas matematicas.  la mayor parte de la notacion​ matematica que se utiliza hoy en dia no se invento hasta el siglo xviii.​​ antes de eso, las matematicas eran escritas con palabras, un minucioso proceso que limitaba el avance matematico. en el siglo xviii, euler, fue responsable de muchas de las notaciones empleadas en la actualidad. la notacion​ moderna hace que las matematicas sean mucho mas facil para los profesionales, pero para los principiantes resulta complicada. la notacion reduce las matematicas al maximo, hace que algunos simbolos​ contengan una gran cantidad de informacion. al igual que la notacion musical, la notacion matematica moderna tiene una sintaxis estricta y codifica la informacion que seria dificil de escribir de otra manera.  el lenguaje matematico tambien puede ser dificil para los principiantes. palabras tales como o y solo tienen significados mas precisos que en lenguaje cotidiano. ademas, palabras como abierto y cuerpo tienen significados matematicos muy concretos. la jerga matematica, o lenguaje matematico, incluye terminos tecnicos como homeomorfismo o integrabilidad. la razon que explica la necesidad de utilizar la notacion y la jerga es que el lenguaje matematico requiere mas precision que el lenguaje cotidiano. los matematicos se refieren a esta precision en el lenguaje y en la logica como el «rigor».  el rigor es una condicion indispensable que debe tener una demostracion matematica. los matematicos quieren que sus teoremas a partir de los axiomas sigan un razonamiento sistematico. esto sirve para evitar teoremas erroneos, basados en intuiciones falibles, que se han dado varias veces en la historia de esta ciencia.​ el nivel de rigor previsto en las matematicas ha variado con el tiempo: los griegos buscaban argumentos detallados, pero en tiempos de isaac newton los metodos empleados eran menos rigurosos. los problemas inherentes de las definiciones que newton utilizaba dieron lugar a un resurgimiento de un analisis cuidadoso y a las demostraciones oficiales del siglo xix. ahora, los matematicos continuan apoyandose entre ellos mediante demostraciones asistidas por ordenador.​  un axioma se interpreta tradicionalmente como una «verdad evidente», pero esta concepcion es problematica. en el ambito formal, un axioma no es mas que una cadena de simbolos, que tiene un significado intrinseco solo en el contexto de todas las formulas derivadas de un sistema axiomatico.  carl friedrich gauss se referia a la matematica como «la reina de las ciencias».​ tanto en el latin original scientiarum regina, asi como en aleman konigin der wissenschaften, la palabra ciencia debe ser interpretada como (campo de) conocimiento. si se considera que la ciencia es el estudio del mundo fisico, entonces las matematicas, o por lo menos las matematicas puras, no son una ciencia.  muchos filosofos creen que las matematicas no son experimentalmente falsables y, por ende, no son una ciencia segun la definicion de karl popper.​ no obstante, en la decada de 1930 una importante labor en la logica matematica demuestra que las matematicas no pueden reducirse a la logica​ y karl popper llego a la conclusion de que «la mayoria de las teorias matematicas son, como las de fisica y biologia, hipotetico-deductivas. por lo tanto, las matematicas puras se han vuelto mas cercanas a las ciencias naturales​ cuyas hipotesis son conjeturas, asi ha sido hasta ahora».​ otros pensadores, en particular imre lakatos, han solicitado una version de falsacionismo​​ para las propias matematicas.​  una vision alternativa es que determinados campos cientificos (como la fisica teorica) son matematicas con axiomas que pretenden corresponder a la realidad. de hecho, el fisico teorico, john michael ziman, propone que la ciencia es «conocimiento publico» y, por tanto, incluye a las matematicas.​ en cualquier caso, las matematicas tienen mucho en comun con distintos campos de las ciencias fisicas, especialmente la exploracion de las consecuencias logicas de las hipotesis. la intuicion​ y la experimentacion tambien desempeñan un papel importante en la formulacion de conjeturas tanto en las matematicas como en las otras ciencias. las matematicas experimentales siguen ganando representacion dentro de las matematicas. el calculo​ y simulacion​ estan jugando un papel cada vez mayor tanto en las ciencias como en las matematicas, atenuando la objecion de que las matematicas no se sirven del metodo cientifico. en 2002 stephen wolfram propuso, en su libro​ un nuevo tipo de ciencia, que la matematica computacional merece ser explorada empiricamente como un campo cientifico.  las opiniones de los matematicos sobre este asunto son muy variadas. muchos matematicos consideran que llamar a su campo ciencia es minimizar la importancia de su perfil estetico, ademas supone negar su historia dentro de las siete artes liberales. otros consideran que hacer caso omiso de su conexion con las ciencias supone ignorar la evidente conexion entre las matematicas y sus aplicaciones en la ciencia y la ingenieria, que ha impulsado considerablemente el desarrollo de las matematicas. otro asunto de debate, que guarda cierta relacion con el anterior, es si la matematica fue creada (como el arte) o descubierta (como la ciencia). este es uno de los muchos temas de incumbencia de la filosofia de las matematicas.  los premios matematicos se mantienen generalmente separados de sus equivalentes en la ciencia. el mas prestigioso premio dentro de las matematicas es la medalla fields,​ fue instaurado en 1936 y se concede cada cuatro años. a menudo se le considera el equivalente del premio nobel para la ciencia. otros premios son el premio wolf en matematica, creado en 1978, que reconoce los logros en vida de los matematicos, y el premio abel, otro gran premio internacional, que se introdujo en 2003. estos dos ultimos se conceden por un excelente trabajo, que puede ser una investigacion innovadora o la solucion de un problema pendiente en un campo determinado. una famosa lista de esos 23 problemas sin resolver​, denominada los «problemas de hilbert», fue recopilada en 1900 por el matematico aleman david hilbert. esta lista ha alcanzado gran popularidad entre los matematicos y, al menos, nueve de los problemas ya han sido resueltos. una nueva lista de siete problemas fundamentales, titulada «problemas del milenio», se publico en 2000. la solucion de cada uno de los problemas sera recompensada con 1 millon de dolares. curiosamente, tan solo uno (la hipotesis de riemann) aparece en ambas listas.  la sociedad matematica americana distingue unas 5.000 ramas distintas de matematica.​ en una subdivision escolarizada de la matematica se distinguen cinco areas de estudio basicas: la cantidad, la estructura, el espacio, el cambio y la variabilidad que se corresponden con la aritmetica, el algebra, la geometria, el calculo, la probabilidad y estadistica. como señalaba richard courant​ «es posible seguir una ruta directa a partir de los elementos fundamentales hasta puntos avanzados» para que puedan divisarse las directrices de la matematica como ciencia. ademas, hay ramas de las matematicas conectadas a otros campos, por ejemplo la logica, teoria de conjuntos y las matematicas aplicadas entre muchas otras tal como indica la sociedad matematica americana.​  2ei4π⁄3  el concepto «matematica aplicada» se refiere a aquellos metodos y herramientas matematicas que pueden ser utilizados en el analisis o resolucion de problemas pertenecientes al area de las ciencias basicas o aplicadas.  muchos metodos matematicos han resultado efectivos en el estudio de problemas en fisica, quimica, biologia,​ medicina,​ ciencias sociales,​ ingenieria, economia,​ finanzas, ecologia entre otras.  sin embargo, una posible diferencia es que en matematica aplicada se procura el desarrollo de la matematica «hacia afuera», es decir su aplicacion o transferencia hacia el resto de las areas. y en menor grado «hacia dentro» o sea, hacia el desarrollo de la matematica misma. este ultimo seria el caso de la matematica pura o matematica elemental.  la matematica aplicada se usa con frecuencia en distintas areas tecnologicas para modelado,​​ simulacion​ y optimizacion de procesos o fenomenos,​ como el tunel de viento o el diseño de experimentos.  la estadistica es la rama de la matematica que estudia la variabilidad, asi como el proceso aleatorio que la genera siguiendo leyes de probabilidad.​ es un conocimiento fundamental para la investigacion cientifica en algunos campos de la tecnologia, como informatica e ingenieria, y de las ciencias facticas,​ como economia,​ genetica, sociologia,​ psicologia,​ medicina,​ contabilidad, etc. en ocasiones, estas areas de conocimiento necesitan aplicar tecnicas estadisticas durante su proceso de investigacion factual, con el fin de obtener nuevos conocimientos basados en la experimentacion y en la observacion, precisando para ello recolectar, organizar, presentar y analizar un conjunto de datos numericos y, a partir de ellos y de un marco teorico, hacer las inferencias apropiadas.​​​​​  se consagra en forma directa al gran problema universal de como tomar decisiones inteligentes y acertadas en condiciones de incertidumbre. la estadistica descriptiva sirve como fuente de instruccion en los niveles basicos de estadistica aplicada a las ciencias facticas​ y, por tanto, los conceptos manejados y las tecnicas empleadas suelen ser presentadas de la forma mas simple y clara posibles. ",
        "snippet": "Las matemáticas [2]​[3]​[4]​ (del latín mathematĭca, y este del griego μαθηματικά, transliterado como mathēmatiká, derivado de μάθημα, tr. máthēma (conocimiento) son una ciencia formal que surgió del estudio de las figuras geométricas y la aritmética con números. Hoy en día se suele aceptar que la matemática es una ciencia que investiga patrones.[5]​[6]​[7]​[8]​[9]​",
        "enlaces_salientes": [
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Papiro_de_Ahmes",
            "/wiki/Ahmes_(escriba)",
            "/wiki/Gregor_Reisch",
            "/wiki/Algorista",
            "/wiki/Euclides",
            "/wiki/Comp%C3%A1s_(instrumento)",
            "/wiki/Rafael_Sanzio",
            "/wiki/La_escuela_de_Atenas",
            "/wiki/Lat%C3%ADn",
            "/wiki/Griego_antiguo",
            "/wiki/Romanizaci%C3%B3n_del_griego",
            "/wiki/Conocimiento",
            "/wiki/Ciencias_formales",
            "/wiki/Figura_geom%C3%A9trica",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Ciencias_naturales",
            "/wiki/Eugene_Paul_Wigner",
            "/wiki/Galileo_Galilei",
            "/wiki/L%C3%B3gica",
            "/wiki/Razonamiento",
            "/wiki/C%C3%A1lculo",
            "/wiki/Medici%C3%B3n",
            "/wiki/Forma_(figura)",
            "/wiki/Movimiento_(f%C3%ADsica)",
            "/wiki/Matem%C3%A1tica_hel%C3%A9nica",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Euclides",
            "/wiki/Renacimiento",
            "/wiki/Ciencias_naturales",
            "/wiki/Ciencias_aplicadas",
            "/wiki/Humanidades",
            "/wiki/Medicina",
            "/wiki/Ciencias_sociales",
            "/wiki/M%C3%BAsica",
            "/wiki/Cuerda_vibrante",
            "/wiki/Matem%C3%A1tica_aplicada",
            "/wiki/Historia_de_las_matem%C3%A1ticas",
            "/wiki/Antig%C3%BCedad",
            "/wiki/Mesopotamia",
            "/wiki/India",
            "/wiki/Historia_de_China",
            "/wiki/Helenismo",
            "/wiki/Axiomatizaci%C3%B3n",
            "/wiki/Geometr%C3%ADa_euclidiana",
            "/wiki/Edad_Media",
            "/wiki/Era_moderna",
            "/wiki/Fran%C3%A7ois_Vi%C3%A8te",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Coordenadas",
            "/wiki/C%C3%A1lculo_infinitesimal#Modernidad",
            "/wiki/Cuadratura_(geometr%C3%ADa)",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Isaac_Newton",
            "/wiki/Mec%C3%A1nica_cl%C3%A1sica",
            "/wiki/Ley_de_gravitaci%C3%B3n_universal",
            "/wiki/Problema_de_los_tres_cuerpos",
            "/wiki/Niels_Henrik_Abel",
            "/wiki/%C3%89variste_Galois",
            "/wiki/Grupo_(matem%C3%A1tica)",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa_algebraica",
            "/wiki/Blaise_Pascal",
            "/wiki/Pierre_de_Fermat",
            "/wiki/Pierre-Simon_Laplace",
            "/wiki/Andr%C3%A9i_Kolmog%C3%B3rov",
            "/wiki/Rigor_matem%C3%A1tico",
            "/wiki/Augustin_Louis_Cauchy",
            "/wiki/Karl_Weierstra%C3%9F",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Georg_Cantor",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/David_Hilbert",
            "/wiki/Emmy_Noether",
            "/wiki/Felix_Hausdorff",
            "/wiki/Topolog%C3%ADa",
            "/wiki/Espacios_topol%C3%B3gicos",
            "/wiki/Stefan_Banach",
            "/wiki/An%C3%A1lisis_funcional",
            "/wiki/Espacio_de_Banach",
            "/wiki/Teor%C3%ADa_de_categor%C3%ADas",
            "/wiki/Samuel_Eilenberg",
            "/wiki/Saunders_Mac_Lane",
            "/wiki/Astronom%C3%ADa",
            "/wiki/Musa",
            "/wiki/Ret%C3%B3rica",
            "/wiki/Pitag%C3%B3ricos",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Marco_Tulio_Cicer%C3%B3n",
            "/wiki/Nicolas_Bourbaki",
            "/wiki/Elementos_de_matem%C3%A1tica",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Mathesis_Universalis",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/David_Hilbert",
            "/wiki/Finitismo",
            "/wiki/Benjamin_Peirce",
            "/wiki/Bertrand_Russell",
            "/wiki/John_David_Barrow",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/Espacio_m%C3%A9trico",
            "/wiki/C%C3%A1lculo",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Conjetura",
            "/wiki/Verdad",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Rigor",
            "/wiki/Axioma",
            "/wiki/Definici%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Definici%C3%B3n",
            "/wiki/Punto_(geometr%C3%ADa)",
            "/wiki/Benjamin_Peirce",
            "/wiki/Albert_Einstein",
            "/wiki/F%C3%ADsica",
            "/wiki/Qu%C3%ADmica",
            "/wiki/Biolog%C3%ADa",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/A_priori_y_a_posteriori",
            "/wiki/Geolog%C3%ADa",
            "/wiki/Fisiolog%C3%ADa",
            "/wiki/John_Stuart_Mill",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Teorema",
            "/wiki/Teorema_de_Pit%C3%A1goras",
            "/wiki/Ciencias",
            "/wiki/Naturaleza",
            "/wiki/Teorema_de_Pit%C3%A1goras",
            "/wiki/%C3%81baco",
            "/wiki/Calculadora",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Suma",
            "/wiki/Resta",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Galileo_Galilei",
            "/wiki/Isaac_Newton",
            "/wiki/Gottfried_Leibniz",
            "/wiki/C%C3%A1lculo",
            "/wiki/Contabilidad",
            "/wiki/Comercio",
            "/wiki/Agrimensura",
            "/wiki/Astronom%C3%ADa",
            "/wiki/F%C3%ADsico",
            "/wiki/Richard_Feynman",
            "/wiki/Integral_de_caminos_(mec%C3%A1nica_cu%C3%A1ntica)",
            "/wiki/Mec%C3%A1nica_cu%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_cuerdas",
            "/wiki/Interacciones_fundamentales",
            "/wiki/Eugene_Paul_Wigner",
            "/wiki/Ciencias_Naturales",
            "/wiki/Matem%C3%A1ticas_puras",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Licenciatura",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Investigaci%C3%B3n_de_operaciones",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Est%C3%A9tica",
            "/wiki/Belleza",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/N%C3%BAmero_primo",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Transformada_r%C3%A1pida_de_Fourier",
            "/wiki/Godfrey_Harold_Hardy",
            "/wiki/Apolog%C3%ADa_de_un_matem%C3%A1tico",
            "/wiki/Paul_Erd%C5%91s",
            "/wiki/Matem%C3%A1tica_recreativa",
            "/wiki/Notaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Leonhard_Euler",
            "/wiki/Siglo_XVIII",
            "/wiki/Leonhard_Euler",
            "/wiki/Notaci%C3%B3n_musical",
            "/wiki/Infinito",
            "/wiki/Lenguaje",
            "/wiki/Conjunto_abierto",
            "/wiki/Cuerpo_(matem%C3%A1ticas)",
            "/wiki/Jerga",
            "/wiki/Homeomorfismo",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Rigor",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Teorema",
            "/wiki/Isaac_Newton",
            "/wiki/Siglo_XIX",
            "/wiki/Axioma",
            "/wiki/Sistema_axiom%C3%A1tico",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/Ciencia",
            "/wiki/F%C3%ADsico",
            "/wiki/Matem%C3%A1ticas_puras",
            "/wiki/Falsacionismo",
            "/wiki/Karl_Popper",
            "/wiki/A%C3%B1os_1930",
            "/wiki/F%C3%ADsica",
            "/wiki/Biolog%C3%ADa",
            "/wiki/M%C3%A9todo_hipot%C3%A9tico-deductivo",
            "/wiki/Hip%C3%B3tesis_(l%C3%B3gica)",
            "/wiki/Imre_Lakatos",
            "/wiki/Falsacionismo",
            "/wiki/F%C3%ADsica_te%C3%B3rica",
            "/wiki/Axiomas",
            "/wiki/John_Michael_Ziman",
            "/wiki/Ciencias_f%C3%ADsicas",
            "/wiki/Intuici%C3%B3n",
            "/wiki/Experimentaci%C3%B3n",
            "/wiki/Conjeturas",
            "/wiki/C%C3%A1lculo",
            "/wiki/M%C3%A9todo_cient%C3%ADfico",
            "/wiki/Stephen_Wolfram",
            "/wiki/Un_nuevo_tipo_de_ciencia",
            "/wiki/Matem%C3%A1tica_computacional",
            "/wiki/Est%C3%A9tico",
            "/wiki/Artes_liberales",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Debate",
            "/wiki/Filosof%C3%ADa_de_la_matem%C3%A1tica",
            "/wiki/Medalla_Fields",
            "/wiki/Premio_Nobel",
            "/wiki/Premio_Abel",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/David_Hilbert",
            "/wiki/Problemas_del_milenio",
            "/wiki/Hip%C3%B3tesis_de_Riemann",
            "/wiki/%C3%81reas_de_las_matem%C3%A1ticas",
            "/wiki/Sociedad_Matem%C3%A1tica_Americana",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/C%C3%A1lculo",
            "/wiki/Probabilidad",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Richard_Courant",
            "/wiki/L%C3%B3gica",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Matem%C3%A1ticas_puras",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/N%C3%BAmero_real",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/Combinatoria",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Teor%C3%ADa_de_grupos",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Teor%C3%ADa_del_orden",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Trigonometr%C3%ADa",
            "/wiki/Geometr%C3%ADa_diferencial",
            "/wiki/Topolog%C3%ADa",
            "/wiki/Fractal",
            "/wiki/Teor%C3%ADa_de_la_medida",
            "/wiki/C%C3%A1lculo",
            "/wiki/C%C3%A1lculo_vectorial",
            "/wiki/Ecuaci%C3%B3n_diferencial",
            "/wiki/Sistema_din%C3%A1mico",
            "/wiki/Teor%C3%ADa_del_caos",
            "/wiki/An%C3%A1lisis_complejo",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Ciencias_f%C3%A1cticas",
            "/wiki/F%C3%ADsica_matem%C3%A1tica",
            "/wiki/Mec%C3%A1nica_de_fluidos",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Teor%C3%ADa_de_la_probabilidad",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Matem%C3%A1tica_financiera",
            "/wiki/Teor%C3%ADa_de_juegos",
            "/wiki/Biolog%C3%ADa_matem%C3%A1tica",
            "/wiki/Qu%C3%ADmica_matem%C3%A1tica",
            "/wiki/Econom%C3%ADa_matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_control",
            "/wiki/Belleza_matem%C3%A1tica",
            "/wiki/Filosof%C3%ADa_de_las_matem%C3%A1ticas",
            "/wiki/Fundamentos_de_las_matem%C3%A1ticas",
            "/wiki/Matem%C3%A1ticas_y_arquitectura",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Olimpiada_Internacional_de_Matem%C3%A1tica",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Euclides",
            "/wiki/Keith_Devlin",
            "/wiki/ISBN",
            "/wiki/Mate_(infusi%C3%B3n)",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Demostraci%C3%B3n_inv%C3%A1lida",
            "/wiki/Teorema_de_los_cuatro_colores",
            "/wiki/ISBN",
            "/wiki/Constante_macabra",
            "/wiki/Funci%C3%B3n_gaussiana",
            "/wiki/Eric_Temple_Bell",
            "/wiki/Albert_Einstein",
            "/wiki/Benjamin_Peirce",
            "/wiki/Karl_Popper",
            "/wiki/Wolfgang_Sartorius_von_Waltershausen",
            "/wiki/Wolfgang_Sartorius_von_Waltershausen",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Historical_Dictionary_of_Switzerland",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Medical_Subject_Headings"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_de_multiplicaci%C3%B3n",
        "titulo": "Algoritmo de multiplicación",
        "contenido": "multiplicaciones  el algoritmo estandar para multiplicar dos numeros enteros, requiere el aprendizaje previo de las tablas de multiplicar. la multiplicacion se empieza desde la derecha, teniendo cuidado con la ley de los signos y con colocar las unidades de un orden bajo las unidades del mismo orden (unidades bajo unidades, decenas bajo decenas, centenas bajo centenas, etc.). luego se suman los productos de cada cifra del segundo factor por todas las del primero.  sea la multiplicacion de 4103 como multiplicando y 254 como multiplicador.  se coloca el multiplicador debajo del multiplicando, haciendo coincidir las columnas de las unidades por la derecha.   4 1 0 3 × 2 5 4 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline \\end{array}}}  conforme a las tablas elementales, se multiplica la cifra de unidades (4)del multiplicador por cada una de las cifras del multiplicando, empezando por las unidades (3) acarreando, en su caso, las decenas (4 × 3 = 12, acarreo de 1 unidad) como suma al resultado de la multiplicacion de la cifra siguiente [(4 × 0) + 1 = 1), 1 de acarreo], continuandose de igual forma con las demas cifras del multiplicando (4103 × 4 = 16412). consideramos esta linea como linea provisional.   4 1 0 3 × 2 5 4 1 6 4 1 2 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline &&1&6&4&1&2\\\\\\end{array}}}  se procede de igual forma con la cifra de las decenas del multiplicador con cada una de las cifras del multiplicando, si bien el resultado se escribe debajo de la fila anterior corriendo un lugar a la izquierda la cifra de las unidades. (4103 × 5 = 20515)   4 1 0 3 × 2 5 4 1 6 4 1 2 2 0 5 1 5 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline &&1&6&4&1&2\\\\&2&0&5&1&5&\\\\\\end{array}}}  se continua asi con todas las cifras del multiplicador. (4103 × 2 = 8206)   4 1 0 3 × 2 5 4 1 6 4 1 2 2 0 5 1 5 8 2 0 6 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline &&1&6&4&1&2\\\\&2&0&5&1&5&\\\\&8&2&0&6&&\\\\\\end{array}}}  finalmente se suman las cifras de cada una de las lineas provisionales, considerando los huecos de la derecha como ceros.   4 1 0 3 × 2 5 4 1 6 4 1 2 2 0 5 1 5 8 2 0 6 1 0 4 2 1 6 2 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline &&1&6&4&1&2\\\\&2&0&5&1&5&\\\\&8&2&0&6&&\\\\\\hline 1&0&4&2&1&6&2\\\\\\end{array}}}  el resultado o multiplicacion es el que resulta de dicha suma (4103 × 254 = 1042162)  en este ejemplo se utiliza la multiplicacion larga de multiplicar 23 958 233 (multiplicando) por 5 830 (multiplicador) y se llega al 139 676 498 390 como resultado del producto.   2 3 9 5 8 2 3 3 × 5 8 3 0 ⟵ multiplicando ⟵ multiplicador {rrrrrrrrrrrr}&&&&2&3&9&5&8&2&3&3\\\\\\times &&&&&&&&5&8&3&0\\\\\\hline \\end{array}}{l}\\longleftarrow \\;}\\\\\\longleftarrow \\;}\\\\\\end{array}}}  se realizan las operaciones:   2 3 9 5 8 2 3 3 × 5 8 3 0 0 0 0 0 0 0 0 0 7 1 8 7 4 6 9 9 1 9 1 6 6 5 8 6 4 1 1 9 7 9 1 1 6 5 1 3 9 6 7 6 4 9 8 3 9 0 ⟵ 23 958 233 × 0 ⟵ 23 958 233 × 30 ⟵ 23 958 233 × 800 ⟵ 23 958 233 × 5.000 {rrrrrrrrrrrr}&&&&2&3&9&5&8&2&3&3\\\\\\times &&&&&&&&5&8&3&0\\\\\\hline &&&&0&0&0&0&0&0&0&0\\\\&&&7&1&8&7&4&6&9&9&\\\\&1&9&1&6&6&5&8&6&4&&\\\\1&1&9&7&9&1&1&6&5&&&\\\\\\hline 1&3&9&6&7&6&4&9&8&3&9&0\\\\\\end{array}}{l}\\\\\\\\\\longleftarrow 23\\;958\\;233\\times 0\\\\\\longleftarrow 23\\;958\\;233\\times 30\\\\\\longleftarrow 23\\;958\\;233\\times 800\\\\\\longleftarrow 23\\;958\\;233\\times 5.000\\\\\\\\\\end{array}}}  que dan como resultado:   2 3 9 5 8 2 3 3 × 5 8 3 0 0 0 0 0 0 0 0 0 7 1 8 7 4 6 9 9 1 9 1 6 6 5 8 6 4 1 1 9 7 9 1 1 6 5 1 3 9 6 7 6 4 9 8 3 9 0 ⟵ multiplicando ⟵ multiplicador ⟵ producto {rrrrrrrrrrrr}&&&&2&3&9&5&8&2&3&3\\\\\\times &&&&&&&&5&8&3&0\\\\\\hline &&&&0&0&0&0&0&0&0&0\\\\&&&7&1&8&7&4&6&9&9&\\\\&1&9&1&6&6&5&8&6&4&&\\\\1&1&9&7&9&1&1&6&5&&&\\\\\\hline 1&3&9&6&7&6&4&9&8&3&9&0\\\\\\end{array}}{l}\\longleftarrow \\;}\\\\\\longleftarrow \\;}\\\\\\\\\\\\\\\\\\\\\\longleftarrow \\;}\\\\\\end{array}}}  la multiplicacion hindu o de fibonacci requiere la preparacion de una tabla (una rejilla dibujada en un papel) que sirve de guia para el calculo. fue introducida en europa en 1202 por fibonacci en su liber abaci. leonardo describio la operacion como \"calculo mental\", y utilizaba los dedos de las manos para realizar los calculos intermedios. napier tambien publico este metodo en 1617, el año en que murio.  como se muestra en el ejemplo, el multiplicando y el multiplicador se escriben encima y a la derecha de la tabla.  las imagenes de la derecha muestran como calcular 345 × 12 usando la multiplicacion hindu. como ejemplo mas complejo, mas abajo se muestra el calculo de 23.958.233 por 5.830; el resultado es 139.676.498.390. observese que el numero 23.958.233 se encuentra en la parte superior de la tabla, y que 5.830 esta verticalmente en su lado derecho. los productos llenan la tabla y la suma de estos productos (diagonalmente) se encuentran en el lado izquierdo y el inferior. a continuacion estas sumas se agregan, como se muestra al multiplicar la division.  es un sistema de multiplicacion con lineas escritas en un papel y opuestas que representan las cifras y se cortan en un angulo de noventa grados. contando las intersecciones se obtiene el resultado final.​  para multiplicar monomios no es necesario que sean semejantes. para ello se multiplican los coeficientes, se deja la misma parte literal y se suman los grados. ejemplo:  se multiplica cada termino del polinomio por el monomio. ejemplos:  en resumen, se puede concluir con esta regla:  asi:  el producto de dos numeros complejos puede calcularse mediante la siguiente formula:  existen diversos algoritmos que permiten multiplicar numeros grandes. el mas rapido para los enteros que se manejan usualmente es el algoritmo de schonhage-strassen. ",
        "snippet": "Multiplicaciones",
        "enlaces_salientes": [
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/Tabla_de_multiplicar",
            "/wiki/Acarreo",
            "/wiki/Fibonacci",
            "/wiki/C%C3%A1lculo",
            "/wiki/Liber_Abaci",
            "/wiki/Leonardo",
            "/wiki/C%C3%A1lculo_mental",
            "/wiki/John_Napier",
            "/wiki/Polinomio",
            "/wiki/Algoritmo_de_Sch%C3%B6nhage-Strassen",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Tabla_de_multiplicar",
            "/wiki/Multiplicaci%C3%B3n_por_duplicaci%C3%B3n",
            "/wiki/Algoritmo_de_Booth",
            "/wiki/Operaciones_con_polinomios",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/C%C3%A1lculo",
        "titulo": "Cálculo",
        "contenido": "en general el termino calculo (del latin calculus, piedrecita, usado para contar o como ayuda al calcular)​ hace referencia al resultado correspondiente a la accion de calcular. calcular, por su parte, consiste en realizar las operaciones necesarias para prever el resultado de una accion previamente concebida, o conocer las consecuencias que se pueden derivar de unos datos previamente conocidos.  no obstante, el uso mas comun del termino «calculo» es el logico-matematico. desde esta perspectiva, el calculo consiste en un  procedimiento mecanico o algoritmo, mediante el cual podemos conocer las consecuencias que se derivan de las variables previamente conocidas debidamente formalizadas y simbolizadas.  las dos acepciones del calculo (la general y la restringida) arriba definidas estan intimamente ligadas. el calculo es una actividad natural y primordial en el hombre, que comienza en el mismo momento en que empieza a relacionar unas cosas con otras en un pensamiento o discurso. el calculo logico natural como razonamiento es el primer calculo elemental del ser humano. el calculo en sentido logico-matematico aparece cuando se toma conciencia de esta capacidad de razonar y trata de formalizarse.  por lo tanto, podemos distinguir dos tipos de operaciones:  el termino «calculo» procede del latin calculus, piedrecita que se mete en el calzado y que produce molestia. precisamente, tales piedrecitas ensartadas en tiras constituian el abaco romano que, junto con el suanpan chino, constituyen las primeras maquinas de calcular en el sentido de contar.  los antecedentes de procedimiento de calculo, como algoritmo, se encuentran en los que utilizaron los geometras griegos, eudoxo en particular, en el sentido de llegar por aproximacion de restos cada vez mas pequeños, a una medida de figuras curvas; asi como diofanto precursor del algebra.  se considera que arquimedes fue uno de los matematicos mas grandes de la antiguedad y, en general, de toda la historia.​​ uso el metodo exhaustivo para calcular el area bajo el arco de una parabola con el sumatorio de una serie infinita, y dio una aproximacion extremadamente precisa del numero pi.​ tambien definio la espiral que lleva su nombre, formulas para los volumenes de las superficies de revolucion y un ingenioso sistema para expresar numeros muy largos.  la consideracion del calculo como una forma de razonamiento abstracto aplicado en todos los ambitos del conocimiento se debe a aristoteles, quien en sus escritos logicos fue el primero en formalizar y simbolizar los tipos de razonamientos categoricos (silogismos). este trabajo seria completado mas tarde por los estoicos, los megaricos, la escolastica.  los algoritmos actuales del calculo aritmetico, utilizados universalmente, son fruto de un largo proceso historico. de vital importancia son las aportaciones de muhammad ibn al-juarismi en el siglo ix;​  en el siglo xiii, fibonacci introduce en europa la representacion de los numeros arabigos del sistema decimal. se introdujo el 0, ya de antiguo conocido en la india y se construye definitivamente el sistema decimal de diez cifras con valor posicional. la escritura antigua de numeros en babilonia, en egipto, en grecia o en roma, hacia muy dificil un procedimiento mecanico de calculo.​  el sistema decimal fue muy importante para el desarrollo de la contabilidad de los comerciantes de la baja edad media, en los inicios del capitalismo.  el concepto de funcion por tablas ya era practicado de antiguo pero adquirio especial importancia en la universidad de oxford en el siglo xiv.​ la idea de un lenguaje o algoritmo capaz de determinar todas las verdades, incluidas las de la fe, aparecen en el intento de raimundo lulio en su ars magna  a fin de lograr una operatividad mecanica se confeccionaban unas tablas a partir de las cuales se podia generar un algoritmo practicamente mecanico. este sistema de tablas ha perdurado en algunas operaciones durante siglos, como las tablas de logaritmos, o las funciones trigonometricas; las tablas venian a ser como la calculadora de hoy dia; un instrumento imprescindible de calculo. las amortizaciones de los creditos en los bancos, por ejemplo, se calculaban a partir de tablas elementales hasta que se produjo la aplicacion de la informatica en el tercer tercio del siglo xx.  a finales de la edad media la discusion entre los partidarios del abaco y los partidarios del algoritmo se decanto claramente por estos ultimos.​ de especial importancia es la creacion del sistema contable por partida doble recomendado por luca pacioli fundamental para el progreso del capitalismo en el renacimiento.​  el sistema que usamos actualmente fue introducido por luca pacioli en 1494, el cual fue creado y desarrollado para responder a la necesidad de la contabilidad en los negocios de la burguesia renacentista.  el desarrollo del algebra (con la introduccion de un sistema de simbolos por un lado, y la resolucion de problemas por medio de las ecuaciones) vino de la mano de los grandes matematicos de la epoca renacentista como tartaglia, stevin, cardano o vieta y fue esencial para el planteamiento y solucion de los mas diversos problemas que surgieron en la epoca, que dieron como consecuencia los grandes descubrimientos que hicieron posible el progreso cientifico que surgiria en el siglo xvii.​  en el siglo xvii el calculo conocio un enorme desarrollo siendo los autores mas destacados descartes,​ pascal​ y, finalmente, leibniz y newton​ con el calculo infinitesimal que en muchas ocasiones ha recibido simplemente, por absorcion, el nombre de calculo.  el concepto de calculo formal en el sentido de algoritmo reglado para el desarrollo de un razonamiento y su aplicacion al mundo de lo real,​ adquiere una importancia y desarrollo enorme respondiendo a una necesidad de establecer relaciones matematicas entre diversas medidas, esencial para el progreso de la ciencia fisica que, debido a esto, es tomada como nuevo modelo de ciencia frente a la especulacion tradicional filosofica, por el rigor y seguridad que ofrece el calculo matematico. cambia asi el sentido tradicional de la fisica como filosofia de la naturaleza y toma el sentido de ciencia que estudia los cuerpos materiales, en cuanto materiales.  a partir de entonces el propio sistema de calculo permite establecer modelos sobre la realidad fisica, cuya comprobacion experimental​ supone la confirmacion de la teoria como sistema. es el momento de la consolidacion del llamado metodo cientifico cuyo mejor exponente es en aquel momento la teoria de la gravitacion universal y las leyes de la mecanica de newton.​  durante el siglo xix y xx el desarrollo cientifico y la creacion de modelos teoricos fundados en sistemas de calculo aplicables tanto en mecanica como en electromagnetismo y radioactividad, etc., asi como en astronomia fue impresionante. las geometrias no euclidianas encuentran aplicacion en modelos teoricos de astronomia y fisica. el mundo deja de ser un conjunto de infinitas particulas que se mueven en un espacio-tiempo absoluto y se convierte en un espacio de configuracion o espacio de fases de n dimensiones que fisicamente se hacen consistentes en la teoria de la relatividad, la mecanica cuantica, la teoria de cuerdas, etc., que cambia por completo la imagen del mundo fisico.  la logica asimismo sufrio una transformacion radical.​ la formalizacion simbolica fue capaz de integrar las leyes logicas en un calculo matematico, hasta el punto que la distincion entre razonamiento logico-formal y calculo matematico viene a considerarse como meramente utilitaria.  en la segunda mitad del siglo xix y primer tercio del xx, a partir del intento de formalizacion de todo el sistema matematico, frege, y de matematizacion de la logica, (bolzano, boole, whitehead, russell) fue posible la generalizacion del concepto como calculo logico. se lograron metodos muy potentes de calculo, sobre todo a partir de la posibilidad de tratar como «objeto» conjuntos de infinitos elementos, dando lugar a los numeros transfinitos de cantor.  mediante el calculo la logica encuentra nuevos desarrollos como logicas modales y logicas polivalentes.  los intentos de axiomatizar el calculo como calculo perfecto por parte de hilbert y poincare, llevaron, como consecuencia de diversas paradojas (cantor, russell, etc.) a nuevos intentos de axiomatizacion, axiomas de zermelo-fraenkel y a la demostracion de godel de la imposibilidad de un sistema de calculo perfecto: consistente, decidible y completo en 1931, de grandes implicaciones logicas, matematicas y cientificas.  en la actualidad, el calculo en su sentido mas general, en tanto que calculo logico interpretado matematicamente como sistema binario, y fisicamente hecho material mediante la logica de circuitos electronicos, ha adquirido una dimension y desarrollo impresionante por la potencia de calculo conseguida por los ordenadores, propiamente maquinas computadoras. la capacidad y velocidad de calculo de estas maquinas hace lo que humanamente seria imposible: millones de operaciones por segundo.  el calculo asi utilizado se convierte en un instrumento fundamental de la investigacion cientifica por las posibilidades que ofrece para la modelizacion de las teorias cientificas, adquiriendo especial relevancia en ello el calculo numerico.  el calculo infinitesimal, llamado por brevedad «calculo», tiene su origen en la antigua geometria griega. democrito calculo el volumen de piramides y conos considerandolos formados por un numero infinito de secciones de grosor infinitesimal (infinitamente pequeño). eudoxo y arquimedes utilizaron el «metodo de agotamiento» o exhaucion para encontrar el area de un circulo con la exactitud finita requerida mediante el uso de poligonos regulares inscritos de cada vez mayor numero de lados. en el periodo tardio de grecia, el neoplatonico pappus de alejandria hizo contribuciones sobresalientes en este ambito. sin embargo, las dificultades para trabajar con numeros irracionales y las paradojas de zenon de elea impidieron formular una teoria sistematica del calculo en el periodo antiguo.  en el siglo xvii, cavalieri y torricelli ampliaron el uso de los infinitesimales, descartes y fermat utilizaron el algebra para encontrar el area y las tangentes (integracion y derivacion en terminos modernos). fermat e isaac barrow tenian la certeza de que ambos calculos estaban relacionados, aunque fueron newton (hacia 1660), en inglaterra y leibniz en alemania (hacia 1670) quienes demostraron que los problemas del area y la tangente son inversos, lo que se conoce como teorema fundamental del calculo. leibniz es el creador del simbolismo de la derivada, diferencial y la ∫ estilizada para la integracion, en vez de la i de bernoulli. uso el nombre de calculo diferencial y el nombre de calculo integral propuso juan bernoulli, que sustituyo al nombre de 'calculo sumatorio' de leibniz. la simbologia de leibniz impulso el avance del calculo en europa continental.​  el descubrimiento de newton, a partir de su teoria de la gravitacion universal, fue anterior al de leibniz, pero el retraso en su publicacion aun provoca controversias sobre quien de los dos fue el primero. newton utilizo el calculo en mecanica en el marco de su tratado «principios matematicos de filosofia natural», obra cientifica por excelencia, llamando a su metodo de «fluxiones». leibniz utilizo el calculo en el problema de la tangente a una curva en un punto, como limite de aproximaciones sucesivas, dando un caracter mas filosofico a su discurso. sin embargo, termino por adoptarse la notacion de leibniz por su versatilidad.  en el siglo xviii aumento considerablemente el numero de aplicaciones del calculo, pero el uso impreciso de las cantidades infinitas e infinitesimales, asi como la intuicion geometrica, causaban todavia confusion y duda sobre sus fundamentos. de hecho, la nocion de limite, central en el estudio del calculo, era aun vaga e imprecisa en ese entonces. uno de sus criticos mas notables fue el filosofo george berkeley.  en el siglo xix el trabajo de los analistas matematicos sustituyeron esas vaguedades por fundamentos solidos basados en cantidades finitas: bolzano y cauchy definieron con precision los conceptos de limite en terminos de epsilon-delta y de derivada, cauchy y riemann hicieron lo propio con las integrales, y dedekind y weierstrass con los numeros reales. fue el periodo de la fundamentacion del calculo. por ejemplo, se supo que las funciones diferenciables son continuas y que las funciones continuas son integrables, aunque los reciprocos son falsos. en el siglo xx, el analisis no convencional, legitimo el uso de los infinitesimales, al mismo tiempo que la aparicion de las computadoras ha incrementado las aplicaciones y velocidad del calculo.  actualmente, el calculo infinitesimal tiene un doble aspecto: por un lado, se ha consolidado su caracter disciplinario en la formacion de la sociedad culta del conocimiento, destacando en este ambito textos propios de la disciplina como el de louis leithold, el de earl w. swokowski o el de james stewart entre muchos otros; por otro su desarrollo como disciplina cientifica que ha desembocado en ambitos tan especializados como el calculo fraccional, la teoria de funciones analiticas de variable compleja o el analisis matematico. el exito del calculo ha sido extendido con el tiempo a las ecuaciones diferenciales, al calculo de vectores, al calculo de variaciones, al analisis complejo y a las topologia algebraica y topologia diferencial entre muchas otras ramas.  el desarrollo y uso del calculo ha tenido efectos muy importantes en casi todas las areas de la vida moderna: es fundamento para el calculo numerico aplicado en casi todos los campos tecnicos y/o cientificos cuya principal caracteristica es la continuidad de sus elementos, en especial en la fisica. practicamente todos los desarrollos tecnicos modernos como la construccion, aviacion, transporte, meteorologia, etc., hacen uso del calculo. muchas formulas algebraicas se usan hoy en dia en balistica, calefaccion, refrigeracion, etc.  como complemento del calculo, en relacion con sistemas teoricos o fisicos cuyos elementos carecen de continuidad, se ha desarrollado una rama especial conocida como matematica discreta.    el calculo logico es un sistema de reglas de inferencia o deduccion de un enunciado a partir de otro u otros. el calculo logico requiere un conjunto consistente de axiomas y unas reglas de inferencia; su proposito es poder deducir algoritmicamente proposiciones logicas verdaderas a partir de dichos axiomas. la inferencia es una operacion logica que consiste en obtener una proposicion logica como conclusion a partir de otra(s) (premisas) mediante la aplicacion de reglas de inferencia.​  informalmente interpretamos que alguien infiere —o deduce— t de r si acepta que si r tiene valor de verdad v, entonces, necesariamente, t tiene valor de verdad v. sin embargo, en el enfoque moderno del calculo logico no es necesario acudir al concepto de verdad, para construir el calculo logico.  los hombres en nuestra tarea diaria, utilizamos constantemente el razonamiento deductivo. partimos de enunciados empiricos —supuestamente verdaderos y validos— para concluir en otro enunciado que se deriva de aquellos, segun las leyes de la logica natural.​  la logica, como ciencia formal, se ocupa de analizar y sistematizar dichas leyes, fundamentarlas y convertirlas en las reglas que permiten la transformacion de unos enunciados —premisas- en otros -conclusiones— con objeto de convertir las operaciones en un algoritmo riguroso y eficaz, que garantiza que dada la verdad de las premisas, la conclusion es necesariamente verdadera.  al aplicar las reglas de un calculo logico a los enunciados de un argumento mediante la simbolizacion adecuada como formulas o expresiones bien formadas (ebf) del calculo, construimos un modelo o sistema deductivo. en ese contexto, las reglas de formacion de formulas definen la sintaxis de un lenguaje formal de simbolos no interpretados, es decir, sin significado alguno; y las reglas de transformacion del sistema permiten transformar dichas expresiones en otras equivalentes; entendiendo por equivalentes que ambas tienen siempre y de forma necesaria el mismo valor de verdad. dichas transformaciones son meramente tautologias.  un lenguaje formal que sirve de base para el calculo logico esta formado por varias clases de entidades:  cuando en un calculo asi definido se establecen algunas expresiones determinadas como verdades primitivas o axiomas, decimos que es un sistema formal axiomatico. un calculo asi definido si cumple al mismo tiempo estas tres condiciones decimos que es un calculo perfecto:  la misma logica-matematica ha demostrado que tal sistema de calculo perfecto «no es posible» (vease el teorema de godel).  i. una letra enunciativa (con o sin subindice) es una ebf.  ii. si a es una ebf,  ¬ a tambien lo es.  iii. si a es una ebf y b tambien, entonces  a ∧ b;   a ∨ b;    a → b;    a ↔ b,    tambien lo son.  iv. ninguna expresion es una formula del calculo sino en virtud de i, ii, iii.  1) regla de sustitucion (r.t.1):  dada una tesis ebf del calculo, en la que aparecen variables de enunciados, el resultado de sustituir una, algunas o todas esas variables por expresiones bien formadas (ebf) del calculo, sera tambien una tesis ebf del calculo. y ello con una unica restriccion, si bien muy importante: cada variable ha de ser sustituida siempre que aparece y siempre por el mismo sustituto.  veamos el ejemplo:   o viceversa   2) regla de separacion (r.t.2):  si x es una tesis ebf del sistema y lo es tambien x → y, entonces y es una tesis ebf del sistema.  sobre la base de estas dos reglas, siempre podremos reducir un argumento cualquiera a la forma:  [a ∧ b ∧ c … ∧ n] → y  lo que constituye un esquema de inferencia en el que una vez conocida la verdad de cada una de las premisas a, b, … n y, por tanto, de su producto, podemos obtener la conclusion y con valor de verdad v, siempre y cuando dicho esquema de inferencia sea una ley logica, es decir su tabla de verdad nos muestre que es una tautologia.  por la regla de separacion podremos concluir y, de forma independiente como verdad.  dada la poca operatividad de las tablas de verdad, el calculo se construye como una cadena deductiva aplicando a las premisas o a los teoremas deducidos las leyes logicas utilizadas como reglas de transformacion, como se expone en calculo logico.  naturalmente el calculo logico es util porque puede tener aplicaciones, pero ¿en que consisten o como se hacen tales aplicaciones?  podemos considerar que el lenguaje natural es un modelo de c si podemos someterlo, es decir, aplicarle una correspondencia en c.​  para ello es necesario someter al lenguaje natural a un proceso de formalizacion de tal forma que podamos reducir las expresiones linguisticas del lenguaje natural a ebf de un calculo mediante reglas estrictas manteniendo el sentido de verdad logica de dichas expresiones del lenguaje natural. esto es lo que se expone en calculo logico.  las diversas formas en que tratemos las expresiones linguisticas formalizadas como proposiciones logicas dan lugar a sistemas diversos de formalizacion y calculo:   la simbolizacion y formacion de ebfs en cada uno de esos calculos, asi como las reglas de calculo se trata en calculo logico.   ",
        "snippet": "En general el término cálculo (del latín calculus, piedrecita, usado para contar o como ayuda al calcular)[1]​ hace referencia al resultado correspondiente a la acción de calcular. Calcular, por su parte, consiste en realizar las operaciones necesarias para prever el resultado de una acción previamente concebida, o conocer las consecuencias que se pueden derivar de unos datos previamente conocidos.",
        "enlaces_salientes": [
            "/wiki/C%C3%A1lculo",
            "/wiki/C%C3%A1lculo",
            "/wiki/C%C3%A1lculo",
            "/wiki/C%C3%A1lculo_(desambiguaci%C3%B3n)",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/An%C3%A1lisis_matem%C3%A1tico",
            "/wiki/Lat%C3%ADn",
            "/wiki/Algoritmo",
            "/wiki/Lenguaje_formalizado",
            "/wiki/S%C3%ADmbolo",
            "/wiki/Razonamiento",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Argumento",
            "/wiki/Algoritmo",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Inferencia",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Modelo_cient%C3%ADfico",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/An%C3%A1lisis_matem%C3%A1tico",
            "/wiki/C%C3%A1lculo_diferencial",
            "/wiki/Historia_del_c%C3%A1lculo",
            "/wiki/%C3%81baco",
            "/wiki/Lat%C3%ADn",
            "/wiki/%C3%81baco",
            "/wiki/Suanpan",
            "/wiki/Eudoxo_de_Cnido",
            "/wiki/Diofanto",
            "/wiki/%C3%81lgebra",
            "/wiki/Arqu%C3%ADmedes",
            "/wiki/Matem%C3%A1tico",
            "/wiki/M%C3%A9todo_exhaustivo",
            "/wiki/%C3%81rea",
            "/wiki/Par%C3%A1bola_(matem%C3%A1tica)",
            "/wiki/Serie_matem%C3%A1tica",
            "/wiki/N%C3%BAmero_Pi",
            "/wiki/Espiral_de_Arqu%C3%ADmedes",
            "/wiki/Volumen",
            "/wiki/Superficie_de_revoluci%C3%B3n",
            "/wiki/Lenguaje_formal",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Categ%C3%B3rico",
            "/wiki/Silogismo",
            "/wiki/Estoicismo",
            "/wiki/Megara",
            "/wiki/Escol%C3%A1stica",
            "/wiki/Algoritmo",
            "/wiki/C%C3%A1lculo_aritm%C3%A9tico",
            "/wiki/Al-Juarismi",
            "/wiki/Fibonacci",
            "/wiki/N%C3%BAmeros_ar%C3%A1bigos",
            "/wiki/Sistema_decimal",
            "/wiki/Sistema_de_numeraci%C3%B3n_decimal",
            "/wiki/Universidad_de_Oxford",
            "/wiki/Raimundo_Lulio",
            "/wiki/Partida_doble",
            "/wiki/Luca_Pacioli",
            "/wiki/Luca_Pacioli",
            "/wiki/%C3%81lgebra",
            "/wiki/Sistema",
            "/wiki/S%C3%ADmbolo",
            "/wiki/Ecuaci%C3%B3n",
            "/wiki/Tartaglia",
            "/wiki/Simon_Stevin",
            "/wiki/Gerolamo_Cardano",
            "/wiki/Fran%C3%A7ois_Vi%C3%A8te",
            "/wiki/Leibniz",
            "/wiki/Descartes",
            "/wiki/Blaise_Pascal",
            "/wiki/Leibniz",
            "/wiki/Isaac_Newton",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Ecuaci%C3%B3n",
            "/wiki/F%C3%ADsica",
            "/wiki/Revoluci%C3%B3n_cient%C3%ADfica",
            "/wiki/Filosof%C3%ADa_natural",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Experimento",
            "/wiki/Verificaci%C3%B3n",
            "/wiki/Sistema",
            "/wiki/M%C3%A9todo_cient%C3%ADfico",
            "/wiki/George_Boole",
            "/wiki/Geometr%C3%ADa_no_euclidiana",
            "/wiki/Espacio_de_configuraci%C3%B3n",
            "/wiki/Espacio_de_fases",
            "/wiki/Teor%C3%ADa_de_la_relatividad",
            "/wiki/Mec%C3%A1nica_cu%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_cuerdas",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Frege",
            "/wiki/Bernard_Bolzano",
            "/wiki/Boole",
            "/wiki/Whitehead",
            "/wiki/Bertrand_Russell",
            "/wiki/Georg_Cantor",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/L%C3%B3gica_polivalente",
            "/wiki/Axioma",
            "/wiki/Hilbert",
            "/wiki/Poincar%C3%A9",
            "/wiki/Paradoja",
            "/wiki/Axiomas_de_Zermelo-Fraenkel",
            "/wiki/Teorema_de_G%C3%B6del",
            "/wiki/Consistencia_(l%C3%B3gica)",
            "/wiki/Decidibilidad",
            "/wiki/Completitud_sem%C3%A1ntica",
            "/wiki/Puerta_l%C3%B3gica",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Segundo",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Modelo_cient%C3%ADfico",
            "/wiki/C%C3%A1lculo_num%C3%A9rico",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Dem%C3%B3crito",
            "/wiki/Pir%C3%A1mide_(geometr%C3%ADa)",
            "/wiki/Cono_(geometr%C3%ADa)",
            "/wiki/Infinito",
            "/wiki/Infinitesimal",
            "/wiki/Eudoxo",
            "/wiki/Arqu%C3%ADmedes",
            "/wiki/M%C3%A9todo_de_agotamiento",
            "/wiki/C%C3%ADrculo",
            "/wiki/Pol%C3%ADgono",
            "/wiki/Pappus_de_Alejandr%C3%ADa",
            "/wiki/N%C3%BAmeros_Irracionales",
            "/wiki/Paradoja",
            "/wiki/Zen%C3%B3n_de_Elea",
            "/wiki/Cavalieri",
            "/wiki/Torricelli",
            "/wiki/Descartes",
            "/wiki/Fermat",
            "/wiki/%C3%81lgebra",
            "/wiki/%C3%81rea",
            "/wiki/Tangente_(geometr%C3%ADa)",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Derivaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Fermat",
            "/wiki/Isaac_Barrow",
            "/wiki/Isaac_Newton",
            "/wiki/1660",
            "/wiki/Leibniz",
            "/wiki/1670",
            "/wiki/Teorema_fundamental_del_c%C3%A1lculo",
            "/wiki/Isaac_Newton",
            "/wiki/Teor%C3%ADa_de_la_gravitaci%C3%B3n_universal",
            "/wiki/Notaci%C3%B3n_de_Leibniz",
            "/wiki/George_Berkeley",
            "/wiki/Bernard_Bolzano",
            "/wiki/Cauchy",
            "/wiki/L%C3%ADmite_de_una_funci%C3%B3n",
            "/wiki/Funci%C3%B3n_derivada",
            "/wiki/Cauchy",
            "/wiki/Riemann",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Julius_Wilhelm_Richard_Dedekind",
            "/wiki/Weierstrass",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Funci%C3%B3n_continua",
            "/wiki/Infinitesimal",
            "/wiki/Computadoras",
            "/wiki/Ecuaci%C3%B3n_diferencial",
            "/wiki/Espacio_vectorial",
            "/wiki/C%C3%A1lculo_de_variaciones",
            "/wiki/An%C3%A1lisis_complejo",
            "/wiki/Topolog%C3%ADa_algebraica",
            "/wiki/Topolog%C3%ADa_diferencial",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Inferencia",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Consistencia_l%C3%B3gica",
            "/wiki/Axiomas",
            "/wiki/Reglas_de_inferencia",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Inferencia",
            "/wiki/Proposici%C3%B3n_l%C3%B3gica",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Premisas",
            "/wiki/Regla_de_inferencia",
            "/wiki/Necesario",
            "/wiki/Verdad",
            "/wiki/Validez_(epistemolog%C3%ADa)",
            "/wiki/Ciencia_formal",
            "/wiki/Necesario",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Enunciado",
            "/wiki/Argumento",
            "/wiki/Sintaxis",
            "/wiki/Lenguaje_formal",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/Lenguaje_formal",
            "/wiki/Axiomas",
            "/wiki/Teoremas",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Teorema_de_G%C3%B6del",
            "/wiki/Metalenguaje",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Inferencia",
            "/wiki/Tabla_de_verdad",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/Tablas_de_verdad",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Lenguaje_formalizado",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Propiedad_(l%C3%B3gica)",
            "/wiki/Clase_natural",
            "/wiki/Conjunto",
            "/wiki/Individuo",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Lenguaje_formal",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/Sistema_formal",
            "/wiki/Silogismo",
            "/wiki/C%C3%A1lculo_de_la_ra%C3%ADz_cuadrada",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/Puerta_l%C3%B3gica",
            "/wiki/Tabla_de_valores_de_verdad",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Historia_del_hardware_de_computador",
            "/wiki/Regla_de_c%C3%A1lculo",
            "/wiki/Sistema_de_numeraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Matem%C3%A1tica_egipcia",
            "/wiki/Numeraci%C3%B3n_egipcia",
            "/wiki/Numeraci%C3%B3n_griega",
            "/wiki/Numeraci%C3%B3n_romana",
            "/wiki/Acarreo",
            "/wiki/Potenciaci%C3%B3n",
            "/wiki/Radicaci%C3%B3n",
            "/wiki/Logaritmaci%C3%B3n",
            "/wiki/%C3%81lgebra",
            "/wiki/%C3%81lgebra_elemental",
            "/wiki/Modelo_cient%C3%ADfico",
            "/wiki/Lat%C3%ADn",
            "/wiki/ISBN",
            "/wiki/Algoritmo",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/L%C3%B3gica_emp%C3%ADrica",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/Tartaglia",
            "/wiki/M%C3%A9todo_cient%C3%ADfico",
            "/wiki/C%C3%B3nicas",
            "/wiki/Principio_de_Pascal",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/L%C3%B3gica_emp%C3%ADrica",
            "/wiki/Masa",
            "/wiki/Gravitaci%C3%B3n_Universal",
            "/wiki/Arist%C3%B3teles",
            "/wiki/A_priori",
            "/wiki/Lenguaje_formal",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Divisi%C3%B3n_(matem%C3%A1ticas)",
        "titulo": "División (matemática)",
        "contenido": "en la matematica, la division es una operacion parcialmente definida en el conjunto de  los numeros enteros; en cambio, en el caso de los numeros racionales, reales y complejos es siempre posible efectuar la division, exigiendo que el divisor sea distinto de cero, sea cual fuera la naturaleza de los numeros por dividir. en el caso de que sea posible efectuar la division, esta  consiste en indagar cuantas veces un numero (divisor) esta «contenido» en otro numero (dividendo). el resultado de una division recibe el nombre de «cociente». de manera general puede decirse que la division es la operacion inversa de la multiplicacion, siempre y cuando se realice en un campo.​  debe distinguirse la division «exacta» (sujeto principal de este articulo) de la «division con resto» o residuo (la division euclidea). a diferencia de la suma, la resta o la multiplicacion, la division entre numeros enteros no esta siempre definida; en efecto: 4 dividido 2 es igual a 2 (un numero entero), pero 2 entre 4 es igual a ²⁄₄ (un medio), que ya no es un numero entero. la definicion formal de «division» , «divisibilidad» y «conmensurabilidad», dependera luego del conjunto de definicion.  como cualquier operacion, en el resultado de una division tiene que ser unico, por eso existe una definicion para cociente y resto.  para que la division produzca siempre un numero en lugar de un cociente mas un resto, los numeros naturales deben ampliarse a numeros racionales o numeros reales. en estos  sistemas numericos ampliados, la division es la operacion inversa a la multiplicacion, es decir a = c / b significa a × b = c, siempre que b no sea cero. si b = 0, entonces se trata de una division por cero, que no esta definida.​​: 246  en el ejemplo de las 21 manzanas, cada uno recibiria 5 manzanas y un cuarto de manzana, con lo que se evitaria cualquier sobrante.  ambas formas de division aparecen en diversas estructura algebraicas, diferentes formas de definir la estructura matematica. aquellas en las que se define una division euclidea (con resto) se denominan dominio euclideos e incluyen anillo polinomicos en una indeterminada (que definen la multiplicacion y la suma sobre formulas de una sola variable). aquellos en los que se define una division (con un unico resultado) por todos los elementos distintos de cero se denominan campos y anillo de division. en un anillo los elementos por los que siempre es posible la division se llaman unidades (por ejemplo, 1 y -1 en el anillo de los enteros). otra generalizacion de la division a estructuras algebraicas es el grupo cociente, en el que el resultado de la \"division\" es un grupo en lugar de un numero.  la forma mas sencilla de ver la division es en terminos de «cociente y particion»: desde el punto de vista del cociente, 20 / 5 significa el numero de 5s que hay que sumar para obtener 20. desde el punto de vista de la particion, 20 / 5 significa el tamaño de cada una de las 5 partes en que se divide un conjunto de tamaño 20. por ejemplo, 20 manzanas se dividen en cinco grupos de cuatro manzanas, lo que significa que veinte dividido por cinco es igual a cuatro. esto se denota como 20 / 5 = 4, o 20/5 = 4.​ lo que se divide se llama el dividendo, que se divide por el divisor, y el resultado se llama el cociente. en el ejemplo, 20 es el dividendo, 5 es el divisor y 4 es el cociente.  a diferencia de las otras operaciones basicas, al dividir numeros naturales a veces hay un resto que no va uniformemente al dividendo; por ejemplo, 10 / 3 deja un resto de 1, ya que 10 no es multiplo de 3. a veces este resto se añade al cociente como una parte fraccionaria, por lo que 10 / 3 es igual a {sfrac}} o 3... 33..., pero en el contexto de la division entera, donde los numeros no tienen parte fraccionaria, el resto se guarda por separado (o excepcionalmente, se descarta o se redondea).​ cuando el resto se guarda como fraccion, da lugar a un numero racional. el conjunto de todos los numeros racionales se crea ampliando los enteros con todos los posibles resultados de divisiones de enteros.  a diferencia de la multiplicacion y la suma, la division no es conmutativa, lo que significa que a / b no siempre es igual a b / a.​ la division tampoco es, en general, asociativa, lo que significa que al dividir varias veces, el orden de la division puede cambiar el resultado.​ por ejemplo, (24 / 6) / 2 = 2, pero 24 / (6 / 2) = 8 (donde el uso del parentesis indica que las operaciones dentro del parentesis se realizan antes que las operaciones fuera del parentesis).  la division se considera tradicionalmente como asociativo izquierdo. es decir, si hay varias divisiones seguidas, el orden de calculo va de izquierda a derecha:​​  la division es  derecho-distributiva sobre la suma y la resta, en el sentido de que  lo mismo ocurre con la multiplicacion, ya que ( a + b ) × c = a × c + b × c . sin embargo, la division no es  distributiva por la izquierda, ya que  por ejemplo 12 2 + 4 = 12 6 = 2 , {2+4}}={6}}=2,} pero 12 2 + 12 4 = 6 + 3 = 9. {2}}+{4}}=6+3=9.}  a diferencia de la multiplicacion, que es a la vez distributiva por la izquierda y por la derecha y, por tanto, distributiva.  conceptualmente, la division describe uno o dos nociones relacionadas, aunque diferentes, la de «separar» y la de «repartir».​​ de manera formal, la division es una operacion binaria que a dos numeros asocia el producto del primero por el inverso del segundo. para un numero no nulo, la funcion «division por ese numero» es el reciproco de «multiplicacion por ese numero». de este modo, el cociente a dividido b se interpreta como el producto a por 1 b {b}}} .  si la division no es exacta, es decir, el divisor no esta contenido un numero exacto de veces en el dividendo, la operacion tendra un resto o residuo, donde:  etimologia: la palabra deriva del latin dividere: partir, separar.  en algebra y ciencias, la division se denota generalmente a modo de fraccion, con el dividendo escrito sobre el divisor. por ejemplo 3 4 {4}}} se lee: tres dividido cuatro. tambien puede emplearse una barra oblicua: 3 / 4 ; este es el modo mas corriente en los lenguajes de programacion por computadora u ordenador, puesto que puede ser facilmente inscrito como secuencia simple del codigo ascii.  otro modo de indicar una division es por medio del simbolo obelo ( ÷ ) (tambien llamado «signo de la division»). este simbolo tambien se usa para representar la operacion de division en si, como es de uso frecuente en las calculadoras. otras variantes son los dos puntos (:) o el punto y coma (;).  la division no es propiamente dicho una «operacion» (es decir, una ley de composicion interna definida por todas partes), sus «propiedades» no tienen implicaciones estructurales sobre el conjunto de numeros, y deben ser comprendidas dentro del contexto de los numeros fraccionarios.  hasta el siglo xvi fue muy comun el algoritmo de la division por galera, muy similar a la division larga y a la postre (sustituido por esta como metodo predilecto de division). el proceso usual de division (division larga) suele representarse bajo el diagrama:   d i v i d e n d o }}  tambien se usa un diagrama equivalente con la linea debajo del dividendo   d i v i d e n d o }}  y tambien se usa otro diagrama equivalente   d i v i s o r }}  otro metodo consiste en la utilizacion de una «tabla elemental», similar a las tablas de multiplicar, con los resultados preestablecidos.  consideremos el conjunto ℕ = {0, 1, 2, ...n, ...} de los numeros naturales  y sean a,b no nulo, c numeros naturales, diremos que  si  si es asi se dira que a es el dividendo; b, el divisor; y c, el cociente si existe.​  sin embargo, dados dos numeros naturales a y b = 0, existen dos unicos numeros naturales q y r tal que se cumplen las relaciones a = b ⋅ q + r , 0 ≤ r < b .  el algoritmo que permite encontrar q y r, conociendo a y b, se denomina division entera, entre otros nombres.​  la division no es una operacion cerrada, lo cual quiere decir que, en general, el resultado de dividir dos numeros enteros no sera otro numero entero, a menos que el dividendo sea un multiplo entero del divisor.  existen criterios de divisibilidad para numeros enteros (por ejemplo, todo numero terminado en 0,2,4,6 u 8 sera divisible entre 2), utilizados particularmente para descomponer los enteros en factores primos, lo que se usa en calculos como el minimo comun multiplo o el maximo comun divisor.  la division en ℚ siempre es posible, toda vez que el divisor no sea nulo. pues el cociente x ÷ y , no es sino el producto x ⋅ y − 1 }  en los racionales, el resultado de dividir dos numeros racionales (a condicion de que  el divisor no sea 0) puede calcularse con cualesquiera de las fracciones representativas. se puede definir de la manera siguiente:​ dados p/q y r/s,  esta definicion demuestra que la division funciona como la operacion inversa de la multiplicacion.  el resultado de dividir dos numeros reales es otro numero real (siempre y cuando el divisor no sea 0). se define como a/b = c si y solo si a = cb y b = 0.  la division de cualquier numero entre cero es una «indefinicion». esto resulta del hecho que cero multiplicado por cualquier cantidad finita es otra vez cero, es decir que el cero no posee un inverso multiplicativo.  el resultado de dividir dos numeros complejos es otro numero complejo (siempre y cuando el divisor no sea 0). se define como  en donde r y s no son ambos iguales a 0.  en la forma trigonometrica r ( cos ⁡ a + i sin ⁡ a ) ÷ s ( cos ⁡ b + i sin ⁡ b ) = ( r ÷ s ) ( cos ⁡ ( a − b ) + i sin ⁡ ( a − b ) ) ​  en forma exponencial:  la division euclidea es la formulacion matematica del resultado del proceso habitual de division de numeros enteros. afirma que, dados dos enteros, a, el dividendo, y b, el divisor, tales que b = 0, existen unos unicos enteros q, el cociente, y r, el resto, tales que a = bq + r y 0 ≤ r < |b|, donde |b| denota el valor absoluto de b.  los numeros enteros no son cerrados bajo division. aparte de que la division por cero es indefinida, el cociente no es un entero a menos que el dividendo sea un multiplo entero del divisor. por ejemplo, 26 no puede dividirse por 11 para obtener un numero entero. en tal caso se utiliza uno de los cinco enfoques siguientes:  la division de enteros en un programa de ordenador requiere un cuidado especial. algunos lenguajes de programacion tratan la division de enteros como en el caso 5 anterior, por lo que la respuesta es un numero entero. otros lenguajes, como matlab y cualquier sistema de algebra computacional devuelven un numero racional como respuesta, como en el caso 3 anterior. estos lenguajes tambien proporcionan funciones para obtener los resultados de los otros casos, ya sea directamente o a partir del resultado del caso 3.  los nombres y simbolos utilizados para la division de enteros incluyen div, /, \\ y %. las definiciones varian con respecto a la division de enteros cuando el dividendo o el divisor es negativo: redondeo puede ser hacia cero (la llamada division t) o hacia -∞ (division f); pueden ocurrir estilos mas raros - vease operacion modulo para los detalles.  las reglas de divisibilidad pueden usarse a veces para determinar rapidamente si un entero divide exactamente a otro.  el resultado de dividir dos numeros racionaless es otro numero racional cuando el divisor es distinto de 0. la division de dos numeros racionales p'/q y r'/s se puede calcular como p / q r / s = p q × s r = p s q r . ={p \\over q}\\times {s \\over r}={ps \\over qr}.}  las cuatro cantidades son numeros enteros, y solo p puede ser 0. esta definicion asegura que la division es la operacion inversa de la multiplicacion. ",
        "snippet": "En la matemática, la división es una operación parcialmente definida en el conjunto de los números enteros; en cambio, en el caso de los números racionales, reales y complejos es siempre posible efectuar la división, exigiendo que el divisor sea distinto de cero, sea cual fuera la naturaleza de los números por dividir. En el caso de que sea posible efectuar la división, esta consiste en indagar cuántas veces un número (divisor) está «contenido» en otro número (dividendo). El resultado de una división recibe el nombre de «cociente». De manera general puede decirse que la división es la operación inversa de la multiplicación, siempre y cuando se realice en un campo.[1]​",
        "enlaces_salientes": [
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Divisi%C3%B3n",
            "/wiki/Matem%C3%A1tica",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/N%C3%BAmeros_racionales",
            "/wiki/N%C3%BAmeros_reales",
            "/wiki/N%C3%BAmeros_complejos",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Resto",
            "/wiki/Divisi%C3%B3n_eucl%C3%ADdea",
            "/wiki/Suma",
            "/wiki/Resta",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/Divisibilidad",
            "/wiki/Conmensurabilidad",
            "/wiki/N%C3%BAmeros_racionales",
            "/wiki/N%C3%BAmeros_reales",
            "/wiki/Divisi%C3%B3n_por_cero",
            "/wiki/Estructura_algebraica",
            "/wiki/Dominio_eucl%C3%ADdeo",
            "/wiki/Anillo_polin%C3%B3mico",
            "/wiki/Campo_(matem%C3%A1ticas)",
            "/wiki/Anillo_de_divisi%C3%B3n",
            "/wiki/Anillo_(matem%C3%A1tica)",
            "/wiki/Unidad_(teor%C3%ADa_de_anillos)",
            "/wiki/Grupo_cociente",
            "/wiki/Resto",
            "/wiki/Parte_fraccionaria",
            "/wiki/Entera",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/Conmutativa",
            "/wiki/Asociativa",
            "/wiki/Asociatividad_(%C3%A1lgebra)",
            "/wiki/Distributividad",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Distributividad",
            "/wiki/Ley_distributiva",
            "/wiki/Operaci%C3%B3n_binaria",
            "/wiki/Inverso_multiplicativo",
            "/wiki/Resto",
            "/wiki/Fracci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/ASCII",
            "/wiki/%C3%93belo",
            "/wiki/Calculadora",
            "/wiki/Operaci%C3%B3n_binaria",
            "/wiki/Conmutatividad",
            "/wiki/Asociatividad_(%C3%A1lgebra)",
            "/wiki/Elementos_del_periodo_2",
            "/wiki/Elemento_absorbente",
            "/wiki/Fracci%C3%B3n_equivalente",
            "/wiki/Divisi%C3%B3n_por_galera",
            "/wiki/Divisi%C3%B3n_larga",
            "/wiki/Tablas_de_multiplicar",
            "/wiki/Operaci%C3%B3n_interna",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/M%C3%BAltiplo",
            "/wiki/Divisibilidad#criterios_de_divisibilidad",
            "/wiki/Factorizaci%C3%B3n",
            "/wiki/M%C3%ADnimo_com%C3%BAn_m%C3%BAltiplo",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/Divisi%C3%B3n_por_cero",
            "/wiki/Cero",
            "/wiki/Inverso_multiplicativo",
            "/wiki/N%C3%BAmeros_complejos",
            "/wiki/Divisi%C3%B3n_eucl%C3%ADdea",
            "/wiki/Valor_absoluto",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Coma_flotante",
            "/wiki/C%C3%A1lculo_num%C3%A9rico",
            "/wiki/Fracci%C3%B3n",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/N%C3%BAmero_mixto",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/Cociente",
            "/wiki/Resto",
            "/wiki/Divisi%C3%B3n_eucl%C3%ADdea",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Funci%C3%B3n_suelo",
            "/wiki/Programa_de_ordenador",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/MATLAB",
            "/wiki/Sistema_de_%C3%A1lgebra_computacional",
            "/wiki/Redondeo",
            "/wiki/Operaci%C3%B3n_m%C3%B3dulo",
            "/wiki/N%C3%BAmeros_racionales",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Algoritmo_de_la_divisi%C3%B3n",
            "/wiki/Divisi%C3%B3n_larga",
            "/wiki/Divisi%C3%B3n_por_galera",
            "/wiki/Divisibilidad",
            "/wiki/Divisi%C3%B3n_por_cero",
            "/wiki/Divisi%C3%B3n_polinomial",
            "/wiki/Algoritmo_divide_y_vencer%C3%A1s",
            "/wiki/Raz%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/New_York_City",
            "/wiki/Penguin_Books",
            "/wiki/ISBN",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_de_Euclides",
        "titulo": "Algoritmo de Euclides",
        "contenido": "en matematicas, el algoritmo de euclides, o algoritmo euclidiano, es un metodo eficiente para calcular el maximo comun divisor (mcd) de dos numeros enteros, el numero mas grande que los divide a ambos sin dejar resto. lleva el nombre del antiguo matematico griego euclides, quien lo describio por primera vez en elementos (ca. 300 a. c.). es un ejemplo de un algoritmo, un procedimiento paso a paso para realizar un calculo de acuerdo con reglas bien definidas, y es uno de los algoritmos mas antiguos que se siguen utilizando. se puede usar para reducir fracciones a su forma mas simple y es parte de muchos otros calculos teorico-numericos y criptograficos.  el algoritmo euclidiano se basa en el principio de que el maximo comun divisor de dos numeros no cambia si el numero mas grande se reemplaza por su diferencia con el numero mas pequeño. por ejemplo, 21 es el mcd de 252 y 105 (ya que 252 = 21 × 12 y 105 = 21 × 5), y el mismo numero 21 tambien es el mcd de 105 y 252 − 105 = 147. dado que este reemplazo reduce el mas grande de los dos numeros, al repetir este proceso se obtienen pares de numeros sucesivamente mas pequeños hasta que los dos numeros se vuelven iguales. cuando eso ocurre, son el mcd de los dos numeros originales. al invertir los pasos o usar el algoritmo de euclides extendido, el mcd se puede expresar como una combinacion lineal de los dos numeros originales, es decir, la suma de los dos numeros, cada uno multiplicado por un numero entero (por ejemplo, 21 = 5 × 105 + (−2) × 252). el hecho de que el mcd siempre se pueda expresar de esta manera se conoce como la identidad de bezout.  la version del algoritmo euclidiano descrita anteriormente (y por euclides) puede requerir muchos pasos de resta para encontrar el mcd cuando uno de los numeros dados es mucho mas grande que el otro. una version mas eficiente del algoritmo acorta estos pasos, en lugar de reemplazar el mas grande de los dos numeros por su resto al dividirlo por el mas pequeño de los dos (con esta version, el algoritmo se detiene al alcanzar un resto cero). con esta mejora, el algoritmo nunca requiere mas pasos que cinco veces el numero de digitos (base 10) del numero entero mas pequeño. esto fue demostrado por gabriel lame en 1844 (teorema de lame),​​ y marca el comienzo de la teoria de la complejidad informatica. se desarrollaron metodos adicionales para mejorar la eficiencia del algoritmo en el siglo xx.  el algoritmo euclidiano tiene muchas aplicaciones teoricas y practicas. se utiliza para reducir fracciones a su forma mas simple y para realizar divisiones en aritmetica modular. los calculos que utilizan este algoritmo forman parte de los protocolos criptograficos que se usan para proteger las comunicaciones de internet, y en los metodos para romper estos sistemas criptograficos mediante la factorizacion de grandes numeros compuestos. el algoritmo euclidiano se puede usar para resolver ecuaciones diofanticas, como encontrar numeros que satisfagan multiples congruencias de acuerdo con el teorema chino del resto, para construir fracciones continuas y para encontrar aproximaciones racionales precisas a numeros reales. finalmente, se puede utilizar como una herramienta basica para demostrar teoremas en la teoria de numeros, como el teorema de los cuatro cuadrados de lagrange y la unicidad de las factorizaciones primas.  en la concepcion griega de la matematica, los numeros se entendian como magnitudes geometricas. un tema recurrente en la geometria griega es el de la conmensurabilidad de dos segmentos: dos segmentos (numeros) ab y cd son conmensurables cuando existe un tercer segmento pq que cabe exactamente un numero entero de veces en los primeros dos; es decir, pq «mide» (mensura: medida) a los segmentos ab y cd.  no cualquier par de segmentos es conmensurable, como encontraron los pitagoricos cuando establecen que el lado y la diagonal de un cuadrado no son conmensurables, pero en el caso de dos segmentos conmensurables se desea hallar la mayor medida comun posible.  euclides describe en la proposicion i.2 en su libro vii de sus elementos un metodo que permite hallar la mayor medida comun posible de dos numeros (segmentos) que no sean primos entre si, aunque de acuerdo a la epoca tal metodo se explica en terminos geometricos, lo que se ilustra en la siguiente transcripcion.  sean ab y cd los dos numeros que no son primos uno al otro. se necesita entonces encontrar la maxima medida comun de ab y cd.  si cd mide ab entonces es una medida comun puesto que cd se mide a si mismo. y es manifiesto que tambien es la mayor medida pues nada mayor a cd puede medir a cd. pero si cd no mide a ab entonces algun numero quedara de ab y cd, el menor siendo continuamente restado del mayor y que medira al numero que le precede. porque una unidad no quedara pues si no es asi, ab y cd seran primos uno del otro [prop. vii.1], lo cual es lo contrario de lo que se supuso.  por tanto, algun numero queda que medira el numero que le precede. y sea cd midiendo be dejando ea menor que si mismo y sea ea midiendo  df dejando fc menor que si mismo y sea fc medida de ae. entonces, como fc mide ae y ae mide df, fc sera entonces medida de df. y tambien se mide a si mismo. por tanto tambien medira todo cd. y cd mide a be. entonces cf mide a be y tambien mide a ea. asi mide a todo ba y tambien mide a cd. esto es, cf mide tanto a ab y cd por lo que es una medida comun de ab y cd.  afirmo que tambien es la mayor medida comun posible porque si no lo fuera, entonces un numero mayor que cf mide a los numeros ab y cd, sea este g. dado que g mide a cd y cd mide a be, g tambien mide a be. ademas, mide a todo ba por lo que mide tambien al residuo ae. y ae mide a df por lo que g tambien mide a df. mide tambien a todo dc por lo que mide tambien al residuo cf, es decir el mayor mide al menor, lo cual es imposible.  en lenguaje moderno, el algoritmo se describe como sigue:  el hecho de que los segmentos son conmesurables es clave para asegurar que el proceso termina tarde o temprano  al dividir a entre b (numeros enteros), se obtiene un cociente q y un resto r . es posible demostrar que el maximo comun divisor de a y b es el mismo que el de b y r . sea c el maximo comun divisor de a y b , como a = b q + r y c divide a a y a b ,  divide tambien a r . si existiera otro numero mayor que c que divide a b y a r , tambien dividiria a a , por lo que c no seria el mcd de a y b , lo que contradice la hipotesis). este es el fundamento principal del algoritmo. tambien es importante tener en cuenta que el maximo comun divisor de cualquier numero a y 0 es precisamente a . para fines practicos, la notacion m c d ( a , b ) (a,b)} significa maximo comun divisor de a y b .  segun lo antes mencionado, para calcular el maximo comun divisor de 2366 y 273 se puede proseguir de la siguiente manera:  la secuencia de igualdades m c d ( 2366 , 273 ) = m c d ( 273 , 182 ) = m c d ( 182 , 91 ) = m c d ( 91 , 0 ) (2366,273)=\\mathrm {mcd} (273,182)=\\mathrm {mcd} (182,91)=\\mathrm {mcd} (91,0)} implican que m c d ( 2366 , 273 ) = m c d ( 91 , 0 ) (2366,273)=\\mathrm {mcd} (91,0)} . dado que m c d ( 91 , 0 ) = 91 (91,0)=91} , entonces se concluye que m c d ( 2366 , 273 ) = 91 (2366,273)=91} . este mismo procedimiento se puede aplicar a cualesquiera dos numeros naturales. en general, si se desea encontrar el maximo comun divisor de dos numeros naturales a y b , se siguen las siguientes reglas:  asuma que llamamos a = r 0 } y b = r 1 } . aplicando estas reglas se obtiene la siguiente secuencia de operaciones:  como la sucesion de residuos va disminuyendo, al final un residuo tiene que ser cero y es en ese momento cuando el algoritmo termina. el maximo comun divisor es precisamente r n + 1 } (el ultimo residuo que no es cero).  en realidad, el algoritmo de euclides funciona no solo para los numeros naturales, sino para cualquier elemento en el que exista una \"division con residuo\". a este tipo de divisiones se les llama divisiones euclidianas y a los conjuntos donde se puede definir dicha division se les llama dominios euclideos. por ejemplo, el conjunto de los numeros enteros y el de los polinomios con coeficientes racionales son dominios euclideos porque podemos definir una division con residuo (vease division polinomial). de esta manera, se puede calcular el maximo comun divisor de dos numeros enteros o de dos polinomios.  por ejemplo, para calcular el maximo comun divisor de los polinomios p ( x ) = x 5 + 2 x 3 + x +2x^{3}+x} y q ( x ) = x 4 − 1 -1} el algoritmo de euclides sugiere la siguiente secuencia de operaciones:  de esta manera se concluye que su maximo comun divisor es − x 2 − 1 -1} .  se puede expresar este algoritmo de manera mas formal usando pseudocodigo. en este caso la expresion \" x mod y }y} \" significa \"el residuo de dividir x entre y \" (vease aritmetica modular).  entrada: valores a y b pertenecientes a un dominio euclideo  salida: un maximo comun divisor de a y b  vale la pena notar que este algoritmo no es eficiente ser implementado directamente en una computadora, ya que requeriria memorizar todos los valores de r i } .  el algoritmo de euclides extendido permite, ademas de encontrar un maximo comun divisor de dos numeros enteros a y b , expresarlo como la minima combinacion lineal de esos numeros, es decir, encontrar numeros enteros s y t tales que m c d ( a , b ) = a s + b t (a,b)=as+bt} . esto se generaliza tambien hacia cualquier dominio euclidiano.  existen varias maneras de explicar el algoritmo de euclides extendido, una de las mas comunes consiste en la siguiente:  sin embargo, en aras de la comprension y memorizacion de este algoritmo, es conveniente conocer la siguiente caracterizacion. para multiplicar dos matrices de tamaño 2 × 2 se usa la siguiente formula (vease producto de matrices):  (1) [ e f g h ] × [ a b c d ] = [ e a + f c e b + f d g a + h c g b + h d ] e&f\\\\g&h\\end{bmatrix}}\\times a&b\\\\c&d\\end{bmatrix}}=ea+fc&eb+fd\\\\ga+hc&gb+hd\\end{bmatrix}}}  supongase que se utiliza el algoritmo de euclides tradicional para calcular los valores q i } y r i } que ahi se describen. por cada valor q i } calculado se puede formar la matriz q i = [ 0 1 1 − q i ] =0&1\\\\1&-q_{i}\\end{bmatrix}}} . usando la ecuacion (1) de manera repetida se puede calcular el producto de las primeras i matrices de este tipo:   [ s i t i s i + 1 t i + 1 ] = [ 0 1 1 − q i ] × [ 0 1 1 − q i − 1 ] × ⋯ × [ 0 1 1 − q 1 ] s_{i}&t_{i}\\\\s_{i+1}&t_{i+1}\\end{bmatrix}}=0&1\\\\1&-q_{i}\\end{bmatrix}}\\times 0&1\\\\1&-q_{i-1}\\end{bmatrix}}\\times \\cdots \\times 0&1\\\\1&-q_{1}\\end{bmatrix}}}  resulta ser que los valores s i } y t i } tienen la propiedad de que r i = a s i + b t i =as_{i}+bt_{i}} , es decir, expresan a r i } como una combinacion lineal de a y b . particularmente, como m c d ( a , b ) = r n + 1 (a,b)=r_{n+1}} entonces se tiene m c d ( a , b ) = a s n + 1 + b t n + 1 (a,b)=as_{n+1}+bt_{n+1}} , lo cual es la solucion del problema. esta propiedad no deberia ser sorprendente, pues esta multiplicacion de matrices equivale al metodo antes descrito donde se substituye cada ecuacion en la anterior. es importante calcular q i × ⋯ × q 3 × q 2 × q 1 \\times \\cdots \\times q_{3}\\times q_{2}\\times q_{1}} en ese mismo orden. la matriz q 1 } aparece en el extremo derecho y la matriz q i } en el izquierdo.  regresando al primer ejemplo, la sucesion de cocientes es q 1 = 8 =8} , q 2 = 1 =1} y q 3 = 2 =2} . entonces se puede calcular   [ − 1 9 3 − 26 ] = [ 0 1 1 − 2 ] × [ 0 1 1 − 1 ] × [ 0 1 1 − 8 ] -1&9\\\\3&-26\\end{bmatrix}}=0&1\\\\1&-2\\end{bmatrix}}\\times 0&1\\\\1&-1\\end{bmatrix}}\\times 0&1\\\\1&-8\\end{bmatrix}}}  utilizando el primer renglon de esta matriz se puede leer que 91 = 2366 ( − 1 ) + 273 ( 9 ) , es decir, se ha encontrado la manera de expresar al maximo comun divisor de 2366 y 273 como una combinacion lineal.  para expresar el algoritmo de euclides extendido es conveniente notar la manera en que se calculan los valores s i } y t i } con la multiplicacion de matrices:   [ s i t i s i + 1 t i + 1 ] = [ s i t i s i − 1 − q i s i t i − 1 − q i t i ] = [ 0 1 1 − q i ] × [ s i − 1 t i − 1 s i t i ] s_{i}&t_{i}\\\\s_{i+1}&t_{i+1}\\end{bmatrix}}=s_{i}&t_{i}\\\\s_{i-1}-q_{i}s_{i}&t_{i-1}-q_{i}t_{i}\\end{bmatrix}}=0&1\\\\1&-q_{i}\\end{bmatrix}}\\times s_{i-1}&t_{i-1}\\\\s_{i}&t_{i}\\end{bmatrix}}}  de esta manera s i + 1 = s i − 1 − q i s i =s_{i-1}-q_{i}s_{i}} y ademas t i + 1 = t i − 1 − q i t i =t_{i-1}-q_{i}t_{i}} . por lo tanto el algoritmo en pseudocodigo se puede expresar como sigue:  entrada: valores a y b pertenecientes a un dominio euclideo  salida: un maximo comun divisor de a y b , y valores s y t tales que m c d ( a , b ) = a s + b t (a,b)=as+bt}  al momento de hacer calculos con fracciones, es de gran importancia saber como simplificarlas. por ejemplo, la fraccion 65 91 {91}}} es equivalente con 5 7 {7}}} (vease numero racional). de manera mas general, a b = c a c b {b}}={cb}}} siempre que c = 0 . para reducir una fraccion cualquiera a b {b}}} , solo se necesita dividir a y b entre su maximo comun divisor.  por ejemplo, si se desea reducir 166 249 {249}}} , primero se usa el algoritmo de euclides para encontrar m c d ( 166 , 249 ) = 83 (166,249)=83} . se hacen las divisiones 166 ÷ 83 = 2 y 249 ÷ 83 = 3 . luego entonces se concluye que 166 249 = 2 3 {249}}={3}}} .  la sucesion de divisiones que se efectuan al seguir el algoritmo de euclides puede ser utilizada para expresar una fraccion cualquiera a b {b}}} como fraccion continua. esto se debe a que si a = b q + r y r = 0 , entonces  (3) a b = q + 1 b r {b}}=q+{r}}}}  por ejemplo, para encontrar el maximo comun divisor de 93164 y 5826 el algoritmo genera la siguiente secuencia de divisiones:  todas estas ecuaciones las podemos hacer parecidas a la ecuacion (3  3):  si se sustituye la segunda ecuacion en la primera, se obtiene   93164 5826 = 15 + 1 1 + 1 5774 52 {5826}}=15+{1+{52}}}}}}  si se repite este proceso de substitucion entonces se obtiene la expresion deseada:   93164 5826 = 15 + 1 1 + 1 111 + 1 26 {5826}}=15+{1+{111+{26}}}}}}}  de manera mas general, la fraccion continua encontrada con este algoritmo siempre es de la forma   a b = q 1 + 1 q 2 + 1 q 3 + 1 ⋱ q n − 1 + 1 q n {b}}=q_{1}+{q_{2}+{q_{3}++{q_{n}}}}}}}}}}    decimos que dos numeros enteros son congruentes modulo m (aunque tambien se puede generalizar para cualquier otro dominio euclideo) si al dividirlos entre m obtenemos el mismo residuo (vease congruencia). por ejemplo, 7 es congruente con 12 modulo 5 porque al dividir 7 entre 5 y 12 entre 5, en ambos casos obtenemos el mismo residuo (que es 2). cuando a es congruente con b modulo m se escribe a ≡ b ( mod m ) }} , en el ejemplo anterior se tiene 7 ≡ 12 ( mod 5 ) }} . supongase que se conocen los valores de a , b y m , pero que se desconoce el valor x en la siguiente congruencia:  (2) a x ≡ b ( mod m ) }}  basta  encontrar un valor a − 1 } que satisfaga: a − 1 a ≡ 1 ( mod m ) a\\equiv 1}} , pues de esta manera al multiplicar la ecuacion (2) por a − 1 } se tendra la solucion deseada:   x ≡ a − 1 b ( mod m ) b}}  al elemento a − 1 } se le llama \"inverso modulo m \" de a . desafortunadamente este valor no siempre existe. por ejemplo, con a = 4 y m = 6 no existe ningun numero entero a − 1 } tal que a − 1 4 ≡ 1 ( mod 6 ) 4\\equiv 1}} . de hecho este valor existe si y solo si m c d ( a , m ) = 1 (a,m)=1} (la   existencia de soluciones depende de la condicion m c d ( a , m ) | b (a,m)|b} , mientras que la unicidad depende de que el m c d ( a , m ) = 1 (a,m)=1} ). mas aun, si al usar el algoritmo de euclides extendido (ahora con b = m ) se obtiene 1 = a s + m t , entonces el valor s es el inverso modulo m de a . por ejemplo, se desea resolver la ecuacion   5 x ≡ 2 ( mod 9 ) }}  entonces con el algoritmo de euclides extendido se obtiene que m c d ( 5 , 9 ) = 1 = 5 ( 2 ) + 9 ( − 1 ) (5,9)=1=5(2)+9(-1)} . como m c d ( 5 , 9 ) = 1 (5,9)=1} entonces 5 tiene un inverso modulo 9 . mas aun, como 1 = 5 ( 2 ) + 9 ( − 1 ) , entonces ese inverso es 2. entonces   x ≡ 2 ( 2 ) ( mod 9 ) }}  es decir que el valor de x es 4 .  el teorema de lame afirma que el caso peor para este algoritmo es cuando se le pide calcular el maximo comun divisor de dos numeros consecutivos de la sucesion de fibonacci. por ejemplo, si se desea calcular el maximo comun divisor de f 10 = 55 =55} y f 11 = 89 =89} se obtiene la siguiente secuencia de operaciones:  en este ejemplo se observa que con estos dos numeros de dos digitos decimales, se necesita hacer 9 divisiones. en general, el numero de divisiones efectuadas por el algoritmo nunca supera 5 veces el numero de digitos que tienen estos numeros. en terminos de complejidad computacional, esto significa que se requieren o ( log ⁡ n ) divisiones para calcular el maximo comun divisor de n y m donde n > m .  el numero promedio de divisiones efectuadas por el algoritmo se estuvo investigando desde 1968, pero solo hasta apenas el año 2002, brigitte vallee demostro que si los dos numeros se pueden representar con n bits, entonces el numero promedio de divisiones necesarias es π 2 6 n }{6}}n}} .  sin embargo, no basta con saber el numero de divisiones. hay que recordar que el algoritmo de euclides funciona tanto para polinomios como para numeros enteros, y en general, cualquier dominio euclideo. en cada caso, la complejidad del algoritmo depende del numero de divisiones efectuadas y del costo de cada division. en el caso de los polinomios, el numero de divisiones es o ( log ⁡ n ) donde n es el grado de los polinomios.  en general, los algoritmos 1 y 2 no son muy apropiados para implementarse directamente en un lenguaje de programacion, especialmente porque consumen mucha memoria. si no se necesitan los valores intermedios, y solo se desea calcular el maximo comun divisor de dos numeros enteros, conviene usar estas variantes:  funcion m c d ( a , b ) (a,b)} :  funcion m c d ( a , b ) (a,b)} :  funcion e u c l i d e s ( a , b ) }(a,b)} :  funcion e u c l i d e s ( a , b ) }(a,b)} :  funcion e u c l i d e s ( a , b ) }(a,b)} :  acerca de la notacion empleada: ",
        "snippet": "En matemáticas, el algoritmo de Euclides, o algoritmo euclidiano, es un método eficiente para calcular el máximo común divisor (MCD) de dos números enteros, el número más grande que los divide a ambos sin dejar resto. Lleva el nombre del antiguo matemático griego Euclides, quien lo describió por primera vez en Elementos (ca. 300 a. C.). Es un ejemplo de un algoritmo, un procedimiento paso a paso para realizar un cálculo de acuerdo con reglas bien definidas, y es uno de los algoritmos más antiguos que se siguen utilizando. Se puede usar para reducir fracciones a su forma más simple y es parte de muchos otros cálculos teórico-numéricos y criptográficos.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/Resto",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Euclides",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Algoritmo",
            "/wiki/Fracci%C3%B3n",
            "/wiki/Fracci%C3%B3n_irreducible",
            "/wiki/Combinaci%C3%B3n_lineal",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Identidad_de_B%C3%A9zout",
            "/wiki/Gabriel_Lam%C3%A9",
            "/wiki/Teor%C3%ADa_de_la_complejidad_inform%C3%A1tica",
            "/wiki/Fracci%C3%B3n",
            "/wiki/Fracci%C3%B3n_irreducible",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Aritm%C3%A9tica_modular",
            "/wiki/Protocolo_criptogr%C3%A1fico",
            "/wiki/Internet",
            "/wiki/Factorizaci%C3%B3n_de_enteros",
            "/wiki/Ecuaciones_diof%C3%A1nticas",
            "/wiki/Teorema_chino_del_resto",
            "/wiki/Fracciones_continuas",
            "/wiki/Aproximaci%C3%B3n_diof%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Teorema_de_los_cuatro_cuadrados_de_Lagrange",
            "/wiki/Teorema_fundamental_de_la_aritm%C3%A9tica",
            "/wiki/Conmensurabilidad",
            "/wiki/Segmento",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Euclides",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Algoritmo_de_la_divisi%C3%B3n",
            "/wiki/Cociente_(aritm%C3%A9tica)",
            "/wiki/Resto",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Divisi%C3%B3n_euclidiana",
            "/wiki/Dominio_eucl%C3%ADdeo",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Polinomio",
            "/wiki/Divisi%C3%B3n_polinomial",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Aritm%C3%A9tica_modular",
            "/wiki/Algoritmo_de_la_divisi%C3%B3n",
            "/wiki/Producto_de_matrices",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/Fracci%C3%B3n_continua",
            "/wiki/Inverso_multiplicativo_(aritm%C3%A9tica_modular)",
            "/wiki/Congruencia",
            "/wiki/Sucesi%C3%B3n_de_Fibonacci",
            "/wiki/Complejidad_computacional",
            "/wiki/Lenguaje_C",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/C_Sharp",
            "/wiki/Python",
            "/wiki/Visual_Basic",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Pascal",
            "/wiki/Maxima",
            "/wiki/R-project",
            "/wiki/APL",
            "/wiki/Ruby",
            "/wiki/Parte_fraccionaria",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Universidad_de_La_Laguna",
            "/wiki/Cambridge_University_Press",
            "/wiki/MIT_Press",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/YouTube",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
        "titulo": "Máximo común divisor",
        "contenido": "en las matematicas, se define el maximo comun divisor (mcd o m. c. d.) de dos o mas numeros enteros al mayor numero entero que los  divide sin dejar residuo alguno.  el a y b dos numeros enteros distintos de cero. si un numero c divide a a y b , es decir, c | a y c | b , diremos que c es divisor comun de a y b .​ observese que dos numeros enteros cualesquiera tienen divisores comunes. si los divisores comunes de a y b son unicamente 1 y -1 entonces diremos son primos entre si'.  un numero entero d se llama maximo comun divisor (m.c.d) de los numeros a y b cuando:  ejemplo:  los tres metodos mas utilizados para el calculo del maximo comun divisor de dos numeros son:  el maximo comun divisor de dos numeros puede calcularse determinando la descomposicion en factores primos de los dos numeros y tomando los factores comunes elevados a la menor potencia, el producto de los cuales sera el mcd.  ejemplo: para calcular el maximo comun divisor de 48 y de 60 se obtiene de su factorizacion en factores primos.  el mcd son los factores comunes con su menor exponente, esto es:  en la practica, este metodo solo es operativo para numeros pequeños tomando en general demasiado tiempo calcular la descomposicion en factores primos de dos numeros cualesquiera.  un metodo mas eficiente es el algoritmo de euclides, que utiliza el algoritmo de la division junto al hecho que el mcd de dos numeros tambien divide al resto obtenido de dividir el mayor entre el mas pequeño.  ejemplo 1:  si se divide 60 entre 48 dando un cociente de 1 y un resto de 12, el mcd sera por tanto divisor de 12. despues se divide 48 entre 12 dando un resto de 0, lo que significa que 12 es el mcd. formalmente puede describirse como:  ejemplo 2:  el mcd de 42 y 56 es 14. en efecto:  operando:  el maximo comun divisor tambien puede ser calculado usando el minimo comun multiplo. si a y b son distintos de cero, entonces el maximo comun divisor de a y b se obtiene mediante la siguiente formula, que involucra el minimo comun multiplo de a y b:  el maximo comun divisor de tres o mas numeros se puede definir usando recursivamente: mcd ⁡ ( a , b , c ) = mcd ⁡ ( a , mcd ⁡ ( b , c ) ) (a,b,c)=\\operatorname {mcd} (a,\\operatorname {mcd} (b,c))} .​​  la ultima propiedad indica que el maximo comun divisor de dos numeros resulta ser el producto de sus factores primos comunes elevados al menor exponente.  geometricamente, el maximo comun divisor de a y b es el numero de puntos de coordenadas enteras que hay en el segmento que une los puntos (0,0) y (a,b), excluyendo el (0,0).  el mcd se utiliza para simplificar fracciones. por ejemplo, para simplificar la fraccion 48 60 {60}}} se calcula primero el mcd(60, 48) = 12, dividiendose el numerador y el denominador de la fraccion inicial por 12 para obtener la fraccion simplificada 4 5 {5}}} .  el mcd tambien se utiliza para calcular el minimo comun multiplo de dos numeros. en efecto, el producto de los dos numeros es igual al producto de su maximo comun divisor por su minimo comun multiplo. asi, para calcular el minimo comun multiplo de 48 y de 60, calculamos primero su mcd, 12, siendo su minimo comun multiplo 48 ⋅ 60 12 = 240 {12}}=240} .  el mcd y el algoritmo de euclides se emplea en la resolucion de ecuaciones diofanticas lineales con dos incognitas.​  el algoritmo de euclides se emplea en el desarrollo de un numero racional en fraccion continuada (sic).​   ",
        "snippet": "En las matemáticas, se define el máximo común divisor (mcd o m. c. d.) de dos o más números enteros al mayor número entero que los divide sin dejar residuo alguno.",
        "enlaces_salientes": [
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/M%C3%ADnimo_com%C3%BAn_denominador",
            "/wiki/M%C3%ADnimo_com%C3%BAn_m%C3%BAltiplo",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Divisor",
            "/wiki/N%C3%BAmeros_primos_entre_s%C3%AD",
            "/wiki/Factorizaci%C3%B3n_de_enteros",
            "/wiki/Descomposici%C3%B3n_en_factores_primos",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Algoritmo_de_la_divisi%C3%B3n",
            "/wiki/M%C3%ADnimo_com%C3%BAn_m%C3%BAltiplo",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Combinaci%C3%B3n_lineal",
            "/wiki/N%C3%BAmeros_primos_entre_s%C3%AD",
            "/wiki/Identidad_de_B%C3%A9zout",
            "/wiki/Coprimo",
            "/wiki/Asociatividad_(%C3%A1lgebra)",
            "/wiki/Fracci%C3%B3n",
            "/wiki/M%C3%ADnimo_com%C3%BAn_m%C3%BAltiplo",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Ecuaci%C3%B3n_diof%C3%A1ntica",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/M%C3%ADnimo_com%C3%BAn_m%C3%BAltiplo",
            "/wiki/N%C3%BAmeros_primos_entre_s%C3%AD",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/N%C3%BAmeros_enteros",
        "titulo": "Número entero",
        "contenido": "un numero entero es un elemento del conjunto numerico que contiene los numeros naturales; que son n = { 0 , 1 , 2 , 3 , 4 , ⋯ } =\\{0,1,2,3,4,\\cdots \\}} ​  o n ∗ = { 1 , 2 , 3 , 4 , ⋯ } ^=\\{1,2,3,4,\\cdots \\}} ; dependiendo de como se definan, sus opuestos, y en la segunda definicion, ademas el cero.​ los enteros negativos, como −1 o −13 (se leen «menos uno», «menos trece», etc.), son menores que cero y tambien son menores que todos los enteros positivos. para resaltar la diferencia entre positivos y negativos, se puede escribir un signo «menos» delante de los negativos: -1, -5, etc. y si no se escribe signo al numero se asume que es positivo.  el conjunto de todos los numeros enteros se representa por la letra z = { . . . , − 4 , − 3 , − 2 , − 1 , 0 , + 1 , + 2 , + 3 , … } =\\{...,-4,-3,-2,-1,0,+1,+2,+3,\\,\\dots \\}} letra inicial del vocablo aleman zahlen («numeros», pronunciado [ˈtsaːlən]).  en la recta numerica los numeros negativos se encuentran a la izquierda del cero y los positivos a su derecha.  los numeros enteros pueden sumarse, restarse, multiplicarse y dividirse, siguiendo el modelo de los numeros naturales añadiendo unas normas para el uso del signo.  los numeros enteros extienden la utilidad de los numeros naturales para contar cosas. pueden utilizarse para contabilizar perdidas: si en un colegio entran 80 alumnos nuevos de primer curso un cierto año, pero hay 100 alumnos de ultimo curso que pasaron a educacion secundaria, en total habra 100 − 80 = 20 alumnos menos; pero tambien puede decirse que dicho numero ha aumentado en 80 − 100 = −20 alumnos.  ciertas magnitudes, como la temperatura o la altura, usan valores por debajo del cero. la altura del everest es 8848 metros por encima del nivel del mar, y por el contrario, la orilla del mar muerto esta 423 metros por debajo del nivel del mar; es decir, su altura se puede expresar como −423 m.  la palabra entero procede del latin integer que significa \"entero\" o (literalmente) \"intacto\", de in (\"no\") mas tangere (\"tocar\"). \"entire\" deriva del mismo origen a traves de la palabra french entier, que significa tanto entero como entero.​ historicamente el termino se utilizaba para un numero que era multiplo de 1,​​ o a la parte entera de un numero mixto.​​ solo se consideraban enteros positivos, lo que convertia el termino en sinonimo de numero naturals. la definicion de numero entero se amplio con el tiempo para incluir numero negativos a medida que se reconocio su utilidad.​ por ejemplo leonhard euler en su 1765 elementos de algebra definio los numeros enteros para incluir tanto los numeros positivos como los negativos.​ sin embargo, los matematicos europeos, en su mayor parte, se resistieron al concepto de numeros negativos hasta mediados del siglo xix.​  el uso de la letra z para denotar el conjunto de los numeros enteros proviene de la palabra aleman zahlen (\"numeros\")​​ y se ha atribuido a david hilbert.​ el uso mas antiguo conocido de la notacion en un libro de texto se produce en algebre escrito por el colectivo nicolas bourbaki, que data de 1947.​​ la notacion no se adopto inmediatamente, por ejemplo otro libro de texto utilizaba la letra j​ y en un articulo de 1960 se utilizo z para designar los enteros no negativos.​ pero en 1961, z se utilizaba generalmente en los textos modernos de algebra para designar los enteros positivos y negativos.​  el simbolo z } es a menudo anotado para denotar varios conjuntos, con uso variable entre diferentes autores: z + ^{+}} , z + _{+}} o z > ^{>}} para los enteros positivos, z 0 + ^{0+}} o z ≥ ^} para los enteros no negativos, y z = ^} para los enteros distintos de cero. algunos autores usan z ∗ ^{*}} para enteros no nulos, mientras que otros lo usan para enteros no negativos, o para -1, 1 (el grupo de unidades de z } ). ademas, z p _{p}} se utiliza para denotar ya sea el conjunto de integros de modulo p (es decir, el conjunto de clases de congruencia de enteros), o el conjunto de p-adicos.​​  los numeros enteros fueron sinonimos de los enteros hasta principios de la decada de 1950.​​​ a finales de la decada de 1950, como parte del movimiento matematica moderna,​ los profesores de primaria estadounidenses empezaron a enseñar que los \"numeros enteros\" se referian a los numeros naturaless, excluyendo los numeros negativos, mientras que los \"enteros\" incluian los numeros negativos.​​\"numero entero\" sigue siendo ambiguo en la actualidad.​  los numeros negativos son necesarios para realizar operaciones como:  cuando el minuendo es mas pequeño que el sustraendo, la resta no puede realizarse con numeros naturales. sin embargo, hay situaciones en las que es util el concepto de numeros negativos, como por ejemplo al hablar de ganancias y perdidas:  ejemplo: un hombre juega a la ruleta dos dias seguidos. si el primero gana 2000 pesos y al dia siguiente pierde 1000, el hombre gano en total 2000 − 1000 = $ 1000. sin embargo, si el primer dia gana 500 y al siguiente pierde 2000, se dice que perdio en total 2000 − 500 = $ 1500. la expresion usada cambia en cada caso: gano en total o perdio en total, dependiendo de si las ganancias fueron mayores que las perdidas o viceversa. estas dos posibilidades se pueden expresar utilizando el signo de los numeros negativos (o positivos): en el primer caso gano en total 2000 − 1000 = + $ 1000 y en el segundo gano en total 500 − 2000 = − $ 1500. asi, se entiende que una perdida es una ganancia negativa.  los numeros naturales 0, 1, 2, 3,... son los numeros ordinarios que se utilizan para contar. al añadirles un signo menos («−») delante se obtienen los numeros negativos:  un numero entero negativo es un numero natural como 1, 2, 3, etc. precedido de un signo menos, «−». por ejemplo −1, −2, −3, etcetera. se leen «menos 1», «menos 2», «menos 3»,...  ademas, para diferenciarlos mejor, a los numeros naturales se les añade un signo mas («+») delante y se les llama numeros positivos.  un numero entero positivo es un numero natural como 1, 2, 3,... precedido de un signo mas. «+».  el cero no es positivo ni negativo, y puede escribirse con signo mas o menos o sin signo indistintamente, ya que sumar o restar cero es igual a no hacer nada. toda esta coleccion de numeros son los llamados «enteros».  los numeros enteros son el conjunto de todos los numeros enteros con signo (positivos y negativos) junto con el 0. se les representa por la letra z, tambien escrita en «negrita de pizarra» como ℤ :   z = { … , − 2 , − 1 , 0 , + 1 , + 2 , … } =\\}  los numeros enteros negativos son menores que todos los positivos y que el cero. es decir, todo numero que se encuentra ubicado a la derecha es mayor que el numero que se encuentra ubicado a la izquierda. para entender como estan ordenados se utiliza la recta numerica:  se ve con esta representacion que los numeros negativos son mas pequeños cuanto mas a la izquierda, es decir, cuanto mayor es el numero tras el signo. a este numero se le llama el valor absoluto:  el valor absoluto de un numero entero es la distancia que hay del origen (cero) hasta un punto dado. el valor absoluto de 0 es simplemente 0. se representa por dos barras verticales «||».  ejemplos. |+5| = 5 , |−2| = 2 , |0| = 0.  el orden de los numeros enteros puede resumirse en:  el orden de los numeros enteros se define como:  ejemplos. +23 > −56 , +31 < +47 , −15 < −9 , 0 > −36  los numeros enteros pueden sumarse, restarse, multiplicarse y dividirse, igual que puede hacerse con los numeros naturales.  en la suma de dos numeros enteros, se determina por separado el signo y el valor absoluto del resultado.  para sumar dos numeros enteros, se determina el signo y el valor absoluto del resultado del siguiente modo:  ejemplos. (+21) + (−13) = +8 , (+17) + (+26) = +43 , (−41) + (+19) = −22 , (−33) + (−28) = −61  la suma de numeros enteros se comporta de manera similar a la suma de numeros naturales:  la suma de numeros enteros cumple las siguientes propiedades:  ejemplo.  ademas, la suma de numeros enteros posee una propiedad adicional que no tienen los numeros naturales:  elemento opuesto o simetrico: para cada numero entero a, existe otro entero −a, que sumado al primero resulta en cero: a + (−a) = 0​.  la resta de numeros enteros es muy sencilla, ya que ahora es un caso particular de la suma.  la resta de dos numeros enteros (minuendo menos sustraendo) se realiza sumando el minuendo mas el sustraendo cambiando de signo.  ejemplos (+10) − (−5) = (+10) + (+5) = +15 (−7) − (+6) = (−7) + (−6) = −13 (−4) − (−8) = (−4) + (+8) = + 4(+2) − (+9) = (+2) + (−9) = −7  la multiplicacion y division de numeros enteros, al igual que la suma, requiere determinar por separado el signo y valor absoluto del resultado.  en la multiplicacion y en la division de dos numeros enteros se determinan el valor absoluto y el signo del resultado de la siguiente manera:  para recordar el signo del resultado, tambien se utiliza la regla de los signos:  regla de los signos - multiplicacion regla de los signos - division ejemplos multiplicacion. (+5) × (+3) = +15 , (+4) × (-6) = -24 , (−7) × (+8) = −56 , (−9) × (−2) = +18.  ejemplos division. (+15) : (+3) = +5 , (+12) : (-6) = -2 , (−16) : (+4) = −4 , (−18) : (−2) = +9.   la multiplicacion de numeros enteros tiene tambien propiedades similares a la de numeros naturales:  la multiplicacion de numeros enteros cumple las siguientes propiedades:  ejemplo.  la suma y multiplicacion de numeros enteros estan relacionadas, al igual que los numeros naturales, por la propiedad distributiva:  propiedad distributiva. dados tres numeros enteros a, b y c, el producto a × (b + c) y la suma de productos (a × b) + (a × c) son identicos.  ejemplo.   la division de numeros enteros no tiene las propiedades asociativa, conmutativa ni la distributiva.   ",
        "snippet": "Un número entero es un elemento del conjunto numérico que contiene los números naturales; que son N = { 0 , 1 , 2 , 3 , 4 , ⋯ } {\\displaystyle \\mathbb {N} =\\{0,1,2,3,4,\\cdots \\}} [1]​ o N ∗ = { 1 , 2 , 3 , 4 , ⋯ } {\\displaystyle \\mathbb {N} ^{\\ast }=\\{1,2,3,4,\\cdots \\}} ; dependiendo de cómo se definan, sus opuestos, y en la segunda definición, además el cero.[2]​ Los enteros negativos, como −1 o −13 (se leen «menos uno», «menos trece», etc.), son menores que cero y también son menores que todos los enteros positivos. Para resaltar la diferencia entre positivos y negativos, se puede escribir un signo «menos» delante de los negativos: -1, -5, etc. Y si no se escribe signo al número se asume que es positivo.",
        "enlaces_salientes": [
            "/wiki/N%C3%BAmero_entero",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Conjunto_num%C3%A9rico",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Cero",
            "/wiki/N%C3%BAmero_positivo",
            "/wiki/Numero_positivo",
            "/wiki/N%C3%BAmero_negativo",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/Suma",
            "/wiki/Resta",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/Signo_(matem%C3%A1ticas)",
            "/wiki/Educaci%C3%B3n_secundaria",
            "/wiki/Temperatura",
            "/wiki/Altitud",
            "/wiki/Monte_Everest",
            "/wiki/Metro",
            "/wiki/Nivel_del_mar",
            "/wiki/Mar_Muerto",
            "/wiki/Lat%C3%ADn",
            "/wiki/Lengua_francesa",
            "/wiki/N%C3%BAmero",
            "/wiki/N%C3%BAmero_mixto",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/N%C3%BAmero_negativo",
            "/wiki/Leonhard_Euler",
            "/wiki/Elementos_de_%C3%81lgebra",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/David_Hilbert",
            "/wiki/Nicolas_Bourbaki",
            "/wiki/Grupo_de_unidades",
            "/wiki/Aritm%C3%A9tica_modular",
            "/wiki/Relaci%C3%B3n_de_congruencia",
            "/wiki/N%C3%BAmero_p-%C3%A1dico",
            "/wiki/Matem%C3%A1tica_moderna",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/N%C3%BAmeros_negativos",
            "/wiki/Minuendo",
            "/wiki/Sustraendo",
            "/wiki/Resta",
            "/wiki/Signo_(matem%C3%A1ticas)",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Contar",
            "/wiki/Blackboard_bold",
            "/wiki/Recta_num%C3%A9rica",
            "/wiki/Recta_num%C3%A9rica",
            "/wiki/Valor_absoluto",
            "/wiki/Suma",
            "/wiki/Resta",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Valor_absoluto",
            "/wiki/Signo_(matem%C3%A1ticas)",
            "/wiki/C%C3%ADrculo",
            "/wiki/Signo_(matem%C3%A1ticas)",
            "/wiki/Valor_absoluto",
            "/wiki/Propiedad_asociativa",
            "/wiki/Propiedad_conmutativa",
            "/wiki/Elemento_neutro",
            "/wiki/Elemento_opuesto",
            "/wiki/Resta",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Signo_(matem%C3%A1ticas)",
            "/wiki/Valor_absoluto",
            "/wiki/Regla_de_los_signos",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Propiedad_asociativa",
            "/wiki/Propiedad_conmutativa",
            "/wiki/Elemento_neutro",
            "/wiki/Propiedad_distributiva",
            "/wiki/Propiedades_de_los_n%C3%BAmeros_enteros",
            "/wiki/Operaci%C3%B3n_binaria",
            "/wiki/Suma",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Anillo_(matem%C3%A1ticas)",
            "/wiki/Relaci%C3%B3n_de_orden",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Clase_de_equivalencia",
            "/wiki/Parte_entera",
            "/wiki/Entero_(tipo_de_dato)",
            "/wiki/N%C3%BAmero",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/N%C3%BAmero_real",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Cero",
            "/wiki/N%C3%BAmero_negativo",
            "/wiki/Fracci%C3%B3n",
            "/wiki/N%C3%BAmero_irracional",
            "/wiki/N%C3%BAmero_imaginario",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Fibonacci",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Britannica",
            "/wiki/ISBN",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
        "titulo": "Eliminación de Gauss-Jordan",
        "contenido": "en algebra lineal, la eliminacion de gauss-jordan, llamada asi en honor de carl friedrich gauss y wilhelm jordan, es un algoritmo que se usa para determinar la inversa de una matriz y las soluciones de un sistema de ecuaciones lineales.​ un sistema de ecuaciones se resuelve por el metodo de gauss cuando se obtienen sus soluciones mediante la reduccion del sistema dado a otro equivalente en el que cada ecuacion tiene una incognita menos que la anterior. el metodo de gauss transforma la matriz de coeficientes en una matriz triangular superior. el metodo de gauss-jordan continua el proceso de transformacion hasta obtener una matriz diagonal.  para realizar la reduccion de filas en una matriz, se utiliza una secuencia de  operaciones elementales de fila para modificar la matriz hasta que la esquina inferior izquierda de la matriz se llene de ceros, tanto como sea posible. hay tres tipos de operaciones elementales de fila:  utilizando estas operaciones, una matriz siempre se puede transformar en una matriz triangular superior, y de hecho en una que este en forma escalonada. una vez que todos los coeficientes principales (la entrada mas a la izquierda distinta de cero en cada fila) son 1, y cada columna que contiene un coeficiente principal tiene ceros en otros lugares, se dice que la matriz esta en  forma escalonada reducida. esta forma final es unica; en otras palabras, es independiente de la secuencia de operaciones de fila utilizadas. por ejemplo, en la siguiente secuencia de operaciones de fila (donde dos operaciones elementales en filas diferentes se realizan en el primer y tercer paso), la tercera y cuarta matrices son las que estan en forma escalonada, y la matriz final es la unica forma escalonada reducida.  el uso de operaciones de fila para convertir una matriz en forma escalonada reducida se denomina a veces eliminacion de gauss-jordan. en este caso, el termino eliminacion de gauss se refiere al proceso hasta que ha alcanzado su forma triangular superior, o forma escalonada (no reducida). por razones computacionales, cuando se resuelven sistemas de ecuaciones lineales, a veces es preferible detener las operaciones de fila antes de que la matriz este completamente reducida.  algunos casos especiales del metodo -aunque presentados sin demostracion- ya eran conocidos por los matematicos chinos en torno al año 179 de nuestra era.​  el metodo de eliminacion de gauss-jordan aparece en el capitulo ocho del importante texto matematico chino jiuzhang suanshu o los nueve capitulos sobre el arte matematico. su uso se ilustra en dieciocho problemas, de dos a cinco ecuaciones cada uno. la primera referencia al libro por este titulo data del 179  dc, pero algunas de sus partes fueron escritas tan pronto como alrededor del 150 a. c.,​​ en este año fue señalado por liu hui en el siglo iii.  el proceso de reduccion de filas hace uso de  operaciones elementales de filas, y se puede dividir en dos partes. la primera parte (a veces llamada eliminacion hacia adelante) reduce un sistema dado a la forma escalonada de filas, a partir de la cual se puede decir si no hay soluciones, una solucion unica, o infinitas soluciones. la segunda parte (a veces llamada sustitucion hacia atras) continua utilizando operaciones de fila hasta que se encuentra la solucion; en otras palabras, pone la matriz en forma escalonada reducida.  otro punto de vista, que resulta muy util para analizar el algoritmo, es que la reduccion de filas produce una descomposicion matricial de la matriz original. las operaciones elementales de fila pueden verse como la multiplicacion a la izquierda de la matriz original por matrices elementales. alternativamente, una secuencia de operaciones elementales que reduce una sola fila puede verse como la multiplicacion por una matriz de frobenius. entonces, la primera parte del algoritmo calcula una descomposicion lu, mientras que la segunda parte escribe la matriz original como el producto de una matriz invertible determinada de forma unica y una matriz escalonada de filas reducida determinada de forma unica.  hay tres tipos de operaciones elementales de fila que se pueden realizar en las filas de una matriz ya indicados anteriormente:  si la matriz esta asociada a un sistema de ecuaciones lineales, entonces estas operaciones no cambian el conjunto solucion. por lo tanto, si el objetivo es resolver un sistema de ecuaciones lineales, el uso de estas operaciones de fila podria facilitar el problema.  la complejidad computacional de la eliminacion gaussiana es  o(n³). esto es, el maximo numero de operaciones requeridas es del orden de n³ si el tamaño de la matriz es n × n.​  una variante interesante de la eliminacion de gauss es la que llamamos eliminacion de gauss-jordan, (debido al mencionado gauss y a wilhelm jordan), esta consiste en ir obteniendo los 1 delanteros durante los pasos uno al cuatro (llamados paso directo) asi para cuando estos finalicen ya se obtendra la matriz en forma escalonada reducida.  supongamos que es necesario encontrar los numeros \"x\", \"y\", \"z\", que satisfacen simultaneamente estas ecuaciones:  esto es llamado un sistema lineal de ecuaciones. el objetivo es reducir el sistema a otro equivalente, que tenga las mismas soluciones. las operaciones (llamadas elementales) son estas:  estas operaciones pueden representarse con matrices elementales que se usan tambien en otros procedimientos como la factorizacion lu o la diagonalizacion por congruencia de una matriz simetrica.  en nuestro ejemplo, eliminamos x de la segunda ecuacion sumando 3/2 veces la primera ecuacion a la segunda y despues sumamos la primera ecuacion a la tercera. el resultado es:  ahora eliminamos y de la primera ecuacion sumando -2 veces la segunda ecuacion a la primera, y sumamos -4 veces la segunda ecuacion a la tercera para eliminar y.  entonces podemos resolver por gauss al sustituir en el sistema de ecuaciones el valor de z continuando con las incognitas anteriores de abajo hacia arriba y de derecha a izquierda obteniendo el valor de todas las incognitas. si continuamos con la variante de gauss-jordan eliminamos z de la primera ecuacion sumando -2 veces la tercera ecuacion a la primera, y sumando 1/2 veces la tercera ecuacion a la segunda para eliminar z.  despejando, podemos ver las soluciones:  para clarificar los pasos, se trabaja con la matriz aumentada. podemos ver los 3 pasos en su notacion matricial:  primero:  despues,  por ultimo.  si el sistema fuera incompatible, entonces nos encontrariamos con una fila como esta:  que representa la ecuacion: 0 x + 0 y + 0 z = a , donde a = 0. es decir, 0 = a , lo que supone una contradiccion y, por tanto, no tiene solucion. en el caso de que a=0 el sistema tiene varias soluciones.  dos formas especiales de matrices son la escalonada y la escalonada reducida. una matriz puede tener las siguientes propiedades:  si una matriz a cumple con esas propiedades, se dice escalonada. ademas, cumpliendo estas otras condiciones que detallaremos a continuacion, decimos que la matriz se encuentra en la forma escalonada reducida por filas, o simplemente en forma escalonada reducida.  cuando una matriz representa a un sistema de ecuaciones situaciones como tener una columna de ceros parece imposible ya que corresponderia a una variable que nunca habria aparecido. sin embargo esta situacion puede presentarse (imaginemos la ecuacion de un plano en el espacio en la que no aparece alguna de las componentes, por ejemplo y+z=5). asi la matriz  tambien es una matriz escalonada.  una vez que la matriz del sistema se ha transformado hasta obtener una matriz escalonada reducida es muy facil discutirlo (es decir, determinar cuantas soluciones tiene):  es posible usar la eliminacion gaussiana para encontrar inversas de matrices n × n. para ello se aumenta la matriz dada, digamos a con una matriz identidad, simplemente escribiendo las filas de la identidad a continuacion de las de nuestra matriz a, por ejemplo dada:  se construiria  y ahora se realizan las operaciones elementales sobre las filas de la matriz aumentada que sean necesarias para obtener la forma escalonada reducida de la matriz a; sumando tanto a la segunda como a la tercera fila la primera obtenemos  multiplicamos a la segunda fila por -1 y la intercambiamos con la primera  ya tenemos el pivote de la primera fila que usamos para hacer ceros debajo  ahora usamos el pivote de la segunda fila  y por ultimo cambiamos de signo la tercera fila y usamos el pivote correspondiente  el proceso ha finalizado porque en la parte izquierda tenemos la forma escalonada reducida de a y puesto que esta es la matriz identidad, entonces a tiene inversa y su inversa es la matriz que aparece a la derecha, en el lugar que al principio ocupaba la identidad. cuando la forma escalonada reducida que aparece no es la identidad es que la matriz de partida no tiene inversa. ",
        "snippet": "En álgebra lineal, la eliminación de Gauss-Jordan, llamada así en honor de Carl Friedrich Gauss y Wilhelm Jordan, es un algoritmo que se usa para determinar la inversa de una matriz y las soluciones de un sistema de ecuaciones lineales.[1]​ Un sistema de ecuaciones se resuelve por el método de Gauss cuando se obtienen sus soluciones mediante la reducción del sistema dado a otro equivalente en el que cada ecuación tiene una incógnita menos que la anterior. El método de Gauss transforma la matriz de coeficientes en una matriz triangular superior. El método de Gauss-Jordan continúa el proceso de transformación hasta obtener una matriz diagonal.",
        "enlaces_salientes": [
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/M%C3%A9todo_de_Gauss-Seidel",
            "/wiki/%C3%81lgebra_lineal",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/Wilhelm_Jordan",
            "/wiki/Algoritmo",
            "/wiki/Matriz_invertible",
            "/wiki/Resoluci%C3%B3n_de_ecuaciones",
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/Ecuaci%C3%B3n",
            "/wiki/Inc%C3%B3gnita",
            "/wiki/Matriz_triangular",
            "/wiki/Matriz_diagonal",
            "/wiki/Matriz_elemental",
            "/wiki/Matriz_triangular",
            "/wiki/Forma_escalonada",
            "/wiki/Matriz_escalonada",
            "/wiki/Jiuzhang_suanshu",
            "/wiki/179",
            "/wiki/150_a._C.",
            "/wiki/Liu_Hui",
            "/wiki/Matriz_elemental",
            "/wiki/Matriz_triangular#Sustitución_hacia_delante_y_hacia_atrás",
            "/wiki/Descomposici%C3%B3n_matricial",
            "/wiki/Matriz_elemental",
            "/wiki/Descomposici%C3%B3n_LU",
            "/wiki/Escalar_(matem%C3%A1tica)",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Submatriz",
            "/wiki/Wilhelm_Jordan",
            "/wiki/Sistema_lineal_de_ecuaciones",
            "/wiki/Matrices_elementales",
            "/wiki/Factorizaci%C3%B3n_LU",
            "/wiki/Matriz_aumentada",
            "/wiki/Matriz_escalonada",
            "/wiki/Matriz_invertible",
            "/wiki/Matriz_identidad",
            "/wiki/%C3%81lgebra_elemental",
            "/wiki/%C3%81lgebra_lineal",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/John_Wiley_%26_Sons",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Semantic_Scholar",
            "/wiki/ArXiv",
            "/wiki/Digital_object_identifier",
            "/wiki/Society_for_Industrial_and_Applied_Mathematics",
            "/wiki/ISBN",
            "/wiki/Addison-Wesley",
            "/wiki/ISBN",
            "/wiki/McGraw-Hill",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Semantic_Scholar",
            "/wiki/Princeton_University_Press",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Sistema_de_ecuaciones_lineales",
        "titulo": "Sistema de ecuaciones lineales",
        "contenido": "en matematicas y algebra lineal, un sistema algebraico de ecuaciones lineales, tambien conocido como sistema lineal de ecuaciones o simplemente sistema lineal, es un sistema de ecuaciones en donde cada ecuacion es de primer grado, definidas sobre un cuerpo. un ejemplo de sistema lineal de ecuaciones seria el siguiente:   { 3 x 1 + 2 x 2 + x 3 = 1 2 x 1 + 2 x 2 + 4 x 3 = − 2 − x 1 + 1 2 x 2 − x 3 = 7 {rcrcrcr}3\\,x_{1}&+&2\\,x_{2}&+&\\,x_{3}&=&1\\\\2\\,x_{1}&+&2\\,x_{2}&+&4\\,x_{3}&=&-2\\\\-\\,x_{1}&+&{2}}\\,x_{2}&-&\\,x_{3}&=&7\\end{array}}\\right.}  el problema consiste en encontrar los valores desconocidos de las variables x1, x2 y x3 que satisfacen las tres ecuaciones.  el problema de los sistemas lineales de ecuaciones es uno de los mas antiguos de la matematica y tiene una infinidad de aplicaciones, como en procesamiento digital de señales, analisis estructural, estimacion, prediccion y mas generalmente en programacion lineal, asi como en la aproximacion de problemas no lineales de analisis numerico.  en general, un sistema con m ecuaciones lineales y n incognitas puede ser escrito en forma normal como:   { a 11 x 1 + a 12 x 2 + … + a 1 n x n = b 1 a 21 x 1 + a 22 x 2 + … + a 2 n x n = b 2 … … … … … a m 1 x 1 + a m 2 x 2 + … + a m n x n = b m a_{11}x_{1}&+a_{12}x_{2}&+\\dots &+a_{1n}x_{n}&=b_{1}\\\\a_{21}x_{1}&+a_{22}x_{2}&+\\dots &+a_{2n}x_{n}&=b_{2}\\\\\\dots &\\dots &\\dots &\\dots &\\dots \\\\a_{m1}x_{1}&+a_{m2}x_{2}&+\\dots &+a_{mn}x_{n}&=b_{m}\\end{matrix}}\\right.}  donde x 1 , … , x n ,\\dots ,x_{n}} son las incognitas, los numeros a i j ∈ k \\in \\mathbb {k} } son los coeficientes del sistema sobre el cuerpo k [ = r , c , … ] \\ [=\\mathbb {r} ,\\mathbb {c} ,\\dots ]} y b 1 , … , b m ,\\dots ,b_{m}} son los terminos independientes. es posible reescribir el sistema separando los coeficientes con notacion matricial:  (1) ( a 11 a 12 ⋯ a 1 n a 21 a 22 ⋯ a 2 n ⋮ ⋮ ⋱ ⋮ a m 1 a m 2 ⋯ a m n ) ( x 1 x 2 ⋮ x n ) = ( b 1 b 2 ⋮ b m ) a_{11}&a_{12}&\\cdots &a_{1n}\\\\a_{21}&a_{22}&\\cdots &a_{2n}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{m1}&a_{m2}&\\cdots &a_{mn}\\end{pmatrix}}x_{1}\\\\x_{2}\\\\\\vdots \\\\x_{n}\\end{pmatrix}}=b_{1}\\\\b_{2}\\\\\\vdots \\\\b_{m}\\end{pmatrix}}}  si representamos cada matriz con una unica letra obtenemos:   a x = b =\\mathbf {b} }  donde a es una matriz m por n, x es un vector columna de longitud n y b es otro vector columna de longitud m. el sistema de eliminacion de gauss-jordan se aplica a este tipo de sistemas, sea cual sea el cuerpo del que provengan los coeficientes. la matriz a se llama matriz de coeficientes de este sistema lineal. a b se le llama vector de terminos independientes del sistema y a x se le llama vector de incognitas.  en esta seccion se analizan las propiedades de los sistemas de ecuaciones lineales sobre el cuerpo r } , es decir, los sistemas lineales en los cuales los coeficientes de las ecuaciones son numeros reales.  un sistema con n incognitas se puede representar en el n-espacio correspondiente.  en los sistemas con 2 incognitas, el universo de nuestro sistema sera el plano bidimensional, mientras que cada una de las ecuaciones sera representada por una recta. la solucion sera el punto (o linea) donde se intersequen todas las rectas que representan a las ecuaciones. si no existe ningun punto en el que se intersequen al mismo tiempo todas las lineas, el sistema es incompatible, o lo que es lo mismo, no tiene solucion.  en el caso de un sistema con 3 incognitas, el universo sera el espacio tridimensional, siendo cada ecuacion un plano dentro del mismo. si todos los planos intersecan en un unico punto, las coordenadas de este seran la solucion al sistema. si, por el contrario, la interseccion de todos ellos es una recta o incluso un plano, el sistema tendra infinitas soluciones, que seran las coordenadas de los puntos que forman dicha linea o superficie.  para sistemas de 4 o mas incognitas, la representacion grafica no existe, por lo que dichos problemas no se enfocan desde esta optica.  los sistemas de ecuaciones se pueden clasificar segun el numero de soluciones que pueden presentar. de acuerdo con ese caso se pueden presentar los siguientes casos:  quedando asi la clasificacion:  los sistemas incompatibles geometricamente se caracterizan por (hiper)planos o rectas que se cruzan sin cortarse. los sistemas compatibles determinados se caracterizan por un conjunto de (hiper)planos o rectas que se cortan en un unico punto. los sistemas compatibles indeterminados se caracterizan por (hiper)planos que se cortan a lo largo de una recta [o mas generalmente un hiperplano de dimension menor]. desde un punto de vista algebraico los sistemas compatibles determinados se caracterizan porque el determinante de la matriz es diferente de cero:   sistema compatible determinado ⟺ det ( a ) = 0 }\\longleftrightarrow \\det(\\mathbf {a} )\\neq 0}  podemos averiguar si un sistema es o no compatible mediante el teorema de rouche-frobenius que establece que un sistema de ecuaciones lineales es compatible solo si el rango de su matriz ampliada coincide con el de su matriz de coeficientes. supongamos que el sistema es compatible. si el valor comun de los rangos de las matrices coincide con el numero de variables, el sistema es compatible determinado; en caso contrario, es compatible indeterminado.  un sistema sobre un cuerpo k es compatible indeterminado cuando posee un numero infinito de soluciones. por ejemplo, el siguiente sistema:   { x + 2 y = 1 2 x + 4 y = 2 x&+2y&=1\\\\2x&+4y&=2\\end{matrix}}\\right.}  tanto la primera como la segunda ecuacion se corresponden con la recta cuya pendiente es − 0 , 5 y que pasa por el punto ( − 1 , 1 ) , por lo que ambas coinciden en todos los puntos de dicha recta. el sistema es compatible por tener solucion o puntos comunes entre las rectas, pero es indeterminado al ocurrir esto en infinitos puntos.   s i s t e m a c o m p a t i b l e i n d e t e r m i n a d o ⇒ det a = 0 \\rightarrow \\det \\mathbf {a} =0}  de un sistema se dice que es incompatible cuando no presenta ninguna solucion. por ejemplo, supongamos el siguiente sistema:   { x + 2 y = 4 2 x + 4 y = 1236 x&+2y&=4\\\\2x&+4y&=1236\\end{matrix}}\\right.}  las ecuaciones se corresponden graficamente con dos rectas, ambas con la misma pendiente, al ser paralelas, no se cortan en ningun punto, es decir, no existe ningun valor que satisfaga a la vez ambas ecuaciones.  matematicamente un sistema de estos es incompatible cuando el rango de la matriz del sistema es inferior al rango de la matriz ampliada. una condicion necesaria para que esto suceda es que el determinante de la matriz del sistema sea cero:   s i s t e m a i n c o m p a t i b l e ⇒ det a = 0 \\rightarrow \\det \\mathbf {a} =0}  el metodo de sustitucion consiste en despejar en una de las ecuaciones con cualquier incognita, preferiblemente la que tenga menor coeficiente y a continuacion sustituirla en otra ecuacion por su valor.  en caso de sistemas con mas de dos incognitas, la seleccionada debe ser sustituida por su valor equivalente en todas las ecuaciones excepto en la que la hemos despejado. en ese instante, tendremos un sistema con una ecuacion y una incognita menos que el inicial, en el que podemos seguir aplicando este metodo reiteradamente. por ejemplo, supongamos que queremos resolver por sustitucion este sistema:   { 3 x + y = 22 4 x − 3 y = − 1 3x&+y&=&22\\\\4x&-3y&=&-1\\end{matrix}}\\right.}  en la primera ecuacion, seleccionamos la incognita y por ser la de menor coeficiente y que posiblemente nos facilite mas las operaciones, y la despejamos, obteniendo la siguiente ecuacion.   y = 22 − 3 x  el siguiente paso sera sustituir cada ocurrencia de la incognita y en la otra ecuacion, para asi obtener una ecuacion donde la unica incognita sea la x .   4 x − 3 ( 22 − 3 x ) = − 1 ⇒ 4 x − 66 + 9 x = − 1 ⇒ 13 x − 66 = − 1 , ⇒ 13 x = 65  al resolver la ecuacion obtenemos el resultado x = 5 , y si ahora sustituimos esta incognita por su valor en alguna de las ecuaciones originales obtendremos y = 7 , con lo que el sistema queda ya resuelto.  el metodo de igualacion se puede entender como un caso particular del metodo de sustitucion en el que se despeja la misma incognita en dos ecuaciones y a continuacion se igualan entre si la parte derecha de ambas ecuaciones.  tomando el mismo sistema utilizado como ejemplo para el metodo de sustitucion, si despejamos la incognita y en ambas ecuaciones nos queda de la siguiente manera:   { y = 22 − 3 x y = 4 x + 1 3 y=&22-3x\\\\y=&{3}}\\end{matrix}}\\right.}  como se puede observar, ambas ecuaciones comparten la misma parte izquierda, por lo que podemos afirmar que las partes derechas tambien son iguales entre si.   22 − 3 x = 4 x + 1 3 ⇒ 3 ( 22 − 3 x ) = 4 x + 1 ⇒ 65 = 13 x ⇒ x = 5 {3}}\\rightarrow \\quad \\ 3(22-3x)=4x+1\\rightarrow \\quad \\ 65=13x\\rightarrow \\quad \\ x=5}  una vez obtenido el valor de la incognita x , se sustituye su valor en una de las ecuaciones originales, y se obtiene el valor de la y .  la forma mas facil de tener el metodo de sustitucion es realizando un cambio para despejar x despues de averiguar el valor de la y.  este metodo suele emplearse mayoritariamente en los sistemas lineales, siendo pocos los casos en que se utiliza para resolver sistemas no lineales. el procedimiento, diseñado para sistemas con dos ecuaciones e incognitas, consiste en transformar una de las ecuaciones (generalmente, mediante productos), de manera que obtengamos dos ecuaciones en la que una misma incognita aparezca con el mismo coeficiente y distinto signo. a continuacion, se suman ambas ecuaciones produciendose asi la reduccion o cancelacion de dicha incognita, obteniendo asi una ecuacion con una sola incognita, donde el metodo de resolucion es simple.  por ejemplo, en el sistema:   { 2 x + 3 y = 5 5 x + 6 y = 4 2x&+3y&=5\\\\5x&+6y&=4\\end{matrix}}\\right.}  no tenemos mas que multiplicar la primera ecuacion por − 2 para poder cancelar la incognita y . al multiplicar, dicha ecuacion nos queda asi:  si sumamos esta ecuacion a la segunda del sistema original, obtenemos una nueva ecuacion donde la incognita y ha sido reducida y que, en este caso, nos da directamente el valor de la incognita x :  el siguiente paso consiste unicamente en sustituir el valor de la incognita x en cualquiera de las ecuaciones donde aparecian ambas incognitas, y obtener asi que el valor de y si sustituimos en la primera ecuacion es igual a:   2 x + 3 y = 5 x = − 6 } ⟶ 2 ( − 6 ) + 3 y = 5 ⟶ y = 17 3 {rrcr}2x&+3y&=&5\\\\x&&=&-6\\end{array}}\\right\\}\\quad \\longrightarrow \\quad 2(-6)+3y=5\\quad \\longrightarrow \\quad y={3}}}  consiste en construir la grafica de cada una de las ecuaciones del sistema. el metodo (manualmente aplicado) solo resulta eficiente en el plano cartesiano, es decir para un espacio de dimension dos.  el proceso de resolucion de un sistema de ecuaciones mediante el metodo grafico se resuelve en los siguientes pasos:  el metodo de eliminacion de gauss o simplemente metodo de gauss consiste en convertir un sistema lineal de n ecuaciones con n incognitas, en uno escalonado, en el que la primera ecuacion tiene n incognitas, la segunda ecuacion tiene n - 1 incognitas, ..., hasta la ultima ecuacion, que tiene 1 incognita. de esta forma, sera facil partir de la ultima ecuacion e ir subiendo para calcular el valor de las demas incognitas.  agrupando las tres ecuaciones tenemos el sistema, que ordenado resulta:  aplicamos gauss, restando la primera ecuacion a las dos siguientes:  en este caso en la tercera ecuacion se ha eliminado la y, por lo que no es necesario hacer mas operaciones. por lo tanto obtenemos que z = 10 de la tercera ecuacion:  sustituyendo z en la segunda ecuacion obtenemos que y = 10:  sustituyendo z e y en la primera ecuacion obtenemos x = 10.  con lo que hemos obtenido el resultado del sistema:  una variante de este metodo, denominada eliminacion de gauss-jordan, es un metodo aplicable unicamente a los sistemas lineales de ecuaciones, y consistente en triangular la matriz aumentada del sistema mediante transformaciones elementales, hasta obtener ecuaciones de una sola incognita, cuyo valor sera igual al coeficiente situado en la misma fila de la matriz. este procedimiento es similar al anterior de reduccion, pero ejecutado de manera reiterada y siguiendo un cierto orden algoritmico.  supongase que es necesario encontrar los numeros x, y, z, que satisfacen simultaneamente al siguiente sistema de ecuaciones lineales:  inicialmente, se escriben los coeficientes del sistema como una matriz aumentada. lo que en notacion matricial se denota por:  posteriormente, se reduce la incognita x , sumando a la segunda fila, la primera multiplicada por 3 2 {2}}} , y a la tercera, la primera fila. la matriz queda asi:   ( 2 1 − 1 8 0 1 2 1 2 1 0 2 1 5 ) {rrrr}2&1&-1&8\\\\0&{2}}&{2}}&1\\\\0&2&1&5\\end{array}}\\right)}  el siguiente paso consiste en eliminar la incognita y en la primera y tercera fila, para lo cual se suma la segunda multiplicada por − 2 y por − 4 , respectivamente.   ( 2 0 − 2 6 0 1 2 1 2 1 0 0 − 1 1 ) {rrrr}2&0&-2&6\\\\0&{2}}&{2}}&1\\\\0&0&-1&1\\end{array}}\\right)}  por ultimo, se elimina z , tanto de la primera como de la segunda fila, sumandoles la tercera multiplicada por − 2 y por 1 2 {2}}} , respectivamente:   ( 2 0 0 4 0 1 2 0 3 2 0 0 − 1 1 ) {rrrr}2&0&0&4\\\\0&{2}}&0&{2}}\\\\0&0&-1&1\\end{array}}\\right)}  llegados a este punto se puede resolver directamente las ecuaciones que se nos plantean:   { 2 x = 4 y 2 = 3 2 − z = 1 2x=4\\\\{2}}={2}}\\\\-z=1\\end{matrix}}\\right.}  o, si se prefiere, se puede multiplicar las tres filas de la matriz por: 1 2 {2}}} , 2 y − 1 respectivamente, y obtener asi automaticamente los valores de las incognitas en la ultima columna.   { x = 2 y = 3 z = − 1 x=&2\\\\y=&3\\\\z=&-1\\end{matrix}}\\right.}    la regla de cramer da una solucion para sistemas compatibles determinados en terminos de determinantes y adjuntos dada por:   x j = det ( a j ) det ( a ) =)} )}}}  donde aj es la matriz resultante de reemplazar la j-esima columna de a por el vector columna b. para un sistema de dos ecuaciones y dos incognitas:   { a x + b y = e c x + d y = f a\\,x&+&b\\,y&=e\\\\c\\,x&+&d\\,y&=f\\end{matrix}}\\right.}  la regla de cramer da la siguiente solucion:   x = | e b f d | | a b c d | = e d − b f a d − b c , y = | a e c f | | a b c d | = a f − e c a d − b c e&b\\\\f&d\\end{vmatrix}}a&b\\\\c&d\\end{vmatrix}}}={ed-bf \\over ad-bc}\\;,\\qquad y=a&e\\\\c&f\\end{vmatrix}}a&b\\\\c&d\\end{vmatrix}}}={af-ec \\over ad-bc}}  nota: cuando en la determinante original  det(a) el resultado es 0, el sistema indica multiples o sin coincidencia.  la eliminacion de gauss-jordan es un algoritmo numerico usado para una gran cantidad de casos especificos, aunque posteriormente se han desarrollado algoritmos alternativos mucho mas eficientes. la mayoria de estos algoritmos mejorados tienen una complejidad computacional de o(n²) (donde n es el numero de ecuaciones del sistema). algunos de los metodos mas usados son:  cuando consideramos ecuaciones lineales cuyas soluciones son numeros racionales, reales o complejos o mas generalmente un cuerpo k } , la solucion puede encontrarse mediante regla de cramer. para sistemas de muchas ecuaciones la regla de cramer puede ser computacionalmente mas costosa y suelen usarse otros metodos mas \"economicos\" en numero de operaciones como la eliminacion de gauss-jordan y la descomposicion de cholesky. existen tambien metodos indirectos (basados en iteraciones) como el metodo de gauss-seidel.  si el cuerpo es infinito (como es el caso de los numeros reales o complejos), entonces solo puede darse una de las tres siguientes situaciones:  los metodos para resolver el sistema (1) sobre un anillo son muy diferentes a los considerados anteriormente. de hecho, la mayoria de los metodos usados en cuerpos, como la regla de cramer, son inaplicables en anillos debido a que no existen inversos multiplicativos.  la existencia de solucion del sistema (1) sobre los enteros requiere varias condiciones: ",
        "snippet": "En matemáticas y álgebra lineal, un sistema algebraico de ecuaciones lineales, también conocido como sistema lineal de ecuaciones o simplemente sistema lineal, es un sistema de ecuaciones en donde cada ecuación es de primer grado, definidas sobre un cuerpo. Un ejemplo de sistema lineal de ecuaciones sería el siguiente:",
        "enlaces_salientes": [
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/%C3%81lgebra_lineal",
            "/wiki/Sistema_de_ecuaciones",
            "/wiki/Ecuaci%C3%B3n",
            "/wiki/Cuerpo_(matem%C3%A1tica)",
            "/wiki/Problema_matem%C3%A1tico",
            "/wiki/Resoluci%C3%B3n_de_ecuaciones",
            "/wiki/Procesamiento_digital_de_se%C3%B1ales",
            "/wiki/An%C3%A1lisis_estructural",
            "/wiki/Programaci%C3%B3n_lineal",
            "/wiki/Aproximaci%C3%B3n",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Inc%C3%B3gnita",
            "/wiki/Matriz_(matem%C3%A1tica)",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Cuerpo_(matem%C3%A1tica)",
            "/wiki/N%C3%BAmeros_reales",
            "/wiki/Plano_(geometr%C3%ADa)",
            "/wiki/Recta",
            "/wiki/Espacio_eucl%C3%ADdeo",
            "/wiki/Plano_(geometr%C3%ADa)",
            "/wiki/Ecuaci%C3%B3n_de_la_recta",
            "/wiki/Recta",
            "/wiki/Punto_(geometr%C3%ADa)",
            "/wiki/L%C3%ADnea",
            "/wiki/Determinante_(matem%C3%A1tica)",
            "/wiki/Teorema_de_Rouch%C3%A9-Frobenius",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Autovalor",
            "/wiki/Espacio_vectorial",
            "/wiki/Paralela",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Recta",
            "/wiki/Plano_cartesiano",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Matriz_aumentada",
            "/wiki/Matriz_aumentada",
            "/wiki/Regla_de_Cramer",
            "/wiki/Determinante_(matem%C3%A1tica)",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Matriz_de_Toeplitz",
            "/wiki/Recursi%C3%B3n_de_Levinson",
            "/wiki/Procesamiento_digital_de_se%C3%B1ales",
            "/wiki/Matriz_singular",
            "/wiki/Descomposici%C3%B3n_en_valores_singulares",
            "/wiki/Regla_de_Cramer",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Descomposici%C3%B3n_de_Cholesky",
            "/wiki/M%C3%A9todo_de_Gauss-Seidel",
            "/wiki/Infinito",
            "/wiki/N%C3%BAmero_real",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/Ecuaci%C3%B3n_diof%C3%A1ntica",
            "/wiki/Anillo_(matem%C3%A1ticas)",
            "/wiki/Cuerpo_(matem%C3%A1ticas)",
            "/wiki/Regla_de_Cramer",
            "/wiki/Inverso_multiplicativo",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Sistema_de_ecuaciones",
            "/wiki/MATLAB",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/C%C3%A1lculo",
        "titulo": "Cálculo",
        "contenido": "en general el termino calculo (del latin calculus, piedrecita, usado para contar o como ayuda al calcular)​ hace referencia al resultado correspondiente a la accion de calcular. calcular, por su parte, consiste en realizar las operaciones necesarias para prever el resultado de una accion previamente concebida, o conocer las consecuencias que se pueden derivar de unos datos previamente conocidos.  no obstante, el uso mas comun del termino «calculo» es el logico-matematico. desde esta perspectiva, el calculo consiste en un  procedimiento mecanico o algoritmo, mediante el cual podemos conocer las consecuencias que se derivan de las variables previamente conocidas debidamente formalizadas y simbolizadas.  las dos acepciones del calculo (la general y la restringida) arriba definidas estan intimamente ligadas. el calculo es una actividad natural y primordial en el hombre, que comienza en el mismo momento en que empieza a relacionar unas cosas con otras en un pensamiento o discurso. el calculo logico natural como razonamiento es el primer calculo elemental del ser humano. el calculo en sentido logico-matematico aparece cuando se toma conciencia de esta capacidad de razonar y trata de formalizarse.  por lo tanto, podemos distinguir dos tipos de operaciones:  el termino «calculo» procede del latin calculus, piedrecita que se mete en el calzado y que produce molestia. precisamente, tales piedrecitas ensartadas en tiras constituian el abaco romano que, junto con el suanpan chino, constituyen las primeras maquinas de calcular en el sentido de contar.  los antecedentes de procedimiento de calculo, como algoritmo, se encuentran en los que utilizaron los geometras griegos, eudoxo en particular, en el sentido de llegar por aproximacion de restos cada vez mas pequeños, a una medida de figuras curvas; asi como diofanto precursor del algebra.  se considera que arquimedes fue uno de los matematicos mas grandes de la antiguedad y, en general, de toda la historia.​​ uso el metodo exhaustivo para calcular el area bajo el arco de una parabola con el sumatorio de una serie infinita, y dio una aproximacion extremadamente precisa del numero pi.​ tambien definio la espiral que lleva su nombre, formulas para los volumenes de las superficies de revolucion y un ingenioso sistema para expresar numeros muy largos.  la consideracion del calculo como una forma de razonamiento abstracto aplicado en todos los ambitos del conocimiento se debe a aristoteles, quien en sus escritos logicos fue el primero en formalizar y simbolizar los tipos de razonamientos categoricos (silogismos). este trabajo seria completado mas tarde por los estoicos, los megaricos, la escolastica.  los algoritmos actuales del calculo aritmetico, utilizados universalmente, son fruto de un largo proceso historico. de vital importancia son las aportaciones de muhammad ibn al-juarismi en el siglo ix;​  en el siglo xiii, fibonacci introduce en europa la representacion de los numeros arabigos del sistema decimal. se introdujo el 0, ya de antiguo conocido en la india y se construye definitivamente el sistema decimal de diez cifras con valor posicional. la escritura antigua de numeros en babilonia, en egipto, en grecia o en roma, hacia muy dificil un procedimiento mecanico de calculo.​  el sistema decimal fue muy importante para el desarrollo de la contabilidad de los comerciantes de la baja edad media, en los inicios del capitalismo.  el concepto de funcion por tablas ya era practicado de antiguo pero adquirio especial importancia en la universidad de oxford en el siglo xiv.​ la idea de un lenguaje o algoritmo capaz de determinar todas las verdades, incluidas las de la fe, aparecen en el intento de raimundo lulio en su ars magna  a fin de lograr una operatividad mecanica se confeccionaban unas tablas a partir de las cuales se podia generar un algoritmo practicamente mecanico. este sistema de tablas ha perdurado en algunas operaciones durante siglos, como las tablas de logaritmos, o las funciones trigonometricas; las tablas venian a ser como la calculadora de hoy dia; un instrumento imprescindible de calculo. las amortizaciones de los creditos en los bancos, por ejemplo, se calculaban a partir de tablas elementales hasta que se produjo la aplicacion de la informatica en el tercer tercio del siglo xx.  a finales de la edad media la discusion entre los partidarios del abaco y los partidarios del algoritmo se decanto claramente por estos ultimos.​ de especial importancia es la creacion del sistema contable por partida doble recomendado por luca pacioli fundamental para el progreso del capitalismo en el renacimiento.​  el sistema que usamos actualmente fue introducido por luca pacioli en 1494, el cual fue creado y desarrollado para responder a la necesidad de la contabilidad en los negocios de la burguesia renacentista.  el desarrollo del algebra (con la introduccion de un sistema de simbolos por un lado, y la resolucion de problemas por medio de las ecuaciones) vino de la mano de los grandes matematicos de la epoca renacentista como tartaglia, stevin, cardano o vieta y fue esencial para el planteamiento y solucion de los mas diversos problemas que surgieron en la epoca, que dieron como consecuencia los grandes descubrimientos que hicieron posible el progreso cientifico que surgiria en el siglo xvii.​  en el siglo xvii el calculo conocio un enorme desarrollo siendo los autores mas destacados descartes,​ pascal​ y, finalmente, leibniz y newton​ con el calculo infinitesimal que en muchas ocasiones ha recibido simplemente, por absorcion, el nombre de calculo.  el concepto de calculo formal en el sentido de algoritmo reglado para el desarrollo de un razonamiento y su aplicacion al mundo de lo real,​ adquiere una importancia y desarrollo enorme respondiendo a una necesidad de establecer relaciones matematicas entre diversas medidas, esencial para el progreso de la ciencia fisica que, debido a esto, es tomada como nuevo modelo de ciencia frente a la especulacion tradicional filosofica, por el rigor y seguridad que ofrece el calculo matematico. cambia asi el sentido tradicional de la fisica como filosofia de la naturaleza y toma el sentido de ciencia que estudia los cuerpos materiales, en cuanto materiales.  a partir de entonces el propio sistema de calculo permite establecer modelos sobre la realidad fisica, cuya comprobacion experimental​ supone la confirmacion de la teoria como sistema. es el momento de la consolidacion del llamado metodo cientifico cuyo mejor exponente es en aquel momento la teoria de la gravitacion universal y las leyes de la mecanica de newton.​  durante el siglo xix y xx el desarrollo cientifico y la creacion de modelos teoricos fundados en sistemas de calculo aplicables tanto en mecanica como en electromagnetismo y radioactividad, etc., asi como en astronomia fue impresionante. las geometrias no euclidianas encuentran aplicacion en modelos teoricos de astronomia y fisica. el mundo deja de ser un conjunto de infinitas particulas que se mueven en un espacio-tiempo absoluto y se convierte en un espacio de configuracion o espacio de fases de n dimensiones que fisicamente se hacen consistentes en la teoria de la relatividad, la mecanica cuantica, la teoria de cuerdas, etc., que cambia por completo la imagen del mundo fisico.  la logica asimismo sufrio una transformacion radical.​ la formalizacion simbolica fue capaz de integrar las leyes logicas en un calculo matematico, hasta el punto que la distincion entre razonamiento logico-formal y calculo matematico viene a considerarse como meramente utilitaria.  en la segunda mitad del siglo xix y primer tercio del xx, a partir del intento de formalizacion de todo el sistema matematico, frege, y de matematizacion de la logica, (bolzano, boole, whitehead, russell) fue posible la generalizacion del concepto como calculo logico. se lograron metodos muy potentes de calculo, sobre todo a partir de la posibilidad de tratar como «objeto» conjuntos de infinitos elementos, dando lugar a los numeros transfinitos de cantor.  mediante el calculo la logica encuentra nuevos desarrollos como logicas modales y logicas polivalentes.  los intentos de axiomatizar el calculo como calculo perfecto por parte de hilbert y poincare, llevaron, como consecuencia de diversas paradojas (cantor, russell, etc.) a nuevos intentos de axiomatizacion, axiomas de zermelo-fraenkel y a la demostracion de godel de la imposibilidad de un sistema de calculo perfecto: consistente, decidible y completo en 1931, de grandes implicaciones logicas, matematicas y cientificas.  en la actualidad, el calculo en su sentido mas general, en tanto que calculo logico interpretado matematicamente como sistema binario, y fisicamente hecho material mediante la logica de circuitos electronicos, ha adquirido una dimension y desarrollo impresionante por la potencia de calculo conseguida por los ordenadores, propiamente maquinas computadoras. la capacidad y velocidad de calculo de estas maquinas hace lo que humanamente seria imposible: millones de operaciones por segundo.  el calculo asi utilizado se convierte en un instrumento fundamental de la investigacion cientifica por las posibilidades que ofrece para la modelizacion de las teorias cientificas, adquiriendo especial relevancia en ello el calculo numerico.  el calculo infinitesimal, llamado por brevedad «calculo», tiene su origen en la antigua geometria griega. democrito calculo el volumen de piramides y conos considerandolos formados por un numero infinito de secciones de grosor infinitesimal (infinitamente pequeño). eudoxo y arquimedes utilizaron el «metodo de agotamiento» o exhaucion para encontrar el area de un circulo con la exactitud finita requerida mediante el uso de poligonos regulares inscritos de cada vez mayor numero de lados. en el periodo tardio de grecia, el neoplatonico pappus de alejandria hizo contribuciones sobresalientes en este ambito. sin embargo, las dificultades para trabajar con numeros irracionales y las paradojas de zenon de elea impidieron formular una teoria sistematica del calculo en el periodo antiguo.  en el siglo xvii, cavalieri y torricelli ampliaron el uso de los infinitesimales, descartes y fermat utilizaron el algebra para encontrar el area y las tangentes (integracion y derivacion en terminos modernos). fermat e isaac barrow tenian la certeza de que ambos calculos estaban relacionados, aunque fueron newton (hacia 1660), en inglaterra y leibniz en alemania (hacia 1670) quienes demostraron que los problemas del area y la tangente son inversos, lo que se conoce como teorema fundamental del calculo. leibniz es el creador del simbolismo de la derivada, diferencial y la ∫ estilizada para la integracion, en vez de la i de bernoulli. uso el nombre de calculo diferencial y el nombre de calculo integral propuso juan bernoulli, que sustituyo al nombre de 'calculo sumatorio' de leibniz. la simbologia de leibniz impulso el avance del calculo en europa continental.​  el descubrimiento de newton, a partir de su teoria de la gravitacion universal, fue anterior al de leibniz, pero el retraso en su publicacion aun provoca controversias sobre quien de los dos fue el primero. newton utilizo el calculo en mecanica en el marco de su tratado «principios matematicos de filosofia natural», obra cientifica por excelencia, llamando a su metodo de «fluxiones». leibniz utilizo el calculo en el problema de la tangente a una curva en un punto, como limite de aproximaciones sucesivas, dando un caracter mas filosofico a su discurso. sin embargo, termino por adoptarse la notacion de leibniz por su versatilidad.  en el siglo xviii aumento considerablemente el numero de aplicaciones del calculo, pero el uso impreciso de las cantidades infinitas e infinitesimales, asi como la intuicion geometrica, causaban todavia confusion y duda sobre sus fundamentos. de hecho, la nocion de limite, central en el estudio del calculo, era aun vaga e imprecisa en ese entonces. uno de sus criticos mas notables fue el filosofo george berkeley.  en el siglo xix el trabajo de los analistas matematicos sustituyeron esas vaguedades por fundamentos solidos basados en cantidades finitas: bolzano y cauchy definieron con precision los conceptos de limite en terminos de epsilon-delta y de derivada, cauchy y riemann hicieron lo propio con las integrales, y dedekind y weierstrass con los numeros reales. fue el periodo de la fundamentacion del calculo. por ejemplo, se supo que las funciones diferenciables son continuas y que las funciones continuas son integrables, aunque los reciprocos son falsos. en el siglo xx, el analisis no convencional, legitimo el uso de los infinitesimales, al mismo tiempo que la aparicion de las computadoras ha incrementado las aplicaciones y velocidad del calculo.  actualmente, el calculo infinitesimal tiene un doble aspecto: por un lado, se ha consolidado su caracter disciplinario en la formacion de la sociedad culta del conocimiento, destacando en este ambito textos propios de la disciplina como el de louis leithold, el de earl w. swokowski o el de james stewart entre muchos otros; por otro su desarrollo como disciplina cientifica que ha desembocado en ambitos tan especializados como el calculo fraccional, la teoria de funciones analiticas de variable compleja o el analisis matematico. el exito del calculo ha sido extendido con el tiempo a las ecuaciones diferenciales, al calculo de vectores, al calculo de variaciones, al analisis complejo y a las topologia algebraica y topologia diferencial entre muchas otras ramas.  el desarrollo y uso del calculo ha tenido efectos muy importantes en casi todas las areas de la vida moderna: es fundamento para el calculo numerico aplicado en casi todos los campos tecnicos y/o cientificos cuya principal caracteristica es la continuidad de sus elementos, en especial en la fisica. practicamente todos los desarrollos tecnicos modernos como la construccion, aviacion, transporte, meteorologia, etc., hacen uso del calculo. muchas formulas algebraicas se usan hoy en dia en balistica, calefaccion, refrigeracion, etc.  como complemento del calculo, en relacion con sistemas teoricos o fisicos cuyos elementos carecen de continuidad, se ha desarrollado una rama especial conocida como matematica discreta.    el calculo logico es un sistema de reglas de inferencia o deduccion de un enunciado a partir de otro u otros. el calculo logico requiere un conjunto consistente de axiomas y unas reglas de inferencia; su proposito es poder deducir algoritmicamente proposiciones logicas verdaderas a partir de dichos axiomas. la inferencia es una operacion logica que consiste en obtener una proposicion logica como conclusion a partir de otra(s) (premisas) mediante la aplicacion de reglas de inferencia.​  informalmente interpretamos que alguien infiere —o deduce— t de r si acepta que si r tiene valor de verdad v, entonces, necesariamente, t tiene valor de verdad v. sin embargo, en el enfoque moderno del calculo logico no es necesario acudir al concepto de verdad, para construir el calculo logico.  los hombres en nuestra tarea diaria, utilizamos constantemente el razonamiento deductivo. partimos de enunciados empiricos —supuestamente verdaderos y validos— para concluir en otro enunciado que se deriva de aquellos, segun las leyes de la logica natural.​  la logica, como ciencia formal, se ocupa de analizar y sistematizar dichas leyes, fundamentarlas y convertirlas en las reglas que permiten la transformacion de unos enunciados —premisas- en otros -conclusiones— con objeto de convertir las operaciones en un algoritmo riguroso y eficaz, que garantiza que dada la verdad de las premisas, la conclusion es necesariamente verdadera.  al aplicar las reglas de un calculo logico a los enunciados de un argumento mediante la simbolizacion adecuada como formulas o expresiones bien formadas (ebf) del calculo, construimos un modelo o sistema deductivo. en ese contexto, las reglas de formacion de formulas definen la sintaxis de un lenguaje formal de simbolos no interpretados, es decir, sin significado alguno; y las reglas de transformacion del sistema permiten transformar dichas expresiones en otras equivalentes; entendiendo por equivalentes que ambas tienen siempre y de forma necesaria el mismo valor de verdad. dichas transformaciones son meramente tautologias.  un lenguaje formal que sirve de base para el calculo logico esta formado por varias clases de entidades:  cuando en un calculo asi definido se establecen algunas expresiones determinadas como verdades primitivas o axiomas, decimos que es un sistema formal axiomatico. un calculo asi definido si cumple al mismo tiempo estas tres condiciones decimos que es un calculo perfecto:  la misma logica-matematica ha demostrado que tal sistema de calculo perfecto «no es posible» (vease el teorema de godel).  i. una letra enunciativa (con o sin subindice) es una ebf.  ii. si a es una ebf,  ¬ a tambien lo es.  iii. si a es una ebf y b tambien, entonces  a ∧ b;   a ∨ b;    a → b;    a ↔ b,    tambien lo son.  iv. ninguna expresion es una formula del calculo sino en virtud de i, ii, iii.  1) regla de sustitucion (r.t.1):  dada una tesis ebf del calculo, en la que aparecen variables de enunciados, el resultado de sustituir una, algunas o todas esas variables por expresiones bien formadas (ebf) del calculo, sera tambien una tesis ebf del calculo. y ello con una unica restriccion, si bien muy importante: cada variable ha de ser sustituida siempre que aparece y siempre por el mismo sustituto.  veamos el ejemplo:   o viceversa   2) regla de separacion (r.t.2):  si x es una tesis ebf del sistema y lo es tambien x → y, entonces y es una tesis ebf del sistema.  sobre la base de estas dos reglas, siempre podremos reducir un argumento cualquiera a la forma:  [a ∧ b ∧ c … ∧ n] → y  lo que constituye un esquema de inferencia en el que una vez conocida la verdad de cada una de las premisas a, b, … n y, por tanto, de su producto, podemos obtener la conclusion y con valor de verdad v, siempre y cuando dicho esquema de inferencia sea una ley logica, es decir su tabla de verdad nos muestre que es una tautologia.  por la regla de separacion podremos concluir y, de forma independiente como verdad.  dada la poca operatividad de las tablas de verdad, el calculo se construye como una cadena deductiva aplicando a las premisas o a los teoremas deducidos las leyes logicas utilizadas como reglas de transformacion, como se expone en calculo logico.  naturalmente el calculo logico es util porque puede tener aplicaciones, pero ¿en que consisten o como se hacen tales aplicaciones?  podemos considerar que el lenguaje natural es un modelo de c si podemos someterlo, es decir, aplicarle una correspondencia en c.​  para ello es necesario someter al lenguaje natural a un proceso de formalizacion de tal forma que podamos reducir las expresiones linguisticas del lenguaje natural a ebf de un calculo mediante reglas estrictas manteniendo el sentido de verdad logica de dichas expresiones del lenguaje natural. esto es lo que se expone en calculo logico.  las diversas formas en que tratemos las expresiones linguisticas formalizadas como proposiciones logicas dan lugar a sistemas diversos de formalizacion y calculo:   la simbolizacion y formacion de ebfs en cada uno de esos calculos, asi como las reglas de calculo se trata en calculo logico.   ",
        "snippet": "En general el término cálculo (del latín calculus, piedrecita, usado para contar o como ayuda al calcular)[1]​ hace referencia al resultado correspondiente a la acción de calcular. Calcular, por su parte, consiste en realizar las operaciones necesarias para prever el resultado de una acción previamente concebida, o conocer las consecuencias que se pueden derivar de unos datos previamente conocidos.",
        "enlaces_salientes": [
            "/wiki/C%C3%A1lculo",
            "/wiki/C%C3%A1lculo",
            "/wiki/C%C3%A1lculo",
            "/wiki/C%C3%A1lculo_(desambiguaci%C3%B3n)",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/An%C3%A1lisis_matem%C3%A1tico",
            "/wiki/Lat%C3%ADn",
            "/wiki/Algoritmo",
            "/wiki/Lenguaje_formalizado",
            "/wiki/S%C3%ADmbolo",
            "/wiki/Razonamiento",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Argumento",
            "/wiki/Algoritmo",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Inferencia",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Modelo_cient%C3%ADfico",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/An%C3%A1lisis_matem%C3%A1tico",
            "/wiki/C%C3%A1lculo_diferencial",
            "/wiki/Historia_del_c%C3%A1lculo",
            "/wiki/%C3%81baco",
            "/wiki/Lat%C3%ADn",
            "/wiki/%C3%81baco",
            "/wiki/Suanpan",
            "/wiki/Eudoxo_de_Cnido",
            "/wiki/Diofanto",
            "/wiki/%C3%81lgebra",
            "/wiki/Arqu%C3%ADmedes",
            "/wiki/Matem%C3%A1tico",
            "/wiki/M%C3%A9todo_exhaustivo",
            "/wiki/%C3%81rea",
            "/wiki/Par%C3%A1bola_(matem%C3%A1tica)",
            "/wiki/Serie_matem%C3%A1tica",
            "/wiki/N%C3%BAmero_Pi",
            "/wiki/Espiral_de_Arqu%C3%ADmedes",
            "/wiki/Volumen",
            "/wiki/Superficie_de_revoluci%C3%B3n",
            "/wiki/Lenguaje_formal",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Categ%C3%B3rico",
            "/wiki/Silogismo",
            "/wiki/Estoicismo",
            "/wiki/Megara",
            "/wiki/Escol%C3%A1stica",
            "/wiki/Algoritmo",
            "/wiki/C%C3%A1lculo_aritm%C3%A9tico",
            "/wiki/Al-Juarismi",
            "/wiki/Fibonacci",
            "/wiki/N%C3%BAmeros_ar%C3%A1bigos",
            "/wiki/Sistema_decimal",
            "/wiki/Sistema_de_numeraci%C3%B3n_decimal",
            "/wiki/Universidad_de_Oxford",
            "/wiki/Raimundo_Lulio",
            "/wiki/Partida_doble",
            "/wiki/Luca_Pacioli",
            "/wiki/Luca_Pacioli",
            "/wiki/%C3%81lgebra",
            "/wiki/Sistema",
            "/wiki/S%C3%ADmbolo",
            "/wiki/Ecuaci%C3%B3n",
            "/wiki/Tartaglia",
            "/wiki/Simon_Stevin",
            "/wiki/Gerolamo_Cardano",
            "/wiki/Fran%C3%A7ois_Vi%C3%A8te",
            "/wiki/Leibniz",
            "/wiki/Descartes",
            "/wiki/Blaise_Pascal",
            "/wiki/Leibniz",
            "/wiki/Isaac_Newton",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Ecuaci%C3%B3n",
            "/wiki/F%C3%ADsica",
            "/wiki/Revoluci%C3%B3n_cient%C3%ADfica",
            "/wiki/Filosof%C3%ADa_natural",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Experimento",
            "/wiki/Verificaci%C3%B3n",
            "/wiki/Sistema",
            "/wiki/M%C3%A9todo_cient%C3%ADfico",
            "/wiki/George_Boole",
            "/wiki/Geometr%C3%ADa_no_euclidiana",
            "/wiki/Espacio_de_configuraci%C3%B3n",
            "/wiki/Espacio_de_fases",
            "/wiki/Teor%C3%ADa_de_la_relatividad",
            "/wiki/Mec%C3%A1nica_cu%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_cuerdas",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Frege",
            "/wiki/Bernard_Bolzano",
            "/wiki/Boole",
            "/wiki/Whitehead",
            "/wiki/Bertrand_Russell",
            "/wiki/Georg_Cantor",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/L%C3%B3gica_polivalente",
            "/wiki/Axioma",
            "/wiki/Hilbert",
            "/wiki/Poincar%C3%A9",
            "/wiki/Paradoja",
            "/wiki/Axiomas_de_Zermelo-Fraenkel",
            "/wiki/Teorema_de_G%C3%B6del",
            "/wiki/Consistencia_(l%C3%B3gica)",
            "/wiki/Decidibilidad",
            "/wiki/Completitud_sem%C3%A1ntica",
            "/wiki/Puerta_l%C3%B3gica",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Segundo",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Modelo_cient%C3%ADfico",
            "/wiki/C%C3%A1lculo_num%C3%A9rico",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Dem%C3%B3crito",
            "/wiki/Pir%C3%A1mide_(geometr%C3%ADa)",
            "/wiki/Cono_(geometr%C3%ADa)",
            "/wiki/Infinito",
            "/wiki/Infinitesimal",
            "/wiki/Eudoxo",
            "/wiki/Arqu%C3%ADmedes",
            "/wiki/M%C3%A9todo_de_agotamiento",
            "/wiki/C%C3%ADrculo",
            "/wiki/Pol%C3%ADgono",
            "/wiki/Pappus_de_Alejandr%C3%ADa",
            "/wiki/N%C3%BAmeros_Irracionales",
            "/wiki/Paradoja",
            "/wiki/Zen%C3%B3n_de_Elea",
            "/wiki/Cavalieri",
            "/wiki/Torricelli",
            "/wiki/Descartes",
            "/wiki/Fermat",
            "/wiki/%C3%81lgebra",
            "/wiki/%C3%81rea",
            "/wiki/Tangente_(geometr%C3%ADa)",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Derivaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Fermat",
            "/wiki/Isaac_Barrow",
            "/wiki/Isaac_Newton",
            "/wiki/1660",
            "/wiki/Leibniz",
            "/wiki/1670",
            "/wiki/Teorema_fundamental_del_c%C3%A1lculo",
            "/wiki/Isaac_Newton",
            "/wiki/Teor%C3%ADa_de_la_gravitaci%C3%B3n_universal",
            "/wiki/Notaci%C3%B3n_de_Leibniz",
            "/wiki/George_Berkeley",
            "/wiki/Bernard_Bolzano",
            "/wiki/Cauchy",
            "/wiki/L%C3%ADmite_de_una_funci%C3%B3n",
            "/wiki/Funci%C3%B3n_derivada",
            "/wiki/Cauchy",
            "/wiki/Riemann",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Julius_Wilhelm_Richard_Dedekind",
            "/wiki/Weierstrass",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Funci%C3%B3n_continua",
            "/wiki/Infinitesimal",
            "/wiki/Computadoras",
            "/wiki/Ecuaci%C3%B3n_diferencial",
            "/wiki/Espacio_vectorial",
            "/wiki/C%C3%A1lculo_de_variaciones",
            "/wiki/An%C3%A1lisis_complejo",
            "/wiki/Topolog%C3%ADa_algebraica",
            "/wiki/Topolog%C3%ADa_diferencial",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Inferencia",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Consistencia_l%C3%B3gica",
            "/wiki/Axiomas",
            "/wiki/Reglas_de_inferencia",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Inferencia",
            "/wiki/Proposici%C3%B3n_l%C3%B3gica",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Premisas",
            "/wiki/Regla_de_inferencia",
            "/wiki/Necesario",
            "/wiki/Verdad",
            "/wiki/Validez_(epistemolog%C3%ADa)",
            "/wiki/Ciencia_formal",
            "/wiki/Necesario",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Enunciado",
            "/wiki/Argumento",
            "/wiki/Sintaxis",
            "/wiki/Lenguaje_formal",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/Lenguaje_formal",
            "/wiki/Axiomas",
            "/wiki/Teoremas",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Teorema_de_G%C3%B6del",
            "/wiki/Metalenguaje",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Inferencia",
            "/wiki/Tabla_de_verdad",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/Tablas_de_verdad",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Lenguaje_formalizado",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Propiedad_(l%C3%B3gica)",
            "/wiki/Clase_natural",
            "/wiki/Conjunto",
            "/wiki/Individuo",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/C%C3%A1lculo_l%C3%B3gico",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Lenguaje_formal",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/Sistema_formal",
            "/wiki/Silogismo",
            "/wiki/C%C3%A1lculo_de_la_ra%C3%ADz_cuadrada",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/Puerta_l%C3%B3gica",
            "/wiki/Tabla_de_valores_de_verdad",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Historia_del_hardware_de_computador",
            "/wiki/Regla_de_c%C3%A1lculo",
            "/wiki/Sistema_de_numeraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Matem%C3%A1tica_egipcia",
            "/wiki/Numeraci%C3%B3n_egipcia",
            "/wiki/Numeraci%C3%B3n_griega",
            "/wiki/Numeraci%C3%B3n_romana",
            "/wiki/Acarreo",
            "/wiki/Potenciaci%C3%B3n",
            "/wiki/Radicaci%C3%B3n",
            "/wiki/Logaritmaci%C3%B3n",
            "/wiki/%C3%81lgebra",
            "/wiki/%C3%81lgebra_elemental",
            "/wiki/Modelo_cient%C3%ADfico",
            "/wiki/Lat%C3%ADn",
            "/wiki/ISBN",
            "/wiki/Algoritmo",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/L%C3%B3gica_emp%C3%ADrica",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/Tartaglia",
            "/wiki/M%C3%A9todo_cient%C3%ADfico",
            "/wiki/C%C3%B3nicas",
            "/wiki/Principio_de_Pascal",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/L%C3%B3gica_emp%C3%ADrica",
            "/wiki/Masa",
            "/wiki/Gravitaci%C3%B3n_Universal",
            "/wiki/Arist%C3%B3teles",
            "/wiki/A_priori",
            "/wiki/Lenguaje_formal",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Problema_abstracto",
        "titulo": "Problema computacional",
        "contenido": "en ciencia computacional teorica, un problema computacional o problema abstracto es una relacion entre un conjunto de instancias y un conjunto de soluciones. un problema abstracto permite establecer formalmente la relacion deseada entre cada instancia del problema y su correspondiente solucion. una solucion algoritmica a un problema abstracto consiste de un algoritmo que por cada instancia del problema calcula al menos una solucion correspondiente –en caso de haberla– o expide un certificado de que no existe solucion alguna. un problema abstracto se convierte en un problema concreto cuando las instancias y soluciones estan codificadas en forma de lenguajes formales.  los problemas abstractos suelen definirse en dos partes: en la primera se describe al conjunto de instancias y en la segunda se describe la solucion esperada para cada instancia. por ejemplo, el problema de ordenacion de numeros enteros se suele definir como sigue:  aqui tanto el conjunto de instancias y el de soluciones es el mismo, pues se trata del conjunto de todas las sucesiones finitas de numeros enteros. la relacion que hay entre ellos asigna a cada sucesion ( a 1 , a 2 , … , a n ) ,a_{2},\\ldots ,a_{n}\\right)} la unica permutacion ( a 1 ′ , a 2 ′ , … , a n ′ ) ^,a_{2}^,\\ldots ,a_{n}^\\right)} tal que a 1 ′ ≤ a 2 ′ ≤ ⋯ ≤ a n ′ ^\\leq a_{2}^\\leq \\cdots \\leq a_{n}^} . por ejemplo, ( 6 , 9 , 4 , 5 ) tiene como solucion a ( 4 , 5 , 6 , 9 ) . una solucion algoritmica al problema de ordenamiento es el ordenamiento de burbuja porque este algoritmo produce una solucion como salida cada vez que se le suministra una instancia como entrada.   en un problema de decision cada instancia tiene asociada exactamente una solucion \"si\" o \"no\". los problemas de decision quedan completamente determinados por el conjunto y de instancias que tienen asociada la solucion \"si\". por ejemplo, el problema de decidir si una grafica tiene o no un ciclo hamiltoniano queda completamente determinado su conjunto de soluciones \"si\":  h a m = { g ∣ g es una grafica hamiltoniana } =\\left\\{g\\mid g}\\right\\}}  con esta representacion el problema equivale a preguntar si una instancia i pertenece o no al conjunto h a m } . en general, los problemas de decision siempre equivalen a decidir la proposicion i ∈ y donde y es el conjunto de instancias con solucion \"si\". una solucion algoritmica para un problema de decision es un algoritmo que calcula la funcion caracteristica de y o equivalente:   χ y ( i ) = { 1 si i ∈ y 0 si i ∈ y (i)=1&}i\\in y\\\\0&}i\\notin y\\end{cases}}}  en los problemas de busqueda la relacion entre el conjunto de instancias y el de soluciones queda determinado por un predicado logico p ( i , s ) que determina si s es una solucion de i . dada una instancia i el problema consiste en encontrar, si es que existe, una solucion s de i . es decir, buscar el elemento s que haga verdadera la proposicion ∃ s ∈ s . p ( i , s ) . cuando se fija el valor de i y la solucion es unica, se dice que es un problema matematico. por ejemplo, el problema de factorizacion de un numero entero n consiste en encontrar un factor no trivial de n ; es decir, numero entero m diferente de 1 y de n tal que m divida exactamente a n . en simbolos   ∃ m ∈ z . m = 1 ∧ m = n ∧ n m ∈ z .m\\neq 1\\wedge m\\neq n\\wedge {m}}\\in \\mathbf {z} }  esta formula simplemente esta preguntando la existencia de un factor no trivial de n . una solucion algoritmica a un problema de busqueda viene dador por un algoritmo f tal que p ( i , f ( i ) ) es verdadera siempre y cuando exista solucion para i , es decir, f siempre calcula una solucion si es que esta existe. en el caso del problema de la factorizacion de enteros se cuenta con el algoritmo de la division por tentativa.  en un problema de optimizacion no solo se busca una solucion, sino que se busca \"la mejor\" de todas. cada problema de optimizacion puede concebirse como un problema de busqueda y una funcion g , comunmente conocida como funcion objetivo, que determina la calidad de las soluciones. el problema de optimizacion (que a su vez es de busqueda) consiste en encontrar la solucion maximice o minimice el valor de g . por ejemplo, el problema del viajante no solamente exige determinar si una grafica tiene o no un ciclo hamiltoniano, sino que ademas pregunta cual es el ciclo hamiltoniano mas corto. en este caso el problema de busqueda subyacente es encontrar un ciclo hamiltoniano cualquiera y la funcion objetivo mide la distancia recorrida por ese ciclo.   ",
        "snippet": "En ciencia computacional teórica, un problema computacional o problema abstracto es una relación entre un conjunto de instancias y un conjunto de soluciones. Un problema abstracto permite establecer formalmente la relación deseada entre cada instancia del problema y su correspondiente solución. Una solución algorítmica a un problema abstracto consiste de un algoritmo que por cada instancia del problema calcula al menos una solución correspondiente –en caso de haberla– o expide un certificado de que no existe solución alguna. Un problema abstracto se convierte en un problema concreto cuando las instancias y soluciones están codificadas en forma de lenguajes formales.",
        "enlaces_salientes": [
            "/wiki/Problema_computacional",
            "/wiki/Problema_computacional",
            "/wiki/Problema_computacional",
            "/wiki/Ciencia_computacional_te%C3%B3rica",
            "/wiki/Relaci%C3%B3n_binaria",
            "/wiki/Lenguaje_formal",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/Problema_de_decisi%C3%B3n",
            "/wiki/Camino_hamiltoniano",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/Problema_matem%C3%A1tico",
            "/wiki/Factorizaci%C3%B3n",
            "/wiki/Divisibilidad",
            "/wiki/Divisi%C3%B3n_por_tentativa",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Problema_del_viajante",
            "/wiki/Thomas_H._Cormen",
            "/wiki/MIT_Press",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Criba_de_Erat%C3%B3stenes",
        "titulo": "Criba de Eratóstenes",
        "contenido": "la criba de eratostenes es un algoritmo que permite hallar todos los numeros primos menores que un numero natural dado. se forma una tabla con todos los numeros naturales comprendidos entre 2 y n, y se van tachando los numeros que no son primos de la siguiente manera: comenzando por el 2, se tachan todos sus multiplos; comenzando de nuevo, cuando se encuentra un numero entero que no ha sido tachado, ese numero es declarado primo, y se procede a tachar todos sus multiplos, asi sucesivamente. el proceso termina cuando el cuadrado del siguiente numero confirmado como primo es mayor que a.  determinemos, mediante el siguiente ejemplo, el proceso para determinar la lista de los numeros primos menores de 20.  como 3² = 9 < 20, se vuelve al segundo paso:  en el cuarto paso, el primer numero que no ha sido tachado ni marcado es 5. como su cuadrado es mayor que 20, el algoritmo termina y se consideran primos todos los numeros que no han sido tachados.  como resultado se obtienen los numeros primos comprendidos entre 2 y 20, y estos son: 2, 3, 5, 7, 11, 13, 17, 19.  un refinamiento de la criba consiste en tachar los multiplos del k-esimo numero primo pk, comenzando por pk2 pues en los anteriores pasos se habian tachado los multiplos de pk correspondientes a todos los anteriores numeros primos, esto es, 2pk, 3pk, 5pk,…, hasta (pk-1)pk. el algoritmo acabaria cuando p2k>n ya que no habria nada que tachar.​  otro refinamiento consiste en generar una lista solo con numeros impares (pues los numeros pares distintos de 2 se sabe que no son primos), e ir tachando los multiplos de los numeros primos mediante incrementos de 2p, es decir, los multiplos impares (2k+1)p de cada primo p. esto aparece en el algoritmo original.​  entrada: un numero natural n  salida: el conjunto de numeros primos anteriores a n (incluyendo n )  acerca de la notacion:  para su implementacion en una computadora, normalmente se maneja un vector de tipo logico con n elementos. de esta manera, la posicion i contiene el valor verdadero como representacion de que i ha sido marcado y falso en otro caso.  una forma especial de la criba de eratostenes aplicada se puede encontrar en la demostracion del producto de euler para la funcion zeta de riemann por parte de leonhard euler, y muestra una forma original de obtener dicho producto, utilizando una modificacion de dicha criba. la funcion zeta de riemann se representa como  multiplicando ambos miembros por 1 2 s {2^{s}}}} se obtiene una nueva serie, y restando esta nueva serie a la serie original miembro a miembro y termino a termino, se eliminan todos los terminos cuyas bases son multiplos de 2 — en la criba de eratostenes se tachan —.  repitiendo el mismo proceso sobre el siguiente termino, 1 3 s {3^{s}}}} , se eliminan todos los terminos cuyas bases son multiplos de 3:  puede comprobarse que la parte de la derecha se esta cribando, de manera que repitiendo este proceso indefinidamente:  se obtiene un producto sobre todos los numeros primos p, que puede escribirse de forma simplificada como:   ",
        "snippet": "La criba de Eratóstenes es un algoritmo que permite hallar todos los números primos menores que un número natural dado. Se forma una tabla con todos los números naturales comprendidos entre 2 y n, y se van tachando los números que no son primos de la siguiente manera: Comenzando por el 2, se tachan todos sus múltiplos; comenzando de nuevo, cuando se encuentra un número entero que no ha sido tachado, ese número es declarado primo, y se procede a tachar todos sus múltiplos, así sucesivamente. El proceso termina cuando el cuadrado del siguiente número confirmado como primo es mayor que a.",
        "enlaces_salientes": [
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Teor%C3%ADa_de_cribas",
            "/wiki/Erat%C3%B3stenes",
            "/wiki/Algoritmo",
            "/wiki/N%C3%BAmeros_primos",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Cuadrado_(%C3%A1lgebra)",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Funci%C3%B3n_parte_entera",
            "/wiki/Cociente_(aritm%C3%A9tica)",
            "/wiki/Vector_(programaci%C3%B3n)",
            "/wiki/Tipo_de_dato_l%C3%B3gico",
            "/wiki/Producto_de_Euler_para_la_funci%C3%B3n_zeta_de_Riemann",
            "/wiki/Leonhard_Euler",
            "/wiki/Funci%C3%B3n_zeta_de_Riemann",
            "/wiki/Miembro_de_una_ecuaci%C3%B3n",
            "/wiki/Serie_matem%C3%A1tica",
            "/wiki/Producto_de_Euler",
            "/wiki/Test_de_primalidad",
            "/wiki/Control_de_autoridades",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Alonzo_Church",
        "titulo": "Alonzo Church",
        "contenido": "alonzo church (14 de junio de 1903 - 11 de agosto de 1995), matematico y logico estadounidense creador de la base de la computacion teorica. nacido en la ciudad de washington, se diplomo en 1924 y obtuvo su doctorado en 1927 en la universidad de princeton, donde ejercio como profesor entre 1929 y 1967.  su obra mas conocida es el desarrollo del calculo lambda, y su trabajo de 1936 que muestra la existencia de problemas indecidibles. este trabajo precedio el famoso trabajo de su alumno alan turing sobre el problema de parada que tambien demostro la existencia de problemas irresolubles por dispositivos mecanicos. luego de revisar la tesis doctoral de turing, demostraron que el calculo lambda y la maquina de turing utilizada para expresar el problema de parada tenian igual poder de expresion; posteriormente demostraron que una variedad de procesos mecanicos alternos para realizar calculos tenian poder de computo equivalente. como resultado se postulo la tesis de church-turing.​  entre los mas conocidos estudiantes de doctorado de church estan stephen kleene, j. barkley rosser, leon henkin, john george kemeny, michael o. rabin, dana scott, simon kochen y raymond smullyan.  church publico entre 1924 y 1995 trabajos sobre logica, filosofia, matematicas y computacion. en su trabajo de 1936 an unsolvable problem of elementary number theory church formulo por primera vez lo que ahora se conoce como la tesis de church que es la identificacion del concepto vago de calculabilidad efectiva con la nocion precisa de funcion recursiva. su articulo a note on the entscheidungsproblem presento lo que ahora se conoce como el teorema de church: la indecidibilidad de la validez de la logica de primer orden. en 1941 publico su monografia the calculi of lambda-conversion. este trabajo tiene gran influencia en el area de computacion teorica.​  el calculo lambda influyo en el diseño del lenguaje lisp, asi como en los lenguajes de programacion funcional. ",
        "snippet": "Alonzo Church (14 de junio de 1903 - 11 de agosto de 1995), matemático y lógico estadounidense creador de la base de la computación teórica. Nacido en la ciudad de Washington, se diplomó en 1924 y obtuvo su doctorado en 1927 en la Universidad de Princeton, donde ejerció como profesor entre 1929 y 1967.",
        "enlaces_salientes": [
            "/wiki/Alonzo_Church",
            "/wiki/Alonzo_Church",
            "/wiki/Alonzo_Church",
            "/wiki/14_de_junio",
            "/wiki/1903",
            "/wiki/Washington,_D._C.",
            "/wiki/EE._UU.",
            "/wiki/11_de_agosto",
            "/wiki/1995",
            "/wiki/EEUU",
            "/wiki/Presbiterianismo",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Oswald_Veblen",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Universidad_de_Princeton",
            "/wiki/UCLA",
            "/wiki/Martin_Davis",
            "/wiki/Leon_Henkin",
            "/wiki/David_Kaplan",
            "/wiki/John_George_Kemeny",
            "/wiki/Stephen_Kleene",
            "/wiki/Michael_O._Rabin",
            "/wiki/Dana_Scott",
            "/wiki/Raymond_Smullyan",
            "/wiki/Alan_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Asociaci%C3%B3n_Estadounidense_para_el_Avance_de_la_Ciencia",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/14_de_junio",
            "/wiki/1903",
            "/wiki/11_de_agosto",
            "/wiki/1995",
            "/wiki/L%C3%B3gico",
            "/wiki/Estadounidense",
            "/wiki/Computaci%C3%B3n_te%C3%B3rica",
            "/wiki/Washington_D.C.",
            "/wiki/1924",
            "/wiki/1927",
            "/wiki/Universidad_de_Princeton",
            "/wiki/1929",
            "/wiki/1967",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/1936",
            "/wiki/Problema_indecidible",
            "/wiki/Alan_Turing",
            "/wiki/Problema_de_parada",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Stephen_Kleene",
            "/wiki/Leon_Henkin",
            "/wiki/John_George_Kemeny",
            "/wiki/Michael_O._Rabin",
            "/wiki/Dana_Scott",
            "/wiki/Raymond_Smullyan",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Entscheidungsproblem",
            "/wiki/Computaci%C3%B3n_te%C3%B3rica",
            "/wiki/Lisp",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/L%C3%B3gica_combinatoria",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Find_a_Grave",
            "/wiki/The_New_York_Times",
            "/wiki/The_Independent",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Pers%C3%A9e_(portal)"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/C%C3%A1lculo_lambda",
        "titulo": "Cálculo lambda",
        "contenido": "en logica matematica, el calculo lambda es un sistema formal diseñado para investigar la definicion de funcion, la nocion de aplicacion de funciones y la recursion. fue introducido por alonzo church y stephen kleene en la decada de 1930 como parte de sus investigaciones sobre los fundamentos de las matematicas. church uso el calculo lambda en 1936 para resolver el entscheidungsproblem. puede ser usado para definir de manera limpia y precisa que es una \"funcion computable\".  el interrogante de si dos expresiones del calculo lambda son equivalentes no puede ser resuelto por un algoritmo general. esta fue la primera pregunta, incluso antes que el problema de la parada, cuya indecidibilidad fue probada. el calculo lambda tiene una gran influencia sobre los lenguajes funcionales, como lisp, ml y haskell.  se puede considerar al calculo lambda como uno de los lenguajes universales de programacion mas minimalistas. consiste en una regla de transformacion simple (sustitucion de variables) y un esquema simple para definir funciones.  el calculo lambda es universal porque cualquier funcion computable puede ser expresada y evaluada a traves de el. por lo tanto, es equivalente a las maquinas de turing. sin embargo, el calculo lambda no hace enfasis en el uso de reglas de transformacion y no considera las maquinas reales que pueden implementarlo. se trata de una propuesta mas cercana al software que al hardware.  este articulo se enfocara sobre el calculo lambda sin tipos, como fue diseñado originalmente por church.​ desde entonces, algunos calculo lambda tipados fueron creados.  originalmente, church habia tratado de construir un sistema formal completo para modelizar la matematica;​ pero en 1934 kleene y rosser publicaron una implementacion de la paradoja de richard.​ desde ese punto, el calculo lambda fue usado para estudiar la computabilidad, culminando en la respuesta negativa al problema de la parada. en 1940, church introdujo el calculo lambda simplemente tipado que es computacionalmente menos poderoso, pero logicamente consistente.​  considerese las siguientes dos funciones. por un lado, la funcion identidad i(x) = x, que toma un unico argumento, x, e inmediatamente devuelve x. por otro lado, la funcion suma s(x,y) = x + y, que toma dos argumentos, x e y, y devuelve la suma de ambos: x + y. usando estas dos funciones como ejemplo, es posible hacer algunas observaciones utiles acerca de varias ideas fundamentales del calculo lambda.  la primera observacion es que las funciones no necesitan ser explicitamente nombradas. esto es, la funcion s(x,y) = x + y puede ser reescrita como una funcion anonima: x,y → x + y (que se lee: «el par de x e y se mapea a x + y»). del mismo modo, i(x) = x puede ser reescrita de forma anonima como x → x, que se lee: «el argumento x se mapea a si mismo».  la segunda observacion es que el nombre que se asigne a los argumentos de la funcion es generalmente irrelevante. esto es, x → x e y → y expresan la misma funcion: la funcion identidad. del mismo modo, x,y → x + y y u,v → u + v expresan la misma funcion: la funcion suma.  una tercera observacion es que toda funcion que requiere dos argumentos, como por ejemplo la funcion suma, puede ser reescrita como una funcion que acepta un unico argumento, pero que devuelve otra funcion, la cual a su vez acepta un unico argumento. por ejemplo, x,y → x + y puede ser reescrita como x → (y → x + y). esta transformacion se conoce como currificacion, y puede generalizarse para funciones que aceptan cualquier numero de argumentos. esto puede parecer dificil de entender, pero se entiende mejor mediante un ejemplo. considerese la funcion suma no currificada:  al tomar a los numeros 2 y 3 como argumentos, se obtiene:  lo cual es igual a 5. considerese ahora la version currificada de la funcion:  si se toma al numero 2 como argumento, se obtiene la funcion:  y tomando luego al numero 3 como argumento, se obtiene:  lo cual es igual a 5. de modo que la version currificada devuelve el mismo resultado que la version no currificada. en el calculo lambda, todas las expresiones representan funciones anonimas de un solo argumento.  una cuarta observacion es que una funcion puede aceptar como argumento a otra funcion, siempre y cuando esta otra funcion tenga ella misma un solo argumento. por ejemplo, la funcion identidad puede aceptar como argumento a la funcion suma (currificada). es decir, se toma a la funcion x → (y → x + y) y se la pone como argumento en z → z. el resultado sera obviamente x → (z → x + z), (igual a la x → (y → x + y)) pues la funcion identidad siempre devuelve lo mismo que se le da.  en el calculo lambda, las funciones estan definidas por expresiones lambda, que dicen que se hace con su argumento. por ejemplo, la funcion \"sumar 2\",  f(x) = x + 2  se expresa en calculo lambda asi:  λ x. x + 2  (o, equivalentemente,  λ y. y + 2 ya que el nombre de su argumento no es importante). y el numero f(3) seria escrito como  (λ x. x + 2) 3. la aplicacion de funciones es asociativa a izquierda:  f x y = (f x) y. considerando la funcion que aplica una funcion al numero 3: λ f. f 3. , podemos pasarle \"sumar 2\", quedando asi:  (λ f. f 3) (λ x. x + 2).  las tres expresiones:  son equivalentes.  no todas las expresiones lambda pueden ser reducidas a un \"valor\" definido. considerese la siguiente:  o  tratar de reducir estas expresiones solo lleva a encontrarse con la misma expresion o algo mas complejo.  (λ x. x x)  es conocido como ω combinador; ((λ x. x x) (λ x. x x)) se conoce como ω, ((λ x. x x x) (λ x. x x x)) como ω2, etc.  en el calculo lambda, una expresion o termino se define recursivamente a traves de las siguientes reglas de formacion:  segun estas reglas de formacion, las siguientes cadenas de caracteres son terminos:  por convencion se suelen omitir los parentesis externos, ya que no cumplen ninguna funcion de desambiguacion. por ejemplo se escribe (λz.z)z en vez de ((λz.z)z), y se escribe x(y(zx)) en vez de (x(y(zx))). ademas se suele adoptar la convencion de que la aplicacion de funciones es asociativa hacia la izquierda. esto quiere decir, por ejemplo, que xyzz debe entenderse como (((xy)z)z), y que (λz.z)yzx debe entenderse como ((((λz.z)y)z)x).  las primeras dos reglas generan funciones, mientras que la ultima describe la aplicacion de una funcion a un argumento. una abstraccion lambda λx.t representa una funcion anonima que toma un unico argumento, y se dice que el signo λ liga la variable x en el termino t. en cambio, una aplicacion lambda ts representa la aplicacion de un argumento s a una funcion t. por ejemplo, λx.x representa la funcion identidad x → x, y (λx.x)y representa la funcion identidad aplicada a y. luego, λx.y representa la funcion constante x → y, que develve y sin importar que argumento se le de.  las expresiones lambda no son muy interesantes por si mismas. lo que las hace interesantes son las muchas nociones de equivalencia y reduccion que pueden ser definidas sobre ellas.  las apariciones (ocurrencias) de variables en una expresion son de tres tipos:  las variables de ligadura son aquellas que estan entre el λ y el punto. por ejemplo, siendo e una expresion lambda:   (λ x y z. e) las ligaduras son x,y y z.  la ligadura de ocurrencias de una variable esta definido recursivamente sobre la estructura de las expresiones lambda, de esta manera:  expresiones lambda tales como  λ x. (x y)  no definen funciones porque las ocurrencias de y estan libres. si la expresion no tiene variables libres, se dice que es cerrada.  como se permite la repeticion del identificador de variables, cada ligadura tiene una zona de alcance asociada. un ejemplo tipico es:  (λx.x(λx.x))x, donde el alcance de la ligadura mas a la derecha afecta solo a la x que tiene ahi, la situacion del otro binding es analoga, pero no incluye el scope de la primera. por ultimo la x mas a la derecha esta libre. por lo tanto, esa expresion puede reexpresarse asi  (λy.y(λz.z))x  la regla de alfa-conversion fue pensada para expresar la idea siguiente: los nombres de las variables ligadas no son importantes. por ejemplo  λx.x  y  λy.y  son la misma funcion. sin embargo, esta regla no es tan simple como parece a primera vista. hay algunas restricciones que hay que cumplir antes de cambiar el nombre de una variable por otra. por ejemplo, si reemplazamos x por y en λx.λy.x, obtenemos λy.λy.y, que claramente, no es la misma funcion. este fenomeno se conoce como captura de variables.  la regla de alfa-conversion establece que si v y w son variables, e es una expresion lambda, y  e[v:= w]  representa la expresion e con todas las ocurrencias libres de v en e reemplazadas con w, entonces  si w no esta libre en e y w no esta ligada a un λ donde se haya reemplazado a v. esta regla nos dice, por ejemplo, que  λ x. (λ x. x) x  es equivalente a  λ y. (λ x. x) y.  en un ejemplo de otro tipo, se ve que  for (int i = 0; i < max; i++) proc (i);  es equivalente a  for (int j = 0; j < max; j++) proc (j);  la regla de beta reduccion expresa la idea de la aplicacion funcional. enuncia que  si todas las ocurrencias de e′ estan libres en e[v:= e′].  una expresion de la forma ((λ v. e) e′) es llamada un beta redex. una lambda expresion que no admite ninguna beta reduccion se dice que esta en su forma normal. no toda expresion lambda tiene forma normal, pero si existe, es unica. mas aun, existe un algoritmo para computar la forma normal: la reduccion de orden normal. la ejecucion de este algoritmo termina si y solo si la expresion lambda tiene forma normal. el teorema de church-rosser nos dice que dos expresiones reducen a una misma si y solo si son equivalentes (salvo por el nombre de sus variables ligadas)  es la tercera regla, esta conversion, que podria ser añadida a las dos anteriores para formar una nueva relacion de equivalencia. la eta conversion expresa la idea de extensionalidad, que en este contexto implica que dos funciones son la misma si y solo si dan el mismo resultado para cualquier argumento. la eta conversion convierte entre  λ x. f x  y  f  siempre que x no aparezca sola en f. esto puede ser entendido como equivalente a la extensionalidad asi:  si f y g son extensionalmente equivalentes, es decir, si  f a== g a  para cualquier expresion lambda a entonces, en particular tomando a como una variable x que no aparece sola en f ni en g, tenemos que  f x  == g x  y por tanto  λ x. f x ==  λ x. g x,  y asi por eta conversion  f  == g.  entonces, si aceptamos la eta conversion como valida, resulta que la extensionalidad es valida.  inversamente, si aceptamos la extensionalidad como valida entonces, dado que por beta reduccion de todo y tenemos que  (λ x. f x) y ==  f y,  resulta que  λ x. f x   ==  f;  es decir, descubrimos que la eta conversion es valida.  hay varias formas posibles de definir los numeros naturales en el calculo lambda, pero el mas comun son los numeros de church, que pueden definirse como sigue:  y asi sucesivamente. instintivamente el numero n en el calculo lambda es una funcion que toma a otra funcion f como argumento y devuelve la n-esima composicion de f. asi que, un numero de church es una funcion de alto nivel -- toma una unica funcion f como parametro y otra funcion de parametro unico.  (vease que en el calculo original lambda de church era obligatorio que el parametro formal de la expresion lambda apareciera al menos una vez en el cuerpo de la funcion, lo que hace imposible definir el 0.) dada esta definicion de los numeros de church, se puede establecer una funcion de sucesion que dado un numero n devuelve n + 1:  la suma se define asi:  plus puede entenderse como una funcion que toma dos numeros naturales como parametros devolviendo otro; puede verificarse que  son expresiones lambda equivalentes. la multiplicacion se expresa como  la idea es que multiplicar m y n es lo mismo que sumar m veces a n. de otra manera:  la funcion predecesor  pred n = n - 1  de un entero positivo n es mas compleja:  o alternativamente  vease que el truco consiste en que (g 1) (λ u. plus (g k) 1) k que devuelve k si el valor de g(1) es cero o g(k) + 1 en cualquier otro caso.  para poder llegar a una definicion de booleanos en calculo lambda, se comienza con su especificacion: true, false y ifthenelse deben ser λ-expresiones en forma normal, tal que para todo par de λ-expresiones p y q  cualquier par de expresiones que cumplan esto sirve. la solucion mas simple resulta de fijar ifthenelse como λb.λx.λy. b x y, dejando que todo el trabajo de aplicar los booleanos recaiga sobre true y false, entonces:  quedando:  los booleanos (como era de esperarse) tambien son funciones. es facil ver que es posible cambiar la λ-expresion ifthenelse para que aplique los parametros en orden inverso, cambiando la forma de true y false. por eso, se adapta, por convencion, de esta manera (conocida como booleanos de church). notese que false es equivalente al numero de church cero.  luego, con estas dos definiciones podemos definir algunos operadores logicos:  ahora podemos reducir, por ejemplo:  y vemos que and true false es equivalente a false.  un predicado es una funcion que devuelve un valor booleano. el predicado mas simple es iszero el cual nos devuelve true si el numero de church argumento es 0 o false en otro caso.  por supuesto, esta definicion nos sirve solo para los numeros naturales definidos previamente.  un par (2-tupla) puede ser definido en terminos de true y false.  una estructura de datos del tipo lista enlazada puede ser definida, tanto como nil para la lista vacia, o como el cons de un elemento y de la lista mas pequeña en tal caso sea requerido.  recursion es la definicion de una funcion usando la funcion que se esta definiendo. el calculo lambda no permite esto. sin embargo, esta nocion es un poco confusa. considere por ejemplo la definicion de la funcion factorial f(n) definida recursivamente por:  en el calculo lambda, no es posible definir funciones que se incluyan a si mismas. para sortear esta dificultad, se comienza por definir una funcion, denominada aqui como g, que toma a una funcion f como argumento y devuelve otra funcion que toma n como argumento:  la funcion que devuelve g es o bien la constante 1, o n veces la aplicacion de la funcion f a n-1. usando el predicado iszero, y las definiciones booleanas y algebraicas anteriores, la funcion g puede ser definida en el calculo lambda.  sin embargo, g todavia no es recursiva en si misma; para usar g para crear la funcion factorial recursiva, la funcion pasada a g como f debe tener unas propiedades especificas. a saber, la funcion pasada como f debe expandirse a la funciong llamada con un argumento -- y que el argumento debe ser la funcion que ha sido pasado como f de nuevo.  en otras palabras, f debe expandir a g(f). esta llamada a g expandira a la siguiente a la funcion factorial y calculara otro nivel de recursion. en la expansion la funcion f aparecera nuevamente, y nuevamente expandira a g(f) y continuara la recursion. este tipo de funcion, donde f = g(f), es llamada un fixed-point de g, y resulta que puede ser implementado en el calculo lambda usando lo que es conocido como el paradoxical operator or fixed-point operator y es representado como y -- el y combinator:  en el calculo lambda, y g es un punto fijo de g, debido a que expande a g (y g). ahora, para completar nuestra llamada recursiva a la funcion factorial, simplemente llamaria  g (y g) n,  donde n es el numero del cual queremos calcular el factorial.  dado, por ejemplo n = 5, esta se expandira como:  y asi, se va evaluando la estructura del algoritmo de forma recursiva. cada funcion recursiva definida puede ser vista como un punto fijo de otra funcion adecuada, y por lo tanto, utilizando y, cada funcion recursiva definida puede expresarse como una expresion lambda. en particular, ahora podemos definir limpiamente la resta, la multiplicacion y la comparacion de predicado de los numeros naturales de forma recursiva.  una funcion f: n → n de numeros naturales es una funcion computable si y solo si existe una expresion lambda f tal que para todo par de x, y in n,  f(x) = y  si y solo si  f x == y,  donde x e y son numerales de church correspondientes a x e y, respectivamente. esta solo es una de tantas maneras de definir computabilidad; vease tesis de church-turing para una discusion, otras aproximaciones y sus equivalencias.  no hay un algoritmo que tome dos expresiones lambda arbitrarias y produzca true o false dependiendo de si las dos expresiones son o no equivalentes. este fue historicamente el primer problema para el cual la irresolubilidad pudo ser probada. por supuesto, de manera previa para hacer esto, la nocion de algoritmo tuvo que ser definida de forma clara; church la definio usando funciones recursivas, la cual se sabe que es equivalente a todas las otras definiciones razonables de esta nocion.  la primera prueba de church reduce el problema de determinar si una expresion lambda dada tiene una forma normal. una forma normal es una expresion equivalente irreductible. entonces se asume que este predicado es computable y que puede ser expresado de aqui en adelante en notacion de calculo lambda. basandose en un trabajo previo de kleene y construyendo una numeracion de godel para expresiones lambda, church construyo una expresion lambda e que seguia la prueba del teorema de incompletitud de godel. si e se aplica a su propio numero godel, se produce una contradiccion.  como lo menciona peter landin en su libro clasico correspondencia entre algol 60 y el calculo lambda de church, la mayoria de los lenguajes de programacion tienen sus raices en el calculo lambda, lo que provee los mecanismos basicos para las abstracciones de procedimiento y abstracciones de aplicaciones (subprogramas).  la implementacion del calculo lambda en una computadora involucra tratar a las \"funciones\" como objetos de primera clase, lo que aumenta la complejidad de su implementacion. un problema particularmente dificil es la implementacion de funciones de orden superior, conocido como el problema de funarg.  las contrapartes mas prominentes del calculo lambda en programacion son los lenguajes de programacion funcional, que esencialmente implementa el calculo aumentado con algunas constantes y tipos de dato.  los lenguajes funcionales no son los unicos que soportan las funciones como objetos de primera clase. muchos lenguajes de programacion imperativa, como pascal, hace tiempo que permiten pasar subprogramas como argumentos a otros subprogramas. en c y su derivado c++ el resultado equivalente se obtiene pasando punteros al codigo de las funciones (subprogramas). estos mecanismos estan limitados a subprogramas escritos explicitamente en el codigo, y no soportan directamente funciones de alto nivel. algunos lenguajes imperativos orientados a objetos, tiene notaciones que representan funciones de cualquier orden; tales mecanismos estan disponibles en c++, smalltalk y mas recientemente en (\"agentes\" de ) eiffel y (\"delegados\" de) c#. como ejemplo, la expresion de \"agente en linea\" de eiffel  denota un objeto correspondiente a la expresion lambda λ x. x*x (con llamada por valor). puede ser tratada como cualquier otra expresion, por ejemplo, asignarla a una variable o pasada a una rutina. si el valor de square es el de la expresion de agente anterior, entonces el resultado de aplicar square a un valor (una reduccion β) es expresada como square.item ([a]), donde el argumento es pasado como una tupla.  un ejemplo en python usa la forma lambda de funciones:  lo anterior crea una funcion anonima llamada func que puede ser pasada como parametros a otras funciones, ser almacenada en variables, etc. python tambien puede tratar cualquier otra funcion creada con la sentencia estandar def como un first-class object.  lo mismo se aplica a la siguiente expresion en smalltalk:  este es un objeto de primera clase (clausura de bloque), que puede ser guardado en variables, pasado como argumento, etc.  un ejemplo similar en c++ (usando la biblioteca boost.lambda):  aqui, la funcion de libreria estandar for_each itera sobre todos los miembros del vector (o lista) v, e imprime el cuadrado de cada elemento. la notacion _1 es la convencion boost de lambda para representar el elemento contenedor, representado como x en cualquier otro lado.  un delegado simple de c# que toma una variable y retorna el cuadrado. esta variable funcion puede ser pasada a otros metodos (o delegados de funciones)  el que un termino llegue a una forma normal o no, y cuanto trabajo debe realizarse para ello si se puede, depende sustancialmente de la estrategia de reduccion utilizada. la distincion entre las estrategias de reduccion esta relacionada con la distincion en lenguajes de programacion funcional entre evaluacion estricta y evaluacion perezosa.  el orden aplicativo no es una estrategia de normalizacion. el ejemplo mas tipico es el siguiente: se define q = ωω donde ω = λx.xx. esta expresion solo contiene una redex (la expresion completa), la cual resulta al ser reducida otra vez en q. como es la unica reduccion posible, q no tiene forma normal bajo ninguna estrategia de reduccion. utilizando orden aplicativo, la expresion kiω = (λx.λy.x) (λx.x)ω es reducida reduciendo primero q, pero como no tiene forma normal, esta estrategia fracasa a la hora de encontrar una forma normal para kiq.  en contraposicion, el orden normal siempre encuentra la forma normal si esta existe. en el ejemplo anterior, kiq es reducido bajo orden normal a i, una forma normal. uno de los inconvenientes es que las redexes en los argumentos pueden ser copiadas, resultando en trabajo duplicado. en ese caso, el orden aplicativo se encuentra en ventaja, porque nunca sustituye argumentos que contengan redexes, y el trabajo es realizado una unica vez.  la mayoria de lenguajes de programacion funcionales puros (sobre todo miranda y sus descendientes, incluyendo haskell) utilizan evaluacion perezosa, que es esencialmente identica a la llamada por necesidad. esta es similar a la reduccion por orden normal, pero evita la duplicacion de trabajo mediante la representacion indirecta de los terminos repetidos, abstraida de su posicion real y accedida de forma indirecta (y por tanto, varias posiciones pueden compartir el mismo termino).  la propiedad church-rosser del calculo lambda significa que la evaluacion (reduccion-β) puede ser llevada a cabo en \"cualquier orden\", incluso al mismo tiempo (de hecho, el calculo lambda es de transparencia referencial). aunque esto significa que el calculo lambda puede crear un modelo de diversas estrategias de evaluacion no deterministas, no ofrece ninguna nocion acerca de la computacion paralela, ni expresa ningun lenguaje de programacion simultaneo (o concurrente). procesadores de calculo tales como el csp, css, el calculo-π y el calculo ambiente han sido diseñados para tales propositos.  a pesar de que el calculo lambda no determinista es capaz de expresar cualquier \"funcion\" parcial recursiva, no es capaz de expresar cualquier \"computacion\". por ejemplo, no es capaz de expresar no-determinismos infinitos (como cualquier expresion lamba no determinista que termine; terminara en un numero finito de expresiones). sin embargo, hay programas concurrentes que garantizan la interrupcion de ese termino en un numero infinito de estados [clinger 1981, hewitt 2006].  levy define en su publicacion de 1988 \"sharing in the evaluation of lambda expressions\" la nocion de compartir optimamente, de forma que no se duplique el trabajo. por ejemplo, realizar una reduccion beta en orden normal sobre (λx.xx) (ii) la reduce a ii (ii). el argumento ii es duplicado por la aplicacion al primer termino lambda. si la reduccion se realizo en orden aplicativo primero, se ahorra trabajo porque no se duplican esfuerzos: (λx.xx) (ii) se reduce a (λx.xx) i. por otra parte, emplear orden aplicativo puede resultar en reducciones redundantes o incluso nunca reducirse a una forma normal. por ejemplo, realizar una reduccion beta en orden normal en (λf.f i) (λy.(λx.xx) (y i)) resulta en (λy.(λx.xx) (y i)) i, (λx.xx) (ii), que puede ser realizado sin duplicar esfuerzos. hacer lo mismo pero en orden aplicativo resulta en (λf.f i) (λy.y i (y i)), (λy.y i (y i)) i, i i (i i), por lo que ahora el trabajo se duplica.  levy muestra la existencia de terminos lambda donde no existe una secuencia de reducciones que las reduzca sin duplicar el trabajo a realizar. el siguiente termino lambda es un ejemplo de estos terminos:  esta compuesto de tres terminos similares, x=((λg. ... ) (λh.y)), y=((λf. ...) (λw.z) ) y z=λw.(h(w(λy.y))). solo hay dos reducciones beta posibles, sobre x y sobre y. reducir el termino x externo primero resulta en terminos duplicados (el termino interno y el termino y), y cada copia debe ser reducida; pero reducir el termino y primero duplica su argumento z, que causara que se duplique el trabajo cuando se conozcan los valores de h y w. curiosamente, dicho termino se reduce a la funcion identidad (λy.y), y se construye realizando encapsulaciones sucesivas.  la nocion precisa de trabajo duplicado se basa en darse cuenta de que tras hacerse la primera reduccion a i i, el valor de otro i i puede determinarse, porque tienen la misma estructura (y tienen de hecho el mismo valor), y resultan de un ancestro comun. a dichas estructuras similares se les puede asignar una etiqueta que puede ser rastreada durante las reducciones. si un nombre es asignado a la redex que produce todos los terminos ii resultantes, despues todas las ocurrencias duplicadas de ii pueden ser localizadas y reducidas de una vez. sin embargo, no es obvio si una redex producira el termino ii. identificar las estructuras que son similares en partes diferentes de un termino lambda puede requerir de algoritmos complejos y puede conllevar incluso una complejidad igual al historial de la reduccion misma.  mientras levy define la nocion de compartir optimamente, no proporciona un algoritmo para hacerlo. en la publicacion de vincent van oostrom, kees-jan van de looij y marijn zwitserlood lambdascope: another optimal implementation of the lambda-calculus, se proporciona tal algoritmo transformando terminos lambda en redes de interaccion, que despues son reducidas. en terminos generales, la reduccion resultante es optima porque cada termino que tuviese la misma etiqueta segun el trabajo de levy serian el mismo grafo en la red de interaccion. en la publicacion, mencionan que su prototipo de lambdascope rinde de forma similar a la version optimizada de la implementacion de referencia de la bohm.  el hecho de que los terminos del calculo lambda puedan actuar como funciones sobre otros terminos, o incluso sobre si mismos, llevo a cuestionarse la semantica del calculo lambda. ¿se le puede asignar un significado a los terminos del calculo lambda? la semantica natural era encontrar un conjunto d isomorfico al espacio de funciones d → d, de funciones de si mismo. sin embargo, no puede existir tal d que no sea trivial, por restricciones de cardinalidad, porque el conjunto de todas las funciones de d a d tiene mayor cardinalidad que d a menos que sea un conjunto unitario  en 1970, dana scott mostro que, si solo se consideran funciones continuas, un conjunto o dominio d con las propiedades necesarias se puede encontrar, proporcionando por tanto un modelo para el calculo lambda.  este trabajo tambien sento las bases para la semantica denotacional de los lenguajes de programacion  some parts of this article are based on material from foldoc, used with permission. ",
        "snippet": "En lógica matemática, el cálculo lambda es un sistema formal diseñado para investigar la definición de función, la noción de aplicación de funciones y la recursión. Fue introducido por Alonzo Church y Stephen Kleene en la década de 1930 como parte de sus investigaciones sobre los fundamentos de las matemáticas. Church usó el cálculo lambda en 1936 para resolver el Entscheidungsproblem. Puede ser usado para definir de manera limpia y precisa qué es una \"función computable\".",
        "enlaces_salientes": [
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Sistema_formal",
            "/wiki/Funci%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Recursi%C3%B3n",
            "/wiki/Alonzo_Church",
            "/wiki/Stephen_Kleene",
            "/wiki/1930",
            "/wiki/Fundamentos_de_las_matem%C3%A1ticas",
            "/wiki/1936",
            "/wiki/Entscheidungsproblem",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Algoritmo",
            "/wiki/Problema_de_la_parada",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Lisp",
            "/wiki/ML_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Haskell",
            "/wiki/Variable_(matem%C3%A1ticas)",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Software",
            "/wiki/Hardware",
            "/wiki/Computabilidad",
            "/wiki/Problema_de_la_parada",
            "/wiki/C%C3%A1lculo_lambda_simplemente_tipado",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Funci%C3%B3n_identidad",
            "/wiki/Suma",
            "/wiki/Currificaci%C3%B3n",
            "/wiki/Asociatividad_(%C3%A1lgebra)",
            "/wiki/Recursi%C3%B3n",
            "/wiki/Cadena_de_caracteres",
            "/wiki/Funci%C3%B3n_identidad",
            "/wiki/Si_y_solo_si",
            "/wiki/Si_y_solo_si",
            "/wiki/Si_y_solo_si",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/CONS",
            "/wiki/CAR_y_CDR",
            "/wiki/CAR_y_CDR",
            "/wiki/Recursi%C3%B3n",
            "/wiki/Factorial",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Si_y_solo_si",
            "/wiki/Computabilidad",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Algoritmo",
            "/wiki/Numeraci%C3%B3n_de_G%C3%B6del",
            "/wiki/Teorema_de_incompletitud_de_G%C3%B6del",
            "/wiki/Numeraci%C3%B3n_de_G%C3%B6del",
            "/wiki/Peter_Landin",
            "/wiki/Objeto_(programaci%C3%B3n)",
            "/wiki/Funci%C3%B3n_de_orden_superior",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Constante_(inform%C3%A1tica)",
            "/wiki/Tipo_de_dato",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%2B%2B",
            "/wiki/Puntero",
            "/wiki/C%2B%2B",
            "/wiki/Smalltalk",
            "/wiki/C_Sharp",
            "/wiki/Tupla",
            "/wiki/Python",
            "/wiki/Evaluaci%C3%B3n_perezosa",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Thunk",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Miranda",
            "/wiki/Cardinalidad",
            "/wiki/Conjunto_unitario",
            "/wiki/Dana_Scott",
            "/wiki/Dominio",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Sem%C3%A1ntica_denotacional",
            "/wiki/ISBN",
            "/wiki/Annals_of_Mathematics",
            "/wiki/Digital_object_identifier",
            "/wiki/MIT_Press",
            "/wiki/1984",
            "/wiki/1977",
            "/wiki/American_Journal_of_Mathematics",
            "/wiki/Wayback_Machine",
            "/wiki/American_Journal_of_Mathematics",
            "/wiki/1935",
            "/wiki/Peter_Landin",
            "/wiki/1965",
            "/wiki/Free_On-line_Dictionary_of_Computing",
            "/wiki/Portable_Document_Format",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Alan_Turing",
        "titulo": "Alan Turing",
        "contenido": "alan mathison turing (paddington, londres; 23 de junio de 1912-wilmslow, cheshire; 7 de junio de 1954) fue un matematico, logico, informatico teorico, criptografo, filosofo y biologo teorico britanico.​​​​​  es considerado como uno de los padres de la ciencia de la computacion y precursor de la informatica moderna. proporciono una formalizacion influyente de los conceptos de algoritmo y computacion: la maquina de turing. formulo su propia version que hoy es ampliamente aceptada como la tesis de church-turing (1936).  durante la segunda guerra mundial, trabajo en descifrar los codigos nazis, particularmente los de la maquina enigma, y durante un tiempo fue el director de la seccion naval enigma de bletchley park. se ha estimado que su trabajo acorto la duracion de esa guerra entre dos y cuatro años.​ tras la guerra, diseño uno de los primeros computadores electronicos programables digitales en el laboratorio nacional de fisica del reino unido y poco tiempo despues construyo otra de las primeras maquinas en la universidad de manchester.  en el campo de la inteligencia artificial, es conocido sobre todo por la concepcion de la prueba de turing (1950), un criterio segun el cual puede juzgarse la inteligencia de una maquina si sus respuestas en la prueba son indistinguibles de las de un ser humano.  la carrera de turing termino subitamente tras ser procesado por homosexualidad en 1952. dos años despues de su condena, murio —segun la version oficial por suicidio; sin embargo, su muerte ha dado lugar a otras hipotesis, incluida la del envenenamiento accidental —. despues de una campaña publica en 2009, el primer ministro britanico, gordon brown, se disculpo publicamente en nombre del gobierno britanico por «la forma espantosa en la que turing habia sido tratado». la reina isabel ii le otorgo un indulto postumo en 2013. el termino «ley alan turing» ahora se usa de manera informal para referirse a una ley de 2017 en el reino unido que perdona retroactivamente a hombres amonestados o condenados en virtud de la legislacion que prohibia los actos homosexuales.​  turing tiene un extenso legado con estatuas y muchas cosas que llevan su nombre, incluido un premio anual por innovacion en informatica. aparece en el billete actual de 50 libras del banco de inglaterra,​ que se lanzo el 23 de junio de 2021, coincidiendo con su cumpleaños. un programa de la bbc de 2019, votado por la audiencia, lo nombro la persona mas grande del siglo xx.​  turing nacio en el distrito londinense de maida vale.​ su padre, julius mathison turing (1873-1944), era miembro del cuerpo de funcionarios britanicos en la india. su madre, ethel sara stoney, hija de edward waller stoney, ingeniero jefe de madras railways. los stoney eran una familia de la nobleza protestante angloirlandesa de los condados de tipperary y longford, mientras que la propia ethel habia pasado gran parte de su infancia en el condado de clare.  por razones de trabajo, la familia residia en la india britanica. sin embargo, tanto julius como ethel querian que sus hijos se criaran en gran bretaña, por lo que se mudaron a maida vale (londres). alli nacio alan turing el 23 de junio de 1912.[n. 1]​ turing tuvo un hermano mayor.  durante su infancia, sus padres viajaron constantemente entre hastings, reino unido, y la india debido a que su padre seguia activo en la administracion colonial, por lo que paso algunos años viviendo con su hermano en la casa de un matrimonio retirado del ejercito.  muy pronto turing mostro signos del genio que luego seria. desde temprana edad mostro un gran interes por la lectura, por los numeros y los rompecabezas.  entre enero de 1922 y 1926, turing estudio en la preparatoria hazelhurst, una escuela independiente en el pueblo de frant en sussex (hoy east oriental).​  en 1926, con trece años, ingreso en el internado de sherborne, en dorset. su primer dia de clase coincidio con la huelga general en inglaterra, pero su determinacion por asistir a clase era tan firme que recorrio con su bicicleta los mas de 96 km que separaban southampton de su escuela, pasando la noche en una posada.​  la inclinacion natural de turing hacia la matematica y la ciencia no le atrajo el respeto de sus profesores de sherborne, cuyo concepto de educacion hacia mayor enfasis en los clasicos. en la escuela de sherbone, gano la mayor parte de los premios matematicos que se otorgaban y, ademas, realizaba experimentos quimicos por su cuenta, aunque la opinion del profesorado respecto a la independencia y ambicion de turing no era demasiado favorable. a pesar de ello, el joven continuo mostrando una singular habilidad para los estudios que realmente le gustaban, y llego a resolver problemas muy avanzados para su edad (16 años) sin ni siquiera haber estudiado calculo elemental.​  christopher morcom estudiaba junto con turing en la escuela de sherborne y ambos compartian la pasion por la ciencia. durante las clases de matematica o fisica, se intercambiaban notas de comentarios sobre rompecabezas. alan se enamoro de el. fue su primer amor y la primera persona que creyo en sus ideas y con quien podia continuar desarrollandolas.​​​  el 13 de febrero de 1930,​ solo unas pocas semanas despues de su ultima temporada en sherborne, morcom fallecio debido a complicaciones de la tuberculosis bovina contraida tras beber leche de alguna vaca infectada. al recordarlo, turing afirmaba: «mis recuerdos mas vividos de chris son casi siempre de las cosas tan amables que me decia».​  a raiz de esas vivencias, su fe religiosa se resquebrajo y se hizo ateo. tambien se obsesiono por entender la naturaleza de la consciencia, su estructura y origenes. adopto la conviccion de que todos los fenomenos, incluyendo el funcionamiento del cerebro humano, son materialistas.​ sin embargo, siguio creyendo en la supervivencia del espiritu despues de la muerte.  debido a su falta de voluntad para esforzarse con la misma intensidad en el estudio de los clasicos que en el de la ciencia y la matematica, turing suspendio sus examenes finales varias veces y tuvo que ingresar en la escuela universitaria que eligio en segundo lugar, king's college, universidad de cambridge, en vez de en la que era su primera eleccion, trinity. tras su graduacion, se traslado a la universidad estadounidense de princeton, donde trabajo con el logico alonzo church. recibio las enseñanzas de godfrey harold hardy, un respetado matematico que ocupo la catedra sadleirian en cambridge, y que posteriormente, fue responsable de un centro de estudios e investigaciones matematicas entre 1931 y 1934. en 1935 turing fue nombrado profesor del king's college.  el entscheidungsproblem, que se traduce como «problema de decision», fue un reto en logica simbolica para encontrar un algoritmo general que decidiera si una formula de calculo de primer orden es un teorema. el problema fue planteado inicialmente por leibniz en el siglo xvii luego de construir su maquina mecanica de calculo. david hilbert formalizo el problema en el vii congreso internacional de matematicas (bolonia, 1928), planteando la busqueda de un procedimiento algoritimico valido para solucionar las posibles cuestiones matematicas, a traves de tres preguntas:  si bien hilbert suponia que la respuesta a las preguntas era afirmativa, kurt godel, mediante los teoremas de incompletitud demostro que las dos primeras preguntas no podrian serlo ya que, tal como afirma godel:  «en cualquier formalizacion consistente de las matematicas que sea lo bastante fuerte para definir el concepto de los numeros naturales, se puede construir una afirmacion que ni se puede demostrar ni se puede refutar dentro de ese sistema», mientras que el primero afirma: «ningun sistema consistente se puede usar para demostrarse a si mismo».​  sin embargo, no podian resolver la ultima pregunta. la dificultad estaba en la ausencia de significado de lo que se entiende por un «procedimiento mecanico». en 1936, alan turing en su trabajo acerca de los numeros computables,  introduce el concepto de la maquina de turing y, junto a  alonzo church demostraron ambos que es imposible escribir tal algoritmo. como consecuencia, es tambien imposible decidir con un algoritmo general si ciertas frases concretas de la aritmetica son ciertas o falsas.  la tesis de church-turing formula hipoteticamente la equivalencia entre los conceptos de funcion computable y maquina de turing, que expresado en lenguaje corriente vendria a ser: «todo algoritmo es equivalente a una maquina de turing». no es en si un teorema matematico: es una afirmacion formalmente indemostrable, una hipotesis que, no obstante, tiene una aceptacion practicamente universal.  la tesis church-turing postula que cualquier modelo computacional existente tiene las mismas capacidades algoritmicas, o un subconjunto, de las que tiene una maquina de turing.  en su estudio los numeros computables, con una aplicacion al entscheidungsproblem (publicado el 28 de mayo de 1936), turing reformulo los resultados obtenidos por kurt godel en 1931 sobre los limites de la demostrabilidad y la computacion, sustituyendo al lenguaje formal universal descrito por godel por lo que hoy se conoce como maquina de turing, unos dispositivos formales y simples.​  turing demostro que dicha maquina era capaz de resolver cualquier problema matematico que pudiera representarse mediante un algoritmo. las maquinas de turing siguen siendo el objeto central de estudio en la teoria de la computacion. llego a probar que no habia ninguna solucion para el problema de decision, entscheidungsproblem, demostrando primero que el problema de la parada para las maquinas de turing es irresoluble: no es posible decidir algoritmicamente si una maquina de turing dada llegara a pararse o no. aunque su demostracion se publico despues de la demostracion equivalente de alonzo church respecto a su calculo lambda, el estudio de turing es mucho mas accesible e intuitivo.​ tambien fue pionero con su concepto de «maquina universal (de turing)», con la tesis de que dicha maquina podria realizar las mismas tareas que cualquier otro tipo de maquina. su estudio tambien introduce el concepto de numeros definibles.​  la mayor parte de 1937 y 1938 la paso en la universidad de princeton, estudiando bajo la direccion de alonzo church. entre 1938 y 1939 volvio a inglaterra y estudio filosofia de las matematicas. en 1938 obtuvo el doctorado en princeton; en su discurso introdujo el concepto de hipercomputacion, en el que ampliaba las maquinas de turing con las llamadas maquinas oracle, las cuales permitian el estudio de los problemas para los que no existe una solucion algoritmica.​  tras su regreso a cambridge en 1939, asistio a las conferencias de ludwig wittgenstein sobre las bases de las matematicas. ambos discutieron y mantuvieron un vehemente desencuentro, ya que turing defendia el formalismo matematico y wittgenstein criticaba que la matematica estaba sobrevalorada y no descubria ninguna verdad absoluta.​  un dia despues de la declaracion de guerra de gran bretaña, en septiembre de 1939, turing fue convocado a bletchley park, donde se encontraba la escuela gubernamental de codigo y cifrado (gc&cs). las nueve mil personas que trabajaban alli se dedicaron a intentar interpretar las comunicaciones alemanas cifradas en codigo morse.  el cifrado lo hacian a traves de una maquina de sistema rotatorio llamada enigma (maquina). enigma habia sido inventada en 1918 por arthur scherbius. era similar a una maquina de escribir, en la cual cada vez que una letra era pulsada, era sustituida por otra mediante el uso de tres rotores internos (las maquinas militares llegaron a usar cinco), cuyo resultado era mas de diez mil billones de configuraciones distintas. debido al caracter portatil de la maquina, los operadores podian estar ubicados en los puestos de mando, interior de los tanques, submarinos, en bombardeos, etc. independientemente de su locacion, los operadores, llevaban las instrucciones de como debian colocarse los rotores, y las posiciones cambiaban cada pocos dias.​  el equipo liderado por turing, a traves de ecuaciones y calculos, encontraron pautas en los mensajes con lo que pudieron detectar una pequeña parte de su funcionamiento. sin embargo, todavia no podian descifrarlos. fue entonces, cuando turing se pregunto:  ¿y si para luchar contra una maquina como enigma hiciese falta otra maquina?​  a raiz de esta pregunta, turing pudo poner en practica sus teorias: diseño la maquina bombe. bombe buscaba la configuracion de los rotores de la maquina alemana, implementando una cadena de deducciones logicas para cada combinacion posible. gracias a las mejoras del matematico,  gordon welchman, el 14 de marzo de 1940, el primer prototipo estaba terminado. al cabo de un tiempo disponian con mas de doscientas bombes.​  los trabajos de la gc&cs, dirigidos por turing, fueron determinantes para acortar la guerra. algunos historiadores afirman que su trabajo acorto dos años la duracion de la guerra, salvando alrededor de catorce millones de vidas.​ al finalizar la guerra, las maquinas bombe se desmantelaron y todo el trabajo permanecio en secreto hasta los setenta. en 1974 el capitan w. f. winterbotham escribio el libro the ultra secret.​  de 1945 a 1948 turing vivio en richmond, londres, donde trabajo en el laboratorio nacional de fisica (npl). en 1947 empezo a trabajar en el diseño del ace (automatic computer engine o motor de computacion automatica). paralelamente, existia un proyecto similar en estados unidos llamado edvac de von neumann. el ace de turing se diferenciaba en que incluia la implementacion de funciones aritmeticas en circuitos electronicos. su deseo era crear una maquina que pudiera ser configurada para hacer calculos algebraicos, desencriptar codigos, manipular archivos y jugar al ajedrez. aunque diseñar el ace era factible, el secretismo que reinaba durante la guerra desemboco en retrasos para iniciar el proyecto por lo que turing se sintio desilusionado.  tiempo mas tarde creo el abbreviated code instruction, que dio origen a los lenguajes de programacion. en 1947 se tomo un año sabatico en cambridge, tiempo durante el cual escribio un trabajo pionero sobre la inteligencia artificial que no fue publicado en vida. en 1948, con la ayuda de frederic calland williams, se dio, por primera vez, la demostracion del principio de la maquina de turing.  mientras se encontraba en cambridge y a pesar de su ausencia, se siguio construyendo el prototipo piloto del ace, que ejecuto su primer programa en mayo de 1950. aunque la version completa del ace de turing jamas fue construida, el diseño de otras computadoras en todo el mundo le debio mucho a su concepcion.​  a mediados de 1948 fue nombrado director delegado del laboratorio de informatica de la universidad de manchester y trabajo en el software de una de las primeras computadoras reales, la manchester mark i. durante esta etapa tambien realizo estudios mas abstractos y en su articulo de octubre de 1950 «computing machinery and intelligence» turing trato el problema de la inteligencia artificial y propuso un experimento que hoy se conoce como prueba de turing, con la intencion de definir una prueba estandar por la que una maquina podria catalogarse como «sensible» o «sintiente». en el documento, turing sugirio que en lugar de construir un programa para simular la mente adulta, seria mejor producir uno mas simple para simular la mente de un niño y luego someterlo a educacion. una forma invertida de la prueba de turing se usa ampliamente en internet, el test captcha que esta diseñado para determinar si un usuario es un humano y no un ordenador.  la prueba de turing es un metodo para determinar si una maquina puede pensar.​  nace de un juego de imitacion, en donde hay tres personas: un interrogador, un hombre y una mujer. el interrogador esta separado de los otros dos, y solo puede comunicarse con ellos a traves de un lenguaje que entiendan. el objetivo del interrogador es descubrir quien es la mujer, y quien es el hombre, mientras que el de los otros dos, es convencerlo de que son la mujer. en su ensayo de 1950, «computing machinery and intelligence», turing sustituye a uno de los interrogados por una computadora y cambia los objetivos del juego: reconocer a la maquina.  «una computadora puede ser llamada inteligente si logra engañar a una persona haciendole creer que es un humano» - alan turing.​  la forma de hacer pasar la prueba a una maquina consiste basicamente en una persona hablando con una computadora en otra habitacion mediante un sistema de chat. si la persona es incapaz de determinar si habla con un humano o con un ordenador, entonces la computadora se considera inteligente.  en el año 2014, por primera vez, el chatbot de eugene gootsman, logro convencer a treinta jueces que estaban participando en la prueba de que estaban chateando con un niño ucraniano de trece años.​​  entre 1948 y 1950 en conjunto con un antiguo compañero, d. g. champernowne, empezo a escribir un programa de ajedrez para un ordenador que aun no existia. en 1952 trato de implementarlo en el ferranti mark 1, pero por falta de potencia, el ordenador no fue capaz de ejecutar el programa. en su lugar turing jugo una partida en la que reprodujo manualmente los calculos que hubiera hecho el ordenador, costando alrededor de hora y media en efectuar un movimiento. una de las partidas llego a registrarse, y el programa perdio frente a un colega de turing, alick glennie. su test fue significativo, caracteristicamente provocativo y una gran contribucion para empezar el debate alrededor de la inteligencia artificial que aun hoy continua.​  trabajo junto a norbert wiener en el desarrollo de la cibernetica. esta rama de estudios se genera a partir de la demanda de sistemas de control que exige el progresivo desarrollo de las tecnicas de produccion a partir del siglo xx. la cibernetica pretende establecer un sistema de comunicacion entre el hombre y la maquina como premisa fundamental para administrar los sistemas de control. sus estudios profundizaron en esta relacion estableciendo el concepto de interfaz y cuestionando los limites de simulacion del razonamiento humano.  turing trabajo desde 1952 hasta que fallecio en 1954 en la biologia matematica, concretamente en la morfogenesis. publico un trabajo sobre esta materia titulado «fundamentos quimicos de la morfogenesis» en 1952. su principal interes era comprender la filotaxis de fibonacci, es decir, la existencia de los numeros de fibonacci en las estructuras vegetales. utilizo ecuaciones de reaccion-difusion que actualmente son cruciales para entender la formacion de patrones en el campo de biologia del desarrollo ontogenetico (embriologia). sus trabajos posteriores no se publicaron hasta 1992 en el libro obras completas de a. m. turing.  las teorias de turing han ido ganando la aceptacion de biologos experimentales, como uno de los mecanismos mediante los cuales celulas que son geneticamente identicas pueden diferenciarse y dar origen a organismos complejos.​  la carrera profesional de turing se vio truncada cuando lo procesaron por su homosexualidad. en 1952, arnold murray, un amante de turing, ayudo a un complice a entrar en la casa de turing para robarle. turing acudio a la policia a denunciar el delito. durante la investigacion policial turing reconocio su homosexualidad, con lo que se le imputaron los cargos de «indecencia grave y perversion sexual» (los actos de homosexualidad eran ilegales en el reino unido en esa epoca), los mismos que a oscar wilde mas de 50 años antes.  convencido de que no tenia de que disculparse, no se defendio de los cargos y fue condenado. segun su ampliamente difundido proceso judicial, se le dio la opcion de ir a prision o de someterse a castracion quimica mediante un tratamiento hormonal de reduccion de la libido. finalmente escogio las inyecciones de estrogenos, que duraron un año y le produjeron importantes alteraciones fisicas, como la aparicion de pechos o un apreciable aumento de peso, que lo condujeron a padecer de disfuncion erectil.   en una carta de esta epoca a su amigo norman routledge, turing escribio en forma de falso silogismo una reflexion, relacionando el rechazo social que provoca la homosexualidad con el desafio intelectual que supone demostrar la posibilidad de inteligencia en los ordenadores. en particular, le preocupaba que los ataques a su persona pudieran oscurecer sus razonamientos sobre la inteligencia artificial:​ dos años despues del juicio, en 1954, fallecio por envenenamiento con cianuro, aparentemente tras comerse una manzana envenenada que no llego a ingerir completamente, en un contexto que se estimo oficialmente como suicidio.​​ varias personas pensaron que su muerte fue intencionada, aunque su madre nego la causa de su muerte, atribuyendola a una ingestion accidental provocada por la falta de precauciones de turing en el almacenamiento de sustancias quimicas de laboratorio. los ultimos años de su vida fueron amargos y reservados. esta muerte no esclarecida ha dado lugar a diversas hipotesis, incluida la del asesinato.​ para jack copeland, experto en la vida y obra del cientifico, las pruebas presentadas para el veredicto oficial de la muerte de alan turing no serian consideradas hoy dia como suficientes: «siempre se llevaba una manzana que dejaba a medio comer antes de dormirse (...) lo cierto es que es imposible estar seguros de lo que paso. la idea de una muerte accidental es coherente con las pruebas que tenemos. lo mejor hubiera sido un veredicto abierto porque la verdad es que probablemente nunca sepamos que paso».​  el 10 de septiembre de 2009, el primer ministro del reino unido, gordon brown, emitio un comunicado declarando sus disculpas en nombre de su gobierno por el trato que recibio alan turing durante sus ultimos años de vida. este comunicado fue consecuencia de una movilizacion publica solicitando al gobierno que ofreciera disculpas oficialmente por la persecucion contra alan turing.​​ sin embargo, en 2012 el gobierno britanico de david cameron denego el indulto al cientifico,​ aduciendo que la homosexualidad era considerada entonces un delito.​ finalmente, el 24 de diciembre de 2013 recibio el indulto de todo tipo de culpa, por orden de la reina isabel ii.​  el 23 de junio de 2001 se inauguro una estatua de turing en manchester. se encuentra en sackville park, entre el edificio de la universidad de manchester en la calle de whitworth y la gay village de la calle del canal. coincidiendo con el 50.º aniversario de su muerte, se descubrio una placa conmemorativa en su antiguo domicilio, hollymeade, en wilmslow el 7 de junio de 2004.  la association for computing machinery otorga anualmente el premio turing a personas destacadas por sus contribuciones tecnicas al mundo de la informatica. este premio esta ampliamente considerado como el equivalente del premio nobel en el mundo de la computacion.  el instituto alan turing fue inaugurado por el umist (instituto de ciencia y tecnologia de la universidad de manchester) y la universidad de manchester en el verano de 2004.  el 5 de junio de 2004 se celebro un acontecimiento conmemorativo de la vida y la obra de turing en la universidad de manchester, organizado por el british logic colloquium y la british society for the history of mathematics.  el 28 de octubre de 2004 se descubrio una estatua de bronce de alan turing esculpida por john w. mills en la universidad de surrey. la estatua conmemora el 50.º aniversario de la muerte de turing. representa a turing transportando sus libros a traves del campus.​  el 23 de junio de 2012, dia en el que se conmemoro el centenario del nacimiento de turing, google presento entre sus habituales doodles una pequeña maquina de turing capaz de comparar dos cadenas de caracteres binarios.  una leyenda urbana asegura que el logo de apple computers (mordisco de la manzana) rinde homenaje a turing y su suicidio comiendo una manzana envenenada con cianuro. incluso, el arco iris en el logo seria un homenaje a la homosexualidad de turing. sin embargo, estas suposiciones fueron desmentidas por rob janoff, creador del logo de apple y de hecho, los colores ni siquiera se muestran en el mismo orden que en la bandera arco iris, dado que esta fue diseñada dos años mas tarde de la creacion de dicha imagen.​ ",
        "snippet": "Alan Mathison Turing (Paddington, Londres; 23 de junio de 1912-Wilmslow, Cheshire; 7 de junio de 1954) fue un matemático, lógico, informático teórico, criptógrafo, filósofo y biólogo teórico británico.[1]​[2]​[3]​[4]​[5]​",
        "enlaces_salientes": [
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Turing_(desambiguaci%C3%B3n)",
            "/wiki/Maida_Vale",
            "/wiki/Reino_Unido_de_Gran_Breta%C3%B1a_e_Irlanda",
            "/wiki/Wilmslow",
            "/wiki/Reino_Unido",
            "/wiki/Intoxicaci%C3%B3n_cianh%C3%ADdrica",
            "/wiki/Ate%C3%ADsmo",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/King%27s_College_(Cambridge)",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Alonzo_Church",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Estad%C3%ADstico",
            "/wiki/Criptoan%C3%A1lisis",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/GCHQ",
            "/wiki/National_Physical_Laboratory",
            "/wiki/Computing_machinery_and_intelligence",
            "/wiki/Problema_de_la_parada",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Prueba_de_Turing",
            "/wiki/Turing_completo",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/M%C3%A1quina_de_Turing_universal",
            "/wiki/Bombe",
            "/wiki/M%C3%A1quina_de_Turing_probabil%C3%ADstica",
            "/wiki/Royal_Society",
            "/wiki/Premio_Smith",
            "/wiki/Oficial_de_la_Orden_del_Imperio_brit%C3%A1nico",
            "/wiki/Miembro_de_la_Royal_Society",
            "/wiki/Delito",
            "/wiki/Paddington",
            "/wiki/Londres",
            "/wiki/Wilmslow",
            "/wiki/Cheshire",
            "/wiki/Matem%C3%A1tico",
            "/wiki/L%C3%B3gico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Cript%C3%B3grafo",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Biolog%C3%ADa_te%C3%B3rica",
            "/wiki/Reino_Unido",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Algoritmo",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Segunda_guerra_mundial",
            "/wiki/Nazismo",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Bletchley_Park",
            "/wiki/Laboratorio_Nacional_de_F%C3%ADsica_(Reino_Unido)",
            "/wiki/Universidad_de_M%C3%A1nchester",
            "/wiki/Inteligencia_artificial",
            "/wiki/Prueba_de_Turing",
            "/wiki/Gordon_Brown",
            "/wiki/Ley_Alan_Turing",
            "/wiki/Premio_Turing",
            "/wiki/Libra_esterlina",
            "/wiki/Banco_de_Inglaterra",
            "/wiki/BBC",
            "/wiki/Maida_Vale",
            "/wiki/Anglo-Irland%C3%A9s",
            "/wiki/Tipperary",
            "/wiki/Longford_(Condado_de_Longford)",
            "/wiki/Condado_de_Clare_(Irlanda)",
            "/wiki/Maida_Vale",
            "/wiki/Rompecabezas",
            "/wiki/Frant",
            "/wiki/Sussex",
            "/wiki/Sherborne",
            "/wiki/Dorset",
            "/wiki/Huelga_general_en_Reino_Unido_de_1926",
            "/wiki/Southampton",
            "/wiki/Posada_(establecimiento)",
            "/wiki/C%C3%A1lculo",
            "/wiki/Tuberculosis_de_los_mam%C3%ADferos",
            "/wiki/Ate%C3%ADsmo",
            "/wiki/King%27s_College_(Cambridge)",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/King%27s_College,_Cambridge",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Trinity_College,_Cambridge",
            "/wiki/Alonzo_Church",
            "/wiki/Godfrey_Harold_Hardy",
            "/wiki/1931",
            "/wiki/1934",
            "/wiki/1935",
            "/wiki/Entscheidungsproblem",
            "/wiki/Entscheidungsproblem",
            "/wiki/Problema_de_decisi%C3%B3n",
            "/wiki/L%C3%B3gica_simb%C3%B3lica",
            "/wiki/C%C3%A1lculo_de_primer_orden",
            "/wiki/Teorema",
            "/wiki/Gottfried_Leibniz",
            "/wiki/David_Hilbert",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Algoritmo",
            "/wiki/Independencia_(l%C3%B3gica_matem%C3%A1tica)",
            "/wiki/Hip%C3%B3tesis_(m%C3%A9todo_cient%C3%ADfico)",
            "/wiki/Consenso_cient%C3%ADfico",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/1936",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/1931",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Entscheidungsproblem",
            "/wiki/Problema_de_la_parada",
            "/wiki/Alonzo_Church",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/M%C3%A1quina_oracle",
            "/wiki/1937",
            "/wiki/1938",
            "/wiki/Universidad_de_Princeton",
            "/wiki/1938",
            "/wiki/1938",
            "/wiki/Hipercomputaci%C3%B3n",
            "/wiki/M%C3%A1quina_oracle",
            "/wiki/1939",
            "/wiki/Ludwig_Wittgenstein",
            "/wiki/Bases_de_las_matem%C3%A1ticas",
            "/wiki/Bombe",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Bletchley_Park",
            "/wiki/Government_Communications_Headquarters",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Arthur_Scherbius",
            "/wiki/M%C3%A1quina_de_escribir",
            "/wiki/Bombe",
            "/wiki/Gordon_Welchman",
            "/wiki/Prueba_de_Turing",
            "/wiki/Inteligencia",
            "/wiki/Richmond_(Londres)",
            "/wiki/Laboratorio_Nacional_de_F%C3%ADsica_(Reino_Unido)",
            "/wiki/Estados_Unidos",
            "/wiki/EDVAC",
            "/wiki/John_von_Neumann",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Inteligencia_artificial",
            "/wiki/Frederic_Calland_Williams",
            "/wiki/Universidad_de_M%C3%A1nchester",
            "/wiki/Manchester_Mark_I",
            "/wiki/Computing_machinery_and_intelligence",
            "/wiki/Inteligencia_artificial",
            "/wiki/Prueba_de_Turing",
            "/wiki/CAPTCHA",
            "/wiki/Prueba_de_Turing",
            "/wiki/Computing_machinery_and_intelligence",
            "/wiki/Eugene_Goostman",
            "/wiki/Ajedrez_por_computadora",
            "/wiki/Ajedrez_por_computadora",
            "/wiki/1952",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Norbert_Wiener",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Patrones_de_Turing",
            "/wiki/Biolog%C3%ADa_matem%C3%A1tica",
            "/wiki/Morfog%C3%A9nesis",
            "/wiki/Filotaxis",
            "/wiki/Fibonacci",
            "/wiki/N%C3%BAmero_de_Fibonacci",
            "/wiki/Sistemas_de_reacci%C3%B3n-difusi%C3%B3n",
            "/wiki/Patr%C3%B3n_(estructura)",
            "/wiki/Biolog%C3%ADa_del_desarrollo",
            "/wiki/Embriolog%C3%ADa",
            "/wiki/1992",
            "/wiki/Homosexualidad",
            "/wiki/Oscar_Wilde",
            "/wiki/Castraci%C3%B3n_qu%C3%ADmica",
            "/wiki/Hormona",
            "/wiki/Libido",
            "/wiki/Estr%C3%B3geno",
            "/wiki/Disfunci%C3%B3n_er%C3%A9ctil",
            "/wiki/Monumento_a_Alan_Turing",
            "/wiki/M%C3%A1nchester",
            "/wiki/Reino_Unido",
            "/wiki/Silogismo",
            "/wiki/Envenenamiento",
            "/wiki/Cianuro",
            "/wiki/Suicidio",
            "/wiki/Jack_Copeland",
            "/wiki/Reino_Unido",
            "/wiki/Gordon_Brown",
            "/wiki/David_Cameron",
            "/wiki/Isabel_II_del_Reino_Unido",
            "/wiki/Monumento_a_Alan_Turing",
            "/wiki/M%C3%A1nchester",
            "/wiki/Universidad_de_M%C3%A1nchester",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Premio_Turing",
            "/wiki/Premios_Nobel",
            "/wiki/Instituto_Alan_Turing",
            "/wiki/Google",
            "/wiki/Doodle",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Cadena_de_caracteres",
            "/wiki/C%C3%B3digo_binario",
            "/wiki/Leyenda_urbana",
            "/wiki/Cianuro",
            "/wiki/Alex_Garland",
            "/wiki/Ex_Machina_(pel%C3%ADcula)",
            "/wiki/Prueba_de_Turing",
            "/wiki/Androide",
            "/wiki/Inteligencia_artificial",
            "/wiki/Breaking_the_Code",
            "/wiki/Derek_Jacobi",
            "/wiki/The_Imitation_Game",
            "/wiki/Morten_Tyldum",
            "/wiki/Benedict_Cumberbatch",
            "/wiki/Keira_Knightley",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Nazi",
            "/wiki/Bletchley_Park",
            "/wiki/Netflix",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/RuPaul%27s_Drag_Race_UK",
            "/wiki/Criptonomic%C3%B3n",
            "/wiki/Neal_Stephenson",
            "/wiki/Breaking_the_Code",
            "/wiki/Greg_Egan",
            "/wiki/2001",
            "/wiki/Arthur_C._Clarke",
            "/wiki/Neuromante",
            "/wiki/William_Gibson",
            "/wiki/Norma_Editorial",
            "/wiki/Ian_McEwan",
            "/wiki/Harry_Harrison",
            "/wiki/Marvin_Minsky",
            "/wiki/Robert_Harris",
            "/wiki/Matmos",
            "/wiki/EP",
            "/wiki/Hidrogenesse",
            "/wiki/Un_d%C3%ADgito_binario_dudoso._Recital_para_Alan_Turing",
            "/wiki/M%C3%A1quina_or%C3%A1culo",
            "/wiki/M%C3%A1quina_universal_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing_alternante",
            "/wiki/M%C3%A1quina_de_Turing_probabil%C3%ADstica",
            "/wiki/Turing_completo",
            "/wiki/N%C3%BAmero_computable",
            "/wiki/Colossus",
            "/wiki/John_von_Neumann",
            "/wiki/El_Pa%C3%ADs",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/David_Leavitt",
            "/wiki/ISBN",
            "/wiki/BBC",
            "/wiki/ISSN",
            "/wiki/Jack_Copeland",
            "/wiki/Oxford_University_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Springer_Science%2BBusiness_Media",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/Conel_Hugh_O%27Donel_Alexander",
            "/wiki/ISBN",
            "/wiki/Harvard_University_Press",
            "/wiki/ISBN",
            "/wiki/Charles_Babbage",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Alonzo_Church",
            "/wiki/American_Journal_of_Mathematics",
            "/wiki/ISSN",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Jack_Copeland",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Jack_Copeland",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Rolf_Hochhuth",
            "/wiki/ISBN",
            "/wiki/David_Leavitt",
            "/wiki/ISBN",
            "/wiki/Janna_Levin",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Indianapolis",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Cambridge_University_Press",
            "/wiki/Martin_Davis",
            "/wiki/Derek_Jacobi",
            "/wiki/Oxford",
            "/wiki/Englewood_Cliffs",
            "/wiki/New_Jersey",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Scopus",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Internet_Movie_Database"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/M%C3%A1quina_de_Turing",
        "titulo": "Máquina de Turing",
        "contenido": " una maquina de turing es un dispositivo que manipula simbolos sobre una tira de cinta de acuerdo con una tabla de reglas. a pesar de su simplicidad, una maquina de turing puede ser adaptada para simular la logica de cualquier algoritmo de computador y es particularmente util en la explicacion de las funciones de una cpu dentro de un computador.  originalmente fue definida por el matematico ingles alan turing como una «maquina automatica» en 1936 en la revista proceedings of the london mathematical society[nota 1]​. la maquina de turing no esta diseñada como una tecnologia de computacion practica, sino como un dispositivo hipotetico que representa una maquina de computacion. las maquinas de turing ayudan a los cientificos a entender los limites del calculo mecanico.​​  turing dio una definicion sucinta del experimento en su ensayo de 1948, «maquinas inteligentes». refiriendose a su publicacion de 1936, turing escribio que la maquina de turing, aqui llamada una maquina de computacion logica, consistia en:  una maquina de turing que es capaz de simular cualquier otra maquina de turing es llamada una maquina universal de turing (utm, o simplemente una maquina universal). una definicion mas matematicamente orientada, con una similar naturaleza \"universal\", fue presentada por alonzo church, cuyo trabajo sobre el calculo lambda se entrelaza con el de turing en una teoria formal de la computacion conocida como la tesis de church-turing. la tesis señala que las maquinas de turing capturan, de hecho, la nocion informal de un metodo eficaz en la logica y las matematicas y proporcionan una definicion precisa de un algoritmo o 'procedimiento mecanico'.  la importancia de la maquina de turing en la historia de la computacion es doble: primero, la maquina de turing fue uno de los primeros (si no el primero) modelos teoricos para las computadoras, viendo la luz en 1936. segundo, estudiando sus propiedades abstractas, la maquina de turing ha servido de base para mucho desarrollo teorico en las ciencias de la computacion y en la teoria de la complejidad. una razon para esto es que las maquinas de turing son simples, y por tanto amenas al analisis. dicho esto, cabe aclarar que las maquinas de turing no son un modelo practico para la computacion en maquinas reales, las cuales precisan modelos mas rapidos como los basados en ram.  alan turing introdujo el concepto de maquina de turing en el trabajo on computable numbers, with an application to the entscheidungsproblem, publicado por la sociedad matematica de londres en 1936, en el que se estudiaba la cuestion planteada por david hilbert sobre si las matematicas son decidibles, es decir, si hay un metodo definido que pueda aplicarse a cualquier sentencia matematica y que nos diga si esa sentencia es cierta o no. turing ideo un modelo formal de computador, la maquina de turing, y demostro que existian problemas que una maquina no podia resolver.​  con este aparato extremadamente sencillo es posible realizar cualquier computo que un computador digital sea capaz de realizar.​  mediante este modelo teorico y el analisis de la complejidad de los algoritmos, fue posible la categorizacion de problemas computacionales de acuerdo a su comportamiento, apareciendo asi, el conjunto de problemas denominados p y np, cuyas soluciones pueden encontrarse en tiempo polinomico por maquinas de turing deterministas y no deterministas, respectivamente.  precisamente, la tesis de church-turing formulada por alan turing y alonzo church, de forma independiente a mediados del siglo xx caracteriza la nocion informal de computabilidad con la computacion mediante una maquina de turing.​  la idea subyacente es el concepto de que una maquina de turing puede verse como un automata ejecutando un procedimiento efectivo definido formalmente, donde el espacio de memoria de trabajo es ilimitado, pero en un momento determinado solo una parte finita es accesible.  la maquina de turing modela matematicamente a una maquina que opera mecanicamente sobre una cinta. en esta cinta hay simbolos que la maquina puede leer y escribir, uno a la vez, usando un cabezal lector/escritor de cinta. la operacion esta completamente determinada por un conjunto finito de instrucciones elementales como \"en el estado 42, si el simbolo visto es 0, escribe un 1; si el simbolo visto es 1, cambia al estado 17; en el estado 17, si el simbolo visto es 0, escribe un 1 y cambia al estado 6; etc\". en el articulo original (\"sobre numeros computables con una aplicacion al entscheidungsproblem\"), turing no imagina un mecanismo, sino una persona a la que el llama la \"computadora\", quien ejecuta servilmente estas reglas mecanicas deterministas (o como turing pone, \"de una manera desganada\").  mas precisamente, una maquina de turing consta de:  note que cada parte de la maquina — su estado y colecciones de simbolos — y sus acciones — imprimir, borrar, movimiento de la cinta — es finito, discreto y distinguible; es la cantidad potencialmente ilimitada de cinta lo que le da una cantidad ilimitada de espacio de almacenamiento.  una maquina de turing​ es un modelo computacional que realiza una lectura/escritura de manera automatica sobre una entrada llamada cinta, generando una salida en esta misma.  este modelo esta formado por un alfabeto de entrada y uno de salida, un simbolo especial llamado blanco (normalmente b, δ o 0), un conjunto de estados finitos y un conjunto de transiciones entre dichos estados. su funcionamiento se basa en una funcion de transicion, que recibe un estado inicial y una cadena de caracteres (la cinta, la cual puede ser infinita) pertenecientes al alfabeto de entrada. la maquina va leyendo una celda de la cinta en cada paso, borrando el simbolo en el que se encuentra posicionado su cabezal y escribiendo un nuevo simbolo perteneciente al alfabeto de salida, para luego desplazar el cabezal a la izquierda o a la derecha (solo una celda a la vez). esto se repite segun se indique en la funcion de transicion, para finalmente detenerse en un estado final o de aceptacion, representando asi la salida.  una maquina de turing con una sola cinta puede definirse como una 7-tupla  donde:​  existe en la literatura un abundante numero de definiciones alternativas, pero todas ellas tienen el mismo poder computacional, por ejemplo se puede añadir el simbolo s como simbolo de \"no movimiento\" en un paso de computo.  la maquina de turing consta de un cabezal lector/escritor y una cinta infinita en la que el cabezal lee el contenido, borra el contenido anterior y escribe un nuevo valor. las operaciones que se pueden realizar en esta maquina se limitan a:  el computo se determina a partir de una tabla de estados de la forma:  esta tabla toma como parametros el estado actual de la maquina y el caracter leido de la cinta, dando la direccion para mover el cabezal, el nuevo estado de la maquina y el valor a escribir en la cinta.  la memoria es la cinta de la maquina que se divide en espacios de trabajo denominados celdas, donde se pueden escribir y leer simbolos. inicialmente todas las celdas contienen un simbolo especial denominado \"blanco\". las instrucciones que determinan el funcionamiento de la maquina tienen la forma, \"si estamos en el estado x leyendo la posicion y, donde hay escrito el simbolo z, entonces este simbolo debe ser reemplazado por este otro simbolo, y pasar a leer la celda siguiente, bien a la izquierda o bien a la derecha\".  la maquina de turing puede considerarse como un automata capaz de reconocer lenguajes formales. en ese sentido, es capaz de reconocer los lenguajes recursivamente enumerables, de acuerdo a la jerarquia de chomsky. su potencia es, por tanto, superior a otros tipos de automatas, como el automata finito, o el automata con pila, o igual a otros modelos con la misma potencia computacional.   las maquinas de turing pueden representarse mediante grafos particulares, tambien llamados diagramas de estados finitos, de la siguiente manera: es una secuencia de la forma α 1 q α 2 q\\alpha _{2}\\!} donde α 1 , α 2 ∈ γ ∗ ,\\alpha _{2}\\in \\gamma ^{*}} y q ∈ q que escribe el estado de una maquina de turing. la cinta contiene la cadena α 1 α 2 \\alpha _{2}\\!} seguida de infinitos blancos. el cabezal señala el primer simbolo de α 2 \\!} .  por ejemplo, para la maquina de turing  con las transiciones  la descripcion instantanea para la cinta 1011 es:  definimos una maquina de turing sobre el alfabeto { 0 , 1 } } , donde 0 representa el simbolo blanco. la maquina comenzara su proceso situada sobre un simbolo \"1\" de una serie. la maquina de turing copiara el numero de simbolos \"1\" que encuentre hasta el primer blanco detras de dicho simbolo blanco. es decir, posiciona el cabezal sobre el 1 situado en el extremo izquierdo, doblara el numero de simbolos 1, con un 0 en medio. asi, si tenemos la entrada \"111\" devolvera \"1110111\", con \"1111\" devolvera \"111101111\", y sucesivamente.  el conjunto de estados es { s 1 , s 2 , s 3 , s 4 , s 5 } ,s_{2},s_{3},s_{4},s_{5}\\}\\!} y el estado inicial es s 1 \\!} . la tabla que describe la funcion de transicion es la siguiente:  el funcionamiento de una computacion de esta maquina puede mostrarse con el siguiente ejemplo (en negrita se resalta la posicion de la cabeza lectora/escritora):  la maquina realiza su proceso por medio de un bucle, en el estado inicial s 1 \\!} , reemplaza el primer 1 con un 0, y pasa al estado s 2 \\!} , con el que avanza hacia la derecha, saltando los simbolos 1 hasta un 0 (que debe existir), cuando lo encuentra pasa al estado s 3 \\!} , con este estado avanza saltando los 1 hasta encontrar otro 0 (la primera vez no habra ningun 1). una vez en el extremo derecho, añade un 1. despues comienza el proceso de retorno; con s 4 \\!} vuelve a la izquierda saltando los 1, cuando encuentra un 0 (en el medio de la secuencia), pasa a s 5 \\!} que continua a la izquierda saltando los 1 hasta el 0 que se escribio al principio. se reemplaza de nuevo este 0 por 1, y pasa al simbolo siguiente, si es un 1, se pasa a otra iteracion del bucle, pasando al estado s1 de nuevo. si es un simbolo 0, sera el simbolo central, con lo que la maquina se detiene al haber finalizado el computo.  una razon para aceptar la maquina de turing como un modelo general de computo es que el modelo que hemos definido anteriormente es equivalente a muchas versiones modificadas que en principio pareciera incrementar el poder computacional.  la funcion de transicion de la mt sencilla esta definida por  la cual puede ser modificada como  donde s significa «permanecer» o «esperar», es decir no mover el cabezal de lectura/escritura. por lo tanto, δ ( q , σ ) = ( p , σ ′ , s ) significa que se pasa del estado q al p, se escribe σ ′ en la celda actual y la cabeza se queda sobre la celda actual.  esta modificacion se denota al igual que una mt sencilla, lo que la hace diferente es que la cinta es infinita tanto por la derecha como por la izquierda, lo cual permite realizar transiciones iniciales como δ ( q 0 , x ) = ( q 1 , y , l ) ,x)=(q_{1},y,l)\\!} .  es aquella que mediante la cual cada celda de la cinta de una maquina sencilla se divide en subceldas. cada celda es asi capaz de contener varios simbolos de la cinta. por ejemplo, la cinta de la figura tiene cada celda subdividida en tres subceldas.  se dice que esta cinta tiene multiples pistas puesto que cada celda de esta maquina de turing contiene multiples caracteres, el contenido de las celdas de la cinta puede ser representado mediante n-tuplas ordenadas. los movimientos que realice esta maquina dependeran de su estado actual y de la n-tupla que represente el contenido de la celda actual. cabe mencionar que posee un solo cabezal al igual que una mt sencilla.  una mt con mas de una cinta consiste de un control finito con k cabezales lectores/escritores y k cintas. cada cinta es infinita en ambos sentidos. la mt define su movimiento dependiendo del simbolo que esta leyendo cada uno de sus cabezales, da reglas de sustitucion para cada uno de los simbolos y direccion de movimiento para cada uno de los cabezales. inicialmente la mt empieza con la entrada en la primera cinta y el resto de las cintas en blanco.  una mt multidimensional es aquella cuya cinta puede verse como extendiendose infinitamente en mas de una direccion, el ejemplo mas basico seria el de una maquina bidimensional cuya cinta se extenderia infinitamente hacia arriba, abajo, derecha e izquierda.  en la modificacion bidimensional de mt que se muestra en la figura tambien se agregan dos nuevos movimientos del cabezal {u,d} (es decir arriba y abajo). de esta forma la definicion de los movimientos que realiza el cabezal sera {l,r,u,d}.  la entrada de una maquina de turing viene determinada por el estado actual y el simbolo leido, un par (estado, simbolo), siendo el cambio de estado, la escritura de un nuevo simbolo y el movimiento del cabezal, las acciones a tomar en funcion de una entrada. en el caso de que para cada par (estado, simbolo) posible exista a lo sumo una posibilidad de ejecucion, se dira que es una maquina de turing determinista, mientras que en el caso de que exista al menos un par (estado, simbolo) con mas de una posible combinacion de actuaciones se dira que se trata de una maquina de turing no determinista.  la funcion de transicion δ en el caso no determinista, queda definida como sigue:  ¿como sabe una maquina no determinista que accion tomar de las varias posibles? hay dos formas de verlo: una es decir que la maquina es \"el mejor adivino posible\", esto es, que siempre elige la transicion que finalmente la llevara a un estado final de aceptacion. la otra es imaginarse que la maquina se \"clona\", bifurcandose en varias copias, cada una de las cuales sigue una de las posibles transiciones. mientras que una maquina determinista sigue un unico \"camino computacional\", una maquina no determinista tiene un \"arbol computacional\". si cualquiera de las ramas del arbol finaliza en un estado de aceptacion, se dice que la maquina acepta la entrada.  la capacidad de computo de ambas versiones es equivalente; se puede demostrar que dada una maquina de turing no determinista existe otra maquina de turing determinista equivalente, en el sentido de que reconoce el mismo lenguaje, y viceversa. no obstante, la velocidad de ejecucion de ambos formalismos no es la misma, pues si una maquina no determinista m reconoce una cierta palabra de tamaño n en un tiempo o ( t ( n ) ) , la maquina determinista equivalente reconocera la palabra en un tiempo o ( 2 t ( n ) ) )\\!} . es decir, el no determinismo permitira reducir la complejidad de la solucion de los problemas, permitiendo resolver, por ejemplo, problemas de complejidad exponencial en un tiempo polinomico.  el problema de la parada o problema de la detencion (halting problem en ingles) para maquinas de turing consiste en: dada una mt m y una palabra w, determinar si m terminara en un numero finito de pasos cuando se ejecuta usando w como entrada.  alan turing, en su famoso articulo «on computable numbers, with an application to the entscheidungsproblem» (1936), demostro que el problema de la parada de la maquina de turing es indecidible, en el sentido de que ninguna maquina de turing lo puede resolver.  toda maquina de turing puede codificarse como una secuencia binaria finita, es decir una secuencia finita de ceros y unos. para simplificar la codificacion, suponemos que toda mt tiene un unico estado inicial denotado por q 1 \\!} , y un unico estado final denotado q 2 \\!} . tendremos que para una mt m de la forma  todos estos simbolos se codifican como secuencias de unos:  los estados de una mt q 1 , q 2 , q 3 , … , q n ,q_{2},q_{3},\\ldots ,q_{n}\\!} se codifican tambien con secuencias de unos:  las directrices de desplazamiento r , l y s se codifican con 1, 11, 111, respectivamente. una transicion δ ( q , a ) = ( p , c , r ) se codifica usando ceros como separadores entre los estados, los simbolos del alfabeto de cinta y la directriz de desplazamiento r . asi, la transicion δ ( q 3 , s 2 ) = ( q 5 , s 3 , r ) ,s_{2})=(q_{5},s_{3},r)\\!} se codifica como  en general, la codificacion de una transicion cualquiera δ ( q i , s k ) = ( q j , s l , r ) ,s_{k})=(q_{j},s_{l},r)\\!} es  donde t ∈ { 1 , 2 , 3 } \\!} , segun la direccion sea d e r e c h a ( r ) , i z q u i e r d a ( l ) , e s p e r a r ( s ) (r),\\ \\mathrm {izquierda} (l),\\ \\mathrm {esperar} (s)} .  una mt se codifica escribiendo consecutivamente las secuencias de las modificaciones de todas sus transiciones. mas precisamente, la codificacion de una mt m es de la forma c 1 c 2 … c i c_{2}\\ldots c_{i}\\!} , donde c i \\!} es la codificacion de la i -esima transicion de m. puesto que el orden en que se representen las transiciones de una mt no es relevante, una misma mt tiene varias codificaciones diferentes. esto no representa ninguna desventaja practica o conceptual ya que no se pretende que las codificaciones sean unicas.  una maquina de turing computa una determinada funcion parcial de caracter definido e univoca, definida sobre las secuencias de posibles cadenas de simbolos de su alfabeto. en este sentido se puede considerar como equivalente a un programa de ordenador, o a un algoritmo. sin embargo es posible realizar una codificacion de la tabla que representa a una maquina de turing, a su vez, como una secuencia de simbolos en un determinado alfabeto; por ello, podemos construir una maquina de turing que acepte como entrada la tabla que representa a otra maquina de turing, y, de esta manera, simule su comportamiento.  en 1947, turing indico:  con esta codificacion de tablas como cadenas, se abre la posibilidad de que unas maquinas de turing se comporten como otras maquinas de turing. sin embargo, muchas de sus posibilidades son indecidibles, pues no admiten una solucion algoritmica. por ejemplo, un problema interesante es determinar si una maquina de turing cualquiera se parara en un tiempo finito sobre una determinada entrada; problema conocido como problema de la parada, y que turing demostro que era indecidible. en general, se puede demostrar que cualquier cuestion no trivial sobre el comportamiento o la salida de una maquina de turing es un problema indecidible.  el concepto de maquina de turing universal esta relacionado con el de un sistema operativo basico, pues puede ejecutar cualquier instruccion computable sobre el.​  en 1985, deutsch presento el diseño de la primera maquina cuantica basada en una maquina de turing. con este fin enuncio una nueva variante la tesis de church-turing dando lugar al denominado \"principio de church-turing-deutsch\".  la estructura de una maquina de turing cuantica es muy similar a la de una maquina de turing clasica. esta compuesta por los tres elementos clasicos:  el procesador contiene el conjunto de instrucciones que se aplica sobre el elemento de la cinta señalado por el cabezal. el resultado dependera del qubit de la cinta y del estado del procesador. el procesador ejecuta una instruccion por unidad de tiempo.  la cinta de memoria es similar a la de una maquina de turing tradicional. la unica diferencia es que cada elemento de la cinta de la maquina cuantica es un qubit. el alfabeto de esta nueva maquina esta formado por el espacio de valores del qubit. la posicion del cabezal se representa con una variable entera.  dos modelos matematicos equivalentes a los de las maquinas de turing son las maquinas de post, creadas en forma paralela por emil leon post,​ y el calculo lambda, introducido por alonzo church y stephen kleene en los años 1930, y tambien usado por church para demostrar en 1936 el entscheidungsproblem.   ",
        "snippet": "Una máquina de Turing es un dispositivo que manipula símbolos sobre una tira de cinta de acuerdo con una tabla de reglas. A pesar de su simplicidad, una máquina de Turing puede ser adaptada para simular la lógica de cualquier algoritmo de computador y es particularmente útil en la explicación de las funciones de una CPU dentro de un computador.",
        "enlaces_salientes": [
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Turing_(desambiguaci%C3%B3n)",
            "/wiki/Algoritmo",
            "/wiki/Computador",
            "/wiki/Unidad_central_de_procesamiento",
            "/wiki/Alan_Turing",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Computador",
            "/wiki/M%C3%A1quina_universal_de_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/L%C3%B3gica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Memoria_de_acceso_aleatorio",
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/David_Hilbert",
            "/wiki/Complejidad_computacional",
            "/wiki/Algoritmo",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/NP_(Complejidad_computacional)",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Alan_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/Siglo_XX",
            "/wiki/Memoria_de_trabajo",
            "/wiki/Conjunto_finito",
            "/wiki/Entscheidungsproblem",
            "/wiki/Registro_de_estado",
            "/wiki/Almacenamiento_de_computadora",
            "/wiki/Modelo_computacional",
            "/wiki/Lectura",
            "/wiki/Escritura",
            "/wiki/Entrada",
            "/wiki/Salida_(inform%C3%A1tica)",
            "/wiki/Alfabeto",
            "/wiki/Estado_(inform%C3%A1tica)",
            "/wiki/Funci%C3%B3n_de_transici%C3%B3n",
            "/wiki/Cadena_de_caracteres",
            "/wiki/Alfabeto",
            "/wiki/Funci%C3%B3n_de_transici%C3%B3n",
            "/wiki/Tupla",
            "/wiki/Estado_f%C3%ADsico",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Lenguaje_formal",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/Aut%C3%B3mata_con_pila",
            "/wiki/Grafo",
            "/wiki/Alfabeto",
            "/wiki/Estados",
            "/wiki/Arista_(teor%C3%ADa_de_grafos)",
            "/wiki/Grafo_dirigido",
            "/wiki/Complejidad_computacional",
            "/wiki/Cambio_de_estado",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/Problema_de_la_parada",
            "/wiki/Alan_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/Problema_indecidible",
            "/wiki/Binario",
            "/wiki/M%C3%A1quina_de_Turing_universal",
            "/wiki/Un%C3%ADvoca",
            "/wiki/Programa_(computaci%C3%B3n)",
            "/wiki/Algoritmo",
            "/wiki/Problema_indecidible",
            "/wiki/Problema_de_la_parada",
            "/wiki/Problema_indecidible",
            "/wiki/Sistema_operativo",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Qubit",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/Qubit",
            "/wiki/Qubit",
            "/wiki/Qubit",
            "/wiki/M%C3%A1quina_de_Post",
            "/wiki/Emil_Leon_Post",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Alonzo_Church",
            "/wiki/Stephen_Kleene",
            "/wiki/Entscheidungsproblem",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Sistema_combinacional",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/Aut%C3%B3mata_con_pila",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/M%C3%A1quina_de_Turing_universal",
            "/wiki/M%C3%A1quina_de_Turing_alternante",
            "/wiki/Problema_de_la_parada",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/Juego_de_la_vida",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/London_Mathematical_Society",
            "/wiki/Wiktionary",
            "/wiki/ISBN",
            "/wiki/Andrew_Hodges",
            "/wiki/ISBN",
            "/wiki/Marvin_Minsky",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Grafo",
        "titulo": "Grafo",
        "contenido": "en matematicas y ciencias de la computacion, un grafo (del griego grafos: dibujo, imagen)​ es un conjunto de objetos llamados vertices o nodos unidos por enlaces llamados aristas o arcos, que permiten representar relaciones binarias entre elementos de un conjunto.​ son objeto de estudio de la teoria de grafos.​  tipicamente, un grafo se representa graficamente como un conjunto de puntos (vertices o nodos) unidos por lineas (aristas o arcos).  desde un punto de vista practico, los grafos permiten estudiar las interrelaciones entre unidades que interactuan unas con otras. por ejemplo, una red de computadoras puede representarse y estudiarse mediante un grafo, en el cual los vertices representan terminales y las aristas representan conexiones (las cuales, a su vez, pueden ser cables o conexiones inalambricas).  practicamente cualquier problema puede representarse mediante un grafo, y su estudio trasciende a las diversas areas de las ciencias exactas y las ciencias sociales.  por lo general, un grafo se representa en forma de diagrama como un conjunto de puntos o circulos para los vertices, unidos por lineas o curvas para los bordes. los grafos son uno de los objetos de estudio de las matematicas discretas.  los bordes pueden ser dirigidos o no dirigidos. por ejemplo, si los vertices representan personas en una fiesta y hay un borde entre dos personas si se dan la mano, entonces este grafo no esta dirigido porque cualquier persona a puede darle la mano a una persona b solo si b tambien le da la mano a a. por el contrario, si una ventaja de una persona a a una persona b significa que a le debe dinero a b , entonces este grafo es dirigido, porque la deuda no es necesariamente reciproca.  los grafos son el tema basico estudiado por la teoria de grafos. la palabra «grafo» (en ingles, graph) fue utilizada por primera vez en este sentido por jj sylvester en 1878 debido a una relacion directa entre las matematicas y la estructura quimica (lo que el llamo una imagen quimico-grafica).​​  el primer articulo cientifico relativo a grafos fue escrito por el matematico suizo leonhard euler en 1736. euler se baso en su articulo en el problema de los puentes de konigsberg. la ciudad de kaliningrado, originalmente konigsberg, es famosa por sus siete puentes que unen ambas margenes del rio pregel con dos de sus islas. dos de los puentes unen la isla mayor con la margen oriental y otros dos con la margen occidental. la isla menor esta conectada a cada margen por un puente y el septimo puente une ambas islas. el problema planteaba lo siguiente: \"¿es posible dar un paseo comenzando desde cualquiera de estas regiones, pasando por todos los puentes, recorriendo solo una vez cada uno y regresando al mismo punto de partida?\"  abstrayendo este problema y planteandolo con la (entonces aun basica) teoria de grafos, euler consigue demostrar que el grafo asociado al esquema de puentes de konigsberg no tiene solucion, es decir, no es posible regresar al vertice de partida sin pasar por alguna arista dos veces.  de hecho, euler resuelve el problema mas general: ¿que condiciones debe satisfacer un grafo para garantizar que se puede regresar al vertice de partida sin pasar por la misma arista mas de una vez? si definimos como <<grado>> al numero de lineas que se encuentran en un punto de un grafo, entonces la respuesta al problema es que los puentes de un pueblo se pueden atravesar exactamente una vez si, salvo a lo sumo dos, todos los puntos tienen un grado par.  un grafo g es un par ordenado g = ( v , e ) , donde:  normalmente v suele ser finito. muchos resultados importantes sobre grafos no son aplicables para grafos infinitos.  se llama orden del grafo g a su numero de vertices, | v | .  el grado de un vertice o nodo v ∈ v es igual al numero de arcos que lo tienen como extremo.  un bucle es una arista que relaciona al mismo nodo; es decir, una arista donde el nodo inicial y el nodo final coinciden.  dos o mas aristas son paralelas si relacionan el mismo par de vertices.  un grafo no dirigido  o grafo propiamente dicho es un grafo g = ( v , e ) donde:  un par no ordenado es un conjunto de la forma { a , b } } , de manera que { a , b } = { b , a } =\\{b,a\\}} . para los grafos, estos conjuntos pertenecen al conjunto potencia de v , denotado p ( v ) }(v)} , y son de cardinalidad 2.  un grafo dirigido o digrafo es un grafo g = ( v , e ) donde:  dada una arista ( a , b ) , a es su nodo inicial y b su nodo final.  por definicion, los grafos dirigidos no contienen bucles.  un grafo mixto es aquel que se define con la capacidad de poder contener aristas dirigidas y no dirigidas. tanto los grafos dirigidos como los no dirigidos son casos particulares de este.  algunas aplicaciones requieren extensiones mas generales a las dos propuestas clasicas de grafos. aunque la definicion original los permite, segun la aplicacion concreta pueden ser validos o no. a veces v o e pueden ser un multiconjunto, pudiendo haber mas de una arista entre cada par de vertices. la palabra grafo (a secas) puede permitir o no multiples aristas entre cada par de vertices, dependiendo del autor de la referencia consultada. si se quiere remarcar la inexistencia de multiples aristas entre cada par de vertices (y en el caso no dirigido, excluir bucles) el grafo puede llamarse simple. por otra parte, si se quiere asegurar la posibilidad de permitir multiples aristas, el grafo puede llamarse multigrafo (a veces se utiliza el termino pseudografo para indicar que se permiten tanto bucles como multiples aristas entre cada par de vertices).  las dos representaciones principales de grafos son las siguientes:  la imagen es una representacion del siguiente grafo:  el hecho que el vertice 1 sea adyacente con el vertice 2 puede ser denotado como 1 ~ 2.  una definicion de grafo orientado es que es un grafo dirigido en el que a lo sumo uno de (x, y) y (y, x) pueden ser aristas del grafo. es decir, es un grafo dirigido que puede formarse como una orientacion de un grafo no dirigido (simple).  algunos autores utilizan \"grafo orientado\" con el mismo significado que \"grafo dirigido\".  algunos autores usan \"grafo orientado\" para referirse a cualquier orientacion de un grafo no dirigido o multigrafo dado.  un grafo regular es un grafo en el que cada vertice tiene el mismo numero de vecinos, es decir, cada vertice tiene el mismo grado. un grafo regular con vertices de grado k se llama grafo k -regular o grafo regular de grado k.  un grafo completo es un grafo en el que cada par de vertices esta unido por una arista. un grafo completo contiene todas las aristas posibles.  un grafo finito es un grafo en el que el conjunto de vertices y el conjunto de aristas son  conjuntos finitos. en caso contrario, se denomina grafo infinito.  comunmente en teoria de grafos se implica que los grafos discutidos son finitos. si los grafos son infinitos, suele indicarse especificamente.  en un grafo no dirigido, un par desordenado de vertices {x, y} se llama conectado si un camino lleva de x a y. en caso contrario, el par desordenado se denomina desconectado.  un grafo conexo es un grafo no dirigido en el que cada par desordenado de vertices del grafo esta conexo. en caso contrario, se denomina \"grafo desconectado\".  en un grafo dirigido, un par ordenado de vertices (x, y) se llama fuertemente conectado si un camino dirigido lleva de x a y. en caso contrario, el par ordenado se denomina debilmente conectado si un camino no dirigido va de x a y despues de reemplazar todas sus aristas dirigidas por aristas no dirigidas. en caso contrario, el par ordenado se denomina desconectado.  un grafo fuertemente conectado es un grafo dirigido en el que cada par ordenado de vertices del grafo esta fuertemente conectado. en caso contrario, se denomina grafo debilmente conectado si cada par ordenado de vertices del grafo esta debilmente conectado. en caso contrario, se denomina grafo desconectado.  un grafo k-conectado por vertices o grafo k-conectado por aristas' es un grafo en el que ningun conjunto de k - 1 vertices (respectivamente, aristas) que, cuando se eliminan, desconectan el grafo. un grafo conectado por vertices k a menudo se llama simplemente grafo conectado por k.  un grafo bipartito' es un grafo simple en el que el conjunto de vertices puede ser particionado en dos conjuntos, w y x, de modo que no hay dos vertices en w que compartan una arista comun y no hay dos vertices en x que compartan una arista comun. alternativamente, es un grafo con un numero cromatico de 2.  en un grafo bipartito completo, el conjunto de vertices es la union de dos conjuntos disjuntos, w y x, de modo que cada vertice en w es adyacente a cada vertice en x pero no hay aristas dentro de w o x.  un grafo de caminos o grafo lineal de orden n ≥ 2 es un grafo en el que los vertices se pueden enumerar en un orden v1, v2, ... , vn tal que las aristas son las {mset}} donde i = 1, 2, ..., n - 1. los grafos de sendero se pueden caracterizar como grafos conexos en los que el grado de todos los vertices menos dos es 2 y el grado de los dos vertices restantes es 1. si un grafo de sendero aparece como un subgraph de otro grafo, es un  camino en ese grafo.  un grafo plano es un grafo cuyos vertices y aristas se pueden dibujar en un plano de forma que ninguna de las aristas se cruce con otra.  un grafo de ciclo o grafo circular de orden n ≥ 3 es un grafo en el que los vertices se pueden enumerar en un orden v1, v2, ... , vn tal que las aristas son las {vi, vi+1} donde i = 1, 2, ... , n - 1, mas la arista {vn, v1}. los grafos de ciclo pueden caracterizarse como grafos conexos en los que el grado de todos los vertices es 2. si un grafo de ciclo aparece como subgrafo de otro grafo, es un ciclo o circuito en ese grafo.  un arbol es un grafo no dirigido en el que dos vertices cualesquiera estan conectados por exactamente una trayectoria, o equivalentemente un conectado no dirigido ciclico.  un bosque es un grafo no dirigido en el que dos vertices cualesquiera estan conectados por a lo sumo un camino, o equivalentemente un grafo aciclico no dirigido, o equivalentemente una union disjunta de arboles.  un poliarbol (o arbol dirigido o arbol orientado o red uniconexa) es un grafo aciclico dirigido (dag) cuyo grafo no dirigido subyacente es un arbol.  un polibosque (o bosque dirigido o bosque orientado) es un grafo aciclico dirigido cuyo grafo no dirigido subyacente es un bosque.  clases mas avanzadas de grafos son:  existen grafos que poseen propiedades destacables. algunos ejemplos basicos son:  una generalizacion de los grafos son los llamados hipergrafos. ",
        "snippet": "En matemáticas y ciencias de la computación, un grafo (del griego grafos: dibujo, imagen)[1]​ es un conjunto de objetos llamados vértices o nodos unidos por enlaces llamados aristas o arcos, que permiten representar relaciones binarias entre elementos de un conjunto.[2]​ Son objeto de estudio de la teoría de grafos.[3]​",
        "enlaces_salientes": [
            "/wiki/Grafo",
            "/wiki/Grafo",
            "/wiki/Grafo",
            "/wiki/Grafo_(desambiguaci%C3%B3n)",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Idioma_griego",
            "/wiki/V%C3%A9rtice_(teor%C3%ADa_de_grafos)",
            "/wiki/V%C3%A9rtice_(teor%C3%ADa_de_grafos)",
            "/wiki/Arista_(teor%C3%ADa_de_grafos)",
            "/wiki/Arista_(teor%C3%ADa_de_grafos)",
            "/wiki/Relaci%C3%B3n_binaria",
            "/wiki/Conjunto",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Red_de_computadoras",
            "/wiki/Terminal_de_computadora",
            "/wiki/Cable",
            "/wiki/Red_inal%C3%A1mbrica",
            "/wiki/Ciencias_exactas",
            "/wiki/Ciencias_sociales",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Suiza",
            "/wiki/Leonhard_Euler",
            "/wiki/1736",
            "/wiki/Problema_de_los_puentes_de_K%C3%B6nigsberg",
            "/wiki/Kaliningrado",
            "/wiki/Puente",
            "/wiki/R%C3%ADo_Pregolia",
            "/wiki/Par_ordenado",
            "/wiki/Conjunto",
            "/wiki/V%C3%A9rtice_(teor%C3%ADa_de_grafos)",
            "/wiki/Arista_(teor%C3%ADa_de_grafos)",
            "/wiki/Relaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Conjunto_finito",
            "/wiki/Grado_(teor%C3%ADa_de_grafos)",
            "/wiki/Bucle_(teor%C3%ADa_de_grafos)",
            "/wiki/Aristas_m%C3%BAltiples",
            "/wiki/Grafo_no_dirigido",
            "/wiki/Conjunto_potencia",
            "/wiki/Cardinalidad",
            "/wiki/Grafo_dirigido",
            "/wiki/Par_ordenado",
            "/wiki/Multiconjunto",
            "/wiki/Multigrafo",
            "/wiki/Problema_del_viajante",
            "/wiki/Algoritmo_de_Dijkstra",
            "/wiki/Matriz_de_adyacencia",
            "/wiki/Lista_de_adyacencia",
            "/wiki/Teor%C3%ADa_de_las_categor%C3%ADas",
            "/wiki/Morfismo",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/M%C3%A1quinas_de_estado_finito",
            "/wiki/Relaci%C3%B3n_binaria",
            "/wiki/Grafo_regular",
            "/wiki/Grafo_completo",
            "/wiki/Conjunto_finito",
            "/wiki/Conectividad_(teor%C3%ADa_de_grafos)",
            "/wiki/Grafo_bipartito",
            "/wiki/Grafo_bipartito",
            "/wiki/Partici%C3%B3n_de_un_conjunto",
            "/wiki/N%C3%BAmero_crom%C3%A1tico",
            "/wiki/Grafo_bipartito_completo",
            "/wiki/Grafo_camino",
            "/wiki/Camino_(teor%C3%ADa_de_grafos)",
            "/wiki/Grafo_plano",
            "/wiki/Grafo_ciclo",
            "/wiki/%C3%81rbol_(teor%C3%ADa_de_grafos)",
            "/wiki/V%C3%A9rtices_(teor%C3%ADa_de_grafos)",
            "/wiki/Camino_(teor%C3%ADa_de_grafos)",
            "/wiki/Conectividad_(teor%C3%ADa_de_grafos)",
            "/wiki/Ciclo_(teor%C3%ADa_de_grafos)",
            "/wiki/Poli%C3%A1rbol",
            "/wiki/Grafo_ac%C3%ADclico_dirigido",
            "/wiki/Grafo_de_Petersen",
            "/wiki/Grafo_perfecto",
            "/wiki/Grafo_sim%C3%A9trico",
            "/wiki/Grafo_distancia-transitivo",
            "/wiki/Grafo_nulo",
            "/wiki/Grafo_nulo",
            "/wiki/Grafo_trivial",
            "/wiki/Bucle_(teor%C3%ADa_de_grafos)",
            "/wiki/Multigrafo",
            "/wiki/Bicondicional",
            "/wiki/Grafo_completo",
            "/wiki/Grafo_bipartito",
            "/wiki/Partici%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Grafo_bipartito_completo",
            "/wiki/Partici%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Grafo_plano",
            "/wiki/Coordenadas_cartesianas",
            "/wiki/%C3%81rbol_(teor%C3%ADa_de_grafos)",
            "/wiki/Grafo_conexo",
            "/wiki/Grafo_ciclo",
            "/wiki/Grafo_rueda",
            "/wiki/Grafo_perfecto",
            "/wiki/Coloraci%C3%B3n_de_grafos",
            "/wiki/Clique",
            "/wiki/Hipergrafo",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Grafo_social",
            "/wiki/Grafo_de_conocimiento",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Wayback_Machine",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Wayback_Machine",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/JSTOR",
            "/wiki/CRC_Press",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Estructura_de_datos",
        "titulo": "Estructura de datos",
        "contenido": "en ciencias de la computacion, una estructura de datos​ es una forma particular de organizar informacion en un computador para que pueda ser utilizada de manera eficiente.​​​ diferentes tipos de estructuras de datos son adecuados para diferentes tipos de aplicaciones, y algunos son altamente especializados para tareas especificas.  las estructuras de datos son medios para manejar grandes cantidades de informacion de manera eficiente para usos tales como grandes bases de datos y servicios de indizacion de internet. por lo general, las estructuras de datos eficientes son clave para diseñar algoritmos eficientes. algunos metodos formales de diseño de lenguajes de programacion destacan las estructuras de datos, en lugar de los algoritmos, como el factor clave de organizacion en el diseño de software. mas precisamente, una estructura de datos es una coleccion de valores, las relaciones entre ellos y las funciones y operaciones que se pueden aplicar a los datos,​ es decir, es una estructura algebraica de datos.  las estructuras de datos se basan generalmente en la capacidad de un ordenador para recuperar y almacenar datos en cualquier lugar de su memoria.  las estructuras de datos pueden ser de diferentes tipos, dependiendo de la tecnica que se utilice para su almacenamiento y recuperacion, estos tipos son los siguientes:  segun la secuencia que se presenta entre cada elemento al momento de realizar el recorrido entre los elementos de la estructura de datos, esta se puede clasificar en los siguientes tipos:  existen numerosos tipos de estructuras de datos, generalmente construidas sobre otras mas simples:  la mayoria de los lenguajes ensambladores y algunos lenguajes de bajo nivel, tales como bcpl, carecen de soporte de estructuras de datos. en cambio, muchos lenguajes de alto nivel y algunos lenguajes ensambladores de alto nivel, tales como masm, tienen algun tipo de soporte incorporado para ciertas estructuras de datos, tales como los registros y arreglos. por ejemplo, los lenguajes c y pascal soportan estructuras y registros, respectivamente, ademas de arreglos y matrices multidimensionales.​​  la mayoria de los lenguajes de programacion disponen de algun tipo de biblioteca o mecanismo que permita el uso de estructuras de datos en los programas. los lenguajes modernos por lo general vienen con bibliotecas estandar que implementan las estructuras de datos mas comunes. ejemplos de ello son la biblioteca  standard template library de c++, las colecciones de java​ y las bibliotecas .net de microsoft.  en programacion, una estructura de datos puede ser declarada inicialmente escribiendo una palabra reservada, luego un identificador para la estructura y un nombre para cada uno de sus miembros, sin olvidar los tipos de datos que estos representan. generalmente, cada miembro se separa con algun tipo de operador, caracter o palabra reservada.  en el lenguaje de programacion pascal, es posible crear una estructura de datos de la forma mencionada. la sintaxis basica es:  para acceder a los miembros de una estructura, primero se debe crear una referencia a esta, generalmente con una variable de tipo; luego se pueden editar y obtener los datos de los miembros libremente. ",
        "snippet": "En ciencias de la computación, una estructura de datos[1]​ es una forma particular de organizar información en un computador para que pueda ser utilizada de manera eficiente.[2]​[3]​[4]​ Diferentes tipos de estructuras de datos son adecuados para diferentes tipos de aplicaciones, y algunos son altamente especializados para tareas específicas.",
        "enlaces_salientes": [
            "/wiki/Estructura_de_datos",
            "/wiki/Estructura_de_datos",
            "/wiki/Estructura_de_datos",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Aplicaci%C3%B3n_inform%C3%A1tica",
            "/wiki/Base_de_datos",
            "/wiki/Indizaci%C3%B3n",
            "/wiki/Internet",
            "/wiki/Algoritmo",
            "/wiki/Dise%C3%B1o_de_software",
            "/wiki/Estructura_algebraica",
            "/wiki/Datos",
            "/wiki/Computadora_electr%C3%B3nica",
            "/wiki/Recuperaci%C3%B3n_de_datos",
            "/wiki/Almacenamiento_de_datos",
            "/wiki/Memoria_(inform%C3%A1tica)",
            "/wiki/Vector_(inform%C3%A1tica)",
            "/wiki/Tabla_hash",
            "/wiki/Registro_(estructura_de_datos)",
            "/wiki/Uni%C3%B3n_de_datos",
            "/wiki/Tipo_variante",
            "/wiki/Conjunto_(programaci%C3%B3n)",
            "/wiki/Multiconjunto",
            "/wiki/Grafo_(estructura_de_datos)",
            "/wiki/V%C3%A9rtice_(teor%C3%ADa_de_grafos)",
            "/wiki/%C3%81rbol_(inform%C3%A1tica)",
            "/wiki/Clase_(inform%C3%A1tica)",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Lenguaje_de_bajo_nivel",
            "/wiki/BCPL",
            "/wiki/Lenguaje_de_programaci%C3%B3n_de_alto_nivel",
            "/wiki/MASM",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Biblioteca_(inform%C3%A1tica)",
            "/wiki/Standard_Template_Library",
            "/wiki/C%2B%2B",
            "/wiki/.NET_Framework",
            "/wiki/Microsoft",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Palabra_reservada",
            "/wiki/Car%C3%A1cter_(tipo_de_dato)",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/National_Institute_of_Standards_and_Technology",
            "/wiki/ISBN",
            "/wiki/Algoritmo",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Tipo_de_dato",
            "/wiki/Uni%C3%B3n_de_datos",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_paralelo",
        "titulo": "Algoritmo paralelo",
        "contenido": "en las ciencias de la computacion, un algoritmo paralelo, en oposicion a los algoritmos clasicos o algoritmos secuenciales, es un algoritmo que puede ser ejecutado por partes en el mismo instante de tiempo por varias unidades de procesamiento, para finalmente unir todas las partes y obtener el resultado correcto.  algunos algoritmos son facilmente divisibles en partes; como por ejemplo, un algoritmo que calcule todos los numeros primos entre 1 y 100, donde se podria dividir los numeros originales en subconjuntos y calcular los primos para cada uno de los subconjuntos de los numeros originales; al final, uniriamos todos los resultados y tendriamos la solucion final del algoritmo. otro ejemplo, puede ser el calculo de pi en paralelo.  por el contrario, a veces los problemas no son tan facilmente paralelizables, de ahi que estos problemas se conozcan como problemas inherentemente secuenciales. como ejemplo de estos metodos tendriamos los metodos numericos iterativos como el metodo de newton o el problema de los tres cuerpos. por otro lado, algunos problemas son dificilmente paralelizables, aunque tengan una estructura recursiva. como ejemplo de esto ultimo tendriamos la busqueda primero en profundidad en un grafo.  los algoritmos paralelos son importantes porque es mas rapido tratar grandes tareas de computacion mediante la paralelizacion que mediante tecnicas secuenciales. esta es la forma en que se trabaja en el desarrollo de los procesadores modernos, ya que es mas dificil incrementar la capacidad de procesamiento con un unico procesador que aumentar su capacidad de computo mediante la inclusion de unidades en paralelo, logrando asi la ejecucion de varios flujos de instrucciones dentro del procesador. pero hay que ser cauto con la excesiva paralelizacion de los algoritmos ya que cada algoritmo paralelo tiene una parte secuencial y debido a esto, los algoritmos paralelos puedes llegar a un punto de saturacion (ver ley de amdahl). por todo esto, a partir de cierto nivel de paralelismo, añadir mas unidades de procesamiento puede solo incrementar el coste y la disipacion de calor.  el coste o complejidad de los algoritmos secuenciales se estima en terminos del espacio (memoria) y tiempo (ciclos de procesador) que requiera. los algoritmos paralelos tambien necesitan optimizar la comunicacion entre diferentes unidades de procesamiento. esto se consigue mediante la aplicacion de dos paradigmas de programacion y diseño de procesadores distintos: memoria compartida o paso de mensajes.  la tecnica memoria compartida necesita del uso de cerrojos en los datos para impedir que se modifique simultaneamente por dos procesadores, por lo que se produce un coste extra en ciclos de cpu desperdiciados y ciclos de bus. tambien obliga a serializar alguna parte del algoritmo.  la tecnica paso de mensajes usa canales y mensajes pero esta comunicacion añade un coste al bus, memoria adicional para las colas y los mensajes y latencia en el mensaje. los diseñadores de procesadores paralelos usan buses especiales para que el coste de la comunicacion sea pequeño pero siendo el algoritmo paralelo el que decide el volumen del trafico.  finalmente, una subclase de los algoritmos paralelos, los algoritmos distribuidos son algoritmos diseñados para trabajar en entornos tipo clusters y de computacion distribuida, donde se usan otras tecnicas, fuera del alcance de los algoritmos paralelos clasicos.  evaluacion de tecnicas de deteccion de errores en programas concurrentes, frati, fernando emmanuel. 1 de abril de 2014, 51 paginas. ",
        "snippet": "En las ciencias de la computación, un algoritmo paralelo, en oposición a los algoritmos clásicos o algoritmos secuenciales, es un algoritmo que puede ser ejecutado por partes en el mismo instante de tiempo por varias unidades de procesamiento, para finalmente unir todas las partes y obtener el resultado correcto.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_paralelo",
            "/wiki/Algoritmo_paralelo",
            "/wiki/Algoritmo_paralelo",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/M%C3%A9todos_num%C3%A9ricos",
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/Problema_de_los_tres_cuerpos",
            "/wiki/Algoritmo_recursivo",
            "/wiki/Ley_de_Amdahl",
            "/wiki/Memoria_compartida",
            "/wiki/Interfaz_de_Paso_de_Mensajes",
            "/wiki/Memoria_compartida",
            "/wiki/Interfaz_de_Paso_de_Mensajes",
            "/wiki/Cluster_(inform%C3%A1tica)",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Programaci%C3%B3n_paralela",
            "/wiki/Programaci%C3%B3n_concurrente",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/L%C3%B3gica_matem%C3%A1tica",
        "titulo": "Lógica matemática",
        "contenido": "el lenguaje, tambien llamada logica simbolica, logica teoretica, logica formal o logistica,​ es el estudio formal y simbolico de la logica y su aplicacion a algunas areas de la matematica y la ciencia. comprende la aplicacion de las tecnicas de la logica formal a la construccion y el desarrollo de las matematicas y el razonamiento matematico, y conversamente la aplicacion de tecnicas matematicas a la representacion y el analisis de la logica formal. la investigacion en logica matematica ha jugado un papel crucial en el estudio de los fundamentos de las matematicas.  la logica matematica estudia la inferencia mediante la construccion de sistemas formales como la logica proposicional, la logica de primer orden o la logica modal. estos sistemas capturan las caracteristicas esenciales de las inferencias validas en los lenguajes naturales, pero al ser estructuras formales susceptibles de analisis matematico, permiten realizar demostraciones rigurosas sobre ellas.  la logica matematica se suele dividir en cuatro areas: teoria de modelos, teoria de la demostracion, teoria de conjuntos y teoria de la computabilidad. la teoria de la demostracion y la teoria de modelos fueron el fundamento de la logica matematica. la teoria de conjuntos se origino en el estudio del infinito por georg cantor y ha sido la fuente de muchos de los temas mas desafiantes e importantes de la logica matematica, desde el teorema de cantor, el axioma de eleccion y la cuestion de la independencia de la hipotesis del continuo, al debate moderno sobre grandes axiomas cardinales. la logica matematica tiene estrechas conexiones con las ciencias de la computacion. la teoria de la computabilidad captura la idea de la computacion en terminos logicos y aritmeticos. sus logros mas clasicos son la indecidibilidad del entscheidungsproblem de alan turing y su presentacion de la tesis de church-turing. hoy en dia, la teoria de la computabilidad se ocupa principalmente del problema mas refinado de las clases de complejidad (¿cuando es un problema eficientemente solucionable?) y de la clasificacion de los grados de insolubilidad.  la logica matematica tambien estudia las definiciones de nociones y objetos matematicos basicos como conjuntos, numeros, demostraciones y algoritmos. la logica matematica estudia las reglas de deduccion formales, las capacidades expresivas de los diferentes lenguajes formales y las propiedades metalogicas de los mismos.  en un nivel elemental, la logica proporciona reglas y tecnicas para determinar si es o no valido un argumento dado dentro de un determinado sistema formal. en un nivel avanzado, la logica matematica se ocupa de la posibilidad de axiomatizar las teorias matematicas, de clasificar su capacidad expresiva, y desarrollar metodos computacionales utiles en sistemas formales. la teoria de la demostracion y la matematica inversa son dos de los razonamientos mas recientes de la logica matematica abstracta. debe señalarse que la logica matematica se ocupa de sistemas formales que pueden no ser equivalentes en todos sus aspectos, por lo que la logica matematica no es un metodo para descubrir verdades del mundo fisico real, sino solo una fuente posible de modelos logicos aplicables a teorias cientificas, muy especialmente a la matematica convencional.   por otra parte, la logica matematica no estudia el concepto de razonamiento humano general o el proceso creativo de construccion de demostraciones matematicas mediante argumentos rigurosos pero con lenguaje informal con algunos signos o diagramas, sino solo de demostraciones y razonamientos que se pueden formalizar por completo.  la mathematics subject classification divide la logica matematica en las siguientes areas:  en algunos casos hay conjuncion de intereses con la informatica teorica, pues muchos pioneros de la informatica, como alan turing, fueron matematicos y logicos. asi, el estudio de la semantica de los lenguajes de programacion procede de la teoria de modelos, asi como tambien la verificacion de programas y el caso particular de la tecnica del model checking. tambien el isomorfismo de churry-howard entre pruebas y programas se corresponde con la teoria de pruebas, donde la logica intuicionista y la logica lineal son especialmente significativas.  algunos sistemas formales como el calculo lambda y la logica combinatoria entre otras han devenido en autenticos lenguajes de programacion, creando nuevos paradigmas como son la programacion funcional y la programacion logica.  un sistema formal o sistema logico es un sistema abstracto compuesto por un lenguaje formal, axiomas, reglas de inferencia y a veces una semantica formal, que se utiliza para deducir o demostrar teoremas y dar una definicion rigurosa del concepto de demostracion. un sistema formal es una formalizacion rigurosa y completa del concepto de sistema axiomatico, los cuales se pueden expresar en lenguaje formal o en lenguaje natural formalizado. al crear un sistema formal se pretende capturar y abstraer la esencia de determinadas caracteristicas del mundo real, en un modelo conceptual expresado en un determinado lenguaje formal. algunos de los sistemas formales mas conocidos son la logica proposicional, la logica de primer orden y la logica modal.  en la teoria de la demostracion, las demostraciones formales se pueden expresar en el lenguaje de los sistemas formales, consistentes en axiomas y reglas de inferencia. los teoremas pueden ser obtenidos por medio de demostraciones formales. este punto de vista de las matematicas ha sido denominado formalista; aunque en muchas ocasiones este termino conlleva una acepcion peyorativa. en ese sentido, david hilbert creo la metamatematica para estudiar los sistemas formales, entendiendo que el lenguaje utilizado para ello, denominado metalenguaje era distinto del lenguaje del sistema formal que se pretendia estudiar, al que se llama lenguaje objeto.  un sistema asi es la reduccion de un lenguaje formalizado a meros simbolos, lenguaje formalizado y simbolizado sin contenido material alguno; un lenguaje reducido a mera forma que se expresa mediante formulas que reflejan las relaciones sintacticas entre los simbolos y las reglas de formacion y transformacion que permiten construir las formulas del sistema y pasar de una formula a otra.​  una teoria axiomatica es un conjunto de formulas en un determinado lenguaje formal y todas las formulas deducibles de dichas expresiones mediante las reglas de inferencia posibles en dicho sistema formal. el objetivo de las teorias axiomaticas es construir sistemas formales que representen las caracteristicas esenciales de ramas enteras de las matematicas. si se selecciona un conjunto mas amplio o menos amplio de axiomas el conjunto de teoremas deducibles cambian. el interes de la teoria de modelos es que en un modelo en que satisfagan los axiomas de determinada teoria tambien se satisfacen los teoremas deducibles de dicha teoria. es decir, si un teorema es deducible en una cierta teoria, entonces ese teorema es universalmente valido en todos los modelos que satisfacen los axiomas. esto es interesante porque en principio la clase de modelos que satisface una cierta teoria es dificil de conocer, ya que las teorias matematicas interesantes en general admiten toda clase infinita de modelos no isomorfos, por lo que su clasificacion en general resulta dificilmente abordable si no existe un sistema formal y un conjunto de axiomas que caracterice los diferentes tipos de modelos.  en el siglo xx, hilbert y otros sostuvieron que la matematica es un sistema formal. pero en 1931, kurt godel demostro que ningun sistema formal con suficiente poder expresivo para capturar la aritmetica de peano puede ser a la vez consistente y completo. el teorema de la incompletitud de godel, junto con la demostracion de alonzo church de que la matematica tampoco es decidible, termino con el programa de hilbert. sin embargo,  a pesar de sus limitaciones, el enfoque sigue siendo ampliamente usado, basicamente porque no se ha encontrado ninguna alternativa mejor al enfoque formalista de hilbert y la pretension de trabajar en el seno de teorias matematicas explicitamente axiomatizadas, aun con sus limitaciones.  en matematica, teoria de modelos es el estudio de (clases de) estructuras matematicas tales como grupos, cuerpos, grafos, o incluso universos de teoria de conjuntos, en relacion con las teorias axiomaticas y la logica matematica. la teoria de modelos permite atribuir una interpretacion semantica a las expresiones puramente formales de los lenguajes formales. ademas permite estudiar en si mismos los conjuntos de axiomas, su completitud, consistencia, independencia mutua, y permiten introducir un importante numero de cuestiones metalogicas.  la teoria de la computabilidad o teoria de la recursion es la parte de la computacion que estudia los problemas de decision que se pueden resolver con un algoritmo o equivalentemente con una maquina de turing. las preguntas fundamentales de la teoria de la computabilidad son:  la teoria de conjuntos es una rama de la logica matematica que estudia las propiedades y relaciones de los conjuntos: colecciones abstractas de objetos, consideradas como objetos en si mismas. los conjuntos y sus operaciones mas elementales son una herramienta basica que permite formular de cualquier otra teoria matematica.​  la teoria de los conjuntos es lo suficientemente flexible y general como para construir el resto de objetos y estructuras de interes en matematicas: numeros, funciones, figuras geometricas, etc; gracias a las herramientas de la logica, permite estudiar los fundamentos.  ademas, la propia teoria de conjuntos es objeto de estudio per se, no solo como herramienta auxiliar, en particular las propiedades y relaciones de los  conjuntos infinitos. en esta disciplina es habitual que se presenten casos de propiedades indemostrables o contradictorias, como la hipotesis del continuo o la existencia de algun cardinal inaccesible. por esta razon, sus razonamientos y tecnicas se apoyan en gran medida en la logica matematica.​  el desarrollo historico de la teoria de conjuntos se atribuye a georg cantor, que comenzo a investigar cuestiones conjuntistas (puras) del infinito en la segunda mitad del siglo xix, precedido por algunas ideas de bernhard bolzano e influido por richard dedekind. el descubrimiento de las paradojas de la teoria cantoriana de conjuntos, formalizada por gottlob frege, propicio los trabajos de bertrand russell, ernst zermelo y abraham fraenkel.​  el uso mas temprano de matematicas y de geometria en relacion con la logica y la filosofia se remonta a los griegos antiguos tales como euclides, platon, y aristoteles. muchos otros filosofos antiguos y medievales aplicaron ideas y metodos matematicos a sus afirmaciones filosoficas.  en el siglo xviii se hicieron algunos intentos de tratar las operaciones logicas formales de una manera simbolica por parte de algunos filosofos matematicos como lambert, pero su labor permanecio desconocida y aislada. tambien por parte de leibniz  que desarrollo la idea de un calculus ratiocinator, un sistema de reglas para simplificar oraciones compuestas.  a partir de la segunda mitad del siglo xix, la logica seria revolucionada profundamente. en 1847, george boole publico un breve tratado titulado el analisis matematico de la logica, y en 1854 otro mas importante titulado las leyes del pensamiento. la idea de boole fue construir a la logica como un calculo en el que los valores de verdad se representan mediante el f (falsedad) y la v (verdad), y a los que se les aplican operaciones matematicas como la suma y la multiplicacion.  en el ultimo tercio del siglo xix la logica va a encontrar su transformacion mas profunda de la mano de las investigaciones matematicas y logicas, junto con el desarrollo de la investigacion de las estructuras profundas del lenguaje, la linguistica, convirtiendose definitivamente en una ciencia formal. es una ciencia formal, ya que estudia las ideas y constituye una herramienta conceptual para todas las otras ciencias y areas del conocimiento. y forma parte de un conjunto sistematico de conocimientos racionales y coherentes, que se ocupan del estudio de los procesos logicos y matematicos,  al mismo tiempo, augustus de morgan publica en 1847 su obra logica formal, donde introduce las leyes de de morgan e intenta generalizar la nocion de silogismo. otro importante contribuyente ingles fue john venn, quien en 1881 publico su libro logica simbolica, donde introdujo los famosos diagramas de venn.  charles sanders peirce y ernst schroder tambien hicieron importantes contribuciones.  sin embargo, la verdadera revolucion de la logica vino de la mano de gottlob frege, quien frecuentemente es considerado como el logico mas importante de la historia, junto con aristoteles. en su trabajo de 1879, la conceptografia, frege ofrece por primera vez un sistema completo de logica de predicados y calculo proposicional. tambien desarrolla la idea de un lenguaje formal y define la nocion de prueba. estas ideas constituyeron una base teorica fundamental para el desarrollo de las computadoras y las ciencias de la computacion, entre otras cosas. pese a esto, los contemporaneos de frege pasaron por alto sus contribuciones, probablemente a causa de la complicada notacion que desarrollo el autor. en 1893 y 1903, frege publica en dos volumenes las leyes de la aritmetica, donde intenta deducir toda la matematica a partir de la logica, en lo que se conoce como el proyecto logicista. su sistema y su aplicacion a la teoria de conjuntos, sin embargo, contenia una contradiccion (la paradoja de russell).  logica matematica fue el nombre dado por giuseppe peano para esta disciplina. en esencia, es la logica de aristoteles, pero desde el punto de vista de una nueva notacion, mas abstracta, tomada del algebra.  ] ]  en el siglo xx hubo uno de los enormes desarrollos en logica. a partir del siglo xx, la logica paso a estudiarse por su interes intrinseco, y no solo por sus virtudes como propedeutica, por lo que se estudio a niveles mucho mas abstractos.  en 1910, bertrand russell y alfred north whitehead publican principia mathematica, un trabajo monumental en el que logran gran parte de la matematica a partir de la logica, evitando caer en las paradojas en las que cayo frege. se suponia que las teorias matematicas eran tautologias logicas, y el programa debia mostrar esto por medio de una reduccion de la matematica a la logica. los autores reconocen el merito de frege en el prefacio. en contraste con el trabajo de frege, principia mathematica tuvo un exito rotundo, y llego a considerarse uno de los trabajos de no ficcion mas importantes e influyentes de todo el siglo xx. principia mathematica utiliza una notacion inspirada en la de giuseppe peano, parte de la cual todavia es muy utilizada hoy en dia.  en 1912 c. i. lewis publica conditionals and the algebra of logic, justo despues de los principia mathematica de russell y whitehead. en 1918 publica a survey of symbolic logic en donde propone un nuevo condicional mas adecuado para recoger el significado de la expresion «si... entonces» del lenguaje natural. lewis lo llama implicacion estricta. el nuevo condicional requiere, para ser verdadero, una relacion mas fuerte entre el antecedente y el consecuente que el condicional clasico.  en 1920 david hilbert propuso de forma explicita un proyecto de investigacion (en metamatematica, como se llamo entonces) que acabo siendo conocido como programa de hilbert. queria que la matematica fuese formulada sobre unas bases solidas y completamente logicas. el proyecto fue refutado por los teoremas de incompletitud de godel. tanto la declaracion del programa de hilbert como su refutacion por godel dependian de su trabajo estableciendo el segundo ambito de la logica matematica, la aplicacion de las matematicas a la logica en la forma de la teoria de la demostracion. a pesar de la naturaleza negativa de los teoremas de la incompletitud, el teorema de la complejidad de godel, un resultado en la teoria de modelos y otra aplicacion de las matematicas a la logica, puede ser entendido como una demostracion del logismo cercano: toda teoria matematica rigurosamente definida puede ser capturada exactamente por una teoria de primer orden. el calculo de la prueba de frege es suficiente para describir toda la matematica, aunque no sea equivalente a ella.  el origen de los modelos abstractos de computacion se encuadra en los años 1930 (antes de que existieran los ordenadores modernos), en el trabajo de los logicos alonzo church, kurt godel, stephen kleene, emil leon post, haskell curry y alan turing. estos trabajos iniciales han tenido una profunda influencia, tanto en el desarrollo teorico como en abundantes aspectos de la practica de la computacion; previendo incluso la existencia de ordenadores de proposito general, la posibilidad de interpretar programas, la dualidad entre software y hardware, y la representacion de lenguajes por estructuras formales basados en reglas de produccion.  la deduccion natural fue introducida por gerhard gentzen en su trabajo investigaciones sobre la inferencia logica (untersuchungen uber das logische schliessen), publicado en 1934-1935.  en los años 1940 alfred tarski comenzo a desarrollar junto a sus discipulos el algebra relacional, en la que pueden expresarse tanto la teoria axiomatica de conjuntos como la aritmetica de peano. tambien desarrollo junto a sus discipulos las algebras cilindricas, que son a la logica de primer orden lo que el algebra booleana a la logica proposicional. en 1941 publico en ingles uno de los manuales de logica mas acreditados, introduction to logic and to the methodology of deductive sciences.  noam chomsky en 1956 propone una clasificacion jerarquica de distintos tipos de gramaticas formales que generan lenguajes formales llamada jerarquia de chomsky.  si bien a la luz de los sistemas contemporaneos la logica aristotelica puede parecer equivocada e incompleta, jan łukasiewicz mostro que, a pesar de sus grandes dificultades, la logica aristotelica era consistente, si bien habia que interpretarse como logica de clases, lo cual no es pequeña modificacion. por ello la silogistica practicamente no tiene uso actualmente.  ademas de la logica proposicional y la logica de predicados, el siglo xx vio el desarrollo de muchos otros sistemas formales; entre los que destacan las muchas logicas modales. ",
        "snippet": "El lenguaje, también llamada lógica simbólica, lógica teorética, lógica formal o logística,[1]​ es el estudio formal y simbólico de la lógica y su aplicación a algunas áreas de la matemática y la ciencia. Comprende la aplicación de las técnicas de la lógica formal a la construcción y el desarrollo de las matemáticas y el razonamiento matemático, y conversamente la aplicación de técnicas matemáticas a la representación y el análisis de la lógica formal. La investigación en lógica matemática ha jugado un papel crucial en el estudio de los fundamentos de las matemáticas.",
        "enlaces_salientes": [
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/L%C3%B3gica",
            "/wiki/Ciencia",
            "/wiki/Fundamentos_de_las_matem%C3%A1ticas",
            "/wiki/Inferencia",
            "/wiki/Sistema_formal",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/Lenguaje_natural",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Georg_Cantor",
            "/wiki/Teorema_de_Cantor",
            "/wiki/Axioma_de_elecci%C3%B3n",
            "/wiki/Hip%C3%B3tesis_del_continuo",
            "/wiki/Axiomas",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Entscheidungsproblem",
            "/wiki/Alan_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Definici%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Conjunto",
            "/wiki/N%C3%BAmero",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Algoritmo",
            "/wiki/Metal%C3%B3gica",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Razonamiento",
            "/wiki/Mathematics_Subject_Classification",
            "/wiki/Filosof%C3%ADa_de_la_matem%C3%A1tica",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/L%C3%B3gica_borrosa",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Inform%C3%A1tica_te%C3%B3rica",
            "/wiki/Alan_Turing",
            "/wiki/Sem%C3%A1ntica",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/Model_checking",
            "/wiki/Isomorfismo",
            "/wiki/L%C3%B3gica_intuicionista",
            "/wiki/L%C3%B3gica_lineal",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/L%C3%B3gica_combinatoria",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Sistema_formal",
            "/wiki/Sistema_formal",
            "/wiki/Sistema",
            "/wiki/Objeto_abstracto",
            "/wiki/Lenguaje_formal",
            "/wiki/Axioma",
            "/wiki/Reglas_de_inferencia",
            "/wiki/Sem%C3%A1ntica_formal",
            "/wiki/Teorema",
            "/wiki/Definici%C3%B3n",
            "/wiki/Demostraci%C3%B3n_en_matem%C3%A1tica",
            "/wiki/Sistema_axiom%C3%A1tico",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Lenguaje_formal",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Axioma",
            "/wiki/Regla_de_inferencia",
            "/wiki/Formalismo_matem%C3%A1tico",
            "/wiki/David_Hilbert",
            "/wiki/Metamatem%C3%A1tica",
            "/wiki/Metalenguaje",
            "/wiki/Lenguaje_objeto",
            "/wiki/Lenguaje_formalizado",
            "/wiki/S%C3%ADmbolos",
            "/wiki/F%C3%B3rmula_(expresi%C3%B3n)",
            "/wiki/Teor%C3%ADa_(l%C3%B3gica)",
            "/wiki/Lenguaje_formal",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Aritm%C3%A9tica_de_Peano",
            "/wiki/Teorema_de_la_incompletitud_de_G%C3%B6del",
            "/wiki/Alonzo_Church",
            "/wiki/Programa_de_Hilbert",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Metal%C3%B3gica",
            "/wiki/Metal%C3%B3gica",
            "/wiki/L%C3%B3gica",
            "/wiki/Sistemas_formales",
            "/wiki/Consistencia_(l%C3%B3gica)",
            "/wiki/Decidibilidad",
            "/wiki/Completitud_sem%C3%A1ntica",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Teorema_de_completitud_de_G%C3%B6del",
            "/wiki/Teorema_de_L%C3%B6wenheim-Skolem",
            "/wiki/Teorema_de_compacidad",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Estructura_algebraica",
            "/wiki/Grupo_(matem%C3%A1tica)",
            "/wiki/Cuerpo_(matem%C3%A1tica)",
            "/wiki/Grafo",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Metal%C3%B3gica",
            "/wiki/Jes%C3%BAs_Padilla_G%C3%A1lvez",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Problema_de_decisi%C3%B3n",
            "/wiki/Algoritmo",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Complejidad_computacional",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Diagrama_de_Venn",
            "/wiki/Intersecci%C3%B3n_de_conjuntos",
            "/wiki/Conjunto",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Conjunto",
            "/wiki/N%C3%BAmero",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Figura_geom%C3%A9trica",
            "/wiki/Conjunto_infinito",
            "/wiki/Independencia_l%C3%B3gica",
            "/wiki/Consistencia_l%C3%B3gica",
            "/wiki/Hip%C3%B3tesis_del_continuo",
            "/wiki/Cardinal_inaccesible",
            "/wiki/Georg_Cantor",
            "/wiki/Infinito",
            "/wiki/Bernhard_Bolzano",
            "/wiki/Richard_Dedekind",
            "/wiki/Gottlob_Frege",
            "/wiki/Bertrand_Russell",
            "/wiki/Ernst_Zermelo",
            "/wiki/Abraham_Fraenkel",
            "/wiki/Axiomas_de_Zermelo-Fraenkel",
            "/wiki/Axioma_de_elecci%C3%B3n",
            "/wiki/Infinito",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Sem%C3%A1ntica_formal",
            "/wiki/Paradojas",
            "/wiki/L%C3%B3gica",
            "/wiki/Filosof%C3%ADa_de_la_matem%C3%A1tica",
            "/wiki/N%C3%BAmeros_reales",
            "/wiki/Consistencia_(l%C3%B3gica)",
            "/wiki/Cardinal_grande",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Objeto_matem%C3%A1tico",
            "/wiki/Estructura_de_datos",
            "/wiki/Axioma",
            "/wiki/Regla_de_inferencia",
            "/wiki/Sintaxis",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Sem%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Fundamentos_de_las_matem%C3%A1ticas",
            "/wiki/Johann_Heinrich_Lambert",
            "/wiki/Gottfried_Leibnitz",
            "/wiki/Calculus_ratiocinator",
            "/wiki/George_Boole",
            "/wiki/C%C3%A1lculo",
            "/wiki/Valor_de_verdad",
            "/wiki/Operaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Suma",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Augustus_De_Morgan",
            "/wiki/Leyes_de_De_Morgan",
            "/wiki/John_Venn",
            "/wiki/Diagrama_de_Venn",
            "/wiki/Charles_Sanders_Peirce",
            "/wiki/Ernst_Schr%C3%B6der",
            "/wiki/Gottlob_Frege",
            "/wiki/L%C3%B3gica_de_predicados",
            "/wiki/C%C3%A1lculo_proposicional_de_Frege",
            "/wiki/Lenguaje_formal",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Computadoras",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Logicismo",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Paradoja_de_Russell",
            "/wiki/Giuseppe_Peano",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Notaci%C3%B3n_matem%C3%A1tica",
            "/wiki/%C3%81lgebra",
            "/wiki/Proped%C3%A9utica",
            "/wiki/Bertrand_Russell",
            "/wiki/Alfred_North_Whitehead",
            "/wiki/Principia_mathematica",
            "/wiki/Giuseppe_Peano",
            "/wiki/Clarence_Irving_Lewis",
            "/wiki/Implicaci%C3%B3n_estricta",
            "/wiki/David_Hilbert",
            "/wiki/Metamatem%C3%A1tica",
            "/wiki/Programa_de_Hilbert",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Alonzo_Church",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Stephen_Kleene",
            "/wiki/Emil_Leon_Post",
            "/wiki/Haskell_Curry",
            "/wiki/Alan_Turing",
            "/wiki/Software",
            "/wiki/Hardware",
            "/wiki/Deducci%C3%B3n_natural",
            "/wiki/Gerhard_Gentzen",
            "/wiki/Alfred_Tarski",
            "/wiki/%C3%81lgebra_relacional",
            "/wiki/Teor%C3%ADa_axiom%C3%A1tica_de_conjuntos",
            "/wiki/Axiomas_de_Peano",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/%C3%81lgebra_booleana",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/Noam_Chomsky",
            "/wiki/Gram%C3%A1tica_formal",
            "/wiki/Lenguaje_formal",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/L%C3%B3gica_aristot%C3%A9lica",
            "/wiki/Jan_%C5%81ukasiewicz",
            "/wiki/L%C3%B3gica_de_clases",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/Noci%C3%B3n_primitiva",
            "/wiki/Funci%C3%B3n_indicatriz",
            "/wiki/Retroalimentacion",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Teor%C3%ADa_de_sistemas",
            "/wiki/Emergencia_(filosof%C3%ADa)",
            "/wiki/Pensamiento_sist%C3%A9mico",
            "/wiki/Din%C3%A1mica_de_sistemas",
            "/wiki/Mereolog%C3%ADa",
            "/wiki/Sistema_complejo",
            "/wiki/Sistema_din%C3%A1mico",
            "/wiki/Argumento",
            "/wiki/L%C3%B3gica_informal",
            "/wiki/Representaci%C3%B3n_del_conocimiento",
            "/wiki/L%C3%B3gica",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/F%C3%B3rmula_bien_formada",
            "/wiki/Oxford_University_Press",
            "/wiki/Jes%C3%BAs_Padilla_G%C3%A1lvez",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Academic_Press",
            "/wiki/ISBN",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/Nueva_York",
            "/wiki/Springer_Science%2BBusiness_Media",
            "/wiki/ISBN",
            "/wiki/Singapore",
            "/wiki/ISBN",
            "/wiki/George_Boolos",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/Oxford_University_Press",
            "/wiki/ISBN",
            "/wiki/Zentralblatt_MATH",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Boston",
            "/wiki/Chapman_%26_Hall",
            "/wiki/ISBN",
            "/wiki/New_York_City",
            "/wiki/Springer_Science%2BBusiness_Media",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Munich",
            "/wiki/Oxford_University_Press",
            "/wiki/ISBN",
            "/wiki/Springer_Science%2BBusiness_Media",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Boston",
            "/wiki/ISBN",
            "/wiki/Amsterdam",
            "/wiki/Elsevier",
            "/wiki/ISBN",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/Springer_Science%2BBusiness_Media",
            "/wiki/ISBN",
            "/wiki/Stephen_Cole_Kleene",
            "/wiki/Stephen_Cole_Kleene",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Stefan_Banach",
            "/wiki/Alfred_Tarski",
            "/wiki/Digital_object_identifier",
            "/wiki/Dordrecht",
            "/wiki/Springer_Science%2BBusiness_Media",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Lewis_Carroll",
            "/wiki/ISBN",
            "/wiki/Richard_Dedekind",
            "/wiki/Richard_Dedekind",
            "/wiki/Oxford_University_Press",
            "/wiki/Abraham_Fraenkel",
            "/wiki/Gottlob_Frege",
            "/wiki/Gottlob_Frege",
            "/wiki/J._L._Austin",
            "/wiki/Gerhard_Gentzen",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Digital_object_identifier",
            "/wiki/Solomon_Feferman",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/Cambridge,_Massachusetts",
            "/wiki/Harvard_University_Press",
            "/wiki/ISBN",
            "/wiki/David_Hilbert",
            "/wiki/Madrid",
            "/wiki/ISBN",
            "/wiki/David_Hilbert",
            "/wiki/Leipzig",
            "/wiki/David_Hilbert",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/David_Hilbert",
            "/wiki/Paul_Bernays",
            "/wiki/Springer_Science%2BBusiness_Media",
            "/wiki/ISBN",
            "/wiki/Jahrbuch_%C3%BCber_die_Fortschritte_der_Mathematik",
            "/wiki/Mathematical_Reviews",
            "/wiki/Stephen_Kleene",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/Nikolai_Lobachevsky",
            "/wiki/ISBN",
            "/wiki/Leopold_L%C3%B6wenheim",
            "/wiki/ISSN",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/Moritz_Pasch",
            "/wiki/Giuseppe_Peano",
            "/wiki/Richard_Swineshead",
            "/wiki/Alfred_Tarski",
            "/wiki/Santa_Monica,_California",
            "/wiki/RAND_Corporation",
            "/wiki/Alan_Turing",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Digital_object_identifier",
            "/wiki/Handle_System",
            "/wiki/Ernst_Zermelo",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Ernst_Zermelo",
            "/wiki/Mathematische_Annalen",
            "/wiki/ISSN",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Ernst_Zermelo",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/M%C3%A9todo_de_Newton",
        "titulo": "Método de Newton",
        "contenido": "en analisis numerico, el metodo de newton (conocido tambien como el metodo de newton-raphson o el metodo de newton-fourier) es un algoritmo para encontrar aproximaciones de los ceros o raices de una funcion real. tambien puede ser usado para encontrar el maximo o minimo de una funcion, encontrando los ceros de su primera derivada.  el metodo numerico de newton fue descrito por sir isaac newton en de analysi per aequationes numero terminorum infinitas ('sobre el analisis mediante ecuaciones con un numero infinito de terminos', escrito en 1669, publicado en 1711 por william jones) y en de metodis fluxionum et serierum infinitarum (escrito en 1671, traducido y publicado como metodo de las fluxiones en 1736 por john colson). sin embargo, su descripcion difiere en forma sustancial de la descripcion moderna presentada mas arriba: newton aplicaba el metodo solo a polinomios, y no consideraba las aproximaciones sucesivas xn, sino que calculaba una secuencia de polinomios para llegar a la aproximacion de la raiz x. finalmente, newton ve el metodo como puramente algebraico y falla al no ver la conexion con el calculo.  isaac newton probablemente derivo su metodo de forma similar aunque menos precisa del metodo de francois viete. la esencia del metodo de viete puede encontrarse en el trabajo del matematico persa sharaf al-din al-tusi.  el metodo de newton-raphson es llamado asi por el matematico ingles joseph raphson (contemporaneo de newton) se hizo miembro de la royal society en 1691 por su libro aequationum universalis, publicado en 1690, que contenia este metodo para aproximar raices. newton en su libro metodo de las fluxiones describe el mismo metodo, en 1671, pero no fue publicado hasta 1736, lo que significa que raphson habia publicado este resultado 46 años antes. aunque no fue tan popular como los trabajos de newton, se le reconocio posteriormente.  el metodo de newton es un metodo abierto, en el sentido de que no esta garantizada su convergencia global. la unica manera de alcanzar la convergencia es seleccionar un valor inicial lo suficientemente cercano a la raiz buscada. asi, se ha de comenzar la iteracion con un valor razonablemente cercano al cero (denominado punto de arranque o valor supuesto). la relativa cercania del punto inicial a la raiz depende mucho de la naturaleza de la propia funcion; si esta presenta multiples puntos de inflexion o pendientes grandes en el entorno de la raiz, entonces las probabilidades de que el algoritmo diverja aumentan, lo cual exige seleccionar un valor supuesto cercano a la raiz. una vez que se ha hecho esto, el metodo linealiza la funcion por la recta tangente en ese valor supuesto. la abscisa en el origen de dicha recta sera, segun el metodo, una mejor aproximacion de la raiz que el valor anterior. se realizaran sucesivas iteraciones hasta que el metodo haya convergido lo suficiente.  sea f : [ a , b ] → r } una funcion derivable definida en el intervalo real [ a , b ] . empezamos con un valor inicial x 0 } y definimos para cada numero natural n  donde f ′ denota la derivada de f .  notese que el metodo descrito es de aplicacion exclusiva para funciones de una sola variable con forma analitica o implicita conocible. existen variantes del metodo aplicables a sistemas discretos que permiten estimar las raices de la tendencia, asi como algoritmos que extienden el metodo de newton a sistemas multivariables, sistemas de ecuaciones, etcetera.  tres son las formas principales por las que tradicionalmente se ha obtenido el algoritmo de newton-raphson.  la primera de ellas es una simple interpretacion geometrica. en efecto, atendiendo al desarrollo geometrico del metodo de la secante, podria pensarse en que si los puntos de iteracion estan lo suficientemente cerca (a una distancia infinitesimal), entonces la secante se sustituye por la tangente a la curva en el punto. asi pues, si por un punto de iteracion trazamos la tangente a la curva, por extension con el metodo de la secante, el nuevo punto de iteracion se tomara como la abscisa en el origen de la tangente (punto de corte de la tangente con el eje x ). esto es equivalente a linealizar la funcion, es decir, f se reemplaza por una recta tal que contiene al punto ( x 0 } , f ( x 0 } )) y cuya pendiente coincide con la derivada de la funcion en el punto, f ′ ( x 0 ) )} . la nueva aproximacion a la raiz, x 1 } , se logra de la interseccion de la funcion lineal con el eje de abscisas. matematicamente:  en la ilustracion adjunta del metodo de newton se puede ver que x n + 1 } es una mejor aproximacion que x n } para el cero (x) de la funcion f .  una forma alternativa de obtener el algoritmo es desarrollando la funcion f ( x ) en serie de taylor, para un entorno del punto x n } :  si se trunca el desarrollo a partir del termino de grado 2, y evaluamos en x n + 1 } :  si ademas se acepta que x n + 1 } tiende a la raiz, se ha de cumplir que f ( x n + 1 ) = 0 )=0} , luego, sustituyendo en la expresion anterior, obtenemos el algoritmo.  finalmente, hay que indicar que el metodo de newton-raphson puede interpretarse como un metodo de iteracion de punto fijo. asi, dada la ecuacion f ( x ) = 0 , se puede considerar el siguiente metodo de iteracion de punto fijo:  se escoge h (x) de manera que g ′ ( r ) = 0 ( r es la raiz buscada). dado que g ′ ( r ) es:  entonces:  como h ( x ) no tiene que ser unica, se escoge de la forma mas sencilla:  por tanto, imponiendo subindices:  expresion que coincide con la del algoritmo de newton-raphson  el orden de convergencia de este metodo es, por lo menos, cuadratico. sin embargo, si la raiz buscada es de multiplicidad algebraica mayor a uno (i.e, una raiz doble, triple, …), el metodo de newton-raphson pierde su convergencia cuadratica y pasa a ser lineal de constante asintotica de convergencia 1-1/m, con m la multiplicidad de la raiz.  existen numerosas formas de evitar este problema, como pudieran ser los metodos de aceleracion de la convergencia tipo δ² de aitken o el metodo de steffensen.  evidentemente, este metodo exige conocer de antemano la multiplicidad de la raiz, lo cual no siempre es posible. por ello tambien se puede modificar el algoritmo tomando una funcion auxiliar g(x) = f(x)/f'(x), resultando:  su principal desventaja en este caso seria lo costoso que pudiera ser hallar g(x) y g'(x) si f(x) no es facilmente derivable.  por otro lado, la convergencia del metodo se demuestra cuadratica para el caso mas habitual sobre la base de tratar el metodo como uno de punto fijo: si g '(r)=0, y g''(r) es distinto de 0, entonces la convergencia es cuadratica. sin embargo, esta sujeto a las particularidades de estos metodos.  notese de todas formas que el metodo de newton-raphson es un metodo abierto: la convergencia no esta garantizada por un teorema de convergencia global como podria estarlo en los metodos de falsa posicion o de biseccion. asi, es necesario partir de una aproximacion inicial proxima a la raiz buscada para que el metodo converja y cumpla el teorema de convergencia local.  sea f ∈ c 2 ( [ a , b ] ) }^{2}([a,b])} . si p ∈ [ a , b ] , f ( p ) = 0 y f ′ ( p ) = 0 , entonces existe un r > 0 tal que si | x 0 − p | < r -p|<r\\,} , entonces la sucesion xn con n ∈ n } verifica que:  si ademas f ∈ c 3 ( [ a , b ] ) }^{3}([a,b])} , entonces la convergencia es cuadratica.  sea f ∈ c 2 [ a , b ] }^{2}[a,b]}} verificando:​  entonces existe un unico s ∈ [ a , b ] } tal que f ( s ) = 0 por lo que la sucesion converge a s .  se puede demostrar que el metodo de newton-raphson tiene convergencia cuadratica: si α es raiz, entonces:  para una cierta constante c . esto significa que si en algun momento el error es menor o igual a 0,1, a cada nueva iteracion doblamos (aproximadamente) el numero de decimales exactos. en la practica puede servir para hacer una estimacion aproximada del error:  error relativo entre dos aproximaciones sucesivas:  con lo cual se toma el error relativo como si la ultima aproximacion fuera el valor exacto. se detiene el proceso iterativo cuando este error relativo es aproximadamente menor que una cantidad fijada previamente.  consideremos el problema de encontrar un numero positivo x tal que cos ⁡ ( x ) = x 3 } . podriamos tratar de encontrar el cero de f ( x ) = cos ⁡ ( x ) − x 3 } .  sabemos que f ′ ( x ) = − sen ⁡ ( x ) − 3 x 2 (x)-3x^{2}} . ya que cos ⁡ ( x ) ≤ 1 para todo x y x 3 > 1 >1} para x > 1 , deducimos que nuestro cero esta entre 0 y 1. comenzaremos probando con el valor inicial x 0 = 0.5 =0.5}  los digitos correctos estan subrayados. en particular, x 6 } es correcto para el numero de decimales pedidos. podemos ver que el numero de digitos correctos despues de la coma se incrementa desde 2 (para x3) a 5 y 10, ilustrando la convergencia cuadratica.   ",
        "snippet": "En análisis numérico, el método de Newton (conocido también como el método de Newton-Raphson o el método de Newton-Fourier) es un algoritmo para encontrar aproximaciones de los ceros o raíces de una función real. También puede ser usado para encontrar el máximo o mínimo de una función, encontrando los ceros de su primera derivada.",
        "enlaces_salientes": [
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Isaac_Newton",
            "/wiki/Joseph_Raphson",
            "/wiki/Algoritmo",
            "/wiki/Ra%C3%ADz_de_una_funci%C3%B3n",
            "/wiki/Funci%C3%B3n_real",
            "/wiki/Derivada",
            "/wiki/Isaac_Newton",
            "/wiki/1669",
            "/wiki/1711",
            "/wiki/William_Jones_(matem%C3%A1tico)",
            "/wiki/1671",
            "/wiki/M%C3%A9todo_de_las_fluxiones",
            "/wiki/1736",
            "/wiki/John_Colson",
            "/wiki/Fran%C3%A7ois_Vi%C3%A8te",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Persia",
            "/wiki/Sharaf_al-Din_al-Tusi",
            "/wiki/Joseph_Raphson",
            "/wiki/Miembro_de_la_Royal_Society",
            "/wiki/Punto_de_inflexi%C3%B3n",
            "/wiki/Tangente_(geometr%C3%ADa)",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Derivada",
            "/wiki/M%C3%A9todo_de_la_secante",
            "/wiki/Infinitesimal",
            "/wiki/Funci%C3%B3n_lineal",
            "/wiki/Serie_de_Taylor",
            "/wiki/Punto_fijo_(matem%C3%A1ticas)",
            "/wiki/Orden_de_convergencia",
            "/wiki/Proceso_%CE%94%C2%B2_de_Aitken",
            "/wiki/M%C3%A9todo_de_Steffensen",
            "/wiki/M%C3%A9todo_de_la_regla_falsa",
            "/wiki/M%C3%A9todo_de_bisecci%C3%B3n",
            "/wiki/F%C3%B3rmulas_de_Newton%E2%80%93Cotes",
            "/wiki/Sobre_el_an%C3%A1lisis_por_ecuaciones_con_un_n%C3%BAmero_infinito_de_t%C3%A9rminos",
            "/wiki/Numerical_Recipes",
            "/wiki/Cambridge_University_Press",
            "/wiki/Numerical_Recipes",
            "/wiki/Numerical_Recipes",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Control_de_autoridades",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
        "titulo": "Eliminación de Gauss-Jordan",
        "contenido": "en algebra lineal, la eliminacion de gauss-jordan, llamada asi en honor de carl friedrich gauss y wilhelm jordan, es un algoritmo que se usa para determinar la inversa de una matriz y las soluciones de un sistema de ecuaciones lineales.​ un sistema de ecuaciones se resuelve por el metodo de gauss cuando se obtienen sus soluciones mediante la reduccion del sistema dado a otro equivalente en el que cada ecuacion tiene una incognita menos que la anterior. el metodo de gauss transforma la matriz de coeficientes en una matriz triangular superior. el metodo de gauss-jordan continua el proceso de transformacion hasta obtener una matriz diagonal.  para realizar la reduccion de filas en una matriz, se utiliza una secuencia de  operaciones elementales de fila para modificar la matriz hasta que la esquina inferior izquierda de la matriz se llene de ceros, tanto como sea posible. hay tres tipos de operaciones elementales de fila:  utilizando estas operaciones, una matriz siempre se puede transformar en una matriz triangular superior, y de hecho en una que este en forma escalonada. una vez que todos los coeficientes principales (la entrada mas a la izquierda distinta de cero en cada fila) son 1, y cada columna que contiene un coeficiente principal tiene ceros en otros lugares, se dice que la matriz esta en  forma escalonada reducida. esta forma final es unica; en otras palabras, es independiente de la secuencia de operaciones de fila utilizadas. por ejemplo, en la siguiente secuencia de operaciones de fila (donde dos operaciones elementales en filas diferentes se realizan en el primer y tercer paso), la tercera y cuarta matrices son las que estan en forma escalonada, y la matriz final es la unica forma escalonada reducida.  el uso de operaciones de fila para convertir una matriz en forma escalonada reducida se denomina a veces eliminacion de gauss-jordan. en este caso, el termino eliminacion de gauss se refiere al proceso hasta que ha alcanzado su forma triangular superior, o forma escalonada (no reducida). por razones computacionales, cuando se resuelven sistemas de ecuaciones lineales, a veces es preferible detener las operaciones de fila antes de que la matriz este completamente reducida.  algunos casos especiales del metodo -aunque presentados sin demostracion- ya eran conocidos por los matematicos chinos en torno al año 179 de nuestra era.​  el metodo de eliminacion de gauss-jordan aparece en el capitulo ocho del importante texto matematico chino jiuzhang suanshu o los nueve capitulos sobre el arte matematico. su uso se ilustra en dieciocho problemas, de dos a cinco ecuaciones cada uno. la primera referencia al libro por este titulo data del 179  dc, pero algunas de sus partes fueron escritas tan pronto como alrededor del 150 a. c.,​​ en este año fue señalado por liu hui en el siglo iii.  el proceso de reduccion de filas hace uso de  operaciones elementales de filas, y se puede dividir en dos partes. la primera parte (a veces llamada eliminacion hacia adelante) reduce un sistema dado a la forma escalonada de filas, a partir de la cual se puede decir si no hay soluciones, una solucion unica, o infinitas soluciones. la segunda parte (a veces llamada sustitucion hacia atras) continua utilizando operaciones de fila hasta que se encuentra la solucion; en otras palabras, pone la matriz en forma escalonada reducida.  otro punto de vista, que resulta muy util para analizar el algoritmo, es que la reduccion de filas produce una descomposicion matricial de la matriz original. las operaciones elementales de fila pueden verse como la multiplicacion a la izquierda de la matriz original por matrices elementales. alternativamente, una secuencia de operaciones elementales que reduce una sola fila puede verse como la multiplicacion por una matriz de frobenius. entonces, la primera parte del algoritmo calcula una descomposicion lu, mientras que la segunda parte escribe la matriz original como el producto de una matriz invertible determinada de forma unica y una matriz escalonada de filas reducida determinada de forma unica.  hay tres tipos de operaciones elementales de fila que se pueden realizar en las filas de una matriz ya indicados anteriormente:  si la matriz esta asociada a un sistema de ecuaciones lineales, entonces estas operaciones no cambian el conjunto solucion. por lo tanto, si el objetivo es resolver un sistema de ecuaciones lineales, el uso de estas operaciones de fila podria facilitar el problema.  la complejidad computacional de la eliminacion gaussiana es  o(n³). esto es, el maximo numero de operaciones requeridas es del orden de n³ si el tamaño de la matriz es n × n.​  una variante interesante de la eliminacion de gauss es la que llamamos eliminacion de gauss-jordan, (debido al mencionado gauss y a wilhelm jordan), esta consiste en ir obteniendo los 1 delanteros durante los pasos uno al cuatro (llamados paso directo) asi para cuando estos finalicen ya se obtendra la matriz en forma escalonada reducida.  supongamos que es necesario encontrar los numeros \"x\", \"y\", \"z\", que satisfacen simultaneamente estas ecuaciones:  esto es llamado un sistema lineal de ecuaciones. el objetivo es reducir el sistema a otro equivalente, que tenga las mismas soluciones. las operaciones (llamadas elementales) son estas:  estas operaciones pueden representarse con matrices elementales que se usan tambien en otros procedimientos como la factorizacion lu o la diagonalizacion por congruencia de una matriz simetrica.  en nuestro ejemplo, eliminamos x de la segunda ecuacion sumando 3/2 veces la primera ecuacion a la segunda y despues sumamos la primera ecuacion a la tercera. el resultado es:  ahora eliminamos y de la primera ecuacion sumando -2 veces la segunda ecuacion a la primera, y sumamos -4 veces la segunda ecuacion a la tercera para eliminar y.  entonces podemos resolver por gauss al sustituir en el sistema de ecuaciones el valor de z continuando con las incognitas anteriores de abajo hacia arriba y de derecha a izquierda obteniendo el valor de todas las incognitas. si continuamos con la variante de gauss-jordan eliminamos z de la primera ecuacion sumando -2 veces la tercera ecuacion a la primera, y sumando 1/2 veces la tercera ecuacion a la segunda para eliminar z.  despejando, podemos ver las soluciones:  para clarificar los pasos, se trabaja con la matriz aumentada. podemos ver los 3 pasos en su notacion matricial:  primero:  despues,  por ultimo.  si el sistema fuera incompatible, entonces nos encontrariamos con una fila como esta:  que representa la ecuacion: 0 x + 0 y + 0 z = a , donde a = 0. es decir, 0 = a , lo que supone una contradiccion y, por tanto, no tiene solucion. en el caso de que a=0 el sistema tiene varias soluciones.  dos formas especiales de matrices son la escalonada y la escalonada reducida. una matriz puede tener las siguientes propiedades:  si una matriz a cumple con esas propiedades, se dice escalonada. ademas, cumpliendo estas otras condiciones que detallaremos a continuacion, decimos que la matriz se encuentra en la forma escalonada reducida por filas, o simplemente en forma escalonada reducida.  cuando una matriz representa a un sistema de ecuaciones situaciones como tener una columna de ceros parece imposible ya que corresponderia a una variable que nunca habria aparecido. sin embargo esta situacion puede presentarse (imaginemos la ecuacion de un plano en el espacio en la que no aparece alguna de las componentes, por ejemplo y+z=5). asi la matriz  tambien es una matriz escalonada.  una vez que la matriz del sistema se ha transformado hasta obtener una matriz escalonada reducida es muy facil discutirlo (es decir, determinar cuantas soluciones tiene):  es posible usar la eliminacion gaussiana para encontrar inversas de matrices n × n. para ello se aumenta la matriz dada, digamos a con una matriz identidad, simplemente escribiendo las filas de la identidad a continuacion de las de nuestra matriz a, por ejemplo dada:  se construiria  y ahora se realizan las operaciones elementales sobre las filas de la matriz aumentada que sean necesarias para obtener la forma escalonada reducida de la matriz a; sumando tanto a la segunda como a la tercera fila la primera obtenemos  multiplicamos a la segunda fila por -1 y la intercambiamos con la primera  ya tenemos el pivote de la primera fila que usamos para hacer ceros debajo  ahora usamos el pivote de la segunda fila  y por ultimo cambiamos de signo la tercera fila y usamos el pivote correspondiente  el proceso ha finalizado porque en la parte izquierda tenemos la forma escalonada reducida de a y puesto que esta es la matriz identidad, entonces a tiene inversa y su inversa es la matriz que aparece a la derecha, en el lugar que al principio ocupaba la identidad. cuando la forma escalonada reducida que aparece no es la identidad es que la matriz de partida no tiene inversa. ",
        "snippet": "En álgebra lineal, la eliminación de Gauss-Jordan, llamada así en honor de Carl Friedrich Gauss y Wilhelm Jordan, es un algoritmo que se usa para determinar la inversa de una matriz y las soluciones de un sistema de ecuaciones lineales.[1]​ Un sistema de ecuaciones se resuelve por el método de Gauss cuando se obtienen sus soluciones mediante la reducción del sistema dado a otro equivalente en el que cada ecuación tiene una incógnita menos que la anterior. El método de Gauss transforma la matriz de coeficientes en una matriz triangular superior. El método de Gauss-Jordan continúa el proceso de transformación hasta obtener una matriz diagonal.",
        "enlaces_salientes": [
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/Eliminaci%C3%B3n_de_Gauss-Jordan",
            "/wiki/M%C3%A9todo_de_Gauss-Seidel",
            "/wiki/%C3%81lgebra_lineal",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/Wilhelm_Jordan",
            "/wiki/Algoritmo",
            "/wiki/Matriz_invertible",
            "/wiki/Resoluci%C3%B3n_de_ecuaciones",
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/Ecuaci%C3%B3n",
            "/wiki/Inc%C3%B3gnita",
            "/wiki/Matriz_triangular",
            "/wiki/Matriz_diagonal",
            "/wiki/Matriz_elemental",
            "/wiki/Matriz_triangular",
            "/wiki/Forma_escalonada",
            "/wiki/Matriz_escalonada",
            "/wiki/Jiuzhang_suanshu",
            "/wiki/179",
            "/wiki/150_a._C.",
            "/wiki/Liu_Hui",
            "/wiki/Matriz_elemental",
            "/wiki/Matriz_triangular#Sustitución_hacia_delante_y_hacia_atrás",
            "/wiki/Descomposici%C3%B3n_matricial",
            "/wiki/Matriz_elemental",
            "/wiki/Descomposici%C3%B3n_LU",
            "/wiki/Escalar_(matem%C3%A1tica)",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Submatriz",
            "/wiki/Wilhelm_Jordan",
            "/wiki/Sistema_lineal_de_ecuaciones",
            "/wiki/Matrices_elementales",
            "/wiki/Factorizaci%C3%B3n_LU",
            "/wiki/Matriz_aumentada",
            "/wiki/Matriz_escalonada",
            "/wiki/Matriz_invertible",
            "/wiki/Matriz_identidad",
            "/wiki/%C3%81lgebra_elemental",
            "/wiki/%C3%81lgebra_lineal",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/John_Wiley_%26_Sons",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Semantic_Scholar",
            "/wiki/ArXiv",
            "/wiki/Digital_object_identifier",
            "/wiki/Society_for_Industrial_and_Applied_Mathematics",
            "/wiki/ISBN",
            "/wiki/Addison-Wesley",
            "/wiki/ISBN",
            "/wiki/McGraw-Hill",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Semantic_Scholar",
            "/wiki/Princeton_University_Press",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Tesis_de_Church-Turing",
        "titulo": "Tesis de Church-Turing",
        "contenido": "en teoria de la computabilidad, la tesis de church-turing formula hipoteticamente la equivalencia entre los conceptos de funcion computable y maquina de turing, que expresado en lenguaje corriente vendria a ser \"todo algoritmo es equivalente a una maquina de turing\". no es un teorema matematico, es una afirmacion formalmente indemostrable que, no obstante, tiene una aceptacion practicamente universal.  en la decada de 1930, uno de los problemas mas estudiados por los matematicos era el entscheidungsproblem propuesto por david hilbert: dada una proposicion en un sistema formal, ¿existe un algoritmo tal que pueda decidir si la proposicion es cierta (y por tanto es un teorema del sistema) o por el contrario es falsa? en 1936 alonzo church y alan turing probaron, de forma independiente, la imposibilidad de la existencia de tal algoritmo, usando el calculo lambda en el caso de church y la maquina de turing en el caso de turing. posteriormente el concepto inicial de dicha \"maquina\" (que no tiene existencia fisica, realmente es una descripcion formal) fue ampliada de diversos modos:  los lenguajes formales que son aceptados por una maquina de turing son todos aquellos que pueden ser generados por una gramatica formal. por otro lado, las funciones que pueden ser computadas con el calculo lambda de church son exactamente aquellas que pueden ser computadas con una maquina de turing. estos tres formalismos, las maquinas de turing, los lenguajes formales y el calculo lambda han sido desarrollados de forma independiente y sin embargo se ha probado que son equivalentes; esta notable coincidencia parece indicar que la tesis de church-turing es cierta, siendo la nocion de algoritmo o procedimiento efectivo de computo equivalente a la nocion de computo en una maquina de turing.  entre los lenguajes formales que son aceptados por una maquina de turing se pueden citar:  donde los tres ultimos ejemplos utilizan una definicion ligeramente distinta de aceptacion de lenguaje pues aceptan una cadena si existe tan solo un computo que la acepta o la mayoria la acepta y entonces es equivalente a maquina de turing.  aunque se asume como cierta, la tesis de church-turing no puede ser probada ya que no se poseen los medios necesarios, por eso es una tesis. ello debido a que “procedimiento efectivo” y “algoritmo” no son conceptos dentro de ninguna teoria matematica y no son definibles facilmente. la evidencia de su verdad es abundante pero no definitiva. precisamente la tesis de church establece que la definicion de algoritmo o procedimiento efectivo es una maquina de turing.  se ha acordado que un procedimiento efectivo o algoritmo consiste en un numero finito y preciso de pasos descrito en un numero finito de simbolos que podria ser tambien ejecutado por un ser humano. en general, la ejecucion de un algoritmo no requiere de mayor inteligencia que la necesaria para entender y seguir las instrucciones (incluso solo seguir).  ejemplos de metodos efectivos o algoritmos abundan, por ejemplo la suma, resta, multiplicacion o division son algoritmos de operaciones aritmeticas. el algoritmo de euclides para obtener el maximo comun divisor de dos numeros naturales es otro ejemplo. sin embargo, nada de esto ha sido una definicion formal pues no es claro que significa “instruccion precisa” o cual es el tipo de inteligencia necesaria para seguir las instrucciones. por esta misma razon, la idea abstracta de una maquina que funciona como parametro para decidir cuando algo es un algoritmo o procedimiento efectivo es de gran valor. esto es una maquina de turing.  la tesis de church-turing ha sido tan exitosa que la mayoria la supone verdadera. los terminos derivados de ella, como metodo efectivo y computable son comunmente utilizados, cuando en realidad computable se refiere a turing-computable, en el salto entre uno y otro se encuentra la tesis de church, y entre muchos otros conceptos y terminos comunmente utilizados en la teoria de la computabilidad o funciones recursivas.  es claro que es mas \"facil\" probar la falsedad de la tesis que la verdad de la misma. basta con exponer un metodo efectivo o algoritmo que no sea computable en el sentido de turing (i.e. turing-computable).  aunque exponer un algoritmo que no sea turing-computable no es tan facil, pero, es mas \"facil\" que probar la verdad de la tesis, ya que parece imposible negar que sea verdadera a pesar de que eso es una posibilidad logica.  existe una tesis relativizada de church-turing que depende de los grados de turing definidos por maquinas de turing con oraculos. los oraculos son medios formales que suponen que se le facilita cierta informacion a la maquina de turing para resolver algun problema, esto define una jerarquia que se ha estudiado tanto en la teoria de la computabilidad como en la teoria de la complejidad.  la tesis de church-turing tiene ademas profundas implicaciones. cuando la tesis es aplicada a la fisica tiene diversos significados: que el universo es una maquina de turing y por lo tanto no es posible construir fisicamente una maquina con mayor poder computacional o que compute funciones no recursivas (la capacidad de computo que puede contener el universo esta acoplado al tipo de universo en el que vivimos). a esto se le ha llamado tesis de church-turing fuerte.  una posible interpretacion valida es que el universo no es una maquina de turing, es decir, las leyes del universo no son computables pero esto no afecta la posibilidad de crear una maquina mas poderosa que una maquina de turing (universo desacoplado al poder computacional de los dispositivos que contiene).  otra posibilidad es que el universo sea una hipercomputadora y entonces sea posible la construccion de maquinas mas poderosas que las maquinas de turing. para ello posiblemente bastaria con que el universo fuera continuo e hiciera uso de esa continuidad (otra pregunta es que tan densa es su continuidad), usando como entrada los resultados de dicha super computadora:  el universo o la naturaleza. ",
        "snippet": "En teoría de la computabilidad, la tesis de Church-Turing formula hipotéticamente la equivalencia entre los conceptos de función computable y máquina de Turing, que expresado en lenguaje corriente vendría a ser \"todo algoritmo es equivalente a una máquina de Turing\". No es un teorema matemático, es una afirmación formalmente indemostrable que, no obstante, tiene una aceptación prácticamente universal.",
        "enlaces_salientes": [
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Algoritmo",
            "/wiki/Independencia_(l%C3%B3gica_matem%C3%A1tica)",
            "/wiki/Consenso_cient%C3%ADfico",
            "/wiki/Entscheidungsproblem",
            "/wiki/David_Hilbert",
            "/wiki/Sistema_formal",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Lenguajes_formales",
            "/wiki/Gram%C3%A1tica_formal",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/Aut%C3%B3matas_celulares",
            "/wiki/Juego_de_la_vida",
            "/wiki/Computadora_cu%C3%A1ntica",
            "/wiki/Relatividad",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Complejidad_computacional",
            "/wiki/Universo",
            "/wiki/Naturaleza",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/Complejidad_computacional",
            "/wiki/Princeton_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Lenguaje_natural",
        "titulo": "Lengua natural",
        "contenido": "una lengua natural es una variedad linguistica o forma de lenguaje humano generada espontaneamente en un grupo de hablantes con proposito de comunicarse, a diferencia de otras lenguas, como puedan ser una lengua construida, los lenguajes de programacion o los lenguajes formales usados en el estudio de la logica formal, especialmente la logica matematica. para servir a su proposito de comunicacion, una lengua natural ha de disponer de una gramatica (sintaxis, morfologia, etc.) y de un lexico. se suele considerar que las lenguas naturales obedecen a principios de economia y optimidad.  hay dos tipos de lenguas naturales:  el linguista charles f. hockett habla de quince rasgos definitorios de la lengua:  las lenguas naturales se contraponen a otras formas de lenguaje tanto humanas como no humanas. asi junto con las lenguas naturales humanas tenemos:  al contrario que en un lenguaje formal de tipo logico-matematico, donde el significado de una cadena o frase solo esta influido por su aspecto o «forma», en los lenguajes naturales la semantica o significado especifico y contextual de sus componentes intervienen en la validez o no de la frase, añadiendo complejidad a su estudio.  la linguistica es la rama del saber que se encarga del estudio del lenguaje, entendido como el conjunto de reglas que gobierna cualquier proceso de comunicacion.  admitiendo la existencia de reglas de comunicacion, la linguistica estructural llego a definir extensivamente una determinada lengua natural como el conjunto de frases que se pueden emitir y utilizar en esa lengua.  a finales de la decada de los años 1950 noam chomsky propuso incorporar los lenguajes naturales al tipo de lenguajes susceptibles de ser estudiados por los sistemas formales por medio de gramaticas generativas, que daran lugar a las cadenas o frases validas en un lenguaje dado.  en el siglo xx se estudiaron con detalle los sistemas de comunicacion e interaccion social de numerosos animales. eso llevo a descubrir que muchas de las caracteristicas presentes en las lenguas naturales humanas tambien estaban presentes en el lenguaje animal. sin embargo un pequeño numero de caracteristicas parecen exclusivas de las lenguas humanas entre ellas:  sorprendentemente, el lenguaje animal permite la prevaricacion o la «mentira» en el sentido de que algunos animales pueden llegar a simular gritos de alarma falsos para confundir a otros individuos.  con respecto al origen de las lenguas, existen dos posturas basicas:  en ambos casos, despues de la aparicion de una o mas lenguas actuaron procesos de diversificacion o cambio linguistico que aumentaron el numero de lenguas, hasta llegar a los varios miles de lenguas existentes en la actualidad.  la teoria de linguistica de las lenguas criollas y los pidgins sugiere que el proceso de formacion de una lengua natural genuina a partir de un input linguistico adecuado puede llevar tan poco tiempo como una generacion. el caso del idioma de señas de nicaragua creada a partir de un sistema semiotico inconsistente es un ejemplo paradigmatico de como puede formarse una lengua consistente con una gramatica bien fijada, a partir de elementos inconsistentes. ",
        "snippet": "Una lengua natural es una variedad lingüística o forma de lenguaje humano generada espontáneamente en un grupo de hablantes con propósito de comunicarse, a diferencia de otras lenguas, como puedan ser una lengua construida, los lenguajes de programación o los lenguajes formales usados en el estudio de la lógica formal, especialmente la lógica matemática. Para servir a su propósito de comunicación, una lengua natural ha de disponer de una gramática (sintaxis, morfología, etc.) y de un léxico. Se suele considerar que las lenguas naturales obedecen a principios de economía y optimidad.",
        "enlaces_salientes": [
            "/wiki/Lengua_natural",
            "/wiki/Lengua_natural",
            "/wiki/Lengua_natural",
            "/wiki/Variedad_ling%C3%BC%C3%ADstica",
            "/wiki/Lenguaje_humano",
            "/wiki/Lengua_construida",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/L%C3%B3gica_formal",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Sintaxis",
            "/wiki/Morfolog%C3%ADa",
            "/wiki/L%C3%A9xico",
            "/wiki/Teor%C3%ADa_de_la_optimidad",
            "/wiki/Comunicaci%C3%B3n_oral",
            "/wiki/Fonolog%C3%ADa",
            "/wiki/Lengua_de_se%C3%B1as",
            "/wiki/Charles_F._Hockett",
            "/wiki/Boca_humana",
            "/wiki/O%C3%ADdo",
            "/wiki/Idioma_croata",
            "/wiki/Fonema",
            "/wiki/De%C3%ADxis",
            "/wiki/Doble_articulaci%C3%B3n",
            "/wiki/Fonema",
            "/wiki/Morfema",
            "/wiki/Hjelmslev",
            "/wiki/Gram%C3%A1tica",
            "/wiki/Competencia_ling%C3%BC%C3%ADstica",
            "/wiki/Gram%C3%A1tica_generativa",
            "/wiki/Chomsky",
            "/wiki/Cambio_ling%C3%BC%C3%ADstico",
            "/wiki/Gram%C3%A1tica_hist%C3%B3rica",
            "/wiki/Metalenguaje",
            "/wiki/Comunicaci%C3%B3n_animal",
            "/wiki/Constituyente_sint%C3%A1ctico",
            "/wiki/Lenguaje_formal",
            "/wiki/Homo_sapiens",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Sintaxis",
            "/wiki/Lenguaje_formal",
            "/wiki/Sem%C3%A1ntica_ling%C3%BC%C3%ADstica",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Estructuralismo_(ling%C3%BC%C3%ADstica)",
            "/wiki/Oraci%C3%B3n_(gram%C3%A1tica)",
            "/wiki/A%C3%B1os_1950",
            "/wiki/Noam_Chomsky",
            "/wiki/Sistema_formal",
            "/wiki/Gram%C3%A1tica_generativa",
            "/wiki/Zoosemi%C3%B3tica",
            "/wiki/Origen_de_las_lenguas",
            "/wiki/Monog%C3%A9nesis_y_polig%C3%A9nesis_ling%C3%BC%C3%ADstica#Monogénesis",
            "/wiki/Protolengua",
            "/wiki/Biblia",
            "/wiki/Monog%C3%A9nesis_y_polig%C3%A9nesis_ling%C3%BC%C3%ADstica#Poligénesis",
            "/wiki/Cambio_ling%C3%BC%C3%ADstico",
            "/wiki/Lenguas_criollas",
            "/wiki/Pidgin",
            "/wiki/Idioma_de_se%C3%B1as_de_Nicaragua",
            "/wiki/Gram%C3%A1tica",
            "/wiki/Lenguas",
            "/wiki/Procesamiento_de_lenguajes_naturales",
            "/wiki/Generaci%C3%B3n_de_lenguajes_naturales",
            "/wiki/Idioma",
            "/wiki/Morris_Swadesh",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Pseudoc%C3%B3digo",
        "titulo": "Pseudocódigo",
        "contenido": "en ciencias de la computacion, y analisis numerico, el pseudocodigo​ (o lenguaje de descripcion algoritmico) es una descripcion de alto nivel compacta e informal​ del principio operativo de un programa informatico u otro algoritmo.  utiliza las convenciones estructurales de un lenguaje de programacion real,​ pero esta diseñado para la lectura humana en lugar de la lectura mediante maquina,​ y con independencia de cualquier otro lenguaje de programacion.​ normalmente, el pseudocodigo omite detalles que no son esenciales para la comprension humana del algoritmo, tales como declaraciones de variables, codigo especifico del sistema y algunas subrutinas. el lenguaje de programacion se complementa, donde sea conveniente, con descripciones detalladas en lenguaje natural, o con notacion matematica compacta. se utiliza pseudocodigo pues este es mas facil de entender para las personas que el codigo del lenguaje de programacion convencional, ya que es una descripcion eficiente y con un entorno independiente de los principios fundamentales de un algoritmo. se utiliza comunmente en los libros de texto y publicaciones cientificas que se documentan varios algoritmos, y tambien en la planificacion del desarrollo de programas informaticos, para esbozar la estructura del programa antes de realizar la efectiva codificacion. es comunmente utilizado por los programadores para omitir secciones de codigo o para dar una explicacion del paradigma que tomo el mismo programador para hacer sus codigos, esto quiere decir que el pseudocodigo no es programable, sino facilita la programacion.  el principal objetivo del pseudocodigo es el de representar la solucion a un algoritmo de la forma mas detallada posible, y a su vez lo mas parecida posible al lenguaje que posteriormente se utilizara para la codificacion del mismo.  no existe una sintaxis estandar para el pseudocodigo, aunque los cinco ide's que manejan pseudocodigo en español tengan su sintaxis propia. aunque sea parecido, el pseudocodigo no debe confundirse con los programas esqueleto que incluyen codigo ficticio, que pueden ser compilados sin errores. los diagramas de flujo y uml pueden ser considerados como una alternativa grafica al pseudocodigo, aunque sean mas amplios  generalmente se utiliza pseudocodigo en los libros de texto y publicaciones cientificas relacionadas con la informatica y la computacion numerica, para la descripcion de algoritmos, de manera que todos los programadores puedan entenderlo, aunque no todos conozcan el mismo lenguaje de programacion. generalmente, en los libros de texto se adjunta una explicacion que acompaña a la introduccion y que explica las convenciones particulares en uso. el nivel de detalle del seudocientifico puede, en algunos casos, acercarse a la de formalizar los idiomas de proposito general.  un programador que tiene que aplicar un algoritmo especifico, sobre todo uno desfamiliarizado, generalmente comienza con una descripcion en pseudocodigo, y luego \"traduce\" esa descripcion en el lenguaje de programacion meta y lo modifica para que interactue correctamente con el resto del programa. los programadores tambien pueden iniciar un proyecto describiendo la forma del codigo en pseudocodigo en el papel antes de escribirlo en su lenguaje de programacion, como ocurre en la estructuracion de un enfoque de top-down y bottom-up arriba hacia abajo.  en la actualidad y por lo general, el pseudocodigo, como su nombre lo indica, no obedece a las reglas de sintaxis de ningun idioma en particular ni es de forma estandar sistematica, a pesar de que cualquier escritor en particular vaya a pedir prestado las estructuras de control general, la sintaxis y el estilo, por ejemplo, de algun lenguaje de programacion convencional. pero en caso de que se quiera ejecutar, se debe llevar a forma tipo, para que no genere mensajes de error. las fuentes populares incluyen la sintaxis de pascal, basic, c, c++, java, lisp, y algol. por lo general, se omiten las declaraciones de variables. a veces, las llamadas a funciones, los bloques de codigo y el codigo contenido dentro de un loop se remplazan por una sentencia de una linea en lenguaje natural.  este es un ejemplo de pseudocodigo (para el juego matematico bizz buzz):  pseudocodigo estilo fortran:  pseudocodigo estilo pascal:  pseudocodigo estilo c:  la definicion de datos se da por supuesta, sobre todo en las variables sencillas, si se emplea formaciones: pilas, colas, vectores o registros, se pueden definir en la cabecera del algoritmo, y naturalmente cuando empleemos el pseudocodigo para definir estructuras de datos, esta parte la desarrollaremos adecuadamente.  cada autor usa su propio pseudocodigo con sus respectivas convenciones. por ejemplo, la instruccion \"reemplace el valor de la variable x por el valor de la variable y \" puede ser representado como:  las operaciones aritmeticas se representan de la forma usual en matematicas.  en la redaccion de pseudocodigo se utiliza tres tipos de estructuras de control: las secuenciales, las selectivas y las iterativas.  las instrucciones se siguen en una secuencia fija que normalmente viene dada por el numero de renglon. es decir que las instrucciones se ejecutan de arriba hacia abajo.  las instrucciones selectivas representan instrucciones que pueden o no ejecutarse, segun el cumplimiento de una condicion.    la condicion es una expresion booleana. instrucciones es ejecutada solo si la condicion es verdadera.  la instruccion alternativa realiza una instruccion de dos posibles, segun el cumplimiento de una condicion.    la condicion es una variable booleana o una funcion reducible a booleana (logica, verdadero/falso). si esta condicion es cierta se ejecuta instrucciones1, si no es asi, entonces se ejecuta instrucciones2.  tambien es comun el uso de una seleccion multiple que equivaldria a anidar varias funciones de seleccion.  en este caso hay una serie de condiciones que tienen que ser mutuamente excluyentes, si una de ellas se cumple las demas tienen que ser falsas necesariamente, hay un caso si no que sera cierto cuando las demas condiciones sean falsas.  en esta estructura si condicion1 es cierta, entonces se ejecuta solo instrucciones1. en general, si condicioni es verdadera, entonces solo se ejecuta instruccionesi  una construccion similar a la anterior (equivalente en algunos casos) es la que se muestra a continuacion.  en este caso hay un indicador es una variable o una funcion cuyo valor es comparado en cada caso con los valores \"valori\", si en algun caso coinciden ambos valores, entonces se ejecutaran las instruccionesi correspondientes. la seccion en otro caso es analoga a la seccion si no del ejemplo anterior.  las instrucciones iterativas representan la ejecucion de instrucciones en mas de una vez.  el bucle se repite mientras la condicion sea cierta, si al llegar por primera vez al bucle mientras la condicion es falsa, el cuerpo del bucle no se ejecuta alguna vez.    existen otras variantes que se derivan a partir de la anterior. la estructura de control repetir se utiliza cuando es necesario que el cuerpo del bucle se ejecuten al menos una vez y hasta que se cumpla la condicion:  la estructura anterior equivaldria a escribir:  el bucle hacer se utiliza para repetir un bloque de codigo mientras se cumpla cierta condicion.  una estructura de control muy comun es el ciclo for, la cual se usa cuando se desea iterar un numero conocido de veces, empleando como indice una variable que se incrementa (o decrementa):  la cual se define como:  por ultimo, tambien es comun usar la estructura de control para cada. esta sentencia se usa cuando se tiene una lista o un conjunto l y se quiere iterar por cada uno de sus elementos:  si asumimos que los elementos de l son l 0 , l 1 , … , l n ,l_{1},\\dots ,l_{n}} , entonces esta sentencia equivaldria a:  que es lo mismo que:  sin embargo, en la practica existen mejores formas de implementar esta instruccion dependiendo del problema.  es importante recalcar que el pseudocodigo no es un lenguaje estandarizado. eso significa que diferentes autores podrian dar otras estructuras de control o bien usar estas mismas estructuras, pero con una notacion diferente. sin embargo, las funciones matematicas y logicas toman el significado usual que tienen en matematica y logica, con las mismas expresiones.  cualquier instruccion puede ser sustituida por una estructura de control. el siguiente ejemplo muestra el pseudocodigo del ordenamiento de burbuja, que tiene varias estructuras anidadas. este algoritmo ordena de menor a mayor los elementos de una lista l .   p r o c e d i m i e n t o o r d e n a r ( l ) ↕ / / c o m e n t a r i o : l = ( l 1 , l 2 , … , l n ) e s u n a l i s t a c o n n e l e m e n t o s / / k ← 0 ; r e p e t i r ↕ i n t e r c a m b i o ← f a l s o ; k ← k + 1 ; p a r a i ← 1 h a s t a n − k c o n p a s o 1 h a c e r ↕ s i l i > l i + 1 e n t o n c e s ↕ i n t e r c a m b i a r ( l i , l i + 1 ) i n t e r c a m b i o ← v e r d a d e r o ; f i n s i f i n p a r a h a s t a q u e i n t e r c a m b i o = f a l s o ; f i n p r o c e d i m i e n t o {l}\\mathrm {procedimiento} }\\;\\mathrm {ordenar} }\\;(l}\\;)\\\\\\left\\updownarrow {l}//comentario:\\;l=(l_{1},l_{2},\\dots ,l_{n})\\;es\\;una\\;lista\\;con\\;n\\;elementos//}\\\\k}\\;\\gets }\\;0;}\\\\\\mathrm {repetir} }\\\\\\left\\updownarrow {l}\\mathrm {intercambio} }\\;\\gets }\\;\\mathrm {falso} ;}\\\\k}\\;\\gets }\\;k+1;}\\\\\\mathrm {para} }\\;i}\\;\\gets }\\;1}\\;\\mathrm {hasta} }\\;n-k}\\;\\mathrm {con\\;paso} }\\;1}\\;\\mathrm {hacer} }\\\\\\left\\updownarrow {l}\\mathrm {si} }\\;l_{i}}\\;>}\\;l_{i+1}}\\;\\mathrm {entonces} }\\;\\\\\\left\\updownarrow {l}\\mathrm {intercambiar} }\\;(l_{i},l_{i+1}}\\;)\\\\\\mathrm {intercambio} }\\;\\gets }\\;\\mathrm {verdadero} ;}\\end{array}}\\right.\\\\\\mathrm {fin\\;si} }\\;\\\\\\end{array}}\\right.\\\\\\mathrm {fin\\;para} }\\\\\\end{array}}\\right.\\\\\\mathrm {hasta\\;que} }\\;\\mathrm {intercambio} }\\;=}\\;\\mathrm {falso} ;}\\end{array}}\\right.\\\\\\mathrm {fin\\;procedimiento} }\\;\\\\\\end{array}}}  en general, las estructuras anidadas se muestran indentadas, para hacer mas sencilla su identificacion a simple vista. en el ejemplo, ademas de la sangria, se ha conectado con flechas los pares de delimitadores de cada nivel de anidamiento.  muchas personas prefieren distinguir entre funciones y procedimientos. una funcion, al igual que una funcion matematica, recibe uno o varios valores de entrada y regresa una salida mientras que un procedimiento recibe una entrada y no genera alguna salida aunque en algun caso podria devolver resultados a traves de sus parametros de entrada si estos se han declarado por referencia (ver formas de pasar argumentos a una funcion o procedimiento).  en ambos casos es necesario dejar en claro cuales son las entradas para el algoritmo, esto se hace comunmente colocando estos valores entre parentesis al principio o bien declarandolo explicitamente con un enunciado. en el caso de las funciones, es necesario colocar una palabra como regresar o devolver para indicar cual es la salida generada por el algoritmo. por ejemplo, el pseudocodigo de una funcion que permite calcular a n } (un numero a elevado a potencia n ).  un ejemplo de procedimiento seria el algoritmo de ordenamiento de burbuja, por el que partiendo de una lista de valores estos se ordenan, notese que en un procedimiento, no se calcula el valor de una funcion, sino que se realiza una accion, en este caso ordenar la lista.  con el pseudocodigo se puede desarrollar cualquier algoritmo que:  los pseudocodigos presentan los siguientes beneficios: ",
        "snippet": "En ciencias de la computación, y análisis numérico, el pseudocódigo[1]​ (o lenguaje de descripción algorítmico) es una descripción de alto nivel compacta e informal[2]​ del principio operativo de un programa informático u otro algoritmo.",
        "enlaces_salientes": [
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Lenguaje",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Algoritmo",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Subrutina",
            "/wiki/Lenguaje_natural",
            "/wiki/Sintaxis",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Compilador",
            "/wiki/Diagrama_de_flujo",
            "/wiki/UML",
            "/wiki/Programador",
            "/wiki/Top-down_y_Bottom-up",
            "/wiki/Estructuras_de_control",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/BASIC",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%2B%2B",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Lisp",
            "/wiki/ALGOL",
            "/wiki/Fortran",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Bucle_while",
            "/wiki/Bloque_de_c%C3%B3digo",
            "/wiki/Bucle_for",
            "/wiki/Lista_enlazada",
            "/wiki/Conjunto",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Argumento_(inform%C3%A1tica)#Paso_de_Argumentos",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/PSeInt",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Resoluci%C3%B3n_de_problemas_de_programaci%C3%B3n",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Estructuras_de_control",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Bucle_for",
            "/wiki/Bucle_do",
            "/wiki/Bucle_while",
            "/wiki/Bucle_repetir",
            "/wiki/Bucle_infinito",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Diagramas_de_flujo",
        "titulo": "Diagrama de flujo",
        "contenido": "el diagrama de flujo o flujograma o diagrama de actividades es la representacion grafica de un algoritmo o proceso. se utiliza en disciplinas como programacion, economia, procesos industriales y psicologia cognitiva.  en lenguaje unificado de modelado (uml), es un diagrama de actividades que representa los flujos de trabajo paso a paso. un diagrama de actividades muestra el flujo de control general.  en sysml el diagrama ha sido extendido para indicar flujos entre pasos que mueven elementos fisicos (p. ej., gasolina) o energia (p. ej., presion). los cambios adicionales permiten al diagrama soportar mejor flujos de comportamiento y datos continuos.  estos diagramas utilizan simbolos con significados definidos que representan los pasos del algoritmo, y representan el flujo de ejecucion mediante flechas que conectan los puntos de inicio y de fin del proceso.  las siguientes son acciones previas a la realizacion del diagrama de flujo:  los pasos a seguir para construir el diagrama de flujo son:  en uml 1.x, un diagrama de actividades es una variacion del diagrama de estado unl donde los \"estados\" representan operaciones, y las transiciones representan las actividades que ocurren cuando la operacion se termina.  el diagrama de mensajes de uml 2.0, mientras que es similar en aspecto al diagrama de actividades uml 1.x, ahora tiene semanticas basadas en redes de petri. en uml 2.0, el diagrama general de interaccion esta basado en el diagrama de actividades. el diagrama de actividad es una forma especial de diagrama de estado usado para modelar una secuencia de acciones y condiciones tomadas dentro de un proceso.  la especificacion del lenguaje de notificacion unificado (unl) define un diagrama de actividad como:  el proposito del diagrama de actividad es modelar un proceso de flujo de trabajo (workflow) y/o modelar operaciones.  una operacion es un servicio proporcionado por un objeto, que esta disponible a traves de una interfaz.  una interfaz es un grupo de operaciones relacionadas con la semantica.  1.-segun gomez cejas, guillermo. año 1997:  2.-segun chiavenato, idalberto. año 1993:  3.-segun gomez rondon, francisco. año 1995:  el instituto nacional estadounidense de estandares (ansi, por su siglas en ingles) establecio estandares para los diagramas de flujo y sus simbolos en los años 1960s.​ la organizacion internacional de normalizacion (iso, por sus siglas en ingles) adopto los simbolos ansi en 1970.​ el estandar actual, iso 5807, fue revisado en 1985.​  se trata de la mas comun y practica entre todas las clases de diagramas de flujo. describe el flujo de informacion en un ente u organizacion, sus procesos, sistemas administrativos y de control. permite la impresion visual de los procedimientos y una clara y logica interpretacion.  segun la normativa, el flujo presupuesto es de izquierda a derecha y de arriba hacia abajo, siendo optativo el uso de flechas. cuando el sentido es invertido (de derecha a izquierda o de abajo hacia arriba), es obligatorio el uso de la flecha.​  la paternidad del diagrama de flujo es en principio algo difusa. el metodo estructurado para documentar graficamente un proceso como un flujo de pasos sucesivos y alternativos, el \"proceso de diagrama de flujo\", fue expuesto por frank gilbreth, en la sociedad americana de ingenieros mecanicos (asme), en 1921, bajo el enunciado de \"proceso de graficas-primeros pasos para encontrar el mejor modo\". estas herramientas de gilbreth rapidamente encontraron sitio en los programas de ingenieria industrial.  al principio de los 30, un ingeniero industrial, allan h. mogensen comenzo la formacion de personas de negocios en lake placid, nueva york, incluyendo el uso del diagrama de flujo. art spinanger, asistente a las clases de mogesen, utilizo las herramientas en su trabajo en procter & gamble, donde desarrollo su “programa metodico de cambios por etapas”. otro asistente al grupo de graduados en 1944, ben s. graham, director de ingenieria de formcraft standard register corporation, adapto la grafica de flujo de procesos al tratamiento de la informacion en su empresa. y desarrollo la grafica del proceso de multiples flujos en multiples pantallas, documentos, y sus relaciones. en 1947, asme adopto un conjunto de simbolos derivados de la obra original de gilbreth como norma asme para los graficos de procesos (preparada mishad, ramsan y raiaan).  sin embargo, segun explica douglas hartree fueron originalmente herman goldstine y john von neumann quienes desarrollaron el diagrama de flujo (inicialmente llamado \"diagrama\") para planificar los programas de ordenador. las tablas de programacion original de flujo de goldstine y von neumann, aparecen en un informe no publicado, \"planificacion y codificacion de los problemas de un instrumento de computacion electronica, la parte ii, volumen 1 \"(1947), reproducido en las obras completas de von neumann.  inicialmente los diagramas de flujo resultaron un medio popular para describir algoritmos de computadora, y aun se utilizan con este fin. herramientas como los diagramas de actividad uml, pueden ser considerados como evoluciones del diagrama de flujo.  en la decada de 1970 la popularidad de los diagramas de flujo como metodo propio de la informatica disminuyo, con el nuevo hardware y los nuevos lenguajes de programacion de tercera generacion. y por otra parte se convirtieron en instrumentos comunes en el mundo empresarial. son una expresion concisa, legible y practica de algoritmos. actualmente se aplican en muchos campos del conocimiento, especialmente como simplificacion y expresion logica de procesos, etc.  actualmente existe una gran cantidad de software para la elaboracion de diagramas de flujo. a continuacion se listan los programas mas comunes para elaborar diagramas de flujo.  tambien existen aplicaciones que permiten que, una vez que un creador haya diseñado el diagrama de flujo, un usuario final lo utilice y, sobre la base de las opciones que vaya escogiendo, se le vayan mostrando las siguientes etapas hasta llegar a un resultado final. un ejemplo de este tipo de aplicaciones es iboske. ",
        "snippet": "El diagrama de flujo o flujograma o diagrama de actividades es la representación gráfica de un algoritmo o proceso. Se utiliza en disciplinas como programación, economía, procesos industriales y psicología cognitiva.",
        "enlaces_salientes": [
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/L%C3%A1mpara",
            "/wiki/Bucle_for",
            "/wiki/Gr%C3%A1fica",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Econom%C3%ADa",
            "/wiki/Proceso_de_fabricaci%C3%B3n",
            "/wiki/Psicolog%C3%ADa_cognitiva",
            "/wiki/Lenguaje_Unificado_de_Modelado",
            "/wiki/Flujo_de_trabajo",
            "/wiki/SysML",
            "/wiki/Red_de_Petri",
            "/wiki/Instituto_Nacional_Estadounidense_de_Est%C3%A1ndares",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/Estadio_(geometr%C3%ADa)",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/Paralelogramo",
            "/wiki/Campo_de_b%C3%A9isbol#Home_plate",
            "/wiki/Pent%C3%A1gono",
            "/wiki/%C3%93valo",
            "/wiki/Elipse",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/C%C3%ADrculo",
            "/wiki/Tri%C3%A1ngulo",
            "/wiki/Lake_Placid",
            "/wiki/Nueva_York",
            "/wiki/Herman_Goldstine",
            "/wiki/John_von_Neumann",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Ordenador",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Microsoft_Office",
            "/wiki/Microsoft_Word",
            "/wiki/Microsoft_Excel",
            "/wiki/Microsoft_PowerPoint",
            "/wiki/Microsoft_Visio",
            "/wiki/LibreOffice_Draw",
            "/wiki/GitMind",
            "/wiki/XMind",
            "/wiki/DRAKON",
            "/wiki/UML",
            "/wiki/Flujo_de_trabajo",
            "/wiki/Red_de_Petri",
            "/wiki/Diagrama_de_secuencia",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Resoluci%C3%B3n_de_problemas_de_programaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Estructuras_de_control",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Bucle_for",
            "/wiki/Bucle_while",
            "/wiki/Bucle_repetir",
            "/wiki/Bucle_infinito",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/National_Archives_and_Records_Administration",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Lenguaje_de_programaci%C3%B3n",
        "titulo": "Lenguaje de programación",
        "contenido": "un lenguaje de programacion es un lenguaje formal (o artificial, es decir, un lenguaje con reglas gramaticales bien definidas) que proporciona a una persona, en este caso el programador, la capacidad y habilidad de escribir (o programar) una serie de instrucciones o secuencias de ordenes en forma de algoritmos con el fin de controlar el comportamiento fisico o logico de un sistema informatico, para que de esa manera se puedan obtener diversas clases de datos o ejecutar determinadas tareas. a todo este conjunto de ordenes escritas mediante un lenguaje de programacion se le denomina programa informatico.​​​​  programar viene a ser el proceso de crear un software fiable mediante la escritura, prueba, depuracion, compilacion o interpretacion, y mantenimiento del codigo fuente de dicho programa informatico. basicamente, este proceso se define aplicando logicamente los siguientes pasos:  los lenguajes de programacion estan formados por un conjunto de simbolos (llamado alfabeto), reglas gramaticales (lexico/morfologicas y sintacticas) y semanticas, que en conjunto definen las estructuras validas del lenguaje y su significado. existe el error comun de tratar como sinonimos los terminos 'lenguaje de programacion' y 'lenguaje informatico'. los lenguajes informaticos engloban a los lenguajes de programacion y a otros mas, como por ejemplo html (lenguaje para el marcado de paginas web, que no es propiamente un lenguaje de programacion, sino un conjunto de instrucciones que permiten estructurar el contenido de los documentos).  el lenguaje de programacion permite especificar de manera precisa sobre que datos debe operar un software especifico, como deben ser almacenados o transmitidos dichos datos, y que acciones debe tomar el software bajo una variada gama de circunstancias. todo esto, a traves de un lenguaje que intenta estar relativamente proximo al lenguaje humano o natural. una caracteristica relevante de los lenguajes de programacion es precisamente que mas de un programador pueda usar un conjunto comun de instrucciones que sean comprendidas entre ellos para realizar la construccion de un programa de forma colaborativa.  para que la computadora entienda nuestras instrucciones debe usarse un lenguaje especifico conocido como codigo maquina, que la maquina lee facilmente, pero que es excesivamente complicado para las personas. de hecho, solo consiste en cadenas extensas de numeros 0 y 1(numeros binarios).  para facilitar el trabajo, los primeros operadores de computadoras decidieron crear un traductor para reemplazar los 0 y 1 por palabras o abstraccion de palabras y letras provenientes del ingles; este se conoce como lenguaje ensamblador. por ejemplo, para sumar se usa la letra a de la palabra inglesa add (sumar). el lenguaje ensamblador sigue la misma estructura del lenguaje maquina, pero las letras y palabras son mas faciles de recordar y entender que los numeros.  la necesidad de recordar secuencias de programacion para las acciones usuales llevo a denominarlas con nombres faciles de memorizar y asociar: add (sumar), sub (restar), mul (multiplicar), call (ejecutar subrutina), etc. a esta secuencia de posiciones se le denomino \"instrucciones\", y a este conjunto de instrucciones se le llamo lenguaje ensamblador. posteriormente aparecieron diferentes lenguajes de programacion, los cuales reciben su denominacion porque tienen una estructura sintactica semejante a la de los lenguajes escritos por los humanos, denominados tambien lenguajes de alto nivel.​  a finales de 1953, john backus sometio una propuesta a sus superiores en ibm para desarrollar una alternativa mas practica al lenguaje ensamblador, para programar la computadora central ibm 704. el historico equipo fortran de john backus consistio en los programadores richard goldberg, sheldon f. best, harlan herrick, peter sheridan, roy nutt, robert nelson, irving ziller, lois haibt y david sayre.​  el primer manual para el lenguaje fortran aparecio en octubre de 1956, con el primer compilador fortran entregado en abril de 1957. esto era un compilador optimizado, porque los clientes eran reacios a usar un lenguaje de alto nivel a menos que su compilador pudiera generar codigo cuyo desempeño fuera comparable al de un codigo hecho a mano en lenguaje ensamblador.  en 1960 se creo cobol, uno de los lenguajes usados aun en la actualidad, en informatica de gestion.  a medida que la complejidad de las tareas que realizaban las computadoras aumentaba, se hizo necesario disponer de un metodo mas eficiente para programarlas. entonces se crearon los lenguajes de alto nivel, como lo fue basic en las versiones introducidas en los microordenadores de la decada de 1980. mientras que una tarea tan sencilla como sumar dos numeros puede necesitar varias instrucciones en lenguaje ensamblador, en un lenguaje de alto nivel bastara una sola sentencia.  los lenguajes de programacion han sido historicamente clasificados atendiendo a distintos criterios:  en algunas ocasiones los lenguajes de programacion son tambien clasificados en familias que comparten ciertas caracteristicas comunes como el estilo general de la sintaxis que emplean. habitualmente estas caracteristicas suelen ser heredadas de lenguajes de programacion anteriores que sirvieron de inspiracion a los creadores de dicho lenguaje.  los equipos de ordenador (el hardware) han pasado por cuatro generaciones, de las que las tres primeras (ordenadores con valvulas, transistores y circuitos integrados) estan muy claras; la cuarta (circuitos integrados a gran escala) es mas discutible.  algo parecido ha ocurrido con la programacion de los ordenadores (el software), que se realiza en lenguajes que suelen clasificarse en cinco generaciones, de las que las tres primeras son evidentes, mientras no todo el mundo esta de acuerdo en las otras dos. estas generaciones no coincidieron exactamente en el tiempo con las de hardware, pero si de forma aproximada, y son las siguientes:  algunos ejemplos de lenguajes de programacion de quinta generacion son:  un paradigma de programacion consiste en un metodo para llevar a cabo computos y la forma en la que deben estructurarse y organizarse las tareas que debe realizar un programa.​ se trata de una propuesta tecnologica adoptada por una comunidad de programadores, y desarrolladores cuyo nucleo central es incuestionable en cuanto que unicamente trata de resolver uno o varios problemas claramente delimitados; la resolucion de estos problemas debe suponer consecuentemente un avance significativo en al menos un parametro que afecte a la ingenieria de software. representa un enfoque particular o filosofia para diseñar soluciones. los paradigmas difieren unos de otros, en los conceptos y la forma de abstraer los elementos involucrados en un problema, asi como en los pasos que integran su solucion del problema, en otras palabras, el computo. tiene una estrecha relacion con la formalizacion de determinados lenguajes en su momento de definicion. es un estilo de programacion empleado.  un paradigma de programacion esta delimitado en el tiempo en cuanto a aceptacion y uso, porque nuevos paradigmas aportan nuevas o mejores soluciones que lo sustituyen parcial o totalmente.  el paradigma de programacion que actualmente es mas utilizado es la \"orientacion a objetos\" (oo). el nucleo central de este paradigma es la union de datos y procesamiento en una entidad llamada \"objeto\", relacionable a su vez con otras entidades \"objeto\".  tradicionalmente, datos y procesamiento se han separado en areas diferente del diseño y la implementacion de software. esto provoco que grandes desarrollos tuvieran problemas de fiabilidad, mantenimiento, adaptacion a los cambios y escalabilidad. con la oo y caracteristicas como el encapsulado, polimorfismo o la herencia, se permitio un avance significativo en el desarrollo de software a cualquier escala de produccion. la oo parece estar ligada en sus origenes con lenguajes como lisp y simula, aunque el primero que acuño el titulo de \"programacion orientada a objetos\" fue smalltalk.  en general, la mayoria de paradigmas son variantes de los dos tipos principales de programacion, imperativa y declarativa. en la programacion imperativa se describe paso a paso un conjunto de instrucciones que deben ejecutarse para variar el estado del programa y hallar la solucion, es decir, un algoritmo en el que se describen los pasos necesarios para solucionar el problema.  en la programacion declarativa las sentencias que se utilizan lo que hacen es describir el problema que se quiere solucionar; se programa diciendo lo que se quiere resolver a nivel de usuario, pero no las instrucciones necesarias para solucionarlo. esto ultimo se realizara mediante mecanismos internos de inferencia de informacion a partir de la descripcion realizada.  a continuacion se describen algunas de las distintas variantes de paradigmas de programacion:  las variables son titulos asignados a espacios en memoria para almacenar datos especificos. son contenedores de datos y por ello se diferencian segun el tipo de dato que son capaces de almacenar. en la mayoria de lenguajes de programacion se requiere especificar un tipo de variable concreto para guardar un dato especifico. por ejemplo, en java, si deseamos guardar una cadena de texto debemos especificar que la variable es del tipo string. por otra parte, en lenguajes como php o javascript este tipo de especificacion de variables no es necesario. ademas, existen variables compuestas llamadas vectores. un vector no es mas que un conjunto de bytes consecutivas en memoria y del mismo tipo guardadas dentro de una variable contenedor. a continuacion, un listado con los tipos de variables y vectores mas comunes:  en el caso de variables booleanas, el cero es considerado para muchos lenguajes como el literal falso (\"false\"), mientras que el uno se considera verdadero (\"true\").  las sentencias condicionales son estructuras de codigo que indican que, para que cierta parte del programa se ejecute, deben cumplirse ciertas premisas; por ejemplo: que dos valores sean iguales, que un valor exista, que un valor sea mayor que otro… estos condicionantes por lo general solo se ejecutan una vez a lo largo del programa. los condicionantes mas conocidos y empleados en programacion son:  los bucles son parientes cercanos de los condicionantes, pero ejecutan constantemente un codigo mientras se cumpla una determinada condicion. los mas frecuentes son:  hay que decir que a pesar de que existan distintos tipos de bucles, todos son capaces de realizar exactamente las mismas funciones. el empleo de uno u otro depende, por lo general, del gusto del programador.  las funciones se crearon para evitar tener que repetir constantemente fragmentos de codigo. una funcion podria considerarse como una variable que encierra codigo dentro de si. por lo tanto, cuando accedemos a dicha variable (la funcion) en realidad lo que estamos haciendo es ordenar al programa que ejecute un determinado codigo predefinido anteriormente.  todos los lenguajes de programacion tienen algunos elementos de formacion primitivos para la descripcion de los datos y de los procesos o transformaciones aplicadas a estos datos (tal como la suma de dos numeros o la seleccion de un elemento que forma parte de una coleccion). estos elementos primitivos son definidos por reglas sintacticas y semanticas que describen su estructura y significado respectivamente.  a la forma visible de un lenguaje de programacion se la conoce como sintaxis. la mayoria de los lenguajes de programacion son puramente textuales, es decir, utilizan secuencias de texto que incluyen palabras, numeros y puntuacion, de manera similar a los lenguajes naturales escritos. por otra parte, hay algunos lenguajes de programacion que son mas graficos en su naturaleza, utilizando relaciones visuales entre simbolos para especificar un programa.  la sintaxis de un lenguaje de programacion describe las combinaciones posibles de los simbolos que forman un programa sintacticamente correcto. el significado que se le da a una combinacion de simbolos es manejado por su semantica (ya sea formal o como parte del codigo duro de la referencia de implementacion). dado que la mayoria de los lenguajes son textuales, este articulo trata de la sintaxis textual.  la sintaxis de los lenguajes de programacion es definida generalmente utilizando una combinacion de expresiones regulares (para la estructura lexica/morfologica) y la notacion de backus-naur (para la estructura sintactica). este es un ejemplo de una gramatica simple, tomada del lenguaje lisp:  con esta gramatica se especifica lo siguiente:  algunos ejemplos de secuencias bien formadas de acuerdo a esta gramatica:  '12345', '()', '(a b c232 (1))'  no todos los programas sintacticamente correctos son semanticamente correctos. muchos programas sintacticamente correctos tienen inconsistencias con las reglas del lenguaje; y pueden (dependiendo de la especificacion del lenguaje y la solidez de la implementacion) resultar en un error de traduccion o ejecucion. en algunos casos, tales programas pueden exhibir un comportamiento indefinido. ademas, incluso cuando un programa esta bien definido dentro de un lenguaje, todavia puede tener un significado que no es el que la persona que lo escribio estaba tratando de construir.  usando el lenguaje natural, por ejemplo, puede no ser posible asignarle significado a una oracion gramaticalmente valida o la oracion puede ser falsa:  el siguiente fragmento en el lenguaje c es sintacticamente correcto, pero ejecuta una operacion que no esta definida semanticamente (dado que p es un apuntador nulo, las operaciones p->real y p->im no tienen ningun significado):  si la declaracion de tipo de la primera linea fuera omitida, el programa dispararia un error de compilacion, pues la variable \"p\" no estaria definida. pero el programa seria sintacticamente correcto todavia, dado que las declaraciones de tipo proveen informacion semantica solamente.  la gramatica necesaria para especificar un lenguaje de programacion puede ser clasificada por su posicion en la jerarquia de chomsky. la sintaxis de la mayoria de los lenguajes de programacion puede ser especificada utilizando una gramatica tipo-2, es decir, son gramaticas libres de contexto. algunos lenguajes, incluyendo a perl y a lisp, contienen construcciones que permiten la ejecucion durante la fase de analisis. los lenguajes que permiten construcciones que permiten al programador alterar el comportamiento de un analizador hacen del analisis de la sintaxis un problema sin decision unica, y generalmente oscurecen la separacion entre analisis y ejecucion. en contraste con el sistema de macros de lisp y los bloques begin de perl, que pueden tener calculos generales, las macros de c son meros reemplazos de cadenas, y no requieren ejecucion de codigo.  la semantica estatica define las restricciones sobre la estructura de los textos validos que resulta imposible o muy dificil expresar mediante formalismos sintacticos estandar. para los lenguajes compilados, la semantica estatica basicamente incluye las reglas semanticas que se pueden verificar en el momento de compilar. por ejemplo el chequeo de que cada identificador sea declarado antes de ser usado (en lenguajes que requieren tales declaraciones) o que las etiquetas en cada brazo de una estructura case sean distintas. muchas restricciones importantes de este tipo, como la validacion de que los identificadores sean usados en los contextos apropiados (por ejemplo no sumar un entero al nombre de una funcion), o que las llamadas a subrutinas tengan el numero y tipo de parametros adecuado, pueden ser implementadas definiendolas como reglas en una logica conocida como sistema de tipos. otras formas de analisis estaticos, como los analisis de flujo de datos, tambien pueden ser parte de la semantica estatica. otros lenguajes de programacion como java y c# tienen un analisis definido de asignaciones, una forma de analisis de flujo de datos, como parte de su semantica estatica.  un sistema de tipos de datos define la manera en la cual un lenguaje de programacion clasifica los valores y expresiones en tipos, como pueden ser manipulados dichos tipos y como interactuan. el objetivo de un sistema de tipos es verificar y normalmente poner en vigor un cierto nivel de exactitud en programas escritos en el lenguaje en cuestion, detectando ciertas operaciones invalidas. cualquier sistema de tipos decidible tiene sus ventajas y desventajas: mientras por un lado rechaza muchos programas incorrectos, tambien prohibe algunos programas correctos aunque poco comunes. para poder minimizar esta desventaja, algunos lenguajes incluyen lagunas de tipos, conversiones explicitas no verificadas que pueden ser usadas por el programador para permitir explicitamente una operacion normalmente no permitida entre diferentes tipos. en la mayoria de los lenguajes con tipos, el sistema de tipos es usado solamente para verificar los tipos de los programas, pero varios lenguajes, generalmente funcionales, llevan a cabo lo que se conoce como inferencia de tipos, que le quita al programador la tarea de especificar los tipos. al diseño y estudio formal de los sistemas de tipos se le conoce como teoria de tipos.  se dice que un lenguaje es tipado si la especificacion de cada operacion debe definir los tipos de datos para los cuales es aplicable, con la implicacion de que no es aplicable a otros tipos. por ejemplo, \"este texto entre comillas\" es una cadena de caracteres. en la mayoria de los lenguajes de programacion, dividir un numero por una cadena de caracteres no tiene ningun significado. por tanto, la mayoria de los lenguajes de programacion modernos rechazarian cualquier intento de ejecutar dicha operacion por parte de algun programa. en algunos lenguajes, estas operaciones sin significado son detectadas cuando el programa es compilado (validacion de tipos \"estatica\") y son rechazadas por el compilador, mientras en otros son detectadas cuando el programa es ejecutado (validacion de tipos \"dinamica\") y se genera una excepcion en tiempo de ejecucion.  un caso especial de lenguajes de tipo son los lenguajes de tipo sencillo. estos son con frecuencia lenguajes de marcado o de scripts, como rexx o sgml, y solamente cuentan con un tipo de datos; comunmente cadenas de caracteres que luego son usadas tanto para datos numericos como simbolicos.  en contraste, un lenguaje sin tipos, como la mayoria de los lenguajes ensambladores, permiten que cualquier operacion se aplique a cualquier dato, que por lo general se consideran secuencias de bits de varias longitudes. lenguajes de alto nivel sin datos incluyen bcpl y algunas variedades de forth.  en la practica, aunque pocos lenguajes son considerados con tipo desde el punto de vista de la teoria de tipos (es decir, que verifican o rechazan todas las operaciones), la mayoria de los lenguajes modernos ofrecen algun grado de manejo de tipos. si bien muchos lenguajes de produccion proveen medios para evitar o rodear el sistema de tipado.  en lenguajes con tipos estaticos se determina el tipo de todas las expresiones antes de la ejecucion del programa (tipicamente al compilar). por ejemplo, 1 y (2+2) son expresiones enteras; no pueden ser pasadas a una funcion que espera una cadena, ni pueden guardarse en una variable que esta definida como fecha.  los lenguajes con tipos estaticos pueden manejar tipos explicitos o tipos inferidos. en el primer caso, el programador debe escribir los tipos en determinadas posiciones textuales. en el segundo caso, el compilador infiere los tipos de las expresiones y las declaraciones de acuerdo al contexto. la mayoria de los lenguajes populares con tipos estaticos, tales como c++, c# y java, manejan tipos explicitos. inferencia total de los tipos suele asociarse con lenguajes menos populares, tales como haskell y ml. sin embargo, muchos lenguajes de tipos explicitos permiten inferencias parciales de tipo; tanto java y c#, por ejemplo, infieren tipos en un numero limitado de casos.  los lenguajes con tipos dinamicos determinan la validez de los tipos involucrados en las operaciones durante la ejecucion del programa. en otras palabras, los tipos estan asociados con valores en ejecucion en lugar de expresiones textuales. como en el caso de lenguajes con tipos inferidos, los lenguajes con tipos dinamicos no requieren que el programador escriba los tipos de las expresiones. entre otras cosas, esto permite que una misma variable se pueda asociar con valores de tipos distintos en diferentes momentos de la ejecucion de un programa. sin embargo, los errores de tipo no pueden ser detectados automaticamente hasta que se ejecuta el codigo, dificultando la depuracion de los programas, no obstante, en lenguajes con tipos dinamicos se suele dejar de lado la depuracion en favor de tecnicas de desarrollo como por ejemplo bdd y tdd. ruby, lisp, javascript y python son lenguajes con tipos dinamicos.  los lenguajes debilmente tipados permiten que un valor de un tipo pueda ser tratado como de otro tipo, por ejemplo una cadena puede ser operada como un numero. esto puede ser util a veces, pero tambien puede permitir ciertos tipos de fallas que no pueden ser detectadas durante la compilacion o a veces ni siquiera durante la ejecucion.  los lenguajes fuertemente tipados evitan que pase lo anterior. cualquier intento de llevar a cabo una operacion sobre el tipo equivocado dispara un error. a los lenguajes con tipos fuertes se les suele llamar de tipos seguros.  lenguajes con tipos debiles como perl y javascript permiten un gran numero de conversiones de tipo implicitas. por ejemplo en javascript la expresion 2 * x convierte implicitamente x a un numero, y esta conversion es exitosa inclusive cuando x es null, undefined, un array o una cadena de letras. estas conversiones implicitas son utiles con frecuencia, pero tambien pueden ocultar errores de programacion.  las caracteristicas de estaticos y fuertes son ahora generalmente consideradas conceptos ortogonales, pero su trato en diferentes textos varia. algunos utilizan el termino de tipos fuertes para referirse a tipos fuertemente estaticos o, para aumentar la confusion, simplemente como equivalencia de tipos estaticos. de tal manera que c ha sido llamado tanto lenguaje de tipos fuertes como lenguaje de tipos estaticos debiles.  la implementacion de un lenguaje es la que provee una manera de que se ejecute un programa para una determinada combinacion de software y hardware. existen basicamente dos maneras de implementar un lenguaje: compilacion e interpretacion.  se puede tambien utilizar una alternativa para traducir lenguajes de alto nivel. en lugar de traducir el programa fuente y grabar en forma permanente el codigo objeto que se produce durante la compilacion para utilizarlo en una ejecucion futura, el programador solo carga el programa fuente en la computadora junto con los datos que se van a procesar. a continuacion, un programa interprete, almacenado en el sistema operativo del disco, o incluido de manera permanente dentro de la maquina, convierte cada proposicion del programa fuente en lenguaje de maquina conforme vaya siendo necesario durante el procesamiento de los datos. el codigo objeto no se graba para utilizarlo posteriormente.  la siguiente vez que se utilice una instruccion, se la debera interpretar otra vez y traducir a lenguaje maquina. por ejemplo, durante el procesamiento repetitivo de los pasos de un ciclo o bucle, cada instruccion del bucle tendra que volver a ser interpretada en cada ejecucion repetida del ciclo, lo cual hace que el programa sea mas lento en tiempo de ejecucion (porque se va revisando el codigo en tiempo de ejecucion) pero mas rapido en tiempo de diseño (porque no se tiene que estar compilando a cada momento el codigo completo). el interprete elimina la necesidad de realizar una compilacion despues de cada modificacion del programa cuando se quiere agregar funciones o corregir errores; pero es obvio que un programa objeto compilado con antelacion debera ejecutarse con mucha mayor rapidez que uno que se debe interpretar a cada paso durante una ejecucion del codigo.  la mayoria de lenguajes de alto nivel permiten la programacion multiproposito, aunque muchos de ellos fueron diseñados para permitir programacion dedicada, como lo fue el pascal con las matematicas en su comienzo. tambien se han implementado lenguajes educativos infantiles como logo mediante una serie de simples instrucciones. en la actualidad son muy populares algunos lenguajes especialmente indicados para aplicaciones web, como perl, php, ruby, python o javascript.  un dialecto de un lenguaje de programacion es una variacion o extension (relativamente pequeña) del lenguaje que no cambia su naturaleza intrinseca. con lenguajes como scheme y forth, los implementadores pueden considerar que los estandares son insuficientes, inadecuados o ilegitimos, por lo que a menudo se desviaran del estandar, haciendo un nuevo dialecto. en otros casos, se crea un dialecto para su uso en un lenguaje especifico de dominio, a menudo un subconjunto. en el mundo lisp, la mayoria de los lenguajes que utilizan la sintaxis basica de una expresion s y la semantica similar a lisp se consideran dialectos lisp, aunque varian enormemente, al igual que, digamos, raqueta y clojure. como es comun que un lenguaje tenga varios dialectos, puede resultar bastante dificil para un programador sin experiencia encontrar la documentacion correcta. el lenguaje de programacion basic tiene muchos dialectos.  para escribir programas que proporcionen los mejores resultados, cabe tener en cuenta una serie de detalles.  los programas se pueden clasificar por el paradigma del lenguaje que se use para producirlos. los principales paradigmas son: imperativos, declarativos y orientacion a objetos.  los programas que usan un lenguaje imperativo especifican un algoritmo, usan declaraciones, expresiones y sentencias.​ una declaracion asocia un nombre de variable con un tipo de dato, por ejemplo: var x: integer;. una expresion contiene un valor, por ejemplo: 2 + 2 contiene el valor 4. finalmente, una sentencia debe asignar una expresion a una variable o usar el valor de una variable para alterar el flujo de un programa, por ejemplo: x := 2 + 2; if x == 4 then haz_algo();. una critica comun en los lenguajes imperativos es el efecto de las sentencias de asignacion sobre una clase de variables llamadas \"no locales\".​  los programas que usan un lenguaje declarativo especifican las propiedades que la salida debe conocer y no especifican cualquier detalle de implementacion. dos amplias categorias de lenguajes declarativos son los lenguajes funcionales y los lenguajes logicos. los lenguajes funcionales no permiten asignaciones de variables no locales, asi, se hacen mas facil, por ejemplo, programas como funciones matematicas.​ el principio detras de los lenguajes logicos es definir el problema que se quiere resolver (el objetivo) y dejar los detalles de la solucion al sistema.​ el objetivo es definido dando una lista de sub-objetivos. cada sub-objetivo tambien se define dando una lista de sus sub-objetivos, etc. si al tratar de buscar una solucion, una ruta de sub-objetivos falla, entonces tal sub-objetivo se descarta y sistematicamente se prueba otra ruta.  la forma en la cual se programa puede ser por medio de texto o de forma visual. en la programacion visual los elementos son manipulados graficamente en vez de especificarse por medio de texto. ",
        "snippet": "Un lenguaje de programación es un lenguaje formal (o artificial, es decir, un lenguaje con reglas gramaticales bien definidas) que proporciona a una persona, en este caso el programador, la capacidad y habilidad de escribir (o programar) una serie de instrucciones o secuencias de órdenes en forma de algoritmos con el fin de controlar el comportamiento físico o lógico de un sistema informático, para que de esa manera se puedan obtener diversas clases de datos o ejecutar determinadas tareas. A todo este conjunto de órdenes escritas mediante un lenguaje de programación se le denomina programa informático.[1]​[2]​[3]​[4]​",
        "enlaces_salientes": [
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Microcomputadora",
            "/wiki/Commodore_International",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Lenguaje_de_programaci%C3%B3n_de_alto_nivel",
            "/wiki/BASIC",
            "/wiki/Emulador",
            "/wiki/VICE",
            "/wiki/GNU/Linux",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/Compilado",
            "/wiki/Ejecutable",
            "/wiki/Lenguaje_formal",
            "/wiki/Instrucci%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Algoritmo",
            "/wiki/Sistema_inform%C3%A1tico",
            "/wiki/Software",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Beta_tester",
            "/wiki/Depurador",
            "/wiki/Compilador",
            "/wiki/Int%C3%A9rprete_(inform%C3%A1tica)",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Compilador",
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Beta_tester",
            "/wiki/Depuraci%C3%B3n_de_programas",
            "/wiki/Palabra_(matem%C3%A1ticas)",
            "/wiki/Token_(inform%C3%A1tica)",
            "/wiki/Morfolog%C3%ADa_ling%C3%BC%C3%ADstica",
            "/wiki/Sintaxis",
            "/wiki/Sem%C3%A1ntica",
            "/wiki/Lenguaje_inform%C3%A1tico",
            "/wiki/HTML",
            "/wiki/Lenguaje_de_marcado",
            "/wiki/P%C3%A1gina_web",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/Software",
            "/wiki/Lenguaje",
            "/wiki/Historia_de_los_lenguajes_de_programaci%C3%B3n",
            "/wiki/Fortran",
            "/wiki/Tarjeta_perforada",
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Sistema_binario",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Sintaxis",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/1953",
            "/wiki/John_Backus",
            "/wiki/IBM",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Computadora_central",
            "/wiki/IBM_704",
            "/wiki/Fortran",
            "/wiki/John_Backus",
            "/wiki/Lois_Haibt",
            "/wiki/Fortran",
            "/wiki/1956",
            "/wiki/Compilador",
            "/wiki/Fortran",
            "/wiki/Abril",
            "/wiki/1957",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/1960",
            "/wiki/COBOL",
            "/wiki/Inform%C3%A1tica_de_gesti%C3%B3n",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/BASIC",
            "/wiki/1980",
            "/wiki/Arquitectura_de_computaci%C3%B3n",
            "/wiki/Computadora_electr%C3%B3nica",
            "/wiki/Hardware",
            "/wiki/V%C3%A1lvula_termoi%C3%B3nica",
            "/wiki/Transistor",
            "/wiki/Circuito_integrado",
            "/wiki/Circuito_integrado",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Software",
            "/wiki/Hardware",
            "/wiki/C%C3%B3digo_de_m%C3%A1quina",
            "/wiki/Sistema_binario",
            "/wiki/Lenguajes_de_bajo_nivel",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/Abstracci%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Sistemas_operativos",
            "/wiki/Controlador_de_dispositivo",
            "/wiki/Lenguaje_simb%C3%B3lico",
            "/wiki/Ensamblador",
            "/wiki/Lenguajes_de_alto_nivel",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Fortran",
            "/wiki/Smalltalk",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Ada",
            "/wiki/C%2B%2B",
            "/wiki/C_sharp",
            "/wiki/Cobol",
            "/wiki/Embarcadero_Delphi",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/PHP",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Base_de_datos",
            "/wiki/Visual_Basic",
            "/wiki/SQL",
            "/wiki/ISO",
            "/wiki/ANSI",
            "/wiki/Natural_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/PL/SQL",
            "/wiki/Programador",
            "/wiki/Desarrollador_de_software",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Paradigma",
            "/wiki/Orientaci%C3%B3n_a_objetos",
            "/wiki/Desarrollo_de_software",
            "/wiki/Lisp",
            "/wiki/Simula",
            "/wiki/Smalltalk",
            "/wiki/Algoritmo",
            "/wiki/Inferencia",
            "/wiki/Programaci%C3%B3n_imperativa",
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Lenguaje_de_programaci%C3%B3n_C",
            "/wiki/BASIC",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/C_Sharp",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Smalltalk",
            "/wiki/Programaci%C3%B3n_dirigida_por_eventos",
            "/wiki/Programaci%C3%B3n_declarativa",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Computadora",
            "/wiki/Transparencia_referencial",
            "/wiki/Lisp",
            "/wiki/Prolog",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Scheme",
            "/wiki/Lisp",
            "/wiki/Haskell",
            "/wiki/Python",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Prolog",
            "/wiki/Programaci%C3%B3n_con_restricciones",
            "/wiki/Prolog",
            "/wiki/Lisp",
            "/wiki/Python",
            "/wiki/PHP",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Reflexi%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Bjarne_Stroustrup",
            "/wiki/C%2B%2B",
            "/wiki/Genie_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Delphi",
            "/wiki/Visual_Basic",
            "/wiki/D_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Oz",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Scheme",
            "/wiki/Prolog",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Lenguaje_espec%C3%ADfico_del_dominio",
            "/wiki/SQL",
            "/wiki/Logo_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Variable_(programaci%C3%B3n)",
            "/wiki/Pauscal",
            "/wiki/Variable_(programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/PHP",
            "/wiki/JavaScript",
            "/wiki/Python",
            "/wiki/C%C3%B3digo_duro",
            "/wiki/Expresi%C3%B3n_regular",
            "/wiki/Notaci%C3%B3n_de_Backus-Naur",
            "/wiki/Lisp",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/Perl",
            "/wiki/Lisp",
            "/wiki/Lisp",
            "/wiki/Perl",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_Sharp",
            "/wiki/Sistema_de_tipos",
            "/wiki/Tipos_de_datos",
            "/wiki/Tipos_de_datos",
            "/wiki/Decidibilidad",
            "/wiki/Scripts",
            "/wiki/REXX",
            "/wiki/SGML",
            "/wiki/BCPL",
            "/wiki/Forth",
            "/wiki/C%2B%2B",
            "/wiki/C_Sharp",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Haskell",
            "/wiki/ML_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_Sharp",
            "/wiki/Diagrama_de_decisi%C3%B3n_binario",
            "/wiki/TDD",
            "/wiki/Ruby",
            "/wiki/Lisp",
            "/wiki/JavaScript",
            "/wiki/Python",
            "/wiki/Tipado_fuerte",
            "/wiki/Perl",
            "/wiki/JavaScript",
            "/wiki/JavaScript",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/Software",
            "/wiki/Hardware",
            "/wiki/Compilador",
            "/wiki/Interpretaci%C3%B3n_(l%C3%B3gica)",
            "/wiki/Compilaci%C3%B3n",
            "/wiki/Compilador",
            "/wiki/Interpretaci%C3%B3n",
            "/wiki/F%C3%B3rmula_bien_formada",
            "/wiki/Lenguaje_formal",
            "/wiki/Sintaxis",
            "/wiki/Cadena_de_caracteres",
            "/wiki/Int%C3%A9rprete_(inform%C3%A1tica)",
            "/wiki/C%C3%B3digo_objeto",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Pascal",
            "/wiki/Logo_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Aplicaci%C3%B3n_web",
            "/wiki/Perl",
            "/wiki/PHP",
            "/wiki/Ruby",
            "/wiki/Python",
            "/wiki/JavaScript",
            "/wiki/Scheme",
            "/wiki/Forth",
            "/wiki/Dialecto",
            "/wiki/Lenguaje_espec%C3%ADfico_de_dominio",
            "/wiki/Common_Lisp",
            "/wiki/Expresi%C3%B3n_S",
            "/wiki/Racket_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Clojure",
            "/wiki/BASIC",
            "/wiki/Programador",
            "/wiki/Arte_ASCII",
            "/wiki/C%C3%B3digo_ofuscado",
            "/wiki/GNU/Linux",
            "/wiki/Sistemas_operativos",
            "/wiki/Microsoft_Windows",
            "/wiki/Paradigma_de_programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n_imperativa",
            "/wiki/Programaci%C3%B3n_declarativa",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Programaci%C3%B3n_visual",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/Programaci%C3%B3n_modular",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Programaci%C3%B3n_orientada_a_aspectos",
            "/wiki/Programaci%C3%B3n_con_restricciones",
            "/wiki/Programaci%C3%B3n_a_nivel_funcional",
            "/wiki/Programaci%C3%B3n_a_nivel_de_valores",
            "/wiki/Lenguaje_de_programaci%C3%B3n_esot%C3%A9rico",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/D_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Control_de_autoridades",
            "/wiki/MediaWiki",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/MediaWiki"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Teorema",
        "titulo": "Teorema",
        "contenido": "un teorema es  una proposicion cuya verdad se demuestra. en matematicas, es toda proposicion que, partiendo de un supuesto (hipotesis), afirma una racionabilidad (tesis) no evidente por si misma.​  tambien puede decirse que un teorema es una formula bien formada que puede ser demostrada dentro de un sistema formal, partiendo de axiomas, nocion  y otros teoremas. demostrar teoremas es un asunto central en la logica matematica. los teoremas tambien pueden ser expresados en lenguaje natural formalizado.  los teoremas generalmente poseen un numero de premisas que deben ser enumeradas o aclaradas de antemano. la conclusion del teorema es una afirmacion logica o matematica que es verdadera bajo las condiciones dadas. el contenido informativo del teorema es la relacion que existe entre las hipotesis y la tesis o la conclusion.  se llama corolario a una afirmacion logica que es consecuencia inmediata de un teorema, pudiendo ser demostrada usando las propiedades del teorema de referencia.  un teorema requiere de un marco logico; este marco consistira en un conjunto de axiomas (sistema axiomatico) y un proceso de inferencia, el cual permite derivar teoremas a partir de los axiomas y teoremas que han sido derivados pero no son axiomas.  en logica proposicional y de primer orden, cualquier afirmacion demostrada se denomina teorema. mas concretamente en logica se llama demostracion a una secuencia finita de formulas bien formadas (formulas logicas bien formadas) f1, ...,fn, tales que cada fi es o bien un axioma o bien un teorema que se sigue de dos formulas anteriores fj y fk (tales que j<i y k<i) mediante una regla de deduccion. dada una demostracion como la anterior si el elemento final fn no es un axioma entonces es un teorema. resumiendo lo anterior puede decirse formalmente, un teorema es una formula bien formada, que no es un axioma, y que puede ser el elemento final de alguna demostracion, es decir, un teorema es una formula bien formada para la cual existe una demostracion.  hasta finales del siglo xix y la crisis fundacional de las matematicas, todas las teorias matematicas se construyeron a partir de unas pocas propiedades basicas que se consideraban evidentes; por ejemplo, los hechos de que todo numero natural tiene un sucesor, y que hay exactamente una linea que pasa por dos puntos distintos dados. estas propiedades basicas que se consideraban absolutamente evidentes se denominaban postulados o axiomas; por ejemplo los postulados de euclides. todos los teoremas se demostraban usando implicita o explicitamente estas propiedades basicas y, debido a la evidencia de estas propiedades basicas, un teorema probado se consideraba como una verdad definitiva, a menos que hubiera un error en la prueba. por ejemplo, la suma de los angulos interiores de un triangulo es igual a 180°, y esto se consideraba como un hecho indudable.  un aspecto de la crisis fundacional de las matematicas fue el descubrimiento de geometrias no euclidianas que no conducen a ninguna contradiccion, aunque, en tales geometrias, la suma de los angulos de un triangulo es diferente de 180°. entonces, la propiedad \"la suma de los angulos de un triangulo es igual 180°\" es verdadero o falso, dependiendo de si se asume o se niega el quinto postulado de euclides. de manera similar, el uso de propiedades basicas \"evidentes\" de conjuntos conduce a la contradiccion de la paradoja de russel. esto se ha resuelto elaborando las reglas que se permiten para manipular conjuntos.  esta crisis se ha resuelto revisando los fundamentos de las matematicas para hacerlos mas rigurosos. en estos nuevos fundamentos, un teorema es una formula bien formada de una teoria matematica que puede probarse a partir de los axiomas y las reglas de inferencia de la teoria. entonces, el teorema anterior sobre la suma de los angulos de un triangulo se convierte en: bajo los axiomas y reglas de inferencia de la geometria euclidiana, la suma de los angulos interiores de un triangulo es igual a 180°. de manera similar, la paradoja de russel desaparece porque, en una teoria de conjuntos axiomatizada, el \"conjunto de todos los conjuntos\" no puede expresarse con una formula bien formada. mas precisamente, si el conjunto de todos los conjuntos se puede expresar con una formula bien formada, esto implica que la teoria es inconsistente, y toda afirmacion bien formada, asi como su negacion, es un teorema.  en este contexto, la validez de un teorema depende unicamente de la correccion de su prueba. es independiente de la verdad, o incluso del significado de los axiomas. esto no significa que el significado de los axiomas no sea interesante, sino que la validez de un teorema es independiente del significado de los axiomas. esta independencia puede ser util al permitir el uso de resultados de algun area de las matematicas en areas aparentemente no relacionadas.  una consecuencia importante de esta forma de pensar sobre las matematicas es que permite definir teorias y teoremas matematicos como objetos matematicos, y probar teoremas sobre ellos. los ejemplos son los teoremas de incompletitud de godel. en particular, hay afirmaciones bien formadas que pueden demostrarse que no son un teorema de la teoria ambiental, aunque pueden demostrarse en una teoria mas amplia. un ejemplo es el teorema de goodstein, que se puede establecer en la aritmetica de peano, pero se demuestra que no es demostrable en la aritmetica de peano. sin embargo, es demostrable en algunas teorias mas generales, como la teoria de conjuntos de zermelo-fraenkel.  muchos teoremas matematicos son enunciados condicionales, cuyas pruebas deducen conclusiones de condiciones conocidas como hipotesis o premisas. a la luz de la interpretacion de la prueba como justificacion de la verdad, la conclusion se ve a menudo como una consecuencia necesaria de las hipotesis. es decir, que la conclusion es verdadera en caso de que las hipotesis sean verdaderas, sin mas suposiciones. sin embargo, el condicional tambien podria interpretarse de manera diferente en ciertos sistemas deductivos, dependiendo de los significados asignados a las reglas de derivacion y al simbolo condicional (por ejemplo, logica no clasica).  aunque los teoremas se pueden escribir en una forma completamente simbolica (por ejemplo, como proposiciones en calculo proposicional), a menudo se expresan de manera informal en un lenguaje natural como el ingles para una mejor legibilidad. lo mismo ocurre con las demostraciones, que a menudo se expresan como argumentos informales logicamente organizados y claramente redactados, con la intencion de convencer a los lectores de la verdad del enunciado del teorema mas alla de toda duda, y a partir de los cuales se puede, en principio, construir una demostracion simbolica formal.  ademas de la mejor legibilidad, los argumentos informales suelen ser mas faciles de verificar que los puramente simbolicos; de hecho, muchos matematicos expresarian su preferencia por una prueba que no solo demuestre la validez de un teorema, sino que tambien explique de alguna manera \"por que\" es obviamente cierto. en algunos casos, uno podria incluso corroborar un teorema usando una imagen como prueba.  debido a que los teoremas se encuentran en el nucleo de las matematicas, tambien son fundamentales para su estetica. los teoremas a menudo se describen como \"triviales\", \"dificiles\", \"profundos\" o incluso \"hermosos\". estos juicios subjetivos varian no solo de persona a persona, sino tambien con el tiempo y la cultura: por ejemplo, a medida que se obtiene una demostracion, se simplifica o se comprende mejor, un teorema que alguna vez fue dificil puede volverse trivial.​ por otro lado, un teorema profundo puede formularse de manera simple, pero su demostracion puede involucrar conexiones sorprendentes y sutiles entre areas dispares de las matematicas. el ultimo teorema de fermat es un ejemplo particularmente conocido de tal teorema.​  logicamente, muchos teoremas tienen la forma de un indicativo condicional: si a, entonces b. tal teorema no afirma \"b\", solo que \"b\" es una consecuencia necesaria de \"a\". en este caso, a se llama la hipotesis del teorema (\"hipotesis\" aqui significa algo muy diferente de una conjetura), y b la conclusion del teorema. los dos juntos (sin la demostracion) se denominan la proposicion o el enunciado del teorema (por ejemplo, \"si a, entonces b\" es la proposicion). alternativamente, a y b tambien pueden denominarse antecedente y consecuente, respectivamente.​ el teorema \"si n es un numero natural par, entonces n/2 es un numero natural\" es un ejemplo tipico en el que la hipotesis es \"n es un numero natural par\", y la conclusion es \"n/2 es tambien un numero natural\".  para que un teorema sea probado, debe ser en principio expresable como un enunciado formal y preciso. sin embargo, los teoremas generalmente se expresan en lenguaje natural en lugar de una forma completamente simbolica, con la presuncion de que una declaracion formal puede derivarse de una informal.  es comun en matematicas elegir un numero de hipotesis dentro de un lenguaje dado y declarar que la teoria consta de todos los enunciados demostrables a partir de estas hipotesis. estas hipotesis forman la base fundamental de la teoria y se llaman axiomas o postulados. el campo de las matematicas conocido como teoria de la prueba estudia los lenguajes formales, los axiomas y la estructura de las pruebas.  algunos teoremas son \"triviales\", en el sentido de que se derivan de definiciones, axiomas y otros teoremas de manera obvia y no contienen ideas sorprendentes. algunos, por otro lado, pueden llamarse \"profundos\", porque sus demostraciones pueden ser largas y dificiles, involucrar areas de las matematicas superficialmente distintas del enunciado del teorema en si, o mostrar conexiones sorprendentes entre areas dispares de las matematicas.​ un teorema puede ser simple de enunciar y, sin embargo, ser profundo. un excelente ejemplo es el ultimo teorema de fermat,​ y hay muchos otros ejemplos de teoremas simples pero profundos en teoria de numeros y combinatoria, entre otras areas.  otros teoremas tienen una prueba conocida que no se puede escribir facilmente. los ejemplos mas destacados son el teorema de los cuatro colores y la conjetura de kepler. solo se sabe que ambos teoremas son verdaderos al reducirlos a una busqueda computacional que luego es verificada por un programa de ordenador. inicialmente, muchos matematicos no aceptaron esta forma de prueba, pero se ha vuelto mas aceptada. el matematico doron zeilberger incluso ha ido tan lejos como para afirmar que estos son posiblemente los unicos resultados no triviales que los matematicos han probado alguna vez.​ muchos teoremas matematicos se pueden reducir a calculos mas sencillos, incluidas identidades polinomicas, identidades trigonometricas​ e identidades hipergeometricas.​[pagina requerida]  siendo p y q dos proposiciones se obtienen los siguientes teoremas, intercambiando la hipotesis con la conclusion y luego considerando las negaciones de las proposiciones originales.​  teorema directo: p ⇒ q  teorema  reciproco: q ⇒ p  teorema inverso: − p ⇒ − q  teorema contrarreciproco: − q ⇒ − p ​  en matematica un teorema  con frecuencia en fisica o economia algunas afirmaciones importantes que pueden ser deducidas o justificadas a partir de otras afirmaciones o hipotesis basicas se llaman comunmente teoremas. sin embargo, frecuentemente las areas de conocimiento donde aparecen esas afirmaciones con frecuencia no han sido formalizadas adecuadamente en forma de sistema logico por lo que estrictamente deberia usarse con cautela el termino teorema para referirse a esas afirmaciones demostrables o deducibles de supuestos «mas basicos».  un teorema y su prueba normalmente se presentan de la siguiente manera:  el final de la prueba se puede señalar con las letras q.e.d. (quod erat demonstrandum) o con una de las marcas tombstone, como \"□\" o \"∎\", que significa \"fin de la prueba\", introducido por paul halmos tras su uso en revistas para marcar el final de un articulo.​  el estilo exacto depende del autor o publicacion. muchas publicaciones proporcionan instrucciones o macros para componer en el estilo interno.  es comun que un teorema este precedido por definicion que describa el significado exacto de los terminos utilizados en el teorema. tambien es comun que un teorema este precedido por una serie de proposiciones o lemas que luego se usan en la demostracion. sin embargo, los lemas a veces estan incrustados en la demostracion de un teorema, ya sea con demostraciones anidadas o con sus demostraciones presentadas despues de la demostracion del teorema.  los corolarios de un teorema se presentan entre el teorema y la prueba, o directamente despues de la prueba. a veces, los corolarios tienen pruebas propias que explican por que se derivan del teorema.  se ha estimado que cada año se prueban mas de un cuarto de millon de teoremas.​  el conocido aforismo, \"un matematico es un dispositivo para convertir el cafe en teoremas\", probablemente se deba a alfred renyi, aunque a menudo se atribuye al colega de renyi paul erdos (y renyi puede haber estado pensando en erdos), que era famoso por los muchos teoremas que produjo, el numero de sus colaboraciones y su consumo de cafe.​  algunos consideran que la clasificacion de grupos simples finitos es la prueba mas larga de un teorema. comprende decenas de miles de paginas en 500 articulos de revistas de unos 100 autores. se cree que estos documentos en conjunto brindan una prueba completa, y varios proyectos en curso esperan acortar y simplificar esta prueba.​ otro teorema de este tipo es el teorema de los cuatro colores cuya prueba generado por ordenador es demasiado larga para que la lea un ser humano. es una de las demostraciones mas largas conocidas de un teorema cuyo enunciado puede ser entendido facilmente por un profano.  algunos de los teoremas mas conocidos son: ",
        "snippet": "Un teorema es una proposición cuya verdad se demuestra. En matemáticas, es toda proposición que, partiendo de un supuesto (hipótesis), afirma una racionabilidad (tesis) no evidente por sí misma.[1]​",
        "enlaces_salientes": [
            "/wiki/Teorema",
            "/wiki/Teorema",
            "/wiki/Teorema",
            "/wiki/Teorema_(desambiguaci%C3%B3n)",
            "/wiki/Cadena_de_caracteres",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Hip%C3%B3tesis_(l%C3%B3gica)",
            "/wiki/Tesis",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Sistema_formal",
            "/wiki/Axioma",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Lenguaje_formalizado",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Hip%C3%B3tesis_(l%C3%B3gica)",
            "/wiki/Tesis",
            "/wiki/Conclusi%C3%B3n",
            "/wiki/Corolario",
            "/wiki/Axioma",
            "/wiki/Sistema_axiom%C3%A1tico",
            "/wiki/Inferencia",
            "/wiki/L%C3%B3gica_de_predicados",
            "/wiki/F%C3%B3rmula_bien_formada",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Postulado",
            "/wiki/Axioma",
            "/wiki/Postulados_de_Euclides",
            "/wiki/%C3%81ngulos_interiores",
            "/wiki/Tri%C3%A1ngulo",
            "/wiki/Geometr%C3%ADas_no_euclidianas",
            "/wiki/Conjunto_(matem%C3%A1ticas)",
            "/wiki/F%C3%B3rmula_bien_formada",
            "/wiki/Axioma",
            "/wiki/Reglas_de_inferencia",
            "/wiki/Geometr%C3%ADa_euclidiana",
            "/wiki/Objetos_matem%C3%A1ticos",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Aritm%C3%A9tica_de_Peano",
            "/wiki/Teor%C3%ADa_de_conjuntos_de_Zermelo-Fraenkel",
            "/wiki/Premisas",
            "/wiki/L%C3%B3gica_no_cl%C3%A1sica",
            "/wiki/C%C3%A1lculo_proposicional",
            "/wiki/%C3%9Altimo_teorema_de_Fermat",
            "/wiki/L%C3%B3gica",
            "/wiki/Conjetura",
            "/wiki/Antecedente_(l%C3%B3gica)",
            "/wiki/Consecuente",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Axioma",
            "/wiki/Teor%C3%ADa_de_la_prueba",
            "/wiki/Plano_(matem%C3%A1ticas)",
            "/wiki/Teorema_de_los_cuatro_colores",
            "/wiki/%C3%9Altimo_Teorema_de_Fermat",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Combinatoria",
            "/wiki/Conjetura_de_Kepler",
            "/wiki/Doron_Zeilberger",
            "/wiki/Lema_(matem%C3%A1ticas)",
            "/wiki/Lema_de_Gauss",
            "/wiki/Lema_de_Zorn",
            "/wiki/Corolario",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Conjetura_matem%C3%A1tica",
            "/wiki/Hip%C3%B3tesis_(l%C3%B3gica)",
            "/wiki/Conjetura_de_Goldbach",
            "/wiki/Hip%C3%B3tesis_de_Riemann",
            "/wiki/F%C3%ADsica",
            "/wiki/Econom%C3%ADa",
            "/wiki/Hip%C3%B3tesis_(l%C3%B3gica)",
            "/wiki/Sistema_l%C3%B3gico",
            "/wiki/Quod_erat_demonstrandum",
            "/wiki/Paul_Halmos",
            "/wiki/Gu%C3%ADa_de_estilo",
            "/wiki/Definici%C3%B3n",
            "/wiki/Aforismo",
            "/wiki/Alfr%C3%A9d_R%C3%A9nyi",
            "/wiki/Paul_Erd%C5%91s",
            "/wiki/N%C3%BAmero_de_Erd%C5%91s",
            "/wiki/Clasificaci%C3%B3n_de_grupos_simples_finitos",
            "/wiki/Teorema_de_los_cuatro_colores",
            "/wiki/Teorema_de_Pappus-Guldin",
            "/wiki/Teorema_de_Pit%C3%A1goras",
            "/wiki/Teorema_de_Bayes",
            "/wiki/Teorema_del_binomio",
            "/wiki/Teorema_de_muestreo_de_Nyquist-Shannon",
            "/wiki/Teorema_de_incompletitud_de_G%C3%B6del",
            "/wiki/Teorema_del_l%C3%ADmite_central",
            "/wiki/Teorema_de_los_n%C3%BAmeros_primos",
            "/wiki/Teorema_de_la_divergencia",
            "/wiki/Teorema_de_Bell",
            "/wiki/Teorema_de_Stokes",
            "/wiki/Teorema_de_Tales",
            "/wiki/Teorema_de_los_ceros_de_Hilbert",
            "/wiki/Teorema_de_Frobenius_(%C3%A1lgebra)",
            "/wiki/%C3%9Altimo_teorema_de_Fermat",
            "/wiki/Teorema_de_Morley",
            "/wiki/Teorema_de_Shannon",
            "/wiki/Teorema_de_la_bisectriz",
            "/wiki/Teorema_del_valor_medio",
            "/wiki/Teorema_de_Taylor",
            "/wiki/Teorema_de_Rolle",
            "/wiki/Teorema_del_valor_medio_de_Cauchy",
            "/wiki/Axioma",
            "/wiki/Sistema_axiom%C3%A1tico",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/Teor%C3%ADa",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Doron_Zeilberger",
            "/wiki/Nuel_Belnap",
            "/wiki/J%C3%B3zef_Maria_Boche%C5%84ski",
            "/wiki/J%C3%B3zef_Maria_Boche%C5%84ski",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Wikcionario",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Wikcionario"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Diagrama_de_flujo",
        "titulo": "Diagrama de flujo",
        "contenido": "el diagrama de flujo o flujograma o diagrama de actividades es la representacion grafica de un algoritmo o proceso. se utiliza en disciplinas como programacion, economia, procesos industriales y psicologia cognitiva.  en lenguaje unificado de modelado (uml), es un diagrama de actividades que representa los flujos de trabajo paso a paso. un diagrama de actividades muestra el flujo de control general.  en sysml el diagrama ha sido extendido para indicar flujos entre pasos que mueven elementos fisicos (p. ej., gasolina) o energia (p. ej., presion). los cambios adicionales permiten al diagrama soportar mejor flujos de comportamiento y datos continuos.  estos diagramas utilizan simbolos con significados definidos que representan los pasos del algoritmo, y representan el flujo de ejecucion mediante flechas que conectan los puntos de inicio y de fin del proceso.  las siguientes son acciones previas a la realizacion del diagrama de flujo:  los pasos a seguir para construir el diagrama de flujo son:  en uml 1.x, un diagrama de actividades es una variacion del diagrama de estado unl donde los \"estados\" representan operaciones, y las transiciones representan las actividades que ocurren cuando la operacion se termina.  el diagrama de mensajes de uml 2.0, mientras que es similar en aspecto al diagrama de actividades uml 1.x, ahora tiene semanticas basadas en redes de petri. en uml 2.0, el diagrama general de interaccion esta basado en el diagrama de actividades. el diagrama de actividad es una forma especial de diagrama de estado usado para modelar una secuencia de acciones y condiciones tomadas dentro de un proceso.  la especificacion del lenguaje de notificacion unificado (unl) define un diagrama de actividad como:  el proposito del diagrama de actividad es modelar un proceso de flujo de trabajo (workflow) y/o modelar operaciones.  una operacion es un servicio proporcionado por un objeto, que esta disponible a traves de una interfaz.  una interfaz es un grupo de operaciones relacionadas con la semantica.  1.-segun gomez cejas, guillermo. año 1997:  2.-segun chiavenato, idalberto. año 1993:  3.-segun gomez rondon, francisco. año 1995:  el instituto nacional estadounidense de estandares (ansi, por su siglas en ingles) establecio estandares para los diagramas de flujo y sus simbolos en los años 1960s.​ la organizacion internacional de normalizacion (iso, por sus siglas en ingles) adopto los simbolos ansi en 1970.​ el estandar actual, iso 5807, fue revisado en 1985.​  se trata de la mas comun y practica entre todas las clases de diagramas de flujo. describe el flujo de informacion en un ente u organizacion, sus procesos, sistemas administrativos y de control. permite la impresion visual de los procedimientos y una clara y logica interpretacion.  segun la normativa, el flujo presupuesto es de izquierda a derecha y de arriba hacia abajo, siendo optativo el uso de flechas. cuando el sentido es invertido (de derecha a izquierda o de abajo hacia arriba), es obligatorio el uso de la flecha.​  la paternidad del diagrama de flujo es en principio algo difusa. el metodo estructurado para documentar graficamente un proceso como un flujo de pasos sucesivos y alternativos, el \"proceso de diagrama de flujo\", fue expuesto por frank gilbreth, en la sociedad americana de ingenieros mecanicos (asme), en 1921, bajo el enunciado de \"proceso de graficas-primeros pasos para encontrar el mejor modo\". estas herramientas de gilbreth rapidamente encontraron sitio en los programas de ingenieria industrial.  al principio de los 30, un ingeniero industrial, allan h. mogensen comenzo la formacion de personas de negocios en lake placid, nueva york, incluyendo el uso del diagrama de flujo. art spinanger, asistente a las clases de mogesen, utilizo las herramientas en su trabajo en procter & gamble, donde desarrollo su “programa metodico de cambios por etapas”. otro asistente al grupo de graduados en 1944, ben s. graham, director de ingenieria de formcraft standard register corporation, adapto la grafica de flujo de procesos al tratamiento de la informacion en su empresa. y desarrollo la grafica del proceso de multiples flujos en multiples pantallas, documentos, y sus relaciones. en 1947, asme adopto un conjunto de simbolos derivados de la obra original de gilbreth como norma asme para los graficos de procesos (preparada mishad, ramsan y raiaan).  sin embargo, segun explica douglas hartree fueron originalmente herman goldstine y john von neumann quienes desarrollaron el diagrama de flujo (inicialmente llamado \"diagrama\") para planificar los programas de ordenador. las tablas de programacion original de flujo de goldstine y von neumann, aparecen en un informe no publicado, \"planificacion y codificacion de los problemas de un instrumento de computacion electronica, la parte ii, volumen 1 \"(1947), reproducido en las obras completas de von neumann.  inicialmente los diagramas de flujo resultaron un medio popular para describir algoritmos de computadora, y aun se utilizan con este fin. herramientas como los diagramas de actividad uml, pueden ser considerados como evoluciones del diagrama de flujo.  en la decada de 1970 la popularidad de los diagramas de flujo como metodo propio de la informatica disminuyo, con el nuevo hardware y los nuevos lenguajes de programacion de tercera generacion. y por otra parte se convirtieron en instrumentos comunes en el mundo empresarial. son una expresion concisa, legible y practica de algoritmos. actualmente se aplican en muchos campos del conocimiento, especialmente como simplificacion y expresion logica de procesos, etc.  actualmente existe una gran cantidad de software para la elaboracion de diagramas de flujo. a continuacion se listan los programas mas comunes para elaborar diagramas de flujo.  tambien existen aplicaciones que permiten que, una vez que un creador haya diseñado el diagrama de flujo, un usuario final lo utilice y, sobre la base de las opciones que vaya escogiendo, se le vayan mostrando las siguientes etapas hasta llegar a un resultado final. un ejemplo de este tipo de aplicaciones es iboske. ",
        "snippet": "El diagrama de flujo o flujograma o diagrama de actividades es la representación gráfica de un algoritmo o proceso. Se utiliza en disciplinas como programación, economía, procesos industriales y psicología cognitiva.",
        "enlaces_salientes": [
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/L%C3%A1mpara",
            "/wiki/Bucle_for",
            "/wiki/Gr%C3%A1fica",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Econom%C3%ADa",
            "/wiki/Proceso_de_fabricaci%C3%B3n",
            "/wiki/Psicolog%C3%ADa_cognitiva",
            "/wiki/Lenguaje_Unificado_de_Modelado",
            "/wiki/Flujo_de_trabajo",
            "/wiki/SysML",
            "/wiki/Red_de_Petri",
            "/wiki/Instituto_Nacional_Estadounidense_de_Est%C3%A1ndares",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/Estadio_(geometr%C3%ADa)",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/Paralelogramo",
            "/wiki/Campo_de_b%C3%A9isbol#Home_plate",
            "/wiki/Pent%C3%A1gono",
            "/wiki/%C3%93valo",
            "/wiki/Elipse",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/C%C3%ADrculo",
            "/wiki/Tri%C3%A1ngulo",
            "/wiki/Lake_Placid",
            "/wiki/Nueva_York",
            "/wiki/Herman_Goldstine",
            "/wiki/John_von_Neumann",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Ordenador",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Microsoft_Office",
            "/wiki/Microsoft_Word",
            "/wiki/Microsoft_Excel",
            "/wiki/Microsoft_PowerPoint",
            "/wiki/Microsoft_Visio",
            "/wiki/LibreOffice_Draw",
            "/wiki/GitMind",
            "/wiki/XMind",
            "/wiki/DRAKON",
            "/wiki/UML",
            "/wiki/Flujo_de_trabajo",
            "/wiki/Red_de_Petri",
            "/wiki/Diagrama_de_secuencia",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Resoluci%C3%B3n_de_problemas_de_programaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Estructuras_de_control",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Bucle_for",
            "/wiki/Bucle_while",
            "/wiki/Bucle_repetir",
            "/wiki/Bucle_infinito",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/National_Archives_and_Records_Administration",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Diagrama_de_flujo",
        "titulo": "Diagrama de flujo",
        "contenido": "el diagrama de flujo o flujograma o diagrama de actividades es la representacion grafica de un algoritmo o proceso. se utiliza en disciplinas como programacion, economia, procesos industriales y psicologia cognitiva.  en lenguaje unificado de modelado (uml), es un diagrama de actividades que representa los flujos de trabajo paso a paso. un diagrama de actividades muestra el flujo de control general.  en sysml el diagrama ha sido extendido para indicar flujos entre pasos que mueven elementos fisicos (p. ej., gasolina) o energia (p. ej., presion). los cambios adicionales permiten al diagrama soportar mejor flujos de comportamiento y datos continuos.  estos diagramas utilizan simbolos con significados definidos que representan los pasos del algoritmo, y representan el flujo de ejecucion mediante flechas que conectan los puntos de inicio y de fin del proceso.  las siguientes son acciones previas a la realizacion del diagrama de flujo:  los pasos a seguir para construir el diagrama de flujo son:  en uml 1.x, un diagrama de actividades es una variacion del diagrama de estado unl donde los \"estados\" representan operaciones, y las transiciones representan las actividades que ocurren cuando la operacion se termina.  el diagrama de mensajes de uml 2.0, mientras que es similar en aspecto al diagrama de actividades uml 1.x, ahora tiene semanticas basadas en redes de petri. en uml 2.0, el diagrama general de interaccion esta basado en el diagrama de actividades. el diagrama de actividad es una forma especial de diagrama de estado usado para modelar una secuencia de acciones y condiciones tomadas dentro de un proceso.  la especificacion del lenguaje de notificacion unificado (unl) define un diagrama de actividad como:  el proposito del diagrama de actividad es modelar un proceso de flujo de trabajo (workflow) y/o modelar operaciones.  una operacion es un servicio proporcionado por un objeto, que esta disponible a traves de una interfaz.  una interfaz es un grupo de operaciones relacionadas con la semantica.  1.-segun gomez cejas, guillermo. año 1997:  2.-segun chiavenato, idalberto. año 1993:  3.-segun gomez rondon, francisco. año 1995:  el instituto nacional estadounidense de estandares (ansi, por su siglas en ingles) establecio estandares para los diagramas de flujo y sus simbolos en los años 1960s.​ la organizacion internacional de normalizacion (iso, por sus siglas en ingles) adopto los simbolos ansi en 1970.​ el estandar actual, iso 5807, fue revisado en 1985.​  se trata de la mas comun y practica entre todas las clases de diagramas de flujo. describe el flujo de informacion en un ente u organizacion, sus procesos, sistemas administrativos y de control. permite la impresion visual de los procedimientos y una clara y logica interpretacion.  segun la normativa, el flujo presupuesto es de izquierda a derecha y de arriba hacia abajo, siendo optativo el uso de flechas. cuando el sentido es invertido (de derecha a izquierda o de abajo hacia arriba), es obligatorio el uso de la flecha.​  la paternidad del diagrama de flujo es en principio algo difusa. el metodo estructurado para documentar graficamente un proceso como un flujo de pasos sucesivos y alternativos, el \"proceso de diagrama de flujo\", fue expuesto por frank gilbreth, en la sociedad americana de ingenieros mecanicos (asme), en 1921, bajo el enunciado de \"proceso de graficas-primeros pasos para encontrar el mejor modo\". estas herramientas de gilbreth rapidamente encontraron sitio en los programas de ingenieria industrial.  al principio de los 30, un ingeniero industrial, allan h. mogensen comenzo la formacion de personas de negocios en lake placid, nueva york, incluyendo el uso del diagrama de flujo. art spinanger, asistente a las clases de mogesen, utilizo las herramientas en su trabajo en procter & gamble, donde desarrollo su “programa metodico de cambios por etapas”. otro asistente al grupo de graduados en 1944, ben s. graham, director de ingenieria de formcraft standard register corporation, adapto la grafica de flujo de procesos al tratamiento de la informacion en su empresa. y desarrollo la grafica del proceso de multiples flujos en multiples pantallas, documentos, y sus relaciones. en 1947, asme adopto un conjunto de simbolos derivados de la obra original de gilbreth como norma asme para los graficos de procesos (preparada mishad, ramsan y raiaan).  sin embargo, segun explica douglas hartree fueron originalmente herman goldstine y john von neumann quienes desarrollaron el diagrama de flujo (inicialmente llamado \"diagrama\") para planificar los programas de ordenador. las tablas de programacion original de flujo de goldstine y von neumann, aparecen en un informe no publicado, \"planificacion y codificacion de los problemas de un instrumento de computacion electronica, la parte ii, volumen 1 \"(1947), reproducido en las obras completas de von neumann.  inicialmente los diagramas de flujo resultaron un medio popular para describir algoritmos de computadora, y aun se utilizan con este fin. herramientas como los diagramas de actividad uml, pueden ser considerados como evoluciones del diagrama de flujo.  en la decada de 1970 la popularidad de los diagramas de flujo como metodo propio de la informatica disminuyo, con el nuevo hardware y los nuevos lenguajes de programacion de tercera generacion. y por otra parte se convirtieron en instrumentos comunes en el mundo empresarial. son una expresion concisa, legible y practica de algoritmos. actualmente se aplican en muchos campos del conocimiento, especialmente como simplificacion y expresion logica de procesos, etc.  actualmente existe una gran cantidad de software para la elaboracion de diagramas de flujo. a continuacion se listan los programas mas comunes para elaborar diagramas de flujo.  tambien existen aplicaciones que permiten que, una vez que un creador haya diseñado el diagrama de flujo, un usuario final lo utilice y, sobre la base de las opciones que vaya escogiendo, se le vayan mostrando las siguientes etapas hasta llegar a un resultado final. un ejemplo de este tipo de aplicaciones es iboske. ",
        "snippet": "El diagrama de flujo o flujograma o diagrama de actividades es la representación gráfica de un algoritmo o proceso. Se utiliza en disciplinas como programación, economía, procesos industriales y psicología cognitiva.",
        "enlaces_salientes": [
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/L%C3%A1mpara",
            "/wiki/Bucle_for",
            "/wiki/Gr%C3%A1fica",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Econom%C3%ADa",
            "/wiki/Proceso_de_fabricaci%C3%B3n",
            "/wiki/Psicolog%C3%ADa_cognitiva",
            "/wiki/Lenguaje_Unificado_de_Modelado",
            "/wiki/Flujo_de_trabajo",
            "/wiki/SysML",
            "/wiki/Red_de_Petri",
            "/wiki/Instituto_Nacional_Estadounidense_de_Est%C3%A1ndares",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/Estadio_(geometr%C3%ADa)",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/Paralelogramo",
            "/wiki/Campo_de_b%C3%A9isbol#Home_plate",
            "/wiki/Pent%C3%A1gono",
            "/wiki/%C3%93valo",
            "/wiki/Elipse",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/C%C3%ADrculo",
            "/wiki/Tri%C3%A1ngulo",
            "/wiki/Lake_Placid",
            "/wiki/Nueva_York",
            "/wiki/Herman_Goldstine",
            "/wiki/John_von_Neumann",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Ordenador",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Microsoft_Office",
            "/wiki/Microsoft_Word",
            "/wiki/Microsoft_Excel",
            "/wiki/Microsoft_PowerPoint",
            "/wiki/Microsoft_Visio",
            "/wiki/LibreOffice_Draw",
            "/wiki/GitMind",
            "/wiki/XMind",
            "/wiki/DRAKON",
            "/wiki/UML",
            "/wiki/Flujo_de_trabajo",
            "/wiki/Red_de_Petri",
            "/wiki/Diagrama_de_secuencia",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Resoluci%C3%B3n_de_problemas_de_programaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Estructuras_de_control",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Bucle_for",
            "/wiki/Bucle_while",
            "/wiki/Bucle_repetir",
            "/wiki/Bucle_infinito",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/National_Archives_and_Records_Administration",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Organizaci%C3%B3n_Internacional_para_la_Estandarizaci%C3%B3n",
        "titulo": "Organización Internacional de Normalización",
        "contenido": "la organizacion internacional de normalizacion (llamada en ocasiones: organizacion internacional de estandarizacion; conocida por el acronimo iso) es una organizacion para la creacion de estandares internacionales compuesta por diversas organizaciones nacionales de normalizacion.  fundada el 23 de febrero de 1947, la organizacion promueve el uso de estandares privativos, industriales y comerciales a nivel mundial. su sede esta en ginebra (suiza)​ y hasta 2015 trabajaba en 196 paises.​  la organizacion internacional de normalizacion (iso) es una organizacion independiente y no-gubernamental formada por las organizaciones de normalizacion de sus 167 paises miembros. es el mayor desarrollador mundial de estandares internacionales voluntarios y facilita el comercio mundial al proporcionar estandares comunes entre paises. se han establecido cerca de veinte mil estandares cubriendo desde productos manufacturados y tecnologia a seguridad alimenticia, agricultura y sanidad.​  el uso de estandares facilita la creacion de productos y servicios que sean seguros, fiables y de calidad. los estandares ayudan a los negocios a aumentar la productividad a la vez que minimizan los errores y el gasto. al permitir comparar directamente productos de diferentes fabricantes, facilita que nuevas compañias puedan entrar en nuevos mercados y ayudar en el desarrollo de un comercio global con bases justas. los estandares tambien sirven para proteger a los consumidores y usuarios finales de productos y servicios, asegurando que los productos certificados se ajusten a los minimos normalizados internacionalmente.​  los tres idiomas oficiales de iso son ingles, frances y ruso.​ el nombre de la organizacion en frances es organisation internationale de normalisation, international organization for standardization en ingles y международная организация по стандартизации en ruso. segun iso, debido a que su nombre en diferentes idiomas tendria diferentes siglas (\"ios\" en ingles, \"oin\" en frances, etc.), la organizacion adopto \"iso\" como sus siglas en referencia a la palabra griega isos (σος, traducido como igual)​ sin embargo, durante las reuniones fundacionales de la nueva organizacion, esta palabra nunca fue mencionada, asi que esta explicacion podria haber sido imaginada posteriormente.​  tanto el nombre \"iso\" como el logo son marcas registradas, y su uso esta restringido.​  la organizacion conocida hoy en dia como iso nacio en 1926  como la federacion internacional de asociaciones de estandarizacion nacionales (isa). fue suspendida en 1942​ durante la segunda guerra mundial, pero tras la guerra se le propuso por parte del comite coordinador de estandares de las naciones unidas (unscc) formar un nuevo cuerpo de estandares globales.​ en octubre de 1946, delegados de isa y de unscc de 25 paises se reunieron en londres y decidieron unir fuerzas para crear la nueva organizacion internacional de normalizacion; la nueva organizacion comenzaria oficialmente a operar en febrero de 1947.​  iso es una organizacion voluntaria cuyos miembros son autoridades reconocidas en normalizacion, cada uno representando a un pais. los miembros se reunen anualmente en la asamblea general para discutir los objetivos estrategicos de iso. la organizacion esta coordinada por un secretariado central con sede en ginebra.​  un consejo rotativo de 20 miembros proporcionan guia y gobierno, incluyendo el establecimiento de los presupuestos anuales del secretariado central.​​  la junta de administracion tecnica es la responsable de cerca de 250 comites tecnicos, quienes desarrollan los estandares iso.​​​​  iso ha formado varios comites conjuntos con la comision electrotecnica internacional (iec) para desarrollar estandares y la terminologia relacionados con areas de tecnologia electrica y electronica.  el comite conjunto tecnico iso/iec 1 (jtc 1) fue creado en 1987 para \"desarrollar, mantener, promover y facilitar los estandares relacionados con la tecnologia de la informacion\".​  el comite conjunto tecnico iso/iec 2 (jtc 2) se creo en 2009 con el proposito de «normalizar el campo de la eficiencia energetica y las fuentes de energias renovables».​  iso tiene 167 paises miembros,​ de un total de 206 paises en el mundo.  iso tiene tres categorias de miembros:​  los miembros participantes son llamados miembros \"p\", en contraposicion a los miembros observadores, que son llamados miembros \"o\".  iso esta financiada por una combinacion de:​  los principales productos de iso son sus estandares internacionales. iso tambien publica informes tecnicos, especificaciones tecnicas, especificaciones disponibles publicamente, erratas tecnicas, y guias.​​  son metaestandares que cubren «materias relacionadas con la normalizacion internacional».​ son nombradas utilizando el formato \"iso[/iec]guide n:yyyy: titulo\"por ejemplo:  un estandar publicado por iso/iec es la ultima etapa en un largo proceso que normalmente comienza con la propuesta de un nuevo trabajo en un comite. aqui se presentan algunas abreviaturas usadas para marcar un estandar cuando esta en este estado:​​​​​​​  abreviaturas usadas para enmiendas:​​​​​​​​  otras abreviaturas:​​​​  los estandares internacionales son desarrollados por los comites tecnicos de iso (tc) y subcomites (sc) por un proceso con seis etapas:​​  los tc y sc pueden establecer grupos de trabajo (wg) de expertos para la preparacion de borradores de trabajo. los subcomites pueden tener varios grupos de trabajo, los cuales a su vez pueden tener varios subgrupos (sg).​  es posible omitir ciertas etapas, si hay algun documento con un cierto grado de madurez al principio del proyecto de normalizacion, por ejemplo un estandar desarrollado por otra organizacion. las directrices de iso/iec tambien permiten el llamado \"procedimiento abreviado\". en este procedimiento el documento es enviado directamente para aprobacion como un borrador de estandar internacional (dis) a los cuerpos miembros de iso o como un borrador final de estandar internacional (fdis) si el documento fue desarrollado por un cuerpo internacional de normalizacion reconocido por el consejo de iso.​  el primer paso -una propuesta de trabajo (nueva proposicion)- es aprobado el subcomite o comite tecnico relevante (por ejemplo, sc29 y jtc1 respectivamente en el caso de moving picture experts group - iso/iec jtc1/sc29/wg11). un grupo de trabajo (wg) de expertos es establecido por el tc/sc para la preparacion de un borrador de trabajo. cuando el objetivo de un nuevo trabajo esta lo suficientemente claro, alguno de los grupos de trabajo (por ejemplo, mpeg) normalmente hace una peticion abierta de proposiciones -conocido como \"peticion de propuestas\". el primer documento que es producido por ejemplo para los estandares de codificacion de audio y video es llamado un modelo de verificacion (vm) (anteriormente tambien llamado un \"modelo de simulacion y prueba\"). cuando se alcanza la suficiente confianza en la estabilidad del estandar en desarrollo, se produce un borrador de trabajo (wd). tiene la forma de un estandar, pero se mantiene internamente para ser revisado por el grupo de trabajo. cuando un borrador de trabajo es lo suficientemente solido y el grupo de trabajo esta seguro que de ha desarrollado la mejor solucion tecnica para el problema tratado, este se convierte en un borrador de comite (cd). si es necesario, es entonces cuando es enviado a los miembros p del tc/se (los cuerpos nacionales) para votacion.  el cd pasa a ser un borrador final de comite (fcd) si el numero de votos positivos esta por encima del quorum. varios borradores de comite pueden ser evaluados hasta que se alcance un consenso en su contenido tecnico. cuando se alcanza, el texto es finalizado para ser enviado como un borrador de estandar internacional (dis). el texto es entonces enviado a los cuerpos nacionales para votacion y ser comentado en un periodo de cinco meses. es aprobado como un borrador final de estandar internacional (fdis) si un las dos terceras partes de los miembros p del tc/sc estan a favor y no mas de un cuarto del total de votos emitidos son negativos. iso celebrara entonces una votacion con los cuerpos nacionales donde no se podran proponer cambios tecnicos al texto (una votacion se si/no), en un periodo de dos meses. es aprobado como un estandar internacional (is) si las dos terceras partes de los miembros p del tc/sc estan a favor y no mas de un cuarto de los votos emitidos son negativos. tras la aprobacion, solo se introduciran cambios menores editoriales en el texto. el texto final se envia al secretariado central de iso, el cual lo publica como un estandar internacional.​​  el hecho de que muchos de los estandares creados por iso son ubicuos ha llevado, en ocasiones, al uso de \"iso\" para llamar al producto en si que se adecua a un estandar. algunos ejemplos de ello son:  a excepcion de un pequeño numero de estandares aislados,​ los estandares iso no estan disponibles gratuitamente,​ cuyo coste ha sido visto por algunos sectores como demasiado elevado para proyectos pequeños software de codigo abierto.​  los procedimientos abreviados del iso/iec jtc1 (usado por office open xml y opendocument) han cosechado criticas con relacion a la estandarizacion de office open xml. martin bryan, convocante del iso/iec jtc1/sc34 wg1, dijo al respecto:  el empresario en seguridad e inversor de ubuntu, mark shuttleworth, comento en el proceso de estandarizacion de office open xml que \"cree que devalua la confianza de la gente en el procedimiento de creacion de estandares\" y alego que iso no estaba llevando a cabo sus responsabilidades. tambien señalo que microsoft ha presionado activamente a muchos paises que tradicionalmente no han participado en iso y formado comites con empleados de microsoft, proveedores de soluciones y distribuidores afines a office open xlm.  iso 45001 de seguridad y salud en el trabajo ",
        "snippet": "La Organización Internacional de Normalización (llamada en ocasiones: Organización Internacional de Estandarización; conocida por el acrónimo ISO) es una organización para la creación de estándares internacionales compuesta por diversas organizaciones nacionales de normalización.",
        "enlaces_salientes": [
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/ISO_(desambiguaci%C3%B3n)",
            "/wiki/Ginebra",
            "/wiki/Suiza",
            "/wiki/Organizaci%C3%B3n_no_gubernamental",
            "/wiki/Sitio_web",
            "/wiki/Est%C3%A1ndares",
            "/wiki/Normalizaci%C3%B3n#Organismos_Nacionales_de_Normalizaci.C3.B3n",
            "/wiki/Ginebra",
            "/wiki/Suiza",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_franc%C3%A9s",
            "/wiki/Idioma_ruso",
            "/wiki/Idioma_griego",
            "/wiki/Praga",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Londres",
            "/wiki/Ginebra",
            "/wiki/Comisi%C3%B3n_Electrot%C3%A9cnica_Internacional",
            "/wiki/ISO_3166-1",
            "/wiki/Producto_interior_bruto",
            "/wiki/Errata",
            "/wiki/Comisi%C3%B3n_Electrot%C3%A9cnica_Internacional",
            "/wiki/Moving_Picture_Experts_Group",
            "/wiki/Imagen_de_disco_%C3%B3ptico",
            "/wiki/Extensi%C3%B3n_de_archivo",
            "/wiki/Imagen_ISO",
            "/wiki/ISO_9660",
            "/wiki/CD-ROM",
            "/wiki/Disco_Compacto",
            "/wiki/DVD-ROM",
            "/wiki/Escala_de_sensibilidad_fotogr%C3%A1fica",
            "/wiki/Flash_(fotograf%C3%ADa)",
            "/wiki/Software_de_c%C3%B3digo_abierto",
            "/wiki/Office_Open_XML",
            "/wiki/OpenDocument",
            "/wiki/Ubuntu_(sistema_operativo)",
            "/wiki/Mark_Shuttleworth",
            "/wiki/Microsoft",
            "/wiki/Cabildeo",
            "/wiki/Instituto_Argentino_de_Normalizaci%C3%B3n_y_Certificaci%C3%B3n",
            "/wiki/Instituto_Nacional_de_Normalizaci%C3%B3n_(Chile)",
            "/wiki/Asociaci%C3%B3n_Espa%C3%B1ola_de_Normalizaci%C3%B3n_y_Certificaci%C3%B3n",
            "/wiki/Instituto_Nacional_de_Calidad",
            "/wiki/Instituto_Nacional_Estadounidense_de_Est%C3%A1ndares",
            "/wiki/Associa%C3%A7%C3%A3o_Brasileira_de_Normas_T%C3%A9cnicas",
            "/wiki/Deutsches_Institut_f%C3%BCr_Normung",
            "/wiki/British_Standards_Institution",
            "/wiki/Comit%C3%A9_Europeo_de_Normalizaci%C3%B3n",
            "/wiki/GOST",
            "/wiki/International_Electrotechnical_Commission",
            "/wiki/IEEE_Standards_Association",
            "/wiki/International_Telecommunication_Union",
            "/wiki/Normalizaci%C3%B3n",
            "/wiki/Grupo_de_trabajo_de_ingenier%C3%ADa_de_internet",
            "/wiki/Ente_Nazionale_Italiano_di_Unificazione",
            "/wiki/Universidad_Purdue",
            "/wiki/ISBN",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Historical_Dictionary_of_Switzerland",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Pseudoc%C3%B3digo",
        "titulo": "Pseudocódigo",
        "contenido": "en ciencias de la computacion, y analisis numerico, el pseudocodigo​ (o lenguaje de descripcion algoritmico) es una descripcion de alto nivel compacta e informal​ del principio operativo de un programa informatico u otro algoritmo.  utiliza las convenciones estructurales de un lenguaje de programacion real,​ pero esta diseñado para la lectura humana en lugar de la lectura mediante maquina,​ y con independencia de cualquier otro lenguaje de programacion.​ normalmente, el pseudocodigo omite detalles que no son esenciales para la comprension humana del algoritmo, tales como declaraciones de variables, codigo especifico del sistema y algunas subrutinas. el lenguaje de programacion se complementa, donde sea conveniente, con descripciones detalladas en lenguaje natural, o con notacion matematica compacta. se utiliza pseudocodigo pues este es mas facil de entender para las personas que el codigo del lenguaje de programacion convencional, ya que es una descripcion eficiente y con un entorno independiente de los principios fundamentales de un algoritmo. se utiliza comunmente en los libros de texto y publicaciones cientificas que se documentan varios algoritmos, y tambien en la planificacion del desarrollo de programas informaticos, para esbozar la estructura del programa antes de realizar la efectiva codificacion. es comunmente utilizado por los programadores para omitir secciones de codigo o para dar una explicacion del paradigma que tomo el mismo programador para hacer sus codigos, esto quiere decir que el pseudocodigo no es programable, sino facilita la programacion.  el principal objetivo del pseudocodigo es el de representar la solucion a un algoritmo de la forma mas detallada posible, y a su vez lo mas parecida posible al lenguaje que posteriormente se utilizara para la codificacion del mismo.  no existe una sintaxis estandar para el pseudocodigo, aunque los cinco ide's que manejan pseudocodigo en español tengan su sintaxis propia. aunque sea parecido, el pseudocodigo no debe confundirse con los programas esqueleto que incluyen codigo ficticio, que pueden ser compilados sin errores. los diagramas de flujo y uml pueden ser considerados como una alternativa grafica al pseudocodigo, aunque sean mas amplios  generalmente se utiliza pseudocodigo en los libros de texto y publicaciones cientificas relacionadas con la informatica y la computacion numerica, para la descripcion de algoritmos, de manera que todos los programadores puedan entenderlo, aunque no todos conozcan el mismo lenguaje de programacion. generalmente, en los libros de texto se adjunta una explicacion que acompaña a la introduccion y que explica las convenciones particulares en uso. el nivel de detalle del seudocientifico puede, en algunos casos, acercarse a la de formalizar los idiomas de proposito general.  un programador que tiene que aplicar un algoritmo especifico, sobre todo uno desfamiliarizado, generalmente comienza con una descripcion en pseudocodigo, y luego \"traduce\" esa descripcion en el lenguaje de programacion meta y lo modifica para que interactue correctamente con el resto del programa. los programadores tambien pueden iniciar un proyecto describiendo la forma del codigo en pseudocodigo en el papel antes de escribirlo en su lenguaje de programacion, como ocurre en la estructuracion de un enfoque de top-down y bottom-up arriba hacia abajo.  en la actualidad y por lo general, el pseudocodigo, como su nombre lo indica, no obedece a las reglas de sintaxis de ningun idioma en particular ni es de forma estandar sistematica, a pesar de que cualquier escritor en particular vaya a pedir prestado las estructuras de control general, la sintaxis y el estilo, por ejemplo, de algun lenguaje de programacion convencional. pero en caso de que se quiera ejecutar, se debe llevar a forma tipo, para que no genere mensajes de error. las fuentes populares incluyen la sintaxis de pascal, basic, c, c++, java, lisp, y algol. por lo general, se omiten las declaraciones de variables. a veces, las llamadas a funciones, los bloques de codigo y el codigo contenido dentro de un loop se remplazan por una sentencia de una linea en lenguaje natural.  este es un ejemplo de pseudocodigo (para el juego matematico bizz buzz):  pseudocodigo estilo fortran:  pseudocodigo estilo pascal:  pseudocodigo estilo c:  la definicion de datos se da por supuesta, sobre todo en las variables sencillas, si se emplea formaciones: pilas, colas, vectores o registros, se pueden definir en la cabecera del algoritmo, y naturalmente cuando empleemos el pseudocodigo para definir estructuras de datos, esta parte la desarrollaremos adecuadamente.  cada autor usa su propio pseudocodigo con sus respectivas convenciones. por ejemplo, la instruccion \"reemplace el valor de la variable x por el valor de la variable y \" puede ser representado como:  las operaciones aritmeticas se representan de la forma usual en matematicas.  en la redaccion de pseudocodigo se utiliza tres tipos de estructuras de control: las secuenciales, las selectivas y las iterativas.  las instrucciones se siguen en una secuencia fija que normalmente viene dada por el numero de renglon. es decir que las instrucciones se ejecutan de arriba hacia abajo.  las instrucciones selectivas representan instrucciones que pueden o no ejecutarse, segun el cumplimiento de una condicion.    la condicion es una expresion booleana. instrucciones es ejecutada solo si la condicion es verdadera.  la instruccion alternativa realiza una instruccion de dos posibles, segun el cumplimiento de una condicion.    la condicion es una variable booleana o una funcion reducible a booleana (logica, verdadero/falso). si esta condicion es cierta se ejecuta instrucciones1, si no es asi, entonces se ejecuta instrucciones2.  tambien es comun el uso de una seleccion multiple que equivaldria a anidar varias funciones de seleccion.  en este caso hay una serie de condiciones que tienen que ser mutuamente excluyentes, si una de ellas se cumple las demas tienen que ser falsas necesariamente, hay un caso si no que sera cierto cuando las demas condiciones sean falsas.  en esta estructura si condicion1 es cierta, entonces se ejecuta solo instrucciones1. en general, si condicioni es verdadera, entonces solo se ejecuta instruccionesi  una construccion similar a la anterior (equivalente en algunos casos) es la que se muestra a continuacion.  en este caso hay un indicador es una variable o una funcion cuyo valor es comparado en cada caso con los valores \"valori\", si en algun caso coinciden ambos valores, entonces se ejecutaran las instruccionesi correspondientes. la seccion en otro caso es analoga a la seccion si no del ejemplo anterior.  las instrucciones iterativas representan la ejecucion de instrucciones en mas de una vez.  el bucle se repite mientras la condicion sea cierta, si al llegar por primera vez al bucle mientras la condicion es falsa, el cuerpo del bucle no se ejecuta alguna vez.    existen otras variantes que se derivan a partir de la anterior. la estructura de control repetir se utiliza cuando es necesario que el cuerpo del bucle se ejecuten al menos una vez y hasta que se cumpla la condicion:  la estructura anterior equivaldria a escribir:  el bucle hacer se utiliza para repetir un bloque de codigo mientras se cumpla cierta condicion.  una estructura de control muy comun es el ciclo for, la cual se usa cuando se desea iterar un numero conocido de veces, empleando como indice una variable que se incrementa (o decrementa):  la cual se define como:  por ultimo, tambien es comun usar la estructura de control para cada. esta sentencia se usa cuando se tiene una lista o un conjunto l y se quiere iterar por cada uno de sus elementos:  si asumimos que los elementos de l son l 0 , l 1 , … , l n ,l_{1},\\dots ,l_{n}} , entonces esta sentencia equivaldria a:  que es lo mismo que:  sin embargo, en la practica existen mejores formas de implementar esta instruccion dependiendo del problema.  es importante recalcar que el pseudocodigo no es un lenguaje estandarizado. eso significa que diferentes autores podrian dar otras estructuras de control o bien usar estas mismas estructuras, pero con una notacion diferente. sin embargo, las funciones matematicas y logicas toman el significado usual que tienen en matematica y logica, con las mismas expresiones.  cualquier instruccion puede ser sustituida por una estructura de control. el siguiente ejemplo muestra el pseudocodigo del ordenamiento de burbuja, que tiene varias estructuras anidadas. este algoritmo ordena de menor a mayor los elementos de una lista l .   p r o c e d i m i e n t o o r d e n a r ( l ) ↕ / / c o m e n t a r i o : l = ( l 1 , l 2 , … , l n ) e s u n a l i s t a c o n n e l e m e n t o s / / k ← 0 ; r e p e t i r ↕ i n t e r c a m b i o ← f a l s o ; k ← k + 1 ; p a r a i ← 1 h a s t a n − k c o n p a s o 1 h a c e r ↕ s i l i > l i + 1 e n t o n c e s ↕ i n t e r c a m b i a r ( l i , l i + 1 ) i n t e r c a m b i o ← v e r d a d e r o ; f i n s i f i n p a r a h a s t a q u e i n t e r c a m b i o = f a l s o ; f i n p r o c e d i m i e n t o {l}\\mathrm {procedimiento} }\\;\\mathrm {ordenar} }\\;(l}\\;)\\\\\\left\\updownarrow {l}//comentario:\\;l=(l_{1},l_{2},\\dots ,l_{n})\\;es\\;una\\;lista\\;con\\;n\\;elementos//}\\\\k}\\;\\gets }\\;0;}\\\\\\mathrm {repetir} }\\\\\\left\\updownarrow {l}\\mathrm {intercambio} }\\;\\gets }\\;\\mathrm {falso} ;}\\\\k}\\;\\gets }\\;k+1;}\\\\\\mathrm {para} }\\;i}\\;\\gets }\\;1}\\;\\mathrm {hasta} }\\;n-k}\\;\\mathrm {con\\;paso} }\\;1}\\;\\mathrm {hacer} }\\\\\\left\\updownarrow {l}\\mathrm {si} }\\;l_{i}}\\;>}\\;l_{i+1}}\\;\\mathrm {entonces} }\\;\\\\\\left\\updownarrow {l}\\mathrm {intercambiar} }\\;(l_{i},l_{i+1}}\\;)\\\\\\mathrm {intercambio} }\\;\\gets }\\;\\mathrm {verdadero} ;}\\end{array}}\\right.\\\\\\mathrm {fin\\;si} }\\;\\\\\\end{array}}\\right.\\\\\\mathrm {fin\\;para} }\\\\\\end{array}}\\right.\\\\\\mathrm {hasta\\;que} }\\;\\mathrm {intercambio} }\\;=}\\;\\mathrm {falso} ;}\\end{array}}\\right.\\\\\\mathrm {fin\\;procedimiento} }\\;\\\\\\end{array}}}  en general, las estructuras anidadas se muestran indentadas, para hacer mas sencilla su identificacion a simple vista. en el ejemplo, ademas de la sangria, se ha conectado con flechas los pares de delimitadores de cada nivel de anidamiento.  muchas personas prefieren distinguir entre funciones y procedimientos. una funcion, al igual que una funcion matematica, recibe uno o varios valores de entrada y regresa una salida mientras que un procedimiento recibe una entrada y no genera alguna salida aunque en algun caso podria devolver resultados a traves de sus parametros de entrada si estos se han declarado por referencia (ver formas de pasar argumentos a una funcion o procedimiento).  en ambos casos es necesario dejar en claro cuales son las entradas para el algoritmo, esto se hace comunmente colocando estos valores entre parentesis al principio o bien declarandolo explicitamente con un enunciado. en el caso de las funciones, es necesario colocar una palabra como regresar o devolver para indicar cual es la salida generada por el algoritmo. por ejemplo, el pseudocodigo de una funcion que permite calcular a n } (un numero a elevado a potencia n ).  un ejemplo de procedimiento seria el algoritmo de ordenamiento de burbuja, por el que partiendo de una lista de valores estos se ordenan, notese que en un procedimiento, no se calcula el valor de una funcion, sino que se realiza una accion, en este caso ordenar la lista.  con el pseudocodigo se puede desarrollar cualquier algoritmo que:  los pseudocodigos presentan los siguientes beneficios: ",
        "snippet": "En ciencias de la computación, y análisis numérico, el pseudocódigo[1]​ (o lenguaje de descripción algorítmico) es una descripción de alto nivel compacta e informal[2]​ del principio operativo de un programa informático u otro algoritmo.",
        "enlaces_salientes": [
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Lenguaje",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Algoritmo",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Subrutina",
            "/wiki/Lenguaje_natural",
            "/wiki/Sintaxis",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Compilador",
            "/wiki/Diagrama_de_flujo",
            "/wiki/UML",
            "/wiki/Programador",
            "/wiki/Top-down_y_Bottom-up",
            "/wiki/Estructuras_de_control",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/BASIC",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%2B%2B",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Lisp",
            "/wiki/ALGOL",
            "/wiki/Fortran",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Bucle_while",
            "/wiki/Bloque_de_c%C3%B3digo",
            "/wiki/Bucle_for",
            "/wiki/Lista_enlazada",
            "/wiki/Conjunto",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Argumento_(inform%C3%A1tica)#Paso_de_Argumentos",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/PSeInt",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Resoluci%C3%B3n_de_problemas_de_programaci%C3%B3n",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Estructuras_de_control",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Bucle_for",
            "/wiki/Bucle_do",
            "/wiki/Bucle_while",
            "/wiki/Bucle_repetir",
            "/wiki/Bucle_infinito",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
        "titulo": "Teoría de autómatas",
        "contenido": "la teoria de automatas es una rama de la teoria de la computacion que estudia las maquinas abstractas y los problemas que estas son capaces de resolver. la teoria de automatas esta estrechamente relacionada con la teoria del lenguaje formal ya que los automatas son clasificados a menudo por la clase de lenguajes formales que son capaces de reconocer. tambien son de gran utilidad en la teoria de la complejidad computacional.  un automata es un modelo matematico para una maquina de estado finito (fsm sus siglas en ingles). una fsm es una maquina que, dada una entrada de simbolos, \"salta\" a traves de una serie de estados de acuerdo a una funcion de transicion (que puede ser expresada como una tabla). en la variedad comun \"mealy\" de fsms, esta funcion de transicion dice al automata a que estado cambiar dados unos determinados estado y simbolo.  la entrada es leida simbolo por simbolo, hasta que es \"consumida\" completamente (piense en esta como una cinta con una palabra escrita en ella, que es leida por una cabeza lectora del automata; la cabeza se mueve a lo largo de la cinta, leyendo un simbolo a la vez) una vez la entrada se ha agotado, el automata se detiene.  dependiendo del estado en el que el automata finaliza se dice que este ha aceptado o rechazado la entrada. si este termina en el estado \"acepta\", el automata acepta la palabra. si lo hace en el estado \"rechaza\", el automata rechazo la palabra, el conjunto de todas las palabras aceptadas por el automata constituyen el lenguaje aceptado por si mismo.  los conceptos basicos de simbolos, palabras, alfabetos y strings son comunes en la mayoria de las descripciones de los automatas. estos son:  formalmente, un automata finito (af) puede ser descrito como una 5-tupla ⟨ q , σ , δ , s 0 , f ⟩ ,f\\rangle } .  existen tres tipos de automatas finitos  sin embargo, puede observarse que todos estos tipos de automatas pueden aceptar los mismos lenguajes. siempre se puede construir un afd que acepte el mismo lenguaje que el dado por un afnd.  los lenguajes aceptados por los automatas descritos mas arriba se denominan lenguajes regulares. automatas mas potentes pueden aceptar lenguajes mas complejos. algunos de estos automatas son: ",
        "snippet": "La teoría de autómatas es una rama de la teoría de la computación que estudia las máquinas abstractas y los problemas que éstas son capaces de resolver. La teoría de autómatas está estrechamente relacionada con la teoría del lenguaje formal ya que los autómatas son clasificados a menudo por la clase de lenguajes formales que son capaces de reconocer. También son de gran utilidad en la teoría de la complejidad computacional.",
        "enlaces_salientes": [
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Lenguaje_formal",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/S%C3%ADmbolo",
            "/wiki/String",
            "/wiki/Concatenaci%C3%B3n",
            "/wiki/Conjunto",
            "/wiki/Lenguaje_formal",
            "/wiki/Clausura_de_Kleene",
            "/wiki/Clausura_de_Kleene",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/Tupla",
            "/wiki/Aut%C3%B3mata_finito_determinista",
            "/wiki/Aut%C3%B3mata_finito_no_determinista",
            "/wiki/Cadena_de_Markov",
            "/wiki/Aut%C3%B3mata_finito_no_determinista",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/Lenguaje_regular",
            "/wiki/Aut%C3%B3mata_con_pila",
            "/wiki/Memoria_de_ordenador",
            "/wiki/Pila_(estructura_de_datos)",
            "/wiki/Lenguajes_de_contexto_libre",
            "/wiki/Aut%C3%B3mata_linealmente_acotado",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Sistema_combinacional",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/Aut%C3%B3mata_con_pila",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/Cadena_de_M%C3%A1rkov",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Funci%C3%B3n_recursiva",
        "titulo": "Función recursiva",
        "contenido": "en logica matematica y computacion, las funciones recursivas o tambien conocidas como funciones recursivas-μ son una clase de funciones de los numeros naturales en los numeros naturales que son «computables» en un sentido intuitivo. de hecho, en teoria de la computabilidad se demuestra que las funciones recursivas son precisamente las funciones computables, es decir, las que pueden ser calculadas con el formalismo de computo mas general conocido como lo son las maquinas de turing. las funciones recursivas estan relacionadas con las funciones primitivas recursivas y su definicion inductiva se construye basandose en la de las funciones primitivas recursivas (estas se obtienen por medio de recursion primitiva y composicion de funciones iniciales). no toda funcion recursiva es primitiva recursiva. el ejemplo mas conocido es la funcion de ackermann.  existen otros sistemas formales equivalentes en cuanto a poder de expresion, por ejemplo el calculo lambda y las cadenas de markov.  para definir las funciones recursivas se toma la definicion de las funciones primitivas recursivas, para permitir funciones parciales, agregando el operador de busqueda o minimizacion no acotada como sigue:  se puede verificar que la especificacion del minimo valor de x, junto con el resto de la definicion identica a la de las funciones primitivas recursivas, implican el axioma de busqueda acotada de las funciones primitivas recursivas.  el conjunto de las funciones recursivas parciales esta definido como el mas pequeño conjunto de funciones parciales con cualquier numero de argumentos de los naturales en los naturales que contiene el cero, el sucesor y las funciones de proyeccion, tales que la composicion, la recursion primitiva y la busqueda no acotada son operaciones cerradas en este conjunto.  el conjunto de las funciones recursivas totales es el subconjunto de las funciones recursivas parciales que ademas son funciones totales.  en la tesis de church-turing se establece el paralelo entre maquinas de turing que no se detienen para ciertas entradas y el resultado indefinido de una funcion recursiva parcial. el operador de busqueda no acotada no puede ser definido usando las reglas de definicion de las funciones primitivas recursivas, dado que no se dispone en ellas de un mecanismo de iteracion no acotada por el cual podria no encontrarse el resultado de una funcion. ",
        "snippet": "En lógica matemática y computación, las funciones recursivas o también conocidas como funciones recursivas-μ son una clase de funciones de los números naturales en los números naturales que son «computables» en un sentido intuitivo. De hecho, en teoría de la computabilidad se demuestra que las funciones recursivas son precisamente las funciones computables, es decir, las que pueden ser calculadas con el formalismo de cómputo más general conocido como lo son las máquinas de Turing. Las funciones recursivas están relacionadas con las funciones primitivas recursivas y su definición inductiva se construye basándose en la de las funciones primitivas recursivas (estas se obtienen por medio de recursión primitiva y composición de funciones iniciales). No toda función recursiva es primitiva recursiva. El ejemplo más conocido es la función de Ackermann.",
        "enlaces_salientes": [
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Funciones_computables",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Recursi%C3%B3n_primitiva",
            "/wiki/Funci%C3%B3n_de_Ackermann",
            "/wiki/Sistema_formal",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Cadena_de_Markov",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Funci%C3%B3n_total",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/M%C3%A1quina_de_Turing",
        "titulo": "Máquina de Turing",
        "contenido": " una maquina de turing es un dispositivo que manipula simbolos sobre una tira de cinta de acuerdo con una tabla de reglas. a pesar de su simplicidad, una maquina de turing puede ser adaptada para simular la logica de cualquier algoritmo de computador y es particularmente util en la explicacion de las funciones de una cpu dentro de un computador.  originalmente fue definida por el matematico ingles alan turing como una «maquina automatica» en 1936 en la revista proceedings of the london mathematical society[nota 1]​. la maquina de turing no esta diseñada como una tecnologia de computacion practica, sino como un dispositivo hipotetico que representa una maquina de computacion. las maquinas de turing ayudan a los cientificos a entender los limites del calculo mecanico.​​  turing dio una definicion sucinta del experimento en su ensayo de 1948, «maquinas inteligentes». refiriendose a su publicacion de 1936, turing escribio que la maquina de turing, aqui llamada una maquina de computacion logica, consistia en:  una maquina de turing que es capaz de simular cualquier otra maquina de turing es llamada una maquina universal de turing (utm, o simplemente una maquina universal). una definicion mas matematicamente orientada, con una similar naturaleza \"universal\", fue presentada por alonzo church, cuyo trabajo sobre el calculo lambda se entrelaza con el de turing en una teoria formal de la computacion conocida como la tesis de church-turing. la tesis señala que las maquinas de turing capturan, de hecho, la nocion informal de un metodo eficaz en la logica y las matematicas y proporcionan una definicion precisa de un algoritmo o 'procedimiento mecanico'.  la importancia de la maquina de turing en la historia de la computacion es doble: primero, la maquina de turing fue uno de los primeros (si no el primero) modelos teoricos para las computadoras, viendo la luz en 1936. segundo, estudiando sus propiedades abstractas, la maquina de turing ha servido de base para mucho desarrollo teorico en las ciencias de la computacion y en la teoria de la complejidad. una razon para esto es que las maquinas de turing son simples, y por tanto amenas al analisis. dicho esto, cabe aclarar que las maquinas de turing no son un modelo practico para la computacion en maquinas reales, las cuales precisan modelos mas rapidos como los basados en ram.  alan turing introdujo el concepto de maquina de turing en el trabajo on computable numbers, with an application to the entscheidungsproblem, publicado por la sociedad matematica de londres en 1936, en el que se estudiaba la cuestion planteada por david hilbert sobre si las matematicas son decidibles, es decir, si hay un metodo definido que pueda aplicarse a cualquier sentencia matematica y que nos diga si esa sentencia es cierta o no. turing ideo un modelo formal de computador, la maquina de turing, y demostro que existian problemas que una maquina no podia resolver.​  con este aparato extremadamente sencillo es posible realizar cualquier computo que un computador digital sea capaz de realizar.​  mediante este modelo teorico y el analisis de la complejidad de los algoritmos, fue posible la categorizacion de problemas computacionales de acuerdo a su comportamiento, apareciendo asi, el conjunto de problemas denominados p y np, cuyas soluciones pueden encontrarse en tiempo polinomico por maquinas de turing deterministas y no deterministas, respectivamente.  precisamente, la tesis de church-turing formulada por alan turing y alonzo church, de forma independiente a mediados del siglo xx caracteriza la nocion informal de computabilidad con la computacion mediante una maquina de turing.​  la idea subyacente es el concepto de que una maquina de turing puede verse como un automata ejecutando un procedimiento efectivo definido formalmente, donde el espacio de memoria de trabajo es ilimitado, pero en un momento determinado solo una parte finita es accesible.  la maquina de turing modela matematicamente a una maquina que opera mecanicamente sobre una cinta. en esta cinta hay simbolos que la maquina puede leer y escribir, uno a la vez, usando un cabezal lector/escritor de cinta. la operacion esta completamente determinada por un conjunto finito de instrucciones elementales como \"en el estado 42, si el simbolo visto es 0, escribe un 1; si el simbolo visto es 1, cambia al estado 17; en el estado 17, si el simbolo visto es 0, escribe un 1 y cambia al estado 6; etc\". en el articulo original (\"sobre numeros computables con una aplicacion al entscheidungsproblem\"), turing no imagina un mecanismo, sino una persona a la que el llama la \"computadora\", quien ejecuta servilmente estas reglas mecanicas deterministas (o como turing pone, \"de una manera desganada\").  mas precisamente, una maquina de turing consta de:  note que cada parte de la maquina — su estado y colecciones de simbolos — y sus acciones — imprimir, borrar, movimiento de la cinta — es finito, discreto y distinguible; es la cantidad potencialmente ilimitada de cinta lo que le da una cantidad ilimitada de espacio de almacenamiento.  una maquina de turing​ es un modelo computacional que realiza una lectura/escritura de manera automatica sobre una entrada llamada cinta, generando una salida en esta misma.  este modelo esta formado por un alfabeto de entrada y uno de salida, un simbolo especial llamado blanco (normalmente b, δ o 0), un conjunto de estados finitos y un conjunto de transiciones entre dichos estados. su funcionamiento se basa en una funcion de transicion, que recibe un estado inicial y una cadena de caracteres (la cinta, la cual puede ser infinita) pertenecientes al alfabeto de entrada. la maquina va leyendo una celda de la cinta en cada paso, borrando el simbolo en el que se encuentra posicionado su cabezal y escribiendo un nuevo simbolo perteneciente al alfabeto de salida, para luego desplazar el cabezal a la izquierda o a la derecha (solo una celda a la vez). esto se repite segun se indique en la funcion de transicion, para finalmente detenerse en un estado final o de aceptacion, representando asi la salida.  una maquina de turing con una sola cinta puede definirse como una 7-tupla  donde:​  existe en la literatura un abundante numero de definiciones alternativas, pero todas ellas tienen el mismo poder computacional, por ejemplo se puede añadir el simbolo s como simbolo de \"no movimiento\" en un paso de computo.  la maquina de turing consta de un cabezal lector/escritor y una cinta infinita en la que el cabezal lee el contenido, borra el contenido anterior y escribe un nuevo valor. las operaciones que se pueden realizar en esta maquina se limitan a:  el computo se determina a partir de una tabla de estados de la forma:  esta tabla toma como parametros el estado actual de la maquina y el caracter leido de la cinta, dando la direccion para mover el cabezal, el nuevo estado de la maquina y el valor a escribir en la cinta.  la memoria es la cinta de la maquina que se divide en espacios de trabajo denominados celdas, donde se pueden escribir y leer simbolos. inicialmente todas las celdas contienen un simbolo especial denominado \"blanco\". las instrucciones que determinan el funcionamiento de la maquina tienen la forma, \"si estamos en el estado x leyendo la posicion y, donde hay escrito el simbolo z, entonces este simbolo debe ser reemplazado por este otro simbolo, y pasar a leer la celda siguiente, bien a la izquierda o bien a la derecha\".  la maquina de turing puede considerarse como un automata capaz de reconocer lenguajes formales. en ese sentido, es capaz de reconocer los lenguajes recursivamente enumerables, de acuerdo a la jerarquia de chomsky. su potencia es, por tanto, superior a otros tipos de automatas, como el automata finito, o el automata con pila, o igual a otros modelos con la misma potencia computacional.   las maquinas de turing pueden representarse mediante grafos particulares, tambien llamados diagramas de estados finitos, de la siguiente manera: es una secuencia de la forma α 1 q α 2 q\\alpha _{2}\\!} donde α 1 , α 2 ∈ γ ∗ ,\\alpha _{2}\\in \\gamma ^{*}} y q ∈ q que escribe el estado de una maquina de turing. la cinta contiene la cadena α 1 α 2 \\alpha _{2}\\!} seguida de infinitos blancos. el cabezal señala el primer simbolo de α 2 \\!} .  por ejemplo, para la maquina de turing  con las transiciones  la descripcion instantanea para la cinta 1011 es:  definimos una maquina de turing sobre el alfabeto { 0 , 1 } } , donde 0 representa el simbolo blanco. la maquina comenzara su proceso situada sobre un simbolo \"1\" de una serie. la maquina de turing copiara el numero de simbolos \"1\" que encuentre hasta el primer blanco detras de dicho simbolo blanco. es decir, posiciona el cabezal sobre el 1 situado en el extremo izquierdo, doblara el numero de simbolos 1, con un 0 en medio. asi, si tenemos la entrada \"111\" devolvera \"1110111\", con \"1111\" devolvera \"111101111\", y sucesivamente.  el conjunto de estados es { s 1 , s 2 , s 3 , s 4 , s 5 } ,s_{2},s_{3},s_{4},s_{5}\\}\\!} y el estado inicial es s 1 \\!} . la tabla que describe la funcion de transicion es la siguiente:  el funcionamiento de una computacion de esta maquina puede mostrarse con el siguiente ejemplo (en negrita se resalta la posicion de la cabeza lectora/escritora):  la maquina realiza su proceso por medio de un bucle, en el estado inicial s 1 \\!} , reemplaza el primer 1 con un 0, y pasa al estado s 2 \\!} , con el que avanza hacia la derecha, saltando los simbolos 1 hasta un 0 (que debe existir), cuando lo encuentra pasa al estado s 3 \\!} , con este estado avanza saltando los 1 hasta encontrar otro 0 (la primera vez no habra ningun 1). una vez en el extremo derecho, añade un 1. despues comienza el proceso de retorno; con s 4 \\!} vuelve a la izquierda saltando los 1, cuando encuentra un 0 (en el medio de la secuencia), pasa a s 5 \\!} que continua a la izquierda saltando los 1 hasta el 0 que se escribio al principio. se reemplaza de nuevo este 0 por 1, y pasa al simbolo siguiente, si es un 1, se pasa a otra iteracion del bucle, pasando al estado s1 de nuevo. si es un simbolo 0, sera el simbolo central, con lo que la maquina se detiene al haber finalizado el computo.  una razon para aceptar la maquina de turing como un modelo general de computo es que el modelo que hemos definido anteriormente es equivalente a muchas versiones modificadas que en principio pareciera incrementar el poder computacional.  la funcion de transicion de la mt sencilla esta definida por  la cual puede ser modificada como  donde s significa «permanecer» o «esperar», es decir no mover el cabezal de lectura/escritura. por lo tanto, δ ( q , σ ) = ( p , σ ′ , s ) significa que se pasa del estado q al p, se escribe σ ′ en la celda actual y la cabeza se queda sobre la celda actual.  esta modificacion se denota al igual que una mt sencilla, lo que la hace diferente es que la cinta es infinita tanto por la derecha como por la izquierda, lo cual permite realizar transiciones iniciales como δ ( q 0 , x ) = ( q 1 , y , l ) ,x)=(q_{1},y,l)\\!} .  es aquella que mediante la cual cada celda de la cinta de una maquina sencilla se divide en subceldas. cada celda es asi capaz de contener varios simbolos de la cinta. por ejemplo, la cinta de la figura tiene cada celda subdividida en tres subceldas.  se dice que esta cinta tiene multiples pistas puesto que cada celda de esta maquina de turing contiene multiples caracteres, el contenido de las celdas de la cinta puede ser representado mediante n-tuplas ordenadas. los movimientos que realice esta maquina dependeran de su estado actual y de la n-tupla que represente el contenido de la celda actual. cabe mencionar que posee un solo cabezal al igual que una mt sencilla.  una mt con mas de una cinta consiste de un control finito con k cabezales lectores/escritores y k cintas. cada cinta es infinita en ambos sentidos. la mt define su movimiento dependiendo del simbolo que esta leyendo cada uno de sus cabezales, da reglas de sustitucion para cada uno de los simbolos y direccion de movimiento para cada uno de los cabezales. inicialmente la mt empieza con la entrada en la primera cinta y el resto de las cintas en blanco.  una mt multidimensional es aquella cuya cinta puede verse como extendiendose infinitamente en mas de una direccion, el ejemplo mas basico seria el de una maquina bidimensional cuya cinta se extenderia infinitamente hacia arriba, abajo, derecha e izquierda.  en la modificacion bidimensional de mt que se muestra en la figura tambien se agregan dos nuevos movimientos del cabezal {u,d} (es decir arriba y abajo). de esta forma la definicion de los movimientos que realiza el cabezal sera {l,r,u,d}.  la entrada de una maquina de turing viene determinada por el estado actual y el simbolo leido, un par (estado, simbolo), siendo el cambio de estado, la escritura de un nuevo simbolo y el movimiento del cabezal, las acciones a tomar en funcion de una entrada. en el caso de que para cada par (estado, simbolo) posible exista a lo sumo una posibilidad de ejecucion, se dira que es una maquina de turing determinista, mientras que en el caso de que exista al menos un par (estado, simbolo) con mas de una posible combinacion de actuaciones se dira que se trata de una maquina de turing no determinista.  la funcion de transicion δ en el caso no determinista, queda definida como sigue:  ¿como sabe una maquina no determinista que accion tomar de las varias posibles? hay dos formas de verlo: una es decir que la maquina es \"el mejor adivino posible\", esto es, que siempre elige la transicion que finalmente la llevara a un estado final de aceptacion. la otra es imaginarse que la maquina se \"clona\", bifurcandose en varias copias, cada una de las cuales sigue una de las posibles transiciones. mientras que una maquina determinista sigue un unico \"camino computacional\", una maquina no determinista tiene un \"arbol computacional\". si cualquiera de las ramas del arbol finaliza en un estado de aceptacion, se dice que la maquina acepta la entrada.  la capacidad de computo de ambas versiones es equivalente; se puede demostrar que dada una maquina de turing no determinista existe otra maquina de turing determinista equivalente, en el sentido de que reconoce el mismo lenguaje, y viceversa. no obstante, la velocidad de ejecucion de ambos formalismos no es la misma, pues si una maquina no determinista m reconoce una cierta palabra de tamaño n en un tiempo o ( t ( n ) ) , la maquina determinista equivalente reconocera la palabra en un tiempo o ( 2 t ( n ) ) )\\!} . es decir, el no determinismo permitira reducir la complejidad de la solucion de los problemas, permitiendo resolver, por ejemplo, problemas de complejidad exponencial en un tiempo polinomico.  el problema de la parada o problema de la detencion (halting problem en ingles) para maquinas de turing consiste en: dada una mt m y una palabra w, determinar si m terminara en un numero finito de pasos cuando se ejecuta usando w como entrada.  alan turing, en su famoso articulo «on computable numbers, with an application to the entscheidungsproblem» (1936), demostro que el problema de la parada de la maquina de turing es indecidible, en el sentido de que ninguna maquina de turing lo puede resolver.  toda maquina de turing puede codificarse como una secuencia binaria finita, es decir una secuencia finita de ceros y unos. para simplificar la codificacion, suponemos que toda mt tiene un unico estado inicial denotado por q 1 \\!} , y un unico estado final denotado q 2 \\!} . tendremos que para una mt m de la forma  todos estos simbolos se codifican como secuencias de unos:  los estados de una mt q 1 , q 2 , q 3 , … , q n ,q_{2},q_{3},\\ldots ,q_{n}\\!} se codifican tambien con secuencias de unos:  las directrices de desplazamiento r , l y s se codifican con 1, 11, 111, respectivamente. una transicion δ ( q , a ) = ( p , c , r ) se codifica usando ceros como separadores entre los estados, los simbolos del alfabeto de cinta y la directriz de desplazamiento r . asi, la transicion δ ( q 3 , s 2 ) = ( q 5 , s 3 , r ) ,s_{2})=(q_{5},s_{3},r)\\!} se codifica como  en general, la codificacion de una transicion cualquiera δ ( q i , s k ) = ( q j , s l , r ) ,s_{k})=(q_{j},s_{l},r)\\!} es  donde t ∈ { 1 , 2 , 3 } \\!} , segun la direccion sea d e r e c h a ( r ) , i z q u i e r d a ( l ) , e s p e r a r ( s ) (r),\\ \\mathrm {izquierda} (l),\\ \\mathrm {esperar} (s)} .  una mt se codifica escribiendo consecutivamente las secuencias de las modificaciones de todas sus transiciones. mas precisamente, la codificacion de una mt m es de la forma c 1 c 2 … c i c_{2}\\ldots c_{i}\\!} , donde c i \\!} es la codificacion de la i -esima transicion de m. puesto que el orden en que se representen las transiciones de una mt no es relevante, una misma mt tiene varias codificaciones diferentes. esto no representa ninguna desventaja practica o conceptual ya que no se pretende que las codificaciones sean unicas.  una maquina de turing computa una determinada funcion parcial de caracter definido e univoca, definida sobre las secuencias de posibles cadenas de simbolos de su alfabeto. en este sentido se puede considerar como equivalente a un programa de ordenador, o a un algoritmo. sin embargo es posible realizar una codificacion de la tabla que representa a una maquina de turing, a su vez, como una secuencia de simbolos en un determinado alfabeto; por ello, podemos construir una maquina de turing que acepte como entrada la tabla que representa a otra maquina de turing, y, de esta manera, simule su comportamiento.  en 1947, turing indico:  con esta codificacion de tablas como cadenas, se abre la posibilidad de que unas maquinas de turing se comporten como otras maquinas de turing. sin embargo, muchas de sus posibilidades son indecidibles, pues no admiten una solucion algoritmica. por ejemplo, un problema interesante es determinar si una maquina de turing cualquiera se parara en un tiempo finito sobre una determinada entrada; problema conocido como problema de la parada, y que turing demostro que era indecidible. en general, se puede demostrar que cualquier cuestion no trivial sobre el comportamiento o la salida de una maquina de turing es un problema indecidible.  el concepto de maquina de turing universal esta relacionado con el de un sistema operativo basico, pues puede ejecutar cualquier instruccion computable sobre el.​  en 1985, deutsch presento el diseño de la primera maquina cuantica basada en una maquina de turing. con este fin enuncio una nueva variante la tesis de church-turing dando lugar al denominado \"principio de church-turing-deutsch\".  la estructura de una maquina de turing cuantica es muy similar a la de una maquina de turing clasica. esta compuesta por los tres elementos clasicos:  el procesador contiene el conjunto de instrucciones que se aplica sobre el elemento de la cinta señalado por el cabezal. el resultado dependera del qubit de la cinta y del estado del procesador. el procesador ejecuta una instruccion por unidad de tiempo.  la cinta de memoria es similar a la de una maquina de turing tradicional. la unica diferencia es que cada elemento de la cinta de la maquina cuantica es un qubit. el alfabeto de esta nueva maquina esta formado por el espacio de valores del qubit. la posicion del cabezal se representa con una variable entera.  dos modelos matematicos equivalentes a los de las maquinas de turing son las maquinas de post, creadas en forma paralela por emil leon post,​ y el calculo lambda, introducido por alonzo church y stephen kleene en los años 1930, y tambien usado por church para demostrar en 1936 el entscheidungsproblem.   ",
        "snippet": "Una máquina de Turing es un dispositivo que manipula símbolos sobre una tira de cinta de acuerdo con una tabla de reglas. A pesar de su simplicidad, una máquina de Turing puede ser adaptada para simular la lógica de cualquier algoritmo de computador y es particularmente útil en la explicación de las funciones de una CPU dentro de un computador.",
        "enlaces_salientes": [
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Turing_(desambiguaci%C3%B3n)",
            "/wiki/Algoritmo",
            "/wiki/Computador",
            "/wiki/Unidad_central_de_procesamiento",
            "/wiki/Alan_Turing",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Computador",
            "/wiki/M%C3%A1quina_universal_de_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/L%C3%B3gica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Memoria_de_acceso_aleatorio",
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/David_Hilbert",
            "/wiki/Complejidad_computacional",
            "/wiki/Algoritmo",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/NP_(Complejidad_computacional)",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Alan_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/Siglo_XX",
            "/wiki/Memoria_de_trabajo",
            "/wiki/Conjunto_finito",
            "/wiki/Entscheidungsproblem",
            "/wiki/Registro_de_estado",
            "/wiki/Almacenamiento_de_computadora",
            "/wiki/Modelo_computacional",
            "/wiki/Lectura",
            "/wiki/Escritura",
            "/wiki/Entrada",
            "/wiki/Salida_(inform%C3%A1tica)",
            "/wiki/Alfabeto",
            "/wiki/Estado_(inform%C3%A1tica)",
            "/wiki/Funci%C3%B3n_de_transici%C3%B3n",
            "/wiki/Cadena_de_caracteres",
            "/wiki/Alfabeto",
            "/wiki/Funci%C3%B3n_de_transici%C3%B3n",
            "/wiki/Tupla",
            "/wiki/Estado_f%C3%ADsico",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Lenguaje_formal",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/Aut%C3%B3mata_con_pila",
            "/wiki/Grafo",
            "/wiki/Alfabeto",
            "/wiki/Estados",
            "/wiki/Arista_(teor%C3%ADa_de_grafos)",
            "/wiki/Grafo_dirigido",
            "/wiki/Complejidad_computacional",
            "/wiki/Cambio_de_estado",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/Problema_de_la_parada",
            "/wiki/Alan_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/Problema_indecidible",
            "/wiki/Binario",
            "/wiki/M%C3%A1quina_de_Turing_universal",
            "/wiki/Un%C3%ADvoca",
            "/wiki/Programa_(computaci%C3%B3n)",
            "/wiki/Algoritmo",
            "/wiki/Problema_indecidible",
            "/wiki/Problema_de_la_parada",
            "/wiki/Problema_indecidible",
            "/wiki/Sistema_operativo",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Qubit",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/Qubit",
            "/wiki/Qubit",
            "/wiki/Qubit",
            "/wiki/M%C3%A1quina_de_Post",
            "/wiki/Emil_Leon_Post",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Alonzo_Church",
            "/wiki/Stephen_Kleene",
            "/wiki/Entscheidungsproblem",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Sistema_combinacional",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/Aut%C3%B3mata_con_pila",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/M%C3%A1quina_de_Turing_universal",
            "/wiki/M%C3%A1quina_de_Turing_alternante",
            "/wiki/Problema_de_la_parada",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/Juego_de_la_vida",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/London_Mathematical_Society",
            "/wiki/Wiktionary",
            "/wiki/ISBN",
            "/wiki/Andrew_Hodges",
            "/wiki/ISBN",
            "/wiki/Marvin_Minsky",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/M%C3%A1quina_de_registro",
        "titulo": "Máquina de registro",
        "contenido": "en logica matematica y en ciencias de la computacion teorica, una maquina de registro es una clase generica de maquinas abstractas usadas en una manera similar a una maquina de turing. todos los modelos son turing equivalente.  la maquina de registro toma su nombre por sus uno o mas \"registros\" -- en lugar de la cinta y el cabezal de una maquina de turing (o cintas y cabezales) el modelo usa multiples registros con direccion unica, cada uno de los cuales mantiene un simple numero entero positivo.  hay por lo menos 4 subclases encontradas en la literatura, aqui son enumeradas desde la mas primitiva a la mas avanzada como computadora:  cualquier modelo de maquina con registro propiamente definido es turing equivalente. la velocidad de computo es muy dependiente en las especificaciones del modelo.  en ciencias de la computacion practica, un concepto similar conocido como maquina virtual es a veces usado para minimizar las dependencias en las arquitecturas de las maquinas subyacentes. tales maquinas tambien son usadas para enseñar. en libros de textos, el termino \"maquina de registro\" es usado a veces para referirse a una maquina virtual.​ ",
        "snippet": "En lógica matemática y en ciencias de la computación teórica, una máquina de registro es una clase genérica de máquinas abstractas usadas en una manera similar a una máquina de Turing. Todos los modelos son Turing equivalente.",
        "enlaces_salientes": [
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/M%C3%A1quina_de_estado_finito",
            "/wiki/Arquitectura_Harvard",
            "/wiki/Arquitectura_Harvard",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/M%C3%A1quina_universal_de_Turing",
            "/wiki/Arquitectura_de_von_Neumann",
            "/wiki/RISC",
            "/wiki/M%C3%A1quina_virtual",
            "/wiki/MIT_Press",
            "/wiki/Cambridge,_Massachusetts",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_universal_de_Turing",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Internet_Archive",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Funci%C3%B3n_recursiva",
        "titulo": "Función recursiva",
        "contenido": "en logica matematica y computacion, las funciones recursivas o tambien conocidas como funciones recursivas-μ son una clase de funciones de los numeros naturales en los numeros naturales que son «computables» en un sentido intuitivo. de hecho, en teoria de la computabilidad se demuestra que las funciones recursivas son precisamente las funciones computables, es decir, las que pueden ser calculadas con el formalismo de computo mas general conocido como lo son las maquinas de turing. las funciones recursivas estan relacionadas con las funciones primitivas recursivas y su definicion inductiva se construye basandose en la de las funciones primitivas recursivas (estas se obtienen por medio de recursion primitiva y composicion de funciones iniciales). no toda funcion recursiva es primitiva recursiva. el ejemplo mas conocido es la funcion de ackermann.  existen otros sistemas formales equivalentes en cuanto a poder de expresion, por ejemplo el calculo lambda y las cadenas de markov.  para definir las funciones recursivas se toma la definicion de las funciones primitivas recursivas, para permitir funciones parciales, agregando el operador de busqueda o minimizacion no acotada como sigue:  se puede verificar que la especificacion del minimo valor de x, junto con el resto de la definicion identica a la de las funciones primitivas recursivas, implican el axioma de busqueda acotada de las funciones primitivas recursivas.  el conjunto de las funciones recursivas parciales esta definido como el mas pequeño conjunto de funciones parciales con cualquier numero de argumentos de los naturales en los naturales que contiene el cero, el sucesor y las funciones de proyeccion, tales que la composicion, la recursion primitiva y la busqueda no acotada son operaciones cerradas en este conjunto.  el conjunto de las funciones recursivas totales es el subconjunto de las funciones recursivas parciales que ademas son funciones totales.  en la tesis de church-turing se establece el paralelo entre maquinas de turing que no se detienen para ciertas entradas y el resultado indefinido de una funcion recursiva parcial. el operador de busqueda no acotada no puede ser definido usando las reglas de definicion de las funciones primitivas recursivas, dado que no se dispone en ellas de un mecanismo de iteracion no acotada por el cual podria no encontrarse el resultado de una funcion. ",
        "snippet": "En lógica matemática y computación, las funciones recursivas o también conocidas como funciones recursivas-μ son una clase de funciones de los números naturales en los números naturales que son «computables» en un sentido intuitivo. De hecho, en teoría de la computabilidad se demuestra que las funciones recursivas son precisamente las funciones computables, es decir, las que pueden ser calculadas con el formalismo de cómputo más general conocido como lo son las máquinas de Turing. Las funciones recursivas están relacionadas con las funciones primitivas recursivas y su definición inductiva se construye basándose en la de las funciones primitivas recursivas (estas se obtienen por medio de recursión primitiva y composición de funciones iniciales). No toda función recursiva es primitiva recursiva. El ejemplo más conocido es la función de Ackermann.",
        "enlaces_salientes": [
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Funciones_computables",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Recursi%C3%B3n_primitiva",
            "/wiki/Funci%C3%B3n_de_Ackermann",
            "/wiki/Sistema_formal",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Cadena_de_Markov",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Funci%C3%B3n_total",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Lenguaje_m%C3%A1quina",
        "titulo": "Lenguaje de máquina",
        "contenido": "el lenguaje de maquina o codigo maquina es el sistema de codigos directamente interpretable por un circuito microprogramable, como el microprocesador de una computadora o el microcontrolador de un automata. este lenguaje esta compuesto por un conjunto de instrucciones que determinan acciones a ser tomadas por la maquina. un programa consiste en una cadena de estas instrucciones mas un conjunto  cual se trabaja. estas instrucciones son normalmente ejecutadas en secuencia, con eventuales cambios de flujo causados por el propio programa o eventos externos. el lenguaje de maquina es especifico de la arquitectura de la maquina, aunque el conjunto de instrucciones disponibles pueda ser similar entre arquitecturas distintas.  los circuitos microprogramables son digitales, lo que significa que trabajan con dos unicos niveles de tension. dichos niveles, por abstraccion, se simbolizan con los numeros 0 y 1, por eso el lenguaje de maquina solo utiliza dichos signos. esto permite el empleo de las teorias del algebra booleana y del sistema binario en el diseño de este tipo de circuitos y en su programacion.  claude elwood shannon, en su libro analysis of relay and switching circuits, y con sus experiencias en redes de conmutacion, sento las bases para la aplicacion del algebra de boole a las redes de conmutacion. una red de conmutacion es un circuito de interruptores electricos que al cumplir ciertas combinaciones booleanas con las variables de entrada, define el estado de la salida. este concepto es el nucleo de las puertas logicas, las cuales son, por su parte, los ladrillos con que se construyen sistemas logicos cada vez mas complejos. shannon utilizaba el rele como dispositivo fisico de conmutacion en sus redes, dado que el rele, a igual que una lampara electrica, posee dos estados: activado (encendido) o (apagado).  el desarrollo tecnologico ha permitido evolucionar desde las redes de reles electromagneticos a circuitos con tubos de vacio, luego a redes transistorizadas, hasta llegar a los modernos circuitos integrados, en cuya cuspide se encuentran los circuitos microprogramados.  el llamado codigo maquina consistia en introducir la programacion de la maquina mediante unos y ceros. cualquier programa de ordenador debe, finalmente, ser convertido a este codigo para que un ordenador pueda ejecutar las instrucciones de dicho programa.  los ordenadores solo leen este tipo de lenguaje, en donde la combinacion de numeros logra convertirse en acciones. dada su complejidad existen los lenguajes de programacion como javascript para programar paginas web o c++ para programar videojuegos entre muchos otros.​ ",
        "snippet": "El lenguaje de máquina o código máquina es el sistema de códigos directamente interpretable por un circuito microprogramable, como el microprocesador de una computadora o el microcontrolador de un autómata. Este lenguaje está compuesto por un conjunto de instrucciones que determinan acciones a ser tomadas por la máquina. Un programa consiste en una cadena de estas instrucciones más un conjunto cual se trabaja. Estas instrucciones son normalmente ejecutadas en secuencia, con eventuales cambios de flujo causados por el propio programa o eventos externos. El lenguaje de máquina es específico de la arquitectura de la máquina, aunque el conjunto de instrucciones disponibles pueda ser similar entre arquitecturas distintas.",
        "enlaces_salientes": [
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Intel_8086_y_8088",
            "/wiki/Sistema_hexadecimal",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/ASCII",
            "/wiki/Microprocesador",
            "/wiki/Computadora_electr%C3%B3nica",
            "/wiki/Microcontrolador",
            "/wiki/Aut%C3%B3mata_programable",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Arquitectura_de_computadoras",
            "/wiki/Sistema_digital",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/Sistema_binario",
            "/wiki/Claude_Elwood_Shannon",
            "/wiki/Puerta_l%C3%B3gica",
            "/wiki/Sistema_digital",
            "/wiki/Rel%C3%A9",
            "/wiki/V%C3%A1lvula_termoi%C3%B3nica",
            "/wiki/Transistor",
            "/wiki/Circuito_integrado",
            "/wiki/JavaScript",
            "/wiki/C%2B%2B",
            "/wiki/L%C3%B3gica_binaria",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Lenguaje_de_bajo_nivel",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Programa_(computaci%C3%B3n)",
        "titulo": "Programa informático",
        "contenido": "un programa informatico o programa de computadora es una secuencia de instrucciones u ordenes basadas en un lenguaje de programacion que una computadora interpreta para resolver un problema o una funcion especifica.​​ este dispositivo requiere programas para funcionar, por lo general, ejecutando las instrucciones del programa en un procesador central.​  el programa tiene un formato ejecutable que la computadora puede utilizar directamente para ejecutar las instrucciones. el mismo programa en su formato de codigo fuente legible para humanos, del cual se derivan los programas ejecutables (por ejemplo, compilados), le permite a un programador estudiar y desarrollar sus algoritmos. una coleccion de programas de computadora y datos relacionados se conoce como software.  generalmente, el codigo fuente lo escriben profesionales conocidos como programadores de computadora.​ este codigo se escribe en un lenguaje de programacion que sigue uno de los siguientes dos paradigmas: imperativo o declarativo, y que posteriormente puede ser convertido en un archivo ejecutable (usualmente llamado un programa ejecutable o un binario) por un compilador y mas tarde ejecutado por una unidad central de procesamiento. por otra parte, los programas de computadora se pueden ejecutar con la ayuda de un interprete, o pueden ser empotrados directamente en hardware.  de acuerdo a sus funciones, los programas informaticos se clasifican en software de sistema y software de aplicacion. en las computadoras de 2015, al hecho de ejecutar varios programas de forma simultanea y eficiente, se lo conoce como multitarea.  la programacion de computadoras es el proceso iterativo de escribir o editar codigo fuente. dicha edicion implica probar, analizar y perfeccionar, y, a veces, coordinar con otros programadores, en el caso de un programa desarrollado en conjunto. una persona que practica esta tecnica se le conoce como programador de computadoras, desarrollador de software, o codificador. el proceso, a veces a largo plazo, de programacion de computadoras normalmente se lo conoce como desarrollo de software. el termino ingenieria de software se esta convirtiendo en muy popular, ya que esta actividad es vista como una disciplina de ingenieria.  los programas de ordenador se pueden clasificar segun el paradigma del lenguaje de programacion utilizado para producirlos. dos de los principales paradigmas son imperativos y declarativos.  los programas escritos con un lenguaje imperativo especifican un algoritmo utilizando declaraciones, expresiones e informes.​ una declaracion asocia un nombre de variable a un tipo de datos. por ejemplo:  var x: integer; . una expresion produce un valor. por ejemplo:  2 + 2  produce 4. por ultimo, una declaracion puede asignar una expresion a una variable o usar el valor de una variable para alterar las estructuras de control del programa. por ejemplo: x := 2 + 2; if x = 4 then hacer_algo(); una critica de los lenguajes imperativos es el efecto secundario de una sentencia de asignacion en una clase de variables llamadas variables no locales.​  los programas escritos en un lenguaje declarativo especifican las propiedades que tienen o que deben cumplirse para la salida. no especifican detalles expresados en terminos de flujo de control de la maquina de ejecucion pero si de las relaciones matematicas entre los objetos declarados y sus propiedades. los lenguajes funcionales y logicos son dos amplias categorias de lenguajes declarativos. el principio detras de los lenguajes funcionales (como haskell) es el de no permitir efectos secundarios, lo que hace que sea mas facil para razonar sobre los programas como si se tratasen de funciones matematicas.​ el principio detras de los lenguajes logicos (como prolog) es definir el problema a ser resuelto - la meta - y dejar la solucion detallada al propio sistema prolog.​ el objetivo se define proporcionando la lista de sub-objetivos. luego, cada subobjetivo se define mas arriba, proporcionando la lista de sus sub-objetivos, etc. si la ruta de sub-objetivos no encuentra una solucion, entonces ese subobjetivo se retrocede y otra via se intenta sistematicamente.  la forma en que se crea el programa puede ser textual o visual. en un programa de lenguaje visual, los elementos en vez de ser textualmente especificados son manipulados graficamente.  un programa de computadora bajo la forma de lenguaje de programacion de computadoras legible por un humano, se lo llama codigo fuente. dicho codigo fuente se puede convertir en una imagen ejecutable por un compilador o ejecutarse inmediatamente con la ayuda de un interprete.  cualquiera de los programas compilados o interpretados pueden ser ejecutados en un proceso por lotes sin intervencion humana, pero los programas interpretados le permiten al usuario escribir comandos en una sesion interactiva. en este caso, los programas son los comandos separados, cuya ejecucion se produce secuencialmente, y por lo tanto simultaneamente. cuando se utiliza un lenguaje para dar ordenes a una aplicacion de software (como un shell de unix u otra interfaz de linea de comandos), se le llama un lenguaje de scripts.  los compiladores se utilizan para traducir el codigo fuente de un lenguaje de programacion, ya sea en codigo objeto o codigo maquina.​ el codigo objeto de objeto necesita procesamiento adicional para convertirse en codigo maquina, y el codigo maquina es el codigo nativo de la unidad central de procesamiento, listo para su ejecucion. los programas de computadora compilados se conocen comunmente como ejecutables, imagenes binarias, o simplemente como binarios —una referencia al formato de archivo binario utilizado para almacenar el codigo ejecutable—.  los programas de computadora —interpretados en un lote o una sesion interactiva— o bien se descodifican y luego ejecutados inmediatamente o se decodifican en alguna representacion intermedia eficiente para la ejecucion futura. basic, perl y python son ejemplos de programas de computadora ejecutados inmediatamente. por otra parte, los programas de computadora de java se compilan antes de tiempo y se almacena como un codigo independiente de la maquina llamado bytecode. entonces, dicho bytecode es ejecutado a peticion de un interprete llamado maquina virtual.  la principal desventaja de los interpretes es que los programas de computadora corren mas lento que cuando son compilados. la interpretacion de codigo resulta mas lenta que la ejecucion de la version compilada porque el interprete debe decodificar cada declaracion cada vez que se carga y luego realizar la accion deseada. sin embargo, el desarrollo de software puede ser mas rapido usando un interprete porque la prueba es inmediata cuando se omite el paso de la compilacion. otra desventaja de los interpretes es que debe estar presente al menos uno en la computadora durante la ejecucion del programa de computadora. por el contrario, los programas de computadora compilados no necesitan compilador presente durante la ejecucion.  no se requieren propiedades de un lenguaje de programacion si se esta compilado exclusivamente o interpretandose exclusivamente. por lo general, la clasificacion refleja el metodo mas popular de ejecucion del lenguaje. por ejemplo, basic se considera un lenguaje interpretado y c un lenguaje compilado, a pesar de la existencia de compiladores de basic e interpretes de c. algunos sistemas utilizan compilacion en tiempo de ejecucion (jit) mediante la cual las secciones de la fuente se compilan 'sobre la marcha' y se almacenan para ejecuciones posteriores.  un programa informatico en ejecucion, normalmente es tratado como algo diferente de los datos con los cuales opera. sin embargo, en algunos casos esta distincion es ambigua, especialmente cuando un programa se modifica a si mismo. el programa modificado es ejecutado secuencialmente como parte del mismo programa. en el caso de programas escritos en codigo maquina, lenguaje ensamblador, lisp, d, colol, pl/9 y prolog y javascript (la funcion eval), entre otros, es posible tener codigo que se automodifica.  tipicamente, los programas se almacenan en una memoria no volatil (por ejemplo un disco), para que luego el usuario de la computadora, directa o indirectamente, solicite su ejecucion. al momento de dicha solicitud, el programa es cargado en la memoria de acceso aleatorio o ram del equipo, bajo el control del software llamado sistema operativo, el cual puede acceder directamente al procesador. el procesador ejecuta (corre) el programa, instruccion por instruccion hasta que termina. a un programa en ejecucion se le suele llamar tambien proceso. un programa puede terminar su ejecucion en forma normal o por causa de un error, dicho error puede ser de software o de hardware.  algunos programas estan empotrados en el hardware. una computadora con arquitectura de programas almacenados requiere un programa inicial almacenado en su rom para arrancar. el proceso de arranque es para identificar e inicializar todos los aspectos del sistema, desde los registros del procesador, controladores de dispositivos hasta el contenido de la memoria ram.​ seguido del proceso de inicializacion, este programa inicial carga al sistema operativo e inicializa al contador de programa para empezar las operaciones normales. independiente de la computadora, un dispositivo de hardware podria tener firmware empotrado para el control de sus operaciones. el firmware se utiliza cuando se espera que el programa cambie en raras ocasiones o nunca, o cuando el programa no debe perderse cuando haya ausencia de energia.​  historicamente, los programas eran cargados al procesador central de forma manual mediante interruptores. una instruccion se representaba por una configuracion de estados de interruptores de abierto o cerrados. despues de establecer la configuracion, se ejecutaba un boton de ejecucion. este proceso era repetitivo. asimismo, los programas se cargaban manualmente mediante una cinta de papel o tarjetas perforadas. despues de que se cargaba el programa, se establecia la direccion de inicio mediante interruptores y se presionaba el boton de ejecucion.​  la programacion automatica es un estilo de programacion que crea codigo fuente mediante clases genericas, prototipos, plantillas, aspectos, y generadores de codigo para aumentar la productividad del programador. el codigo fuente se genera con herramientas de programacion tal como un procesador de plantilla o un ide. la forma mas simple de un generador de codigo fuente es un procesador macro, tal como el preprocesador de c, que reemplaza patrones de codigo fuente de acuerdo a reglas relativamente simples.  un motor de software da de salida codigo fuente o lenguaje de marcado que simultaneamente se vuelve la entrada de otro proceso informatico. podemos pensar como analogia un proceso manejando a otro siendo el codigo maquina quemado como combustible. los servidores de aplicaciones son motores de software que entregan aplicaciones a computadoras cliente. por ejemplo, un software para wikis es un servidor de aplicaciones que permite a los usuarios desarrollar contenido dinamico ensamblado a partir de articulos. las wikis generan html, css, java, y javascript los cuales son interpretados por un navegador web.  muchos programas pueden ejecutarse simultaneamente en la misma computadora, hecho al cual se lo conoce como multitarea, pudiendose lograr mediante mecanismos de software o de hardware. los sistemas operativos modernos pueden ejecutar varios programas a traves del planificador de procesos — un mecanismo de software para conmutar con frecuencia la cantidad de procesos del procesador de modo que los usuarios puedan interactuar con cada programa mientras estos estan corriendo.​ tambien se puede lograr la multitarea por medio del hardware; las computadoras modernas que usan varios procesadores o procesadores con varios nucleos pueden correr muchos programas a la vez.​  los programas se pueden categorizar aplicando criterios funcionales. estas categorias funcionales son software de sistema y software de aplicacion. el software de sistema incluye al sistema operativo el cual acopla el hardware con el software de aplicacion.​ el proposito del sistema operativo es proveer un ambiente en el cual el software de aplicacion se ejecuta de una manera conveniente y eficiente.​ ademas del sistema operativo, el software de sistema incluye programas utilitarios que ayudan a manejar y configurar la computadora. si un programa no es software de sistema entonces es software de aplicacion. el middleware tambien es un software de aplicacion que acopla el software de sistema con la interfaz de usuario. tambien son software de aplicacion los programas utilitarios que ayudan a los usuarios a resolver problemas de aplicaciones, como por ejemplo la necesidad de ordenamiento. ",
        "snippet": "Un programa informático o programa de computadora es una secuencia de instrucciones u órdenes basadas en un lenguaje de programación que una computadora interpreta para resolver un problema o una función especifica.[1]​[2]​ Este dispositivo requiere programas para funcionar, por lo general, ejecutando las instrucciones del programa en un procesador central.[3]​",
        "enlaces_salientes": [
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Software",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Unidad_central_de_procesamiento",
            "/wiki/Ejecutable",
            "/wiki/Compilador",
            "/wiki/Algoritmo",
            "/wiki/Dato",
            "/wiki/Software",
            "/wiki/Programador",
            "/wiki/Paradigma",
            "/wiki/Archivo_ejecutable",
            "/wiki/Compilador",
            "/wiki/Unidad_central_de_procesamiento",
            "/wiki/Firmware",
            "/wiki/Hardware",
            "/wiki/Software_de_sistema",
            "/wiki/Aplicaci%C3%B3n_inform%C3%A1tica",
            "/wiki/Multitarea",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Hola_mundo",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Hola_mundo",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Hola_mundo",
            "/wiki/C_Sharp",
            "/wiki/Programaci%C3%B3n",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Programador",
            "/wiki/Desarrollo_de_software",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Paradigma_de_programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Algoritmo",
            "/wiki/Estructuras_de_control",
            "/wiki/Efecto_secundario_(inform%C3%A1tica)",
            "/wiki/Lenguajes_funcionales",
            "/wiki/Haskell",
            "/wiki/Efecto_secundario_(inform%C3%A1tica)",
            "/wiki/Prolog",
            "/wiki/Vuelta_atr%C3%A1s",
            "/wiki/Programaci%C3%B3n_visual",
            "/wiki/Legibilidad_humana",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Compilador",
            "/wiki/Int%C3%A9rprete_(inform%C3%A1tica)",
            "/wiki/Proceso_por_lotes",
            "/wiki/Sesi%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Shell_de_Unix",
            "/wiki/Interfaz_de_l%C3%ADnea_de_comandos",
            "/wiki/Scripts",
            "/wiki/C%C3%B3digo_objeto",
            "/wiki/C%C3%B3digo_m%C3%A1quina",
            "/wiki/Microc%C3%B3digo",
            "/wiki/Archivo_binario",
            "/wiki/Formato_de_archivo",
            "/wiki/BASIC",
            "/wiki/Perl",
            "/wiki/Python",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Bytecode",
            "/wiki/M%C3%A1quina_virtual",
            "/wiki/Analizador_sint%C3%A1ctico",
            "/wiki/Compilaci%C3%B3n_en_tiempo_de_ejecuci%C3%B3n",
            "/wiki/Dato",
            "/wiki/C%C3%B3digo_m%C3%A1quina",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Lisp",
            "/wiki/D_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Prolog",
            "/wiki/JavaScript",
            "/wiki/Memoria_no_vol%C3%A1til",
            "/wiki/Computadora",
            "/wiki/Memoria_de_acceso_aleatorio",
            "/wiki/Software",
            "/wiki/Sistema_operativo",
            "/wiki/Microprocesador",
            "/wiki/Proceso_(inform%C3%A1tica)",
            "/wiki/Microcontrolador",
            "/wiki/Memoria_USB",
            "/wiki/Firmware",
            "/wiki/Hardware",
            "/wiki/Computadora",
            "/wiki/Arquitectura_de_von_Neumann",
            "/wiki/Memoria_de_solo_lectura",
            "/wiki/Arranque_(inform%C3%A1tica)",
            "/wiki/Registro_(hardware)",
            "/wiki/Controlador_de_dispositivo",
            "/wiki/Memoria_RAM",
            "/wiki/Sistema_operativo",
            "/wiki/Contador_de_programa",
            "/wiki/Perif%C3%A9rico_(inform%C3%A1tica)",
            "/wiki/Firmware",
            "/wiki/Data_General_Nova",
            "/wiki/Cinta_de_papel",
            "/wiki/Tarjeta_perforada",
            "/wiki/Programaci%C3%B3n_autom%C3%A1tica",
            "/wiki/Programaci%C3%B3n",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Clase_(inform%C3%A1tica)",
            "/wiki/Programaci%C3%B3n_gen%C3%A9rica",
            "/wiki/Programaci%C3%B3n_basada_en_prototipos",
            "/wiki/Generaci%C3%B3n_de_c%C3%B3digo",
            "/wiki/Programador",
            "/wiki/Ambiente_de_desarrollo_integrado",
            "/wiki/Macro",
            "/wiki/Preprocesador_de_C",
            "/wiki/Lenguaje_de_marcado",
            "/wiki/Proceso_(inform%C3%A1tica)",
            "/wiki/Servidor_de_aplicaciones",
            "/wiki/Cliente_(inform%C3%A1tica)",
            "/wiki/Software_para_wikis",
            "/wiki/Contenido_din%C3%A1mico",
            "/wiki/Art%C3%ADculo_(publicaci%C3%B3n)",
            "/wiki/HTML",
            "/wiki/Hojas_de_estilo_en_cascada",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Javascript",
            "/wiki/Int%C3%A9rprete_(inform%C3%A1tica)",
            "/wiki/Navegador_web",
            "/wiki/Proceso_(inform%C3%A1tica)",
            "/wiki/Multiprocesamiento",
            "/wiki/Multitarea",
            "/wiki/Planificaci%C3%B3n",
            "/wiki/Cambio_de_contexto",
            "/wiki/Tiempo_compartido_(inform%C3%A1tica)",
            "/wiki/Software_de_sistema",
            "/wiki/Software_de_aplicaci%C3%B3n",
            "/wiki/Sistema_operativo",
            "/wiki/Hardware",
            "/wiki/Programa_utilitario",
            "/wiki/Middleware",
            "/wiki/Interfaz_de_usuario",
            "/wiki/Algoritmo",
            "/wiki/Aplicaci%C3%B3n_inform%C3%A1tica",
            "/wiki/Virus_inform%C3%A1tico",
            "/wiki/Estructura_de_datos",
            "/wiki/Inteligencia_artificial",
            "/wiki/Sistema_multi-agente",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/1997",
            "/wiki/ISBN",
            "/wiki/1997",
            "/wiki/ISBN",
            "/wiki/1997",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/National_Archives_and_Records_Administration",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Red_neuronal_artificial",
        "titulo": "Red neuronal artificial",
        "contenido": "las redes neuronales artificiales (tambien conocidas como sistemas conexionistas) son un modelo computacional evolucionado a partir de diversas aportaciones cientificas que estan registradas en la historia.​ consiste en un conjunto de unidades, llamadas neuronas artificiales, conectadas entre si para transmitirse señales. la informacion de entrada atraviesa la red neuronal (donde se somete a diversas operaciones) produciendo unos valores de salida.  cada neurona esta conectada con otras a traves de unos enlaces. en estos enlaces el valor de salida de la neurona anterior es multiplicado por un valor de peso. estos pesos en los enlaces pueden incrementar o inhibir el estado de activacion de las neuronas adyacentes. del mismo modo, a la salida de la neurona, puede existir una funcion limitadora o umbral, que modifica el valor resultado o impone un limite que no se debe sobrepasar antes de propagarse a otra neurona. esta funcion se conoce como funcion de activacion.  estos sistemas aprenden y se forman a si mismos, en lugar de ser programados de forma explicita, y sobresalen en areas donde la deteccion de soluciones o caracteristicas es dificil de expresar con la programacion convencional. para realizar este aprendizaje automatico, normalmente, se intenta minimizar una funcion de perdida que evalua la red en su total. los valores de los pesos de las neuronas se van actualizando buscando reducir el valor de la funcion de perdida. este proceso se realiza mediante la propagacion hacia atras.  el objetivo de la red neuronal es resolver los problemas de la misma manera que el cerebro humano, aunque las redes neuronales son mas abstractas. las redes neuronales actuales suelen contener desde unos miles a unos pocos millones de unidades neuronales.  nuevas investigaciones sobre el cerebro a menudo estimulan la creacion de nuevos patrones en las redes neuronales. un nuevo enfoque esta utilizando conexiones que se extienden mucho mas alla y capas de procesamiento de enlace en lugar de estar siempre localizado en las neuronas adyacentes. otra investigacion esta estudiando los diferentes tipos de señal en el tiempo que los axones se propagan, como el aprendizaje profundo, interpola una mayor complejidad que un conjunto de variables booleanas que son simplemente encendido o apagado.  las redes neuronales se han utilizado para resolver una amplia variedad de tareas, como la vision por computador y el reconocimiento de voz, que son dificiles de resolver usando la ordinaria programacion basado en reglas. historicamente, el uso de modelos de redes neuronales marco un cambio de direccion a finales de los años ochenta de alto nivel, que se caracteriza por sistemas expertos con conocimiento incorporado en si-entonces las reglas, a bajo nivel de aprendizaje automatico, caracterizado por el conocimiento incorporado en los parametros de un modelo cognitivo con algun sistema dinamico.  warren mcculloch y walter pitts​ (1943) crearon un modelo informatico para redes neuronales, que se llama logica umbral, que se basa en las matematicas y los algoritmos. este modelo señalo el camino para que la investigacion de redes neuronales se divida en dos enfoques distintos. un enfoque se centro en los procesos biologicos en el cerebro y el otro se centro en la aplicacion de redes neuronales para la inteligencia artificial.  a finales de la decada de 1940 el psicologo donald hebb​​ creo una hipotesis de aprendizaje basado en el mecanismo de plasticidad neuronal que ahora se conoce como aprendizaje de hebb. aprendizaje de hebb se considera que es un \"tipico\" de aprendizaje no supervisado y sus variantes posteriores fueron los primeros modelos de la potenciacion a largo plazo. los investigadores empezaron a aplicar estas ideas a los modelos computacionales en 1948 con la sugerencia de turing, que el cortex humano infantil es lo que llamaba \"maquina desorganizada\" (tambien conocido como \"maquina turing tipo b\").​​  farley y wesley a. clark​ (1954) al principio utilizaron maquinas computacionales, que entonces se llamaban \"calculadoras\", para simular una red de hebb en el mit. otras simulaciones de redes neuronales por computadora han sido creadas por rochester, holland, habit y duda (1956).​  frank rosenblatt​​ (1958) creo el perceptron, un algoritmo de reconocimiento de patrones basado en una red de aprendizaje de computadora de dos capas, que utilizaba adicion y sustraccion simples. con la notacion matematica, rosenblatt tambien describe circuiteria que no esta en el perceptron basico, tal como el circuito de o-exclusiva, un circuito que no se pudo procesar por redes neuronales antes de la creacion del algoritmo de propagacion hacia atras por paul werbos (1975).​  en 1959, un modelo biologico propuesto por dos laureados de los premios nobel, david h. hubel y torsten wiesel, estaba basado en su descubrimiento de dos tipos de celulas en la corteza visual primaria: celulas simples y celulas complejas.​  el primer reporte sobre redes funcionales multicapas fue publicado en 1965 por ivakhnenko y lapa, y se conoce como el metodo de agrupamiento para el manejo de datos.​​​  la investigacion de redes neuronales se estanco despues de la publicacion de la investigacion de aprendizaje automatico por marvin minsky y seymour papert (1969),​ que descubrio dos cuestiones fundamentales con las maquinas computacionales que procesan las redes neuronales. la primera fue que los perceptrones basicos eran incapaces de procesar el circuito de o-exclusivo. la segunda cuestion importante era que los ordenadores no tenian suficiente poder de procesamiento para manejar eficazmente el gran tiempo de ejecucion requerido por las grandes redes neuronales.  un avance clave posterior fue el algoritmo de propagacion hacia atras que resuelve eficazmente el problema de o-exclusivo, y en general el problema de la formacion rapida de redes neuronales de multiples capas (werbos 1975).  el proceso de propagacion hacia atras utiliza la diferencia entre el resultado producido y el resultado deseado para cambiar los \"pesos\" de las conexiones entre las neuronas artificiales.​  a mediados de la decada de 1980, el procesamiento distribuido en paralelo se hizo popular con el nombre conexionismo. el libro de  david e. rumelhart y james mcclelland (1986) proporcionan una exposicion completa de la utilizacion de conexionismo en los ordenadores para simular procesos neuronales.​  las redes neuronales, tal como se utilizan en la inteligencia artificial, han sido consideradas tradicionalmente como modelos simplificados de procesamiento neuronal en el cerebro, a pesar de que la relacion entre este modelo y la arquitectura biologica del cerebro se debate; no esta claro en que medida las redes neuronales artificiales reflejan el funcionamiento cerebral.  maquinas de soporte vectorial y otros metodos mucho mas simples, tales como los clasificadores lineales, alcanzaron gradualmente popularidad en el aprendizaje automatico.  no obstante, el uso de redes neuronales ha cambiado algunos campos, tales como la prediccion de las estructuras de las proteinas.​​  en 1992,fue introducido el max-pooling (una forma de submuestreo, en la que se divide los datos en grupos de tamaños iguales, que no tienen elementos en comun, y se transmite solamente el valor maximo de cada grupo)para ayudar con el reconocimiento de objetos tri-dimensionales.​ ​ ​  en 2010, el uso de max-pooling en la formacion por propagacion hacia atras fue acelerado por los gpus, y se demostro que ofrece mejor rendimiento que otros tipos de agrupamiento.​  el problema del desvanecimiento del gradiente afecta las redes neuronales prealimentadas de multiples capas, que usan la propagacion hacia atras, y tambien los redes neuronales recurrentes (rnns).​​ aunque los errores se propagan de una capa a otra, disminuyen exponencialmente con el numero de capas, y eso impide el ajuste hacia atras de los pesos de las neuronas basado en esos errores. las redes profundas se ven particularmente afectadas.  para vencer este problema, schmidhuber adoptaba una jerarquia multicapa de redes (1992) preformados, una capa a la vez, por aprendizaje no supervisado, y refinado por propagacion hacia atras.​ behnke (2003) contaba solamente con el signo del gradiente (rprop)​ tratandose de problemas tales como la reconstruccion de imagenes y la localizacion de caras.  como retos anteriores en redes neuronales profundas de capacitacion se resolvieron con metodos como preformacion no supervisada y potencia de calculo incrementada a traves del uso de las gpu y la computacion distribuida, las redes neuronales se desplegaron de nuevo a gran escala, sobre todo en problemas de procesamiento de imagenes y de reconocimiento visual. esto se conocio como \"aprendizaje profundo\", aunque el aprendizaje profundo no es estrictamente sinonimo de redes neuronales profundas.  se crearon en cmos dispositivos de computo para la simulacion biofisica al igual que para la computo neuromorfico. nanodispositivos​ para analisis de componentes principales de escala muy grande y convolucion pueden crear una clase nueva de computo neuronal, porque son fundamentalmente analogicos en vez de digitales (aunque las primeras implementaciones puedan utilizar dispositivos digitales).​ ciresan y sus colegos (2010)​ en el grupo de schmidhuber mostraron que, a pesar del problema del desvanecimiento del gradiente, los gpus hacen factible la propagacion hacia atras para las redes neuronales prealimentadas con multiples capas.  se han creado dispositivos computacionales  en el cmos, tanto para la simulacion biofisica como para computacion neuromorfica. los esfuerzos mas recientes se muestran prometedores para la creacion de nanodispositivos​  para analisis de componentes principales de gran escala.  si tiene exito, se crearia una nueva clase de computacion neuronal, ya que depende de aprendizaje automatico en lugar de la programacion y porque es fundamentalmente analogico en lugar de digital a pesar de que las primeras instancias pueden ser de hecho con los dispositivos digitales cmos.​  entre 2009 y 2012, las redes neuronales recurrentes y redes neuronales profundas feedforward desarrollados en el grupo de investigacion de jurgen schmidhuber en el laboratorio suizo de ia idsia han ganado ocho concursos internacionales de reconocimiento de patrones y aprendizaje automatico. por ejemplo, la memoria bidireccional y multidimensional de largo a corto plazo (lstm) de alex graves ha ganado tres competiciones en el reconocimiento de escritura conectada en conferencia internacional sobre analisis de documentos y reconocimiento (icdar) del 2009, sin ningun conocimiento previo acerca de los tres idiomas diferentes que se pueden aprender.  implementaciones de este metodo basadas en unidades de procesamiento grafico rapidas, hechos por dan ciresan y sus colegas de idsia han ganado varios concursos de reconocimiento de patrones, incluyendo la competicion de reconocimiento de señales de trafico del 2011,​ el desafio de isbi 2012 de segmentacion de estructuras neuronales en series de imagenes de microscopia electronica,​ y otros. sus redes neuronales tambien fueron las primeras reconocedoras artificiales de patrones en lograr un rendimiento superior al humano en los puntos de referencia importantes, tales como el reconocimiento de señales de trafico (ijcnn 2012) o el problema de clasificacion de digitos escritos a mano.  arquitecturas profundas altamente no lineales similares a las del 1980 neocognitron por kunihiko fukushima y la \"arquitectura estandar de la vision\", inspirados en las celulas simples y complejas identificadas por david h. hubel y torsten wiesel en la corteza visual, pueden tambien ser preformados por metodos no supervisados en el laboratorio de la universidad de toronto. un equipo de este laboratorio gano un concurso en 2012 patrocinado por merck para el diseño de software para ayudar a encontrar moleculas que podrian conducir a nuevos medicamentos.  los modelos de redes neuronales en la inteligencia artificial se refieren generalmente a las redes neuronales artificiales (rna); estos son modelos matematicos esencialmente simples que definen una funcion f:x→y o una distribucion mas x o ambos x e y. pero a veces los modelos tambien estan intimamente asociadas con un algoritmo de aprendizaje en particular o regla de aprendizaje. un uso comun de la frase \"modelo ann\" es en realidad la definicion de una clase de tales funciones (donde los miembros de la clase se obtiene variando parametros, los pesos de conexion, o especificos de la arquitectura, tales como el numero de neuronas o su conectividad).  la palabra red en el termino \"red neuronal artificial\" se refiere a las interconexiones entre las neuronas en las diferentes capas de cada sistema. un sistema ejemplar tiene tres capas. la primera capa tiene neuronas de entrada que envian datos a traves de las sinapsis a la segunda capa de neuronas, y luego a traves de mas sinapsis a la tercera capa de neuronas de salida. los sistemas mas complejos tendran mas capas, algunos aumentando las de entrada y de salida de neuronas. las sinapsis almacenan parametros llamados \"pesos\" que manipulan los datos en los calculos.  un rna se define tipicamente por tres tipos de parametros:  1.  el patron de interconexion entre las diferentes capas de neuronas  2.  el proceso de aprendizaje para la actualizacion de los pesos de las interconexiones  3.  la funcion de activacion que convierte las entradas ponderadas de una neurona a su activacion a la salida.  matematicamente, la funcion de red de una neurona f ( x ) {2}f(x)\\\\\\end{alignedat}}} se define como una composicion de otras funciones g i ( x ) {2}(x)\\\\\\end{alignedat}}} . este se representa como una estructura de red, con flechas que representan las dependencias entre variables. un tipo ampliamente utilizado de la composicion es la suma ponderada no lineal , donde f ( x ) = k ( ∑ i w i g i ( x ) ) {2}f(x)&=k&\\textstyle \\sum _{i}\\displaystyle &w_{i}&g_{i}(x))\\\\\\end{alignedat}}} , donde k (denominado comunmente como la funcion de activacion​) es una funcion predefinida, como la tangente hiperbolica o funcion sigmoide . la caracteristica importante de la funcion de activacion es que proporciona una transicion suave como valores de entrada de cambio, es decir, un pequeño cambio en la entrada produce un pequeño cambio en la produccion. sera conveniente para la siguiente para referirse a una coleccion de funciones g i } simplemente como un vector g = ( g i , g 2 , . . . , g n ) ,g_{2},...,g_{n})} .  esta cifra representa una descomposicion de tales f , con las dependencias entre las variables indicadas por las flechas. estos pueden ser interpretados de dos maneras.  la primera vista es la vista funcional: la entrada x se transforma en un vector de 3 dimensiones h , que se transforma a continuacion en un vector de 2 dimensiones g , que es finalmente transformado en f . este punto de vista se encuentra mas comunmente en el contexto de la optimizacion.  el segundo punto de vista es la vista probabilistico: la variable aleatoria f = f ( g ) depende de la variable aleatoria g = g ( h ) , que depende de h = h ( x ) , que depende de la variable aleatoria x . este punto de vista se encuentra mas comunmente en el contexto de modelos graficos .  los dos puntos de vista son en gran medida equivalente. en cualquier caso, para esta arquitectura de red en particular, los componentes de las capas individuales son independientes entre si (por ejemplo, los componentes de g son independientes entre si, dada su aportacion h ). esto permite, naturalmente, un grado de paralelismo en la ejecucion.  las redes como la anterior se llaman comunmente alimentacion hacia delante , porque su grafica es un grafo dirigido aciclico . las redes con ciclos se denominan comunmente recurrentes . tales redes se representan comunmente de la manera mostrada en la parte superior de la figura, donde f se muestra como dependiente sobre si misma. sin embargo, no se muestra una dependencia temporal implicita.  lo que ha atraido el mayor interes en las redes neuronales es la posibilidad de aprendizaje. dada una determinada tarea a resolver, y una clase de funciones f , el aprendizaje consiste en utilizar un conjunto de observaciones para encontrar f ∗ ∈ f \\in f} la cual resuelve la tarea de alguna forma optima.  esto implica la definicion de una funcion de coste c : f → r } tal que, para la solucion optima f ∗ , c ( f ∗ ) ≤ c ( f ) ∀ f ∈ f ,c(f^{*})\\leq c(f)\\forall f\\in f} . es decir, ninguna solucion tiene un costo menor que el costo de la solucion optima.  la funcion de coste c es un concepto importante en el aprendizaje, ya que representa lo lejos que una solucion particular se encuentra de la solucion optima al problema a resolver. los algoritmos de aprendizaje buscan a traves del espacio de soluciones para encontrar una funcion que tiene el menor costo posible.  para aplicaciones en las que la solucion es dependiente de algunos datos, el costo debe ser necesariamente una funcion de las observaciones, de lo contrario no estariamos modelando todo lo relacionado con los datos. con frecuencia se define como una estadistica a la que se pueden realizar solo aproximaciones. como un simple ejemplo, considere el problema de encontrar el modelo f , lo que reduce al minimo c = e [ ( f ( x ) − y ) 2 ] ]} , para pares de datos ( x , y ) extraida de alguna distribucion d . en situaciones practicas solo tendriamos n muestras de d y, por tanto, para el ejemplo anterior, tendriamos solamente minimizar c = i n ∑ i = 1 n ( f ( x i ) − y i ) 2 {n}}\\textstyle \\sum _{i=1}^{n}\\displaystyle (f(x_{i})-y_{i})^{2}} . por lo tanto, el coste se reduce al minimo a traves de una muestra de los datos en lugar de toda la distribucion de la generacion de los datos.  cuando n → ∞ alguna forma de aprendizaje automatico en linea debe ser utilizada, donde el costo se reduce al minimo parcialmente como se ve cada nuevo ejemplo. mientras que la maquina de aprendizaje en linea se utiliza a menudo cuando d se fija, es mas util en el caso en el que la distribucion cambia lentamente con el tiempo. en los metodos de redes neuronales, alguna forma de aprendizaje en linea de la maquina se utiliza con frecuencia para conjuntos de datos finitos.  si bien es posible definir alguna funcion de coste, con frecuencia un coste particular, se utilizara, ya sea porque tiene propiedades deseables (tales como convexidad) o porque surge de forma natural a partir de una formulacion particular del problema (por ejemplo, en una formulacion probabilistica la probabilidad posterior del modelo puede ser utilizada como un costo inverso). en ultima instancia, la funcion de coste dependera de la tarea deseada.  hay tres grandes paradigmas de aprendizaje, cada uno correspondiente a una tarea de aprendizaje abstracto en particular. estos son el aprendizaje supervisado ,el  aprendizaje no supervisado y el aprendizaje por refuerzo.  en el aprendizaje supervisado, se nos da una serie de ejemplos de pares ( x , y ) , x ∈ x , y ∈ y y el objetivo es encontrar una funcion f : x → y en la clase permitido de funciones que corresponden con los ejemplos. en otras palabras, deseamos inferir el mapeo derivado de los datos; la funcion de coste esta relacionado con la falta de coincidencia entre nuestro mapeo y los datos, y contiene implicitamente el conocimiento previo sobre el dominio del problema.​  un coste de uso comun es el error cuadratico medio, que trata de minimizar el error cuadratico medio entre las salidas de la red, f ( x ) y el valor objetivo y sobre todos los pares ejemplares. cuando uno trata de minimizar este coste utilizando descenso de gradiente para la clase de las redes neuronales llamadas perceptrones multicapas (mlp), se obtiene el comun y bien conocido algoritmo de propagacion hacia atras para la formacion de redes neuronales.  tareas que caen dentro del paradigma de aprendizaje supervisado son el reconocimiento de patrones (tambien conocido como clasificacion) y regresion (tambien conocido como aproximacion de funcion). el paradigma de aprendizaje supervisado es aplicable tambien a los datos secuenciales (por ejemplo, reconocimiento del habla, del manuscrito, y de gestos). esto se puede considerar como una forma de aprendizaje con un \"maestro\", en la forma de una funcion que proporciona informacion continua sobre la calidad de las soluciones obtenidas hasta el momento.  en el aprendizaje no supervisado, algunos datos x se da y la funcion de coste que se reduce al minimo, que puede ser cualquier funcion de los datos x y la salida de la red, f .  la funcion de coste depende de la tarea (lo que estamos tratando de modelar) y nuestros a priori suposiciones implicitas (las propiedades de nuestro modelo, sus parametros y las variables observadas).  como un ejemplo trivial, considere el modelo f ( x ) = a donde a es una constante y el costo c = e [ ( x − f ( x ) ) 2 ] ]} . minimizar este coste nos dara un valor de a que es igual a la media de los datos. la funcion de coste puede ser mucho mas complicado. su forma depende de la aplicacion: por ejemplo, en la compresion de que podria estar relacionado con la informacion mutua entre x y f ( x ) , mientras que en la modelizacion estadistica, que podria estar relacionado con la probabilidad posterior del modelo dados los datos (tenga en cuenta que en estos dos ejemplos esas cantidades se maximizaria en lugar de reducirse al minimo).  tareas que caen dentro del paradigma de aprendizaje no supervisado estan en generales de estimacion de problemas; las aplicaciones incluyen el agrupamiento, la estimacion de distribuciones estadisticas, la compresion de datos y el filtrado bayesiano de spam.  en el aprendizaje por refuerzo, los datos x por lo general no se dan, pero generada por la interaccion de un agente con el medio ambiente. en cada punto en el tiempo t , el agente realiza una accion y t } y el medio ambiente genera una observacion x t } y un costo instantaneo c t } , de acuerdo con algunas dinamicas (por lo general desconocidos). el objetivo es descubrir una politica para la seleccion de las acciones que minimiza una cierta medida de un costo a largo plazo, por ejemplo, el coste acumulativo esperado. la dinamica del medio ambiente y el coste a largo plazo para cada politica general son desconocidos, pero pueden ser estimados.  mas formalmente el medio ambiente se modela como un proceso de decision de markov (mdp) con los estados s 1 , . . . . , s n ∈ s \\in s} y acciones a 1 , . . . . . , a m ∈ a \\in a} con las siguientes distribuciones de probabilidad: la distribucion de costos instantanea p ( c t | s t ) |s_{t})} ,la distribucion de observacion p ( x t | s t ) |s_{t})} y la transicion p ( s t + 1 | s t a t ) +1|s_{t}a_{t})} mientras que una politica se define como la distribucion condicional sobre las acciones dadas las observaciones. tomados en conjunto, los dos entonces definen una cadena de markov (mc). el objetivo es descubrir la politica (es decir, el mc) que minimice el costo.  rnas se utilizan con frecuencia en el aprendizaje de refuerzo como parte del algoritmo general.​​ la programacion dinamica se ha unido a las rna (dando la programacion neurodinamica) por bertsekas y tsitsiklis​ y se aplico problemas no lineales a la multi-dimensionales, tales como los implicados en enrutamiento de vehiculos , gestion de los recursos naturales​​ o la medicina​ debido a la capacidad de rnas para mitigar las perdidas de precision incluso cuando la reduccion de la densidad de la red de discretizacion para aproximar numericamente la solucion de los problemas de control originales.  tareas que caen dentro del paradigma de aprendizaje por refuerzo son problemas de control, juegos y otras secuenciales tareas.  finalmente las rnas tambien se pueden clasificar segun sean capaces de procesar informacion de distinto tipo en:  la formacion de un modelo de red neuronal en esencia significa seleccionar un modelo de la serie de modelos permitidos (o, en un bayesiano marco, la determinacion de una distribucion en el conjunto de modelos permitidos) que minimiza el criterio de costo. hay numerosos algoritmos disponibles para la formacion de los modelos de redes neuronales; la mayoria de ellos puede ser vista como una aplicacion directa de la teoria de optimizacion y la estimacion estadistica.  la mayoria de los algoritmos utilizados en las redes neuronales artificiales de formacion emplean alguna forma de descenso de gradiente, utilizando propagacion hacia atras para calcular los gradientes reales. esto se hace simplemente tomando la derivada de la funcion de coste con respecto a los parametros de la red y a continuacion, cambiando los parametros en una direccion relacionada al gradiente. los algoritmos de formacion de propagacion hacia atras generalmente se clasifican en tres categorias:  descenso del gradiente (con tasa variable de aprendizaje y momentum, retropropagacion elastica (rprop));  metodos evolutivos,​ de programacion de la expresion genica,​ de recocido simulado,​ de esperanza-maximizacion, los metodos no parametricos y la optimizacion por enjambre de particulas​ son algunos otros metodos para la formacion de redes neuronales.  este es un metodo de aprendizaje especificamente desegnado para redes neuronales controladores de articulacion (cmac por sus siglas en ingles) de modelo cerebelosa.  en 2004, un algoritmo recursivo de minimos cuadrados estaba introducido para formar en linea redes neuronales cmac.​ este algoritmo puede convergir en un solo paso, y actualizar todos los pesos en un solo paso con cualquier dato nuevo de entrada.  al principio, este algoritmo tenia complejidad computacional de o(n3).  basado en factorizacion qr, este algoritmo recursivo de aprendizaje habia sido simplificado para hacerlo o(n).​  tal vez la mayor ventaja de las rna es su capacidad de ser utilizado como un mecanismo de funcion de aproximacion arbitraria que \"aprende\" a partir de datos observados. sin embargo, su uso no es tan sencillo, y una relativamente buena comprension de la teoria subyacente es esencial.  con la aplicacion correcta, las rna pueden ser utilizadas de forma natural en el aprendizaje online y aplicaciones de grandes conjuntos de datos. su aplicacion sencilla y la existencia de dependencias en su mayoria locales expuestos en la estructura permiten implementaciones rapidas y paralelas en el hardware.  rna las hacen bastante apropiadas para aplicaciones en las que no se dispone a priori de un modelo identificable que pueda ser programado, pero se dispone de un conjunto basico de ejemplos de entrada (previamente clasificados o no). asimismo, son altamente robustas tanto al ruido como a la disfuncion de elementos concretos y son facilmente paralelizables.  esto incluye problemas de clasificacion y reconocimiento de patrones de voz, imagenes, señales, etc. asimismo se han utilizado para encontrar patrones de fraude economico, hacer predicciones en el mercado financiero, hacer predicciones de tiempo atmosferico, etc.  tambien se pueden utilizar cuando no existen modelos matematicos precisos o algoritmos con complejidad razonable, por ejemplo la red de kohonen ha sido aplicada con un exito mas que razonable al clasico problema del viajante (un problema para el que no se conoce solucion algoritmica de complejidad polinomica).  otro tipo especial de redes neuronales artificiales se ha aplicado en conjuncion con los algoritmos geneticos (ag) para crear controladores para robots. la disciplina que trata la evolucion de redes neuronales mediante algoritmos geneticos se denomina robotica evolutiva. en este tipo de aplicacion el genoma del ag lo constituyen los parametros de la red (topologia, algoritmo de aprendizaje, funciones de activacion, etc.) y la adecuacion de la red viene dada por la adecuacion del comportamiento exhibido por el robot controlado (normalmente una simulacion de dicho comportamiento).  las tareas se aplican a las redes neuronales artificiales tienden a caer dentro de las siguientes categorias generales:  las areas de aplicacion incluyen la identificacion de sistemas y el control (control del vehiculo, prediccion de trayectorias,​ el control de procesos, manejo de recursos naturales), la quimica cuantica, juegos y la toma de decisiones (backgammon, ajedrez, poquer ), el reconocimiento de patrones (sistemas radar, reconocimiento facial, clasificacion de señales,​ reconocimiento de objetos y mas), de reconocimiento de secuencia (gesto, voz, reconocimiento de texto escrito a mano), diagnostico medico , aplicaciones economico-financieras (por ejemplo, sistemas automatizados para el comercio en varios sectores de actividad), mineria de datos (o descubrimiento de conocimiento en bases de datos, \"kdd\"), la visualizacion, traduccion automatica, diferenciando entre informes deseados y no deseados en redes sociales,​ prevencion de spam (correo basura) de correo electronico.  las redes neuronales artificiales se han utilizado tambien para el diagnostico de varios tipos de cancer. un sistema de deteccion de cancer de pulmon hibrido basado ann llamado hlnd mejora la precision del diagnostico y la velocidad de la radiologia cancer de pulmon. estas redes tambien se han utilizado para diagnosticar el cancer de prostata. los diagnosticos se pueden utilizar para hacer modelos especificos tomados de un gran grupo de pacientes en comparacion con la informacion de un paciente dado. los modelos no dependen de suposiciones acerca de las correlaciones de diferentes variables. el cancer color rectal tambien se ha previsto el uso de las redes neuronales. las redes neuronales podrian predecir el resultado de un paciente con cancer color rectal con mas precision que los metodos clinicos actuales. despues de la formacion, las redes podrian predecir multiples resultados de los pacientes de instituciones relacionadas.  la neurociencia teorica y computacional son el ambito en que se trata del analisis teorico y el modelado computacional de sistemas neuronales biologicos. dado que los sistemas neurales estan intimamente relacionados con los procesos cognitivos y de comportamiento, el campo esta muy relacionado con el modelado cognitivo y conductual.  el objetivo del campo es la creacion de modelos de sistemas neuronales biologicas con el fin de comprender como funcionan los sistemas biologicos. para ganar este entendimiento, los neurologos se esfuerzan por hacer un vinculo entre los procesos biologicos observados (datos), biologicamente plausibles mecanismos para el procesamiento neuronal y aprendizaje ( redes neuronales biologicas modelos) y la teoria (la teoria del aprendizaje estadistico y la teoria de la informacion).  tipos de modelos  muchos modelos se utilizan en el campo, que se define en diferentes niveles de abstraccion y el modelado de diferentes aspectos de los sistemas neurales. se extienden desde modelos del comportamiento a corto plazo de las neuronas individuales, tras los modelos del surgimiento de la dinamica de los circuitos neuronales de la interaccion entre las neuronas individuales hasta, finalmente, los modelos del surgimiento del comportamiento de los modulos neuronales abstractos que representan subsistemas completas. estos incluyen modelos de plasticidad de largo y corto plazo, y de los sistemas neuronales y sus relaciones con el aprendizaje y la memoria de la neurona individual a nivel del sistema.  las redes con memoria  la integracion de los componentes de memoria externa con redes neuronales artificiales tiene una larga historia que se remonta a las primeras investigaciones en las representaciones distribuidas y mapas de auto-organizacion . por ejemplo, en memoria distribuida dispersa los patrones codificados por las redes neuronales se utilizan como direcciones de memoria para la memoria de contenido direccionable, con \"neuronas\" que sirven esencialmente como direccion codificadores y decodificadores .  mas recientemente aprendizaje profundo ha demostrado ser util en hashing semantica , donde un profundo modelo grafico de los vectores de palabra de recuento de se obtiene a partir de un gran conjunto de documentos. los documentos se asignan a las direcciones de memoria de tal manera que los documentos semanticamente similares se encuentran en direcciones cercanas. documentos similares a un documento de consulta a continuacion, se pueden encontrar simplemente accediendo a todas las direcciones que difieren por solo unos pocos bits de la direccion del documento de consulta.  redes de memoria es otra extension de las redes neuronales que incorporan la memoria a largo plazo que fue desarrollado por facebook investigacion.​ la memoria a largo plazo puede ser leido y escrito para, con el objetivo de utilizarlo para la prediccion. estos modelos se han aplicado en el contexto de la busqueda de respuestas (qa), donde la memoria a largo plazo que de hecho actua como un (dinamico) base de conocimientos, y la salida es una respuesta textual.  maquinas de turing neuronales desarrollados por google deepmind permiten ampliar las capacidades de las redes neuronales profundas mediante el acoplamiento a los recursos de memoria externos, que pueden interactuar con los procesos atencionales. el sistema combinado es analogo a una maquina de turing pero es diferenciable de extremo a extremo, lo que le permite ser formado de manera eficiente con descenso del gradiente. los resultados preliminares demuestran que las maquinas de turing neuronales puede deducir algoritmos simples, tales como copiar, clasificar, y recuerdo asociativo a partir de ejemplos de entrada y salida.  computadoras neuronales diferenciables (dnc) son una extension de las maquinas de turing neuronal, tambien de deepmind. se han realizado fuera de las maquinas de turing neuronales, la memoria de largo a corto plazo los sistemas y redes de la memoria en las tareas de procesamiento de secuencia.  software de red neuronal  software de la red neuronal se utiliza para simular, investigacion , desarrollo y aplicacion de redes neuronales artificiales, redes neuronales biologicas y, en algunos casos, una gama mas amplia de sistemas adaptativos.  tipos de redes neuronales artificiales  tipos de redes neuronales artificiales varian de aquellos con solo una o dos capas de logica unica direccion, para muchos bucles complejos multi-direccionales de entrada de realimentacion y capas. en general, estos sistemas utilizan algoritmos en su programacion para determinar el control y la organizacion de sus funciones. la mayoria de los sistemas utilizan \"pesos\" para cambiar los parametros del rendimiento y las diferentes conexiones con las neuronas. las redes neuronales artificiales pueden ser autonomas y aprender mediante el aporte de \"maestros\" externos o incluso auto-enseñanza de las reglas escritas de entrada. redes neuronales estilo cubo neural primera por primera vez por gianna giavelli proporcionan un espacio dinamico en el que las redes se recombinan dinamicamente informacion y enlaces a traves de miles de millones de nodos independientes que utilizan la adaptacion neuronal darwinismo , una tecnica desarrollada por gerald edelman , que permite sistemas mas modeladas biologicamente.  el perceptron multicapa es un aproximado de la funcion universal, como lo demuestra el teorema de aproximacion universal. sin embargo, la prueba no es constructivo sobre el numero de neuronas es necesario, la topologia de red, la configuracion de los pesos y los parametros de aprendizaje.  el trabajo de hava siegelmann y eduardo d. sontag ha proporcionado una prueba de que una arquitectura especifica recurrente con los pesos valorados racionales (en oposicion a la precision total numero real -valued pesos) tiene toda la potencia de una maquina universal de turing utilizando un numero finito de las neuronas y las conexiones lineales estandar. ademas, se ha demostrado que el uso de valores irracionales para resultados pesos en una maquina con super-turing poder.  capacidad  los modelos de redes neuronales artificiales tienen una propiedad denominada \"capacidad\", que corresponde aproximadamente a su capacidad para modelar cualquier funcion dada. se relaciona con la cantidad de informacion que puede ser almacenada en la red y a la nocion de complejidad.  convergencia  nada se puede decir en general sobre la convergencia ya que depende de una serie de factores. en primer lugar, pueden existir muchos minimos locales. esto depende de la funcion de coste y el modelo. en segundo lugar, el metodo de optimizacion utilizado no puede ser garantizado a converger cuando lejos de un minimo local. en tercer lugar, para una cantidad muy grande de datos o parametros, algunos metodos se vuelven poco practico. en general, se ha encontrado que las garantias teoricas sobre la convergencia son una guia fiable para la aplicacion practica.  generalizacion y estadisticas  en aplicaciones donde el objetivo es crear un sistema que generaliza bien en los ejemplos que no se ven, ha surgido el problema de la formacion excesiva. esto surge en los sistemas complicados o sobre especificadas cuando la capacidad de la red supera significativamente los parametros libres necesarios. hay dos escuelas de pensamiento para evitar este problema: la primera es utilizar la validacion cruzada tecnicas similares y para comprobar la presencia de un exceso de formacion y de manera optima seleccione hiper- tales que se minimice el error de generalizacion. la segunda es utilizar algun tipo de regularizacion . este es un concepto que surge de manera natural en un marco probabilistico (bayesiano), donde la regularizacion puede realizarse mediante la seleccion de una probabilidad a priori mas grande sobre los modelos mas simples; sino tambien en la teoria estadistica de aprendizaje, donde el objetivo es reducir al minimo mas de dos cantidades: el \"riesgo empirico\" y el \"riesgo estructural ', que corresponde aproximadamente al error sobre el conjunto de formacion y el error de prediccion en los datos que no se ven debido a sobreajuste. redes neuronales supervisadas que utilicen un error cuadratico medio (mse) funcion de coste se pueden utilizar metodos estadisticos formales para determinar la confianza del modelo formado. el mse en un conjunto de validacion se puede utilizar como una estimacion de la varianza. este valor puede ser utilizado para calcular el intervalo de confianza de la salida de la red, suponiendo una distribucion normal . un analisis de confianza realizado de esta manera es estadisticamente valida siempre que la salida de distribucion de probabilidad sigue siendo el mismo y la red no es modificada.  mediante la asignacion de una funcion de activacion softmax , una generalizacion de la funcion logistica , en la capa de salida de la red neuronal (o un componente softmax en una red neuronal basada en componentes) para las variables categoricas de destino, las salidas se pueden interpretar como las probabilidades. esto es muy util en la clasificacion, ya que da una medida de la seguridad en las clasificaciones.  la funcion de activacion softmax es: y i = e x i ∑ j = 1 c e x j =}}^{c}e^{x_{j}}}}}  una critica comun de las redes neuronales, en particular en la robotica, es que requieren una gran diversidad de formacion para el funcionamiento del mundo real. esto no es sorprendente, ya que cualquier maquina de aprendizaje necesita suficientes ejemplos representativos con el fin de capturar la estructura subyacente que le permite generalizar a nuevos casos. dean a. powerless, en su investigacion presentada en el documento \"formacion basada en el conocimiento de redes neuronales artificiales para la conduccion autonoma del robot\", utiliza una red neuronal para formar a un vehiculo robotico para conducir en multiples tipos de carreteras (de un solo carril, varios carriles, suciedad, etc.). una gran cantidad de su investigacion esta dedicada a (1) la extrapolacion de multiples escenarios de formacion a partir de una sola experiencia de formacion, y (2) la preservacion de la diversidad de formacion pasada para que el sistema no se convierta en sobre formacion (si, por ejemplo, se presenta con una serie de giros a la derecha - no debe aprender a girar siempre a la derecha). estos problemas son comunes en las redes neuronales que debe decidir de entre una amplia variedad de respuestas, pero se pueden tratar de varias maneras, por ejemplo por revolver al azar los ejemplos de formacion, mediante el uso de un algoritmo de optimizacion numerica que no toma demasiado grandes pasos cuando el cambio de las conexiones de red siguiendo un ejemplo, o mediante la agrupacion de ejemplos en los llamados mini-lotes.  ak dewdney , un cientifico matematico e informatica de la universidad de ontario occidental y ex columnista de scientific american, escribio en 1997, \"a pesar de que las redes neurales hacen resolver algunos problemas de juguete, su poder de computacion son tan limitados que me sorprende que nadie los toma en serio como una herramienta general de resolucion de problemas\". no existe una red neuronal nunca se ha demostrado que resuelve los problemas computacionalmente dificiles, tales como la n-queens problema, el problema del viajante de comercio, o el problema de factorizar enteros grandes.  aparte de su utilidad, una objecion fundamental a las redes neuronales artificiales es que no logran reflejar como funcionan las neuronas reales. propagacion hacia atras esta en el corazon de las redes neuronales artificiales y la mayoria no solo no hay evidencia de ningun mecanismo de este tipo de redes neuronales naturales,​ parece contradecir el principio fundamental de las neuronas reales que la informacion solo puede fluir hacia adelante a lo largo del axon. como la informacion esta codificada por las neuronas reales aun no se conoce. lo que se sabe es que las neuronas sensoriales disparan potenciales de accion con mayor frecuencia con la activacion del sensor y las celulas musculares tiran mas fuertemente cuando sus neuronas motoras asociadas reciben los potenciales de accion con mas frecuencia.​ aparte del caso mas simple de solo transmision de informacion de una neurona a un sensor de la neurona motora casi nada se conoce de los principios generales subyacentes de como se maneja la informacion por las redes neuronales reales.  el proposito de las redes neuronales artificiales no es necesariamente replicar la funcion neural real sino inspirarse en redes neuronales naturales como acercamiento a una computacion, inherentemente paralela, que proporcione soluciones a problemas que hasta ahora han sido intratables. por tanto, una afirmacion central de las redes neuronales artificiales es que encarna algun principio general nuevo y potente para el procesamiento de la informacion. por desgracia, estos principios generales estan mal definidos y que a menudo se afirma que son emergentes de la red neuronal en si. esto permite la asociacion estadistica sencilla (la funcion basica de las redes neuronales artificiales), que se describe como el aprendizaje o el reconocimiento. como resultado, las redes neuronales artificiales tienen, segun dewdney, un \"algo para nada la calidad, que imparte un aura peculiar de la pereza y una clara falta de curiosidad acerca de lo bien que estos sistemas de computacion son ninguna mano humana (o la mente) interviene; soluciones. se encuentran como por arte de magia, y nadie, al parecer, ha aprendido nada”.​  los problemas de hardware  para implementar software de redes neuronales grandes y eficaces deben emplearse considerables recursos de procesamiento y almacenamiento. mientras que el cerebro ha adaptado su hardware a la tarea de procesamiento de señales a traves de un grafo de las neuronas, simular incluso una forma simplificada en la arquitectura von neumann puede obligar a un diseñador de la red neural a utilizar muchos millones de filas de bases de datos para sus conexiones, lo que puede consumir grandes cantidades de espacio de memoria ram y disco duro. ademas, el diseñador de sistemas de redes neurales a menudo necesitara utilizar para simular la transmision de señales a traves de muchas de estas conexiones y sus neuronas asociadas una increible cantidad de potencia de procesamiento y tiempo de cpu.  jurgen schmidhuber toma nota de que el resurgimiento de las redes neuronales en el siglo siglo xxi, y su exito renovado en tareas de reconocimiento de imagen es atribuible en gran medida a los avances en el hardware: de 1991 a 2015, el poder de computacion, especialmente en lo entregado por gpgpus (en las gpu ), ha aumentado alrededor de un millon de veces, por lo que el algoritmo de retropropagacion estandar viable para las redes de formacion que son varias capas mas profundas que antes (pero añade que esto no resuelve los problemas algoritmicos tales como el problema del desvanecimiento de gradientes \"de una manera fundamental\"). el uso de la gpu en lugar de cpus ordinarios puede traer los tiempos de formacion para algunas redes por debajo de los meses a meros dias.  potencia de calculo sigue creciendo mas o menos de acuerdo con la ley de moore , que puede proporcionar recursos suficientes para llevar a cabo nuevas tareas. ingenieria neuromorphic aborda la dificultad de hardware directamente, mediante la construccion de chips de no-von neumann con circuitos diseñados para implementar redes neuronales desde el principio. google tambien ha diseñado un chip optimizado para el procesamiento de red neural llamado unidad de procesamiento tensor o tpu.  contraejemplos practicas a las criticas  argumentos en contra de la posicion de dewdney son que las redes neuronales se han utilizado con exito para resolver muchas tareas complejas y diversas, que van desde aviones que vuelan de forma autonoma para la deteccion de fraude de tarjetas de credito.  escritor de tecnologia roger bridgman ha comentado las declaraciones de dewdney sobre redes neuronales:  las redes neuronales, por ejemplo, estan en el muelle no solo porque han sido promocionado al alto cielo, (lo que tiene, no?), sino tambien porque se puede crear una red de exito sin la comprension de como funcionaba: el monton de numeros que captura su comportamiento seria con toda probabilidad \"una, mesa ilegible opaca... sin valor como recurso cientifico\".  a pesar de su enfatica declaracion de que la ciencia no es la tecnologia, parece dewdney aqui para ridiculizar a las redes neuronales como mala ciencia cuando la mayoria de los ideando ellos estan tratando de ser buenos ingenieros. una tabla puede leer que una maquina util podia leer todavia seria bien vale la pena tener.  si bien es cierto que el analisis de lo que se ha aprendido por una red neuronal artificial es dificil, es mucho mas facil de hacerlo que analizar lo que se ha aprendido por una red neuronal biologica. por otra parte, los investigadores involucrados en la exploracion de algoritmos de aprendizaje para redes neuronales estan descubriendo gradualmente principios genericos que permiten que una maquina de aprendizaje tenga exito. por ejemplo, bengio y lecun (2007) escribio un articulo sobre el aprendizaje locales vs. no locales, asi como poco profundas frente a la arquitectura de profundidad.  enfoques hibridos  algunas otras criticas que provienen de los defensores de los modelos hibridos (combinacion de redes neuronales y enfoques simbolicos), que creen que el intermix de estos dos enfoques puede capturar mejor los mecanismos de la mente humana.  conclusion  aunque en algunas facultades de informatica se sigue instruyendo en redes neuronales artificiales, estas no disponen de un rigor cientifico claro, y estan consideradas como una pseudociencia por la mayoria de cientificos e ingenieros.  un bot es un programa que simula a un jugador humano. el neuralbot es un bot para el juego quake ii que utiliza una red neuronal artificial para decidir su comportamiento y un algoritmo genetico para el aprendizaje. es muy facil probarlo para ver su evolucion. mas informacion aqui  es un programa que combina diversas tecnicas computacionales con el objetivo de clasificar familias de proteinas. un posible metodo consiste en utilizar metricas adaptativas como por ejemplo: mapas autoorganizados y algoritmos geneticos.  el problema de clasificacion no sesgada basada en la expresion de las proteinas en aminoacidos puede reducirse, conceptualmente, a lo siguiente:  las rna han sido aplicadas a un numero en aumento de problemas en la vida real y de considerable complejidad, donde su mayor ventaja es en la solucion de problemas que son bastante complejos para la tecnologia actual, tratandose de problemas que no tienen una solucion algoritmica o cuya solucion algoritmica es demasiado compleja para ser encontrada.  en general, debido a que son parecidas a las del cerebro humano, las rna son bien nombradas ya que son buenas para resolver problemas que el humano puede resolver pero las computadoras no. estos problemas incluyen el reconocimiento de patrones y la prediccion del tiempo. de cualquier forma, el humano tiene capacidad para el reconocimiento de patrones, pero la capacidad de las redes neuronales no se ve afectada por la fatiga, condiciones de trabajo, estado emocional, y compensaciones.  se conocen cinco aplicaciones tecnologicas extendidas:  una sola capa de red neural artificial feedforward. flechas procedentes de x2 se omiten para mayor claridad. hay p entradas a esta red y salidas q. en este sistema, el valor de la salida q-esima, y_qse calcula como y_q=k*(∑(x_i*w_iq )-b_q)  una red neuronal artificial feedforward de dos capas.  una red artificial de alimentacion directa de una sola capa neuronal con 4 entradas, 6 ocultos y 2 salidas. las salidas de estado y direccion determinada posicion de la rueda basan los valores de control  una red artificial de alimentacion directa de dos capas neuronales con 8 entradas, 2x8 ocultos y 2 salidas. estado determinada posicion, direccion y otro ambiente de valores. los valores de control basados en salidas empujador.  indefinido  indefinido  existen muchas herramientas de software que implementan redes neuronales artificiales, tanto libres como comerciales como, por ejemplo: ",
        "snippet": "Las redes neuronales artificiales (también conocidas como sistemas conexionistas) son un modelo computacional evolucionado a partir de diversas aportaciones científicas que están registradas en la historia.[1]​ Consiste en un conjunto de unidades, llamadas neuronas artificiales, conectadas entre sí para transmitirse señales. La información de entrada atraviesa la red neuronal (donde se somete a diversas operaciones) produciendo unos valores de salida.",
        "enlaces_salientes": [
            "/wiki/Red_neuronal_artificial",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Red_neuronal_biol%C3%B3gica",
            "/wiki/Sistemas_Conexionistas",
            "/wiki/Sistemas_Conexionistas",
            "/wiki/Modelo_computacional",
            "/wiki/Neurona_de_McCulloch-Pitts",
            "/wiki/Funci%C3%B3n_de_activaci%C3%B3n",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Funci%C3%B3n_de_p%C3%A9rdida",
            "/wiki/Propagaci%C3%B3n_hacia_atr%C3%A1s",
            "/wiki/Aprendizaje_profundo",
            "/wiki/Tipo_de_dato_l%C3%B3gico",
            "/wiki/Visi%C3%B3n_artificial",
            "/wiki/Speech_recognition",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/Sistema_experto",
            "/wiki/Machine_learning",
            "/wiki/Sistema_din%C3%A1mico",
            "/wiki/Warren_McCulloch",
            "/wiki/Walter_Pitts",
            "/wiki/Neurona_de_McCulloch-Pitts#Historia",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Algoritmo",
            "/wiki/Inteligencia_artificial",
            "/wiki/Donald_Hebb",
            "/wiki/Teor%C3%ADa_hebbiana",
            "/wiki/Aprendizaje_no_supervisado",
            "/wiki/Potenciaci%C3%B3n_a_largo_plazo",
            "/wiki/Frank_Rosenblatt",
            "/wiki/Perceptr%C3%B3n",
            "/wiki/Disyunci%C3%B3n_exclusiva",
            "/wiki/Propagaci%C3%B3n_hacia_atr%C3%A1s",
            "/wiki/Paul_Werbos",
            "/wiki/Premio_Nobel",
            "/wiki/David_Hunter_Hubel",
            "/wiki/Torsten_Wiesel",
            "/wiki/Corteza_visual",
            "/wiki/Alexey_Grigorevich_Ivakhnenko",
            "/wiki/M%C3%A9todo_de_agrupamiento_para_el_manejo_de_datos",
            "/wiki/Marvin_Minsky",
            "/wiki/Seymour_Papert",
            "/wiki/Propagaci%C3%B3n_hacia_atr%C3%A1s",
            "/wiki/Disyunci%C3%B3n_exclusiva",
            "/wiki/Conexionismo",
            "/wiki/M%C3%A1quinas_de_vectores_de_soporte",
            "/wiki/Clasificador_lineal",
            "/wiki/Red_neuronal_prealimentada",
            "/wiki/Red_neuronal_recurrente",
            "/wiki/J%C3%BCrgen_Schmidhuber",
            "/wiki/Aprendizaje_no_supervisado",
            "/wiki/Propagaci%C3%B3n_hacia_atr%C3%A1s",
            "/wiki/GPU",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Aprendizaje_profundo",
            "/wiki/CMOS",
            "/wiki/An%C3%A1lisis_de_componentes_principales",
            "/wiki/Convoluci%C3%B3n",
            "/wiki/Se%C3%B1al_anal%C3%B3gica",
            "/wiki/Se%C3%B1al_digital",
            "/wiki/Propagaci%C3%B3n_hacia_atr%C3%A1s",
            "/wiki/CMOS",
            "/wiki/Ingenier%C3%ADa_neurom%C3%B3rfica",
            "/wiki/M%C3%A1quina_molecular",
            "/wiki/An%C3%A1lisis_de_componentes_principales",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Se%C3%B1al_anal%C3%B3gica",
            "/wiki/Se%C3%B1al_digital",
            "/wiki/Red_neuronal_recurrente",
            "/wiki/J%C3%BCrgen_Schmidhuber",
            "/wiki/Reconocimiento_de_patrones",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Reconocimiento_de_escritura",
            "/wiki/Unidad_de_procesamiento_gr%C3%A1fico",
            "/wiki/David_H._Hubel",
            "/wiki/Torsten_Wiesel",
            "/wiki/University_of_Toronto",
            "/wiki/Merck_%26_Co.",
            "/wiki/Funci%C3%B3n_de_activaci%C3%B3n",
            "/wiki/Tangente_hiperb%C3%B3lica",
            "/wiki/Funci%C3%B3n_sigmoide",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Variable_aleatoria",
            "/wiki/Modelo_en_grafo",
            "/wiki/Red_neuronal_prealimentada",
            "/wiki/Grafo_ac%C3%ADclico_dirigido",
            "/wiki/Camino_(teor%C3%ADa_de_grafos)",
            "/wiki/Red_neuronal_recurrente",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Funci%C3%B3n_convexa",
            "/wiki/Probabilidad_a_posteriori",
            "/wiki/Aprendizaje_supervisado",
            "/wiki/Aprendizaje_no_supervisado",
            "/wiki/Aprendizaje_por_refuerzo",
            "/wiki/Aprendizaje_supervisado",
            "/wiki/Error_cuadr%C3%A1tico_medio",
            "/wiki/Perceptr%C3%B3n_multicapa",
            "/wiki/Propagaci%C3%B3n_hacia_atr%C3%A1s",
            "/wiki/Reconocimiento_de_patrones",
            "/wiki/An%C3%A1lisis_de_la_regresi%C3%B3n",
            "/wiki/Reconocimiento_del_habla",
            "/wiki/Reconocimiento_de_gestos",
            "/wiki/Aprendizaje_no_supervisado",
            "/wiki/Informaci%C3%B3n_mutua",
            "/wiki/Probabilidad_a_posteriori",
            "/wiki/Aproximaci%C3%B3n",
            "/wiki/An%C3%A1lisis_de_grupos",
            "/wiki/Distribuci%C3%B3n_de_probabilidad",
            "/wiki/Compresi%C3%B3n_de_datos",
            "/wiki/Filtrado_bayesiano_de_spam",
            "/wiki/Aprendizaje_por_refuerzo",
            "/wiki/Cadena_de_M%C3%A1rkov",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica",
            "/wiki/Problema_de_enrutamiento_de_veh%C3%ADculos",
            "/wiki/Gesti%C3%B3n_de_recursos_naturales",
            "/wiki/Medicina",
            "/wiki/Juego",
            "/wiki/Hopfield_(RNA)",
            "/wiki/Kohonen_(RNA)",
            "/wiki/M%C3%A1quina_de_Boltzmann",
            "/wiki/Hopfield_(RNA)",
            "/wiki/Probabilidad_bayesiana",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Estimaci%C3%B3n_estad%C3%ADstica",
            "/wiki/Descenso_del_gradiente",
            "/wiki/Descenso_del_gradiente",
            "/wiki/Propagaci%C3%B3n_hacia_atr%C3%A1s",
            "/wiki/M%C3%A9todo_de_la_secante",
            "/wiki/M%C3%A9todo_del_gradiente_conjugado",
            "/wiki/Algoritmo_evolutivo",
            "/wiki/Programaci%C3%B3n_de_expresiones_de_genes",
            "/wiki/Algoritmo_de_recocido_simulado",
            "/wiki/Algoritmo_esperanza-maximizaci%C3%B3n",
            "/wiki/Estad%C3%ADstica_no_param%C3%A9trica",
            "/wiki/Optimizaci%C3%B3n_por_enjambre_de_part%C3%ADculas",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Factorizaci%C3%B3n_QR",
            "/wiki/Hiperpar%C3%A1metro",
            "/wiki/Reconocimiento_de_voz",
            "/wiki/Problema_del_viajante",
            "/wiki/Algoritmo_gen%C3%A9tico",
            "/wiki/Robot",
            "/wiki/Algoritmo_gen%C3%A9tico",
            "/wiki/Rob%C3%B3tica_evolutiva",
            "/wiki/Aproximaci%C3%B3n",
            "/wiki/An%C3%A1lisis_de_la_regresi%C3%B3n",
            "/wiki/Series_temporales",
            "/wiki/Clasificaci%C3%B3n_estad%C3%ADstica",
            "/wiki/Reconocimiento_de_patrones",
            "/wiki/Procesamiento_de_datos",
            "/wiki/Rob%C3%B3tica",
            "/wiki/Pr%C3%B3tesis",
            "/wiki/Ingenier%C3%ADa_de_control",
            "/wiki/Control_num%C3%A9rico",
            "/wiki/Identificaci%C3%B3n_de_sistemas",
            "/wiki/Instrumentaci%C3%B3n_y_control_de_procesos",
            "/wiki/Recurso_natural",
            "/wiki/Qu%C3%ADmica_cu%C3%A1ntica",
            "/wiki/Toma_de_decisiones",
            "/wiki/P%C3%B3quer",
            "/wiki/Reconocimiento_de_patrones",
            "/wiki/Sistema_de_reconocimiento_facial",
            "/wiki/Diagn%C3%B3stico_m%C3%A9dico",
            "/wiki/Comercio",
            "/wiki/Miner%C3%ADa_de_datos",
            "/wiki/Traducci%C3%B3n_autom%C3%A1tica",
            "/wiki/Antispam",
            "/wiki/Neurociencia_computacional",
            "/wiki/Circuito_neuronal",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Encoder",
            "/wiki/Deep_learning",
            "/wiki/Memoria_a_largo_plazo",
            "/wiki/Facebook",
            "/wiki/Google_DeepMind",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Descenso_del_gradiente",
            "/wiki/Simulaci%C3%B3n",
            "/wiki/Investigaci%C3%B3n",
            "/wiki/Redes_neuronales_biol%C3%B3gicas",
            "/wiki/Sistema_adaptativo",
            "/wiki/Gerald_Edelman",
            "/wiki/Eduardo_D._Sontag",
            "/wiki/Scientific_American",
            "/wiki/Travelling_salesman_problem",
            "/wiki/Grafo",
            "/wiki/Arquitectura_de_Von_Neumann",
            "/wiki/Database",
            "/wiki/Random-access_memory",
            "/wiki/Hard_drive",
            "/wiki/Central_processing_unit",
            "/wiki/J%C3%BCrgen_Schmidhuber",
            "/wiki/GPGPU",
            "/wiki/Graphics_processing_unit",
            "/wiki/Problema_de_desvanecimiento_de_gradiente",
            "/wiki/Ley_de_Moore",
            "/wiki/Ingenier%C3%ADa_neurom%C3%B3rfica",
            "/wiki/Tensor_Processing_Unit",
            "/wiki/Red_neuronal_prealimentada",
            "/wiki/Red_neuronal_recurrente",
            "/wiki/Hopfield_(RNA)",
            "/wiki/M%C3%A1quina_de_Boltzmann",
            "/wiki/Red_neuronal_estoc%C3%A1stica",
            "/wiki/Mapa_autoorganizado",
            "/wiki/Redes_neuronales_probabil%C3%ADsticas",
            "/wiki/Neurona_de_McCulloch-Pitts",
            "/wiki/RNA_de_base_radial",
            "/wiki/Aprendizaje_de_cuantificaci%C3%B3n_vectorial",
            "/wiki/Perceptr%C3%B3n",
            "/wiki/Adaline",
            "/wiki/Redes_neuronales_convolucionales",
            "/wiki/Memoria_asociativa_(RNA)",
            "/wiki/Google_DeepMind",
            "/wiki/M%C3%A1quina_de_Turing_neuronal",
            "/wiki/ART_(RNA)",
            "/wiki/Red_neuronal_de_impulsos",
            "/wiki/Red_neuronal_residual",
            "/wiki/Bot",
            "/wiki/Quake_II",
            "/wiki/Algoritmo_gen%C3%A9tico",
            "/wiki/Prote%C3%ADnas",
            "/wiki/Teor%C3%ADa_de_la_medida",
            "/wiki/Kohonen_(RNA)",
            "/wiki/Algoritmos_gen%C3%A9ticos",
            "/wiki/Amino%C3%A1cidos",
            "/wiki/Sesgo",
            "/wiki/Neural_Designer",
            "/wiki/Neuroph",
            "/wiki/OpenNN",
            "/wiki/Inteligencia_artificial",
            "/wiki/Din%C3%A1mica_de_sistemas",
            "/wiki/Sistema_complejo",
            "/wiki/Sistema_din%C3%A1mico",
            "/wiki/Rob%C3%B3tica_evolutiva",
            "/wiki/Conformaci%C3%B3n_de_haces_(beamforming)",
            "/wiki/Cerebro_artificial",
            "/wiki/Redes_neuronales_convolucionales",
            "/wiki/Reservoir_computing",
            "/wiki/Perceptr%C3%B3n_multicapa",
            "/wiki/Deep_Dream",
            "/wiki/Ablaci%C3%B3n_(inteligencia_artificial)",
            "/wiki/Confabulaci%C3%B3n_(redes_neuronales)",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Alan_Turing",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/PubMed_Identifier",
            "/wiki/ArXiv",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Bibcode",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Bibcode",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Bibcode",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/PubMed_Central",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Medical_Subject_Headings"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_de_multiplicaci%C3%B3n",
        "titulo": "Algoritmo de multiplicación",
        "contenido": "multiplicaciones  el algoritmo estandar para multiplicar dos numeros enteros, requiere el aprendizaje previo de las tablas de multiplicar. la multiplicacion se empieza desde la derecha, teniendo cuidado con la ley de los signos y con colocar las unidades de un orden bajo las unidades del mismo orden (unidades bajo unidades, decenas bajo decenas, centenas bajo centenas, etc.). luego se suman los productos de cada cifra del segundo factor por todas las del primero.  sea la multiplicacion de 4103 como multiplicando y 254 como multiplicador.  se coloca el multiplicador debajo del multiplicando, haciendo coincidir las columnas de las unidades por la derecha.   4 1 0 3 × 2 5 4 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline \\end{array}}}  conforme a las tablas elementales, se multiplica la cifra de unidades (4)del multiplicador por cada una de las cifras del multiplicando, empezando por las unidades (3) acarreando, en su caso, las decenas (4 × 3 = 12, acarreo de 1 unidad) como suma al resultado de la multiplicacion de la cifra siguiente [(4 × 0) + 1 = 1), 1 de acarreo], continuandose de igual forma con las demas cifras del multiplicando (4103 × 4 = 16412). consideramos esta linea como linea provisional.   4 1 0 3 × 2 5 4 1 6 4 1 2 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline &&1&6&4&1&2\\\\\\end{array}}}  se procede de igual forma con la cifra de las decenas del multiplicador con cada una de las cifras del multiplicando, si bien el resultado se escribe debajo de la fila anterior corriendo un lugar a la izquierda la cifra de las unidades. (4103 × 5 = 20515)   4 1 0 3 × 2 5 4 1 6 4 1 2 2 0 5 1 5 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline &&1&6&4&1&2\\\\&2&0&5&1&5&\\\\\\end{array}}}  se continua asi con todas las cifras del multiplicador. (4103 × 2 = 8206)   4 1 0 3 × 2 5 4 1 6 4 1 2 2 0 5 1 5 8 2 0 6 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline &&1&6&4&1&2\\\\&2&0&5&1&5&\\\\&8&2&0&6&&\\\\\\end{array}}}  finalmente se suman las cifras de cada una de las lineas provisionales, considerando los huecos de la derecha como ceros.   4 1 0 3 × 2 5 4 1 6 4 1 2 2 0 5 1 5 8 2 0 6 1 0 4 2 1 6 2 {rrrrrrr}&&&4&1&0&3\\\\\\times &&&&2&5&4\\\\\\hline &&1&6&4&1&2\\\\&2&0&5&1&5&\\\\&8&2&0&6&&\\\\\\hline 1&0&4&2&1&6&2\\\\\\end{array}}}  el resultado o multiplicacion es el que resulta de dicha suma (4103 × 254 = 1042162)  en este ejemplo se utiliza la multiplicacion larga de multiplicar 23 958 233 (multiplicando) por 5 830 (multiplicador) y se llega al 139 676 498 390 como resultado del producto.   2 3 9 5 8 2 3 3 × 5 8 3 0 ⟵ multiplicando ⟵ multiplicador {rrrrrrrrrrrr}&&&&2&3&9&5&8&2&3&3\\\\\\times &&&&&&&&5&8&3&0\\\\\\hline \\end{array}}{l}\\longleftarrow \\;}\\\\\\longleftarrow \\;}\\\\\\end{array}}}  se realizan las operaciones:   2 3 9 5 8 2 3 3 × 5 8 3 0 0 0 0 0 0 0 0 0 7 1 8 7 4 6 9 9 1 9 1 6 6 5 8 6 4 1 1 9 7 9 1 1 6 5 1 3 9 6 7 6 4 9 8 3 9 0 ⟵ 23 958 233 × 0 ⟵ 23 958 233 × 30 ⟵ 23 958 233 × 800 ⟵ 23 958 233 × 5.000 {rrrrrrrrrrrr}&&&&2&3&9&5&8&2&3&3\\\\\\times &&&&&&&&5&8&3&0\\\\\\hline &&&&0&0&0&0&0&0&0&0\\\\&&&7&1&8&7&4&6&9&9&\\\\&1&9&1&6&6&5&8&6&4&&\\\\1&1&9&7&9&1&1&6&5&&&\\\\\\hline 1&3&9&6&7&6&4&9&8&3&9&0\\\\\\end{array}}{l}\\\\\\\\\\longleftarrow 23\\;958\\;233\\times 0\\\\\\longleftarrow 23\\;958\\;233\\times 30\\\\\\longleftarrow 23\\;958\\;233\\times 800\\\\\\longleftarrow 23\\;958\\;233\\times 5.000\\\\\\\\\\end{array}}}  que dan como resultado:   2 3 9 5 8 2 3 3 × 5 8 3 0 0 0 0 0 0 0 0 0 7 1 8 7 4 6 9 9 1 9 1 6 6 5 8 6 4 1 1 9 7 9 1 1 6 5 1 3 9 6 7 6 4 9 8 3 9 0 ⟵ multiplicando ⟵ multiplicador ⟵ producto {rrrrrrrrrrrr}&&&&2&3&9&5&8&2&3&3\\\\\\times &&&&&&&&5&8&3&0\\\\\\hline &&&&0&0&0&0&0&0&0&0\\\\&&&7&1&8&7&4&6&9&9&\\\\&1&9&1&6&6&5&8&6&4&&\\\\1&1&9&7&9&1&1&6&5&&&\\\\\\hline 1&3&9&6&7&6&4&9&8&3&9&0\\\\\\end{array}}{l}\\longleftarrow \\;}\\\\\\longleftarrow \\;}\\\\\\\\\\\\\\\\\\\\\\longleftarrow \\;}\\\\\\end{array}}}  la multiplicacion hindu o de fibonacci requiere la preparacion de una tabla (una rejilla dibujada en un papel) que sirve de guia para el calculo. fue introducida en europa en 1202 por fibonacci en su liber abaci. leonardo describio la operacion como \"calculo mental\", y utilizaba los dedos de las manos para realizar los calculos intermedios. napier tambien publico este metodo en 1617, el año en que murio.  como se muestra en el ejemplo, el multiplicando y el multiplicador se escriben encima y a la derecha de la tabla.  las imagenes de la derecha muestran como calcular 345 × 12 usando la multiplicacion hindu. como ejemplo mas complejo, mas abajo se muestra el calculo de 23.958.233 por 5.830; el resultado es 139.676.498.390. observese que el numero 23.958.233 se encuentra en la parte superior de la tabla, y que 5.830 esta verticalmente en su lado derecho. los productos llenan la tabla y la suma de estos productos (diagonalmente) se encuentran en el lado izquierdo y el inferior. a continuacion estas sumas se agregan, como se muestra al multiplicar la division.  es un sistema de multiplicacion con lineas escritas en un papel y opuestas que representan las cifras y se cortan en un angulo de noventa grados. contando las intersecciones se obtiene el resultado final.​  para multiplicar monomios no es necesario que sean semejantes. para ello se multiplican los coeficientes, se deja la misma parte literal y se suman los grados. ejemplo:  se multiplica cada termino del polinomio por el monomio. ejemplos:  en resumen, se puede concluir con esta regla:  asi:  el producto de dos numeros complejos puede calcularse mediante la siguiente formula:  existen diversos algoritmos que permiten multiplicar numeros grandes. el mas rapido para los enteros que se manejan usualmente es el algoritmo de schonhage-strassen. ",
        "snippet": "Multiplicaciones",
        "enlaces_salientes": [
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/Algoritmo_de_multiplicaci%C3%B3n",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/Tabla_de_multiplicar",
            "/wiki/Acarreo",
            "/wiki/Fibonacci",
            "/wiki/C%C3%A1lculo",
            "/wiki/Liber_Abaci",
            "/wiki/Leonardo",
            "/wiki/C%C3%A1lculo_mental",
            "/wiki/John_Napier",
            "/wiki/Polinomio",
            "/wiki/Algoritmo_de_Sch%C3%B6nhage-Strassen",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Tabla_de_multiplicar",
            "/wiki/Multiplicaci%C3%B3n_por_duplicaci%C3%B3n",
            "/wiki/Algoritmo_de_Booth",
            "/wiki/Operaciones_con_polinomios",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_de_Euclides",
        "titulo": "Algoritmo de Euclides",
        "contenido": "en matematicas, el algoritmo de euclides, o algoritmo euclidiano, es un metodo eficiente para calcular el maximo comun divisor (mcd) de dos numeros enteros, el numero mas grande que los divide a ambos sin dejar resto. lleva el nombre del antiguo matematico griego euclides, quien lo describio por primera vez en elementos (ca. 300 a. c.). es un ejemplo de un algoritmo, un procedimiento paso a paso para realizar un calculo de acuerdo con reglas bien definidas, y es uno de los algoritmos mas antiguos que se siguen utilizando. se puede usar para reducir fracciones a su forma mas simple y es parte de muchos otros calculos teorico-numericos y criptograficos.  el algoritmo euclidiano se basa en el principio de que el maximo comun divisor de dos numeros no cambia si el numero mas grande se reemplaza por su diferencia con el numero mas pequeño. por ejemplo, 21 es el mcd de 252 y 105 (ya que 252 = 21 × 12 y 105 = 21 × 5), y el mismo numero 21 tambien es el mcd de 105 y 252 − 105 = 147. dado que este reemplazo reduce el mas grande de los dos numeros, al repetir este proceso se obtienen pares de numeros sucesivamente mas pequeños hasta que los dos numeros se vuelven iguales. cuando eso ocurre, son el mcd de los dos numeros originales. al invertir los pasos o usar el algoritmo de euclides extendido, el mcd se puede expresar como una combinacion lineal de los dos numeros originales, es decir, la suma de los dos numeros, cada uno multiplicado por un numero entero (por ejemplo, 21 = 5 × 105 + (−2) × 252). el hecho de que el mcd siempre se pueda expresar de esta manera se conoce como la identidad de bezout.  la version del algoritmo euclidiano descrita anteriormente (y por euclides) puede requerir muchos pasos de resta para encontrar el mcd cuando uno de los numeros dados es mucho mas grande que el otro. una version mas eficiente del algoritmo acorta estos pasos, en lugar de reemplazar el mas grande de los dos numeros por su resto al dividirlo por el mas pequeño de los dos (con esta version, el algoritmo se detiene al alcanzar un resto cero). con esta mejora, el algoritmo nunca requiere mas pasos que cinco veces el numero de digitos (base 10) del numero entero mas pequeño. esto fue demostrado por gabriel lame en 1844 (teorema de lame),​​ y marca el comienzo de la teoria de la complejidad informatica. se desarrollaron metodos adicionales para mejorar la eficiencia del algoritmo en el siglo xx.  el algoritmo euclidiano tiene muchas aplicaciones teoricas y practicas. se utiliza para reducir fracciones a su forma mas simple y para realizar divisiones en aritmetica modular. los calculos que utilizan este algoritmo forman parte de los protocolos criptograficos que se usan para proteger las comunicaciones de internet, y en los metodos para romper estos sistemas criptograficos mediante la factorizacion de grandes numeros compuestos. el algoritmo euclidiano se puede usar para resolver ecuaciones diofanticas, como encontrar numeros que satisfagan multiples congruencias de acuerdo con el teorema chino del resto, para construir fracciones continuas y para encontrar aproximaciones racionales precisas a numeros reales. finalmente, se puede utilizar como una herramienta basica para demostrar teoremas en la teoria de numeros, como el teorema de los cuatro cuadrados de lagrange y la unicidad de las factorizaciones primas.  en la concepcion griega de la matematica, los numeros se entendian como magnitudes geometricas. un tema recurrente en la geometria griega es el de la conmensurabilidad de dos segmentos: dos segmentos (numeros) ab y cd son conmensurables cuando existe un tercer segmento pq que cabe exactamente un numero entero de veces en los primeros dos; es decir, pq «mide» (mensura: medida) a los segmentos ab y cd.  no cualquier par de segmentos es conmensurable, como encontraron los pitagoricos cuando establecen que el lado y la diagonal de un cuadrado no son conmensurables, pero en el caso de dos segmentos conmensurables se desea hallar la mayor medida comun posible.  euclides describe en la proposicion i.2 en su libro vii de sus elementos un metodo que permite hallar la mayor medida comun posible de dos numeros (segmentos) que no sean primos entre si, aunque de acuerdo a la epoca tal metodo se explica en terminos geometricos, lo que se ilustra en la siguiente transcripcion.  sean ab y cd los dos numeros que no son primos uno al otro. se necesita entonces encontrar la maxima medida comun de ab y cd.  si cd mide ab entonces es una medida comun puesto que cd se mide a si mismo. y es manifiesto que tambien es la mayor medida pues nada mayor a cd puede medir a cd. pero si cd no mide a ab entonces algun numero quedara de ab y cd, el menor siendo continuamente restado del mayor y que medira al numero que le precede. porque una unidad no quedara pues si no es asi, ab y cd seran primos uno del otro [prop. vii.1], lo cual es lo contrario de lo que se supuso.  por tanto, algun numero queda que medira el numero que le precede. y sea cd midiendo be dejando ea menor que si mismo y sea ea midiendo  df dejando fc menor que si mismo y sea fc medida de ae. entonces, como fc mide ae y ae mide df, fc sera entonces medida de df. y tambien se mide a si mismo. por tanto tambien medira todo cd. y cd mide a be. entonces cf mide a be y tambien mide a ea. asi mide a todo ba y tambien mide a cd. esto es, cf mide tanto a ab y cd por lo que es una medida comun de ab y cd.  afirmo que tambien es la mayor medida comun posible porque si no lo fuera, entonces un numero mayor que cf mide a los numeros ab y cd, sea este g. dado que g mide a cd y cd mide a be, g tambien mide a be. ademas, mide a todo ba por lo que mide tambien al residuo ae. y ae mide a df por lo que g tambien mide a df. mide tambien a todo dc por lo que mide tambien al residuo cf, es decir el mayor mide al menor, lo cual es imposible.  en lenguaje moderno, el algoritmo se describe como sigue:  el hecho de que los segmentos son conmesurables es clave para asegurar que el proceso termina tarde o temprano  al dividir a entre b (numeros enteros), se obtiene un cociente q y un resto r . es posible demostrar que el maximo comun divisor de a y b es el mismo que el de b y r . sea c el maximo comun divisor de a y b , como a = b q + r y c divide a a y a b ,  divide tambien a r . si existiera otro numero mayor que c que divide a b y a r , tambien dividiria a a , por lo que c no seria el mcd de a y b , lo que contradice la hipotesis). este es el fundamento principal del algoritmo. tambien es importante tener en cuenta que el maximo comun divisor de cualquier numero a y 0 es precisamente a . para fines practicos, la notacion m c d ( a , b ) (a,b)} significa maximo comun divisor de a y b .  segun lo antes mencionado, para calcular el maximo comun divisor de 2366 y 273 se puede proseguir de la siguiente manera:  la secuencia de igualdades m c d ( 2366 , 273 ) = m c d ( 273 , 182 ) = m c d ( 182 , 91 ) = m c d ( 91 , 0 ) (2366,273)=\\mathrm {mcd} (273,182)=\\mathrm {mcd} (182,91)=\\mathrm {mcd} (91,0)} implican que m c d ( 2366 , 273 ) = m c d ( 91 , 0 ) (2366,273)=\\mathrm {mcd} (91,0)} . dado que m c d ( 91 , 0 ) = 91 (91,0)=91} , entonces se concluye que m c d ( 2366 , 273 ) = 91 (2366,273)=91} . este mismo procedimiento se puede aplicar a cualesquiera dos numeros naturales. en general, si se desea encontrar el maximo comun divisor de dos numeros naturales a y b , se siguen las siguientes reglas:  asuma que llamamos a = r 0 } y b = r 1 } . aplicando estas reglas se obtiene la siguiente secuencia de operaciones:  como la sucesion de residuos va disminuyendo, al final un residuo tiene que ser cero y es en ese momento cuando el algoritmo termina. el maximo comun divisor es precisamente r n + 1 } (el ultimo residuo que no es cero).  en realidad, el algoritmo de euclides funciona no solo para los numeros naturales, sino para cualquier elemento en el que exista una \"division con residuo\". a este tipo de divisiones se les llama divisiones euclidianas y a los conjuntos donde se puede definir dicha division se les llama dominios euclideos. por ejemplo, el conjunto de los numeros enteros y el de los polinomios con coeficientes racionales son dominios euclideos porque podemos definir una division con residuo (vease division polinomial). de esta manera, se puede calcular el maximo comun divisor de dos numeros enteros o de dos polinomios.  por ejemplo, para calcular el maximo comun divisor de los polinomios p ( x ) = x 5 + 2 x 3 + x +2x^{3}+x} y q ( x ) = x 4 − 1 -1} el algoritmo de euclides sugiere la siguiente secuencia de operaciones:  de esta manera se concluye que su maximo comun divisor es − x 2 − 1 -1} .  se puede expresar este algoritmo de manera mas formal usando pseudocodigo. en este caso la expresion \" x mod y }y} \" significa \"el residuo de dividir x entre y \" (vease aritmetica modular).  entrada: valores a y b pertenecientes a un dominio euclideo  salida: un maximo comun divisor de a y b  vale la pena notar que este algoritmo no es eficiente ser implementado directamente en una computadora, ya que requeriria memorizar todos los valores de r i } .  el algoritmo de euclides extendido permite, ademas de encontrar un maximo comun divisor de dos numeros enteros a y b , expresarlo como la minima combinacion lineal de esos numeros, es decir, encontrar numeros enteros s y t tales que m c d ( a , b ) = a s + b t (a,b)=as+bt} . esto se generaliza tambien hacia cualquier dominio euclidiano.  existen varias maneras de explicar el algoritmo de euclides extendido, una de las mas comunes consiste en la siguiente:  sin embargo, en aras de la comprension y memorizacion de este algoritmo, es conveniente conocer la siguiente caracterizacion. para multiplicar dos matrices de tamaño 2 × 2 se usa la siguiente formula (vease producto de matrices):  (1) [ e f g h ] × [ a b c d ] = [ e a + f c e b + f d g a + h c g b + h d ] e&f\\\\g&h\\end{bmatrix}}\\times a&b\\\\c&d\\end{bmatrix}}=ea+fc&eb+fd\\\\ga+hc&gb+hd\\end{bmatrix}}}  supongase que se utiliza el algoritmo de euclides tradicional para calcular los valores q i } y r i } que ahi se describen. por cada valor q i } calculado se puede formar la matriz q i = [ 0 1 1 − q i ] =0&1\\\\1&-q_{i}\\end{bmatrix}}} . usando la ecuacion (1) de manera repetida se puede calcular el producto de las primeras i matrices de este tipo:   [ s i t i s i + 1 t i + 1 ] = [ 0 1 1 − q i ] × [ 0 1 1 − q i − 1 ] × ⋯ × [ 0 1 1 − q 1 ] s_{i}&t_{i}\\\\s_{i+1}&t_{i+1}\\end{bmatrix}}=0&1\\\\1&-q_{i}\\end{bmatrix}}\\times 0&1\\\\1&-q_{i-1}\\end{bmatrix}}\\times \\cdots \\times 0&1\\\\1&-q_{1}\\end{bmatrix}}}  resulta ser que los valores s i } y t i } tienen la propiedad de que r i = a s i + b t i =as_{i}+bt_{i}} , es decir, expresan a r i } como una combinacion lineal de a y b . particularmente, como m c d ( a , b ) = r n + 1 (a,b)=r_{n+1}} entonces se tiene m c d ( a , b ) = a s n + 1 + b t n + 1 (a,b)=as_{n+1}+bt_{n+1}} , lo cual es la solucion del problema. esta propiedad no deberia ser sorprendente, pues esta multiplicacion de matrices equivale al metodo antes descrito donde se substituye cada ecuacion en la anterior. es importante calcular q i × ⋯ × q 3 × q 2 × q 1 \\times \\cdots \\times q_{3}\\times q_{2}\\times q_{1}} en ese mismo orden. la matriz q 1 } aparece en el extremo derecho y la matriz q i } en el izquierdo.  regresando al primer ejemplo, la sucesion de cocientes es q 1 = 8 =8} , q 2 = 1 =1} y q 3 = 2 =2} . entonces se puede calcular   [ − 1 9 3 − 26 ] = [ 0 1 1 − 2 ] × [ 0 1 1 − 1 ] × [ 0 1 1 − 8 ] -1&9\\\\3&-26\\end{bmatrix}}=0&1\\\\1&-2\\end{bmatrix}}\\times 0&1\\\\1&-1\\end{bmatrix}}\\times 0&1\\\\1&-8\\end{bmatrix}}}  utilizando el primer renglon de esta matriz se puede leer que 91 = 2366 ( − 1 ) + 273 ( 9 ) , es decir, se ha encontrado la manera de expresar al maximo comun divisor de 2366 y 273 como una combinacion lineal.  para expresar el algoritmo de euclides extendido es conveniente notar la manera en que se calculan los valores s i } y t i } con la multiplicacion de matrices:   [ s i t i s i + 1 t i + 1 ] = [ s i t i s i − 1 − q i s i t i − 1 − q i t i ] = [ 0 1 1 − q i ] × [ s i − 1 t i − 1 s i t i ] s_{i}&t_{i}\\\\s_{i+1}&t_{i+1}\\end{bmatrix}}=s_{i}&t_{i}\\\\s_{i-1}-q_{i}s_{i}&t_{i-1}-q_{i}t_{i}\\end{bmatrix}}=0&1\\\\1&-q_{i}\\end{bmatrix}}\\times s_{i-1}&t_{i-1}\\\\s_{i}&t_{i}\\end{bmatrix}}}  de esta manera s i + 1 = s i − 1 − q i s i =s_{i-1}-q_{i}s_{i}} y ademas t i + 1 = t i − 1 − q i t i =t_{i-1}-q_{i}t_{i}} . por lo tanto el algoritmo en pseudocodigo se puede expresar como sigue:  entrada: valores a y b pertenecientes a un dominio euclideo  salida: un maximo comun divisor de a y b , y valores s y t tales que m c d ( a , b ) = a s + b t (a,b)=as+bt}  al momento de hacer calculos con fracciones, es de gran importancia saber como simplificarlas. por ejemplo, la fraccion 65 91 {91}}} es equivalente con 5 7 {7}}} (vease numero racional). de manera mas general, a b = c a c b {b}}={cb}}} siempre que c = 0 . para reducir una fraccion cualquiera a b {b}}} , solo se necesita dividir a y b entre su maximo comun divisor.  por ejemplo, si se desea reducir 166 249 {249}}} , primero se usa el algoritmo de euclides para encontrar m c d ( 166 , 249 ) = 83 (166,249)=83} . se hacen las divisiones 166 ÷ 83 = 2 y 249 ÷ 83 = 3 . luego entonces se concluye que 166 249 = 2 3 {249}}={3}}} .  la sucesion de divisiones que se efectuan al seguir el algoritmo de euclides puede ser utilizada para expresar una fraccion cualquiera a b {b}}} como fraccion continua. esto se debe a que si a = b q + r y r = 0 , entonces  (3) a b = q + 1 b r {b}}=q+{r}}}}  por ejemplo, para encontrar el maximo comun divisor de 93164 y 5826 el algoritmo genera la siguiente secuencia de divisiones:  todas estas ecuaciones las podemos hacer parecidas a la ecuacion (3  3):  si se sustituye la segunda ecuacion en la primera, se obtiene   93164 5826 = 15 + 1 1 + 1 5774 52 {5826}}=15+{1+{52}}}}}}  si se repite este proceso de substitucion entonces se obtiene la expresion deseada:   93164 5826 = 15 + 1 1 + 1 111 + 1 26 {5826}}=15+{1+{111+{26}}}}}}}  de manera mas general, la fraccion continua encontrada con este algoritmo siempre es de la forma   a b = q 1 + 1 q 2 + 1 q 3 + 1 ⋱ q n − 1 + 1 q n {b}}=q_{1}+{q_{2}+{q_{3}++{q_{n}}}}}}}}}}    decimos que dos numeros enteros son congruentes modulo m (aunque tambien se puede generalizar para cualquier otro dominio euclideo) si al dividirlos entre m obtenemos el mismo residuo (vease congruencia). por ejemplo, 7 es congruente con 12 modulo 5 porque al dividir 7 entre 5 y 12 entre 5, en ambos casos obtenemos el mismo residuo (que es 2). cuando a es congruente con b modulo m se escribe a ≡ b ( mod m ) }} , en el ejemplo anterior se tiene 7 ≡ 12 ( mod 5 ) }} . supongase que se conocen los valores de a , b y m , pero que se desconoce el valor x en la siguiente congruencia:  (2) a x ≡ b ( mod m ) }}  basta  encontrar un valor a − 1 } que satisfaga: a − 1 a ≡ 1 ( mod m ) a\\equiv 1}} , pues de esta manera al multiplicar la ecuacion (2) por a − 1 } se tendra la solucion deseada:   x ≡ a − 1 b ( mod m ) b}}  al elemento a − 1 } se le llama \"inverso modulo m \" de a . desafortunadamente este valor no siempre existe. por ejemplo, con a = 4 y m = 6 no existe ningun numero entero a − 1 } tal que a − 1 4 ≡ 1 ( mod 6 ) 4\\equiv 1}} . de hecho este valor existe si y solo si m c d ( a , m ) = 1 (a,m)=1} (la   existencia de soluciones depende de la condicion m c d ( a , m ) | b (a,m)|b} , mientras que la unicidad depende de que el m c d ( a , m ) = 1 (a,m)=1} ). mas aun, si al usar el algoritmo de euclides extendido (ahora con b = m ) se obtiene 1 = a s + m t , entonces el valor s es el inverso modulo m de a . por ejemplo, se desea resolver la ecuacion   5 x ≡ 2 ( mod 9 ) }}  entonces con el algoritmo de euclides extendido se obtiene que m c d ( 5 , 9 ) = 1 = 5 ( 2 ) + 9 ( − 1 ) (5,9)=1=5(2)+9(-1)} . como m c d ( 5 , 9 ) = 1 (5,9)=1} entonces 5 tiene un inverso modulo 9 . mas aun, como 1 = 5 ( 2 ) + 9 ( − 1 ) , entonces ese inverso es 2. entonces   x ≡ 2 ( 2 ) ( mod 9 ) }}  es decir que el valor de x es 4 .  el teorema de lame afirma que el caso peor para este algoritmo es cuando se le pide calcular el maximo comun divisor de dos numeros consecutivos de la sucesion de fibonacci. por ejemplo, si se desea calcular el maximo comun divisor de f 10 = 55 =55} y f 11 = 89 =89} se obtiene la siguiente secuencia de operaciones:  en este ejemplo se observa que con estos dos numeros de dos digitos decimales, se necesita hacer 9 divisiones. en general, el numero de divisiones efectuadas por el algoritmo nunca supera 5 veces el numero de digitos que tienen estos numeros. en terminos de complejidad computacional, esto significa que se requieren o ( log ⁡ n ) divisiones para calcular el maximo comun divisor de n y m donde n > m .  el numero promedio de divisiones efectuadas por el algoritmo se estuvo investigando desde 1968, pero solo hasta apenas el año 2002, brigitte vallee demostro que si los dos numeros se pueden representar con n bits, entonces el numero promedio de divisiones necesarias es π 2 6 n }{6}}n}} .  sin embargo, no basta con saber el numero de divisiones. hay que recordar que el algoritmo de euclides funciona tanto para polinomios como para numeros enteros, y en general, cualquier dominio euclideo. en cada caso, la complejidad del algoritmo depende del numero de divisiones efectuadas y del costo de cada division. en el caso de los polinomios, el numero de divisiones es o ( log ⁡ n ) donde n es el grado de los polinomios.  en general, los algoritmos 1 y 2 no son muy apropiados para implementarse directamente en un lenguaje de programacion, especialmente porque consumen mucha memoria. si no se necesitan los valores intermedios, y solo se desea calcular el maximo comun divisor de dos numeros enteros, conviene usar estas variantes:  funcion m c d ( a , b ) (a,b)} :  funcion m c d ( a , b ) (a,b)} :  funcion e u c l i d e s ( a , b ) }(a,b)} :  funcion e u c l i d e s ( a , b ) }(a,b)} :  funcion e u c l i d e s ( a , b ) }(a,b)} :  acerca de la notacion empleada: ",
        "snippet": "En matemáticas, el algoritmo de Euclides, o algoritmo euclidiano, es un método eficiente para calcular el máximo común divisor (MCD) de dos números enteros, el número más grande que los divide a ambos sin dejar resto. Lleva el nombre del antiguo matemático griego Euclides, quien lo describió por primera vez en Elementos (ca. 300 a. C.). Es un ejemplo de un algoritmo, un procedimiento paso a paso para realizar un cálculo de acuerdo con reglas bien definidas, y es uno de los algoritmos más antiguos que se siguen utilizando. Se puede usar para reducir fracciones a su forma más simple y es parte de muchos otros cálculos teórico-numéricos y criptográficos.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/Resto",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Euclides",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Algoritmo",
            "/wiki/Fracci%C3%B3n",
            "/wiki/Fracci%C3%B3n_irreducible",
            "/wiki/Combinaci%C3%B3n_lineal",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Identidad_de_B%C3%A9zout",
            "/wiki/Gabriel_Lam%C3%A9",
            "/wiki/Teor%C3%ADa_de_la_complejidad_inform%C3%A1tica",
            "/wiki/Fracci%C3%B3n",
            "/wiki/Fracci%C3%B3n_irreducible",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Aritm%C3%A9tica_modular",
            "/wiki/Protocolo_criptogr%C3%A1fico",
            "/wiki/Internet",
            "/wiki/Factorizaci%C3%B3n_de_enteros",
            "/wiki/Ecuaciones_diof%C3%A1nticas",
            "/wiki/Teorema_chino_del_resto",
            "/wiki/Fracciones_continuas",
            "/wiki/Aproximaci%C3%B3n_diof%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Teorema_de_los_cuatro_cuadrados_de_Lagrange",
            "/wiki/Teorema_fundamental_de_la_aritm%C3%A9tica",
            "/wiki/Conmensurabilidad",
            "/wiki/Segmento",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Euclides",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Algoritmo_de_la_divisi%C3%B3n",
            "/wiki/Cociente_(aritm%C3%A9tica)",
            "/wiki/Resto",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Divisi%C3%B3n_euclidiana",
            "/wiki/Dominio_eucl%C3%ADdeo",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Polinomio",
            "/wiki/Divisi%C3%B3n_polinomial",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Aritm%C3%A9tica_modular",
            "/wiki/Algoritmo_de_la_divisi%C3%B3n",
            "/wiki/Producto_de_matrices",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/Fracci%C3%B3n_continua",
            "/wiki/Inverso_multiplicativo_(aritm%C3%A9tica_modular)",
            "/wiki/Congruencia",
            "/wiki/Sucesi%C3%B3n_de_Fibonacci",
            "/wiki/Complejidad_computacional",
            "/wiki/Lenguaje_C",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/C_Sharp",
            "/wiki/Python",
            "/wiki/Visual_Basic",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Pascal",
            "/wiki/Maxima",
            "/wiki/R-project",
            "/wiki/APL",
            "/wiki/Ruby",
            "/wiki/Parte_fraccionaria",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Universidad_de_La_Laguna",
            "/wiki/Cambridge_University_Press",
            "/wiki/MIT_Press",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/YouTube",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Criba_de_Erat%C3%B3stenes",
        "titulo": "Criba de Eratóstenes",
        "contenido": "la criba de eratostenes es un algoritmo que permite hallar todos los numeros primos menores que un numero natural dado. se forma una tabla con todos los numeros naturales comprendidos entre 2 y n, y se van tachando los numeros que no son primos de la siguiente manera: comenzando por el 2, se tachan todos sus multiplos; comenzando de nuevo, cuando se encuentra un numero entero que no ha sido tachado, ese numero es declarado primo, y se procede a tachar todos sus multiplos, asi sucesivamente. el proceso termina cuando el cuadrado del siguiente numero confirmado como primo es mayor que a.  determinemos, mediante el siguiente ejemplo, el proceso para determinar la lista de los numeros primos menores de 20.  como 3² = 9 < 20, se vuelve al segundo paso:  en el cuarto paso, el primer numero que no ha sido tachado ni marcado es 5. como su cuadrado es mayor que 20, el algoritmo termina y se consideran primos todos los numeros que no han sido tachados.  como resultado se obtienen los numeros primos comprendidos entre 2 y 20, y estos son: 2, 3, 5, 7, 11, 13, 17, 19.  un refinamiento de la criba consiste en tachar los multiplos del k-esimo numero primo pk, comenzando por pk2 pues en los anteriores pasos se habian tachado los multiplos de pk correspondientes a todos los anteriores numeros primos, esto es, 2pk, 3pk, 5pk,…, hasta (pk-1)pk. el algoritmo acabaria cuando p2k>n ya que no habria nada que tachar.​  otro refinamiento consiste en generar una lista solo con numeros impares (pues los numeros pares distintos de 2 se sabe que no son primos), e ir tachando los multiplos de los numeros primos mediante incrementos de 2p, es decir, los multiplos impares (2k+1)p de cada primo p. esto aparece en el algoritmo original.​  entrada: un numero natural n  salida: el conjunto de numeros primos anteriores a n (incluyendo n )  acerca de la notacion:  para su implementacion en una computadora, normalmente se maneja un vector de tipo logico con n elementos. de esta manera, la posicion i contiene el valor verdadero como representacion de que i ha sido marcado y falso en otro caso.  una forma especial de la criba de eratostenes aplicada se puede encontrar en la demostracion del producto de euler para la funcion zeta de riemann por parte de leonhard euler, y muestra una forma original de obtener dicho producto, utilizando una modificacion de dicha criba. la funcion zeta de riemann se representa como  multiplicando ambos miembros por 1 2 s {2^{s}}}} se obtiene una nueva serie, y restando esta nueva serie a la serie original miembro a miembro y termino a termino, se eliminan todos los terminos cuyas bases son multiplos de 2 — en la criba de eratostenes se tachan —.  repitiendo el mismo proceso sobre el siguiente termino, 1 3 s {3^{s}}}} , se eliminan todos los terminos cuyas bases son multiplos de 3:  puede comprobarse que la parte de la derecha se esta cribando, de manera que repitiendo este proceso indefinidamente:  se obtiene un producto sobre todos los numeros primos p, que puede escribirse de forma simplificada como:   ",
        "snippet": "La criba de Eratóstenes es un algoritmo que permite hallar todos los números primos menores que un número natural dado. Se forma una tabla con todos los números naturales comprendidos entre 2 y n, y se van tachando los números que no son primos de la siguiente manera: Comenzando por el 2, se tachan todos sus múltiplos; comenzando de nuevo, cuando se encuentra un número entero que no ha sido tachado, ese número es declarado primo, y se procede a tachar todos sus múltiplos, así sucesivamente. El proceso termina cuando el cuadrado del siguiente número confirmado como primo es mayor que a.",
        "enlaces_salientes": [
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Teor%C3%ADa_de_cribas",
            "/wiki/Erat%C3%B3stenes",
            "/wiki/Algoritmo",
            "/wiki/N%C3%BAmeros_primos",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Cuadrado_(%C3%A1lgebra)",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Funci%C3%B3n_parte_entera",
            "/wiki/Cociente_(aritm%C3%A9tica)",
            "/wiki/Vector_(programaci%C3%B3n)",
            "/wiki/Tipo_de_dato_l%C3%B3gico",
            "/wiki/Producto_de_Euler_para_la_funci%C3%B3n_zeta_de_Riemann",
            "/wiki/Leonhard_Euler",
            "/wiki/Funci%C3%B3n_zeta_de_Riemann",
            "/wiki/Miembro_de_una_ecuaci%C3%B3n",
            "/wiki/Serie_matem%C3%A1tica",
            "/wiki/Producto_de_Euler",
            "/wiki/Test_de_primalidad",
            "/wiki/Control_de_autoridades",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Formas_de_resolver_la_ra%C3%ADz_cuadrada",
        "titulo": "Cálculo de la raíz cuadrada",
        "contenido": "en este articulo se presentan y explican varios metodos que se pueden utilizar para calcular la raiz cuadrada de un numero real positivo, siendo el mas conocido el metodo de resolucion.  en la imagen adjunta podemos ver cinco partes esenciales de la raiz cuadrada en este metodo de resolucion:  los pasos a seguir son estos:  la raiz cuadrada de 5836,369 es 76,39, con un residuo de 0,9369. recordemos que el cero es solo un auxiliar. es tambien que la operacion anterior utilizada como ejemplo no esta completa. si la continuaramos daria como resultado 76,396132101 (con nueve decimales).  los pasos se pueden resumir en ciclos de cuatro despues de separar en grupos de dos cifras y teniendo en cuenta cuando se coloca la coma decimal en la raiz:  las calculadoras de bolsillo tipicamente implementan buenas rutinas para calcular la funcion exponencial y el logaritmo natural; entonces calculan la raiz cuadrada de x utilizando la identidad  la misma identidad es usada cuando se calculan las raices cuadradas con tablas de logaritmos o reglas de calculo.  muchos de los metodos de calculo para raices cuadradas requieren un valor inicial. si el valor inicial esta muy lejos de la raiz cuadrada real, el calculo sera muy lento. por lo tanto es util tener un calculo aproximado, que puede ser muy inexacto pero facil de calcular. una forma de obtener tal estimacion para x }} esta calculando 3 d } , donde d es el numero de digitos (a la izquierda del punto decimal) de x . si x < 1 , d es el negativo del numero de ceros a la derecha inmediata del punto decimal.  un mejor metodo de estimacion es este:  al trabajar en el sistema de numeracion binario (como lo hacen las computadoras internamente), un metodo alternativo es utilizar 2 ⌊ d / 2 ⌋ } (aqui d es el numero de digitos binarios).  el algoritmo babilonico​ se centra en el hecho de que cada lado de un cuadrado es la raiz cuadrada del area. fue usado durante muchos años para calcular raices cuadradas a mano debido a su gran eficacia y rapidez. para calcular una raiz, dibuje un rectangulo cuya area sea el numero al que se le busca raiz y luego aproxime la base y la altura del rectangulo hasta formar o por lo menos aproximar un cuadrado.  el algoritmo se puede enunciar sin el uso de dibujos como sigue:  raiz(x):  este algoritmo aproxima la raiz cuadrada de cualquier numero real tanto como se desee. es claro que no se necesita conocer el valor de h , puesto que depende directamente de x y que el area del rectangulo siempre se aproxima a la raiz cuadrada de x sin importar el valor de b siempre y cuando b > 0 . de esta manera surge la funcion recursiva  de manera tal que n es la n -esima aproximacion a x }} . esto implica que  puesto que algunas raices son numeros irracionales es necesario definir que tanto es \"aproximadamente\". afortunadamente nadie es capaz de escribir un numero con una infinita cantidad de digitos, por lo que el umbral de aproximacion se limita a la cantidad de digitos que se es capaz de escribir. entonces podemos definir que el algoritmo termine en el momento que la ultima aproximacion es la misma que la anterior (es decir, ya no se puede aproximar mas).  de manera formal, se expresa el algoritmo babilonico usando pseudocodigo de la siguiente manera:  funcion r a i z ( x ) (x)\\,}  donde x ← y significa \"sustituya el valor de x por del de y \", y devolver expresa el resultado del algoritmo y su terminacion.  los irracionales cuadraticos (numeros de la forma a + b c }}{c}}} , donde a, b y c son enteros), y en particular, las raices cuadradas de numeros enteros, tienen fracciones continuas periodicas. podemos estar interesados a veces no en encontrar el valor numerico de una raiz cuadrada, sino por algo en su expansion como fraccion continua. el algoritmo iterativo siguiente se puede utilizar para este proposito (s es cualquier numero natural que no sea un cuadrado perfecto):  hay que notar que mn, dn, y an son siempre enteros. el algoritmo termina cuando en este trio el resultado nuevo que obtenemos ya empieza a ser igual al anterior. la expansion se repetira entonces. la secuencia [a0; a1, a2, a3, …] es la expansion fraccion continua:  comenzamos con m0=0; d  ahora de enlaza de nuevo con la segunda ecuacion de arriba.  por lo tanto, la fraccion continua para la raiz cuadrada de 114 es: 114 = [ 10 ; 1 , 2 , 10 , 2 , 1 , 20 , 1 , 2 , 10 , 2 , 1 , 20 , 1 , 2 , 10 , 2 , 1 , 20 , . . . ] . }=[10;1,2,10,2,1,20,1,2,10,2,1,20,1,2,10,2,1,20,...].}  este metodo es para encontrar una aproximacion a la raiz cuadrada fue descrito en un manuscrito antiguo llamado manuscrito de bakhshali. equivale a dos iteraciones del metodo babilonico comenzando con el numero n tal que n 2 } es el cuadrado mas cercano a x .  si queremos calcular 10 , 5 }} con este metodo lo primero que hacemos es asignarle el numero cuadrado perfecto cuyo cuadrado se acerque mas a 10,5, ese numero va a ser 3, ya que al dar 3 2 \\,\\!} como resultado 9 se acerca mas a 10,5 que 4 2 \\,\\!} que da 16, con lo que ahora en la igualdad sustituimos:  siendo las cifras 384615 periodicas.  este metodo da un valor bastante aproximado  de la raiz cuadrada del numero, se puede observar tambien que este metodo al dar el resultado mediante una fraccion da un numero racional, mientras que la raiz cuadrada real de un numero es irracional siempre que este no sea un cuadrado perfecto (o el cociente de dos cuadrados perfectos).  si n es una aproximacion a s }} , una aproximacion mejor puede ser encontrada usando la serie de taylor de la funcion de la raiz cuadrada:  como metodo iterativo, el orden de convergencia es igual al numero de los terminos usados. con 2 terminos, es identica al metodo babilonico; con 3 terminos, cada iteracion toma casi tantas operaciones como la aproximacion de bakhshali, pero converge mas lentamente. por lo tanto, esta no es una manera particularmente eficiente de la operacion.   ",
        "snippet": "En este artículo se presentan y explican varios métodos que se pueden utilizar para calcular la raíz cuadrada de un número real positivo, siendo el más conocido el método de resolución.",
        "enlaces_salientes": [
            "/wiki/C%C3%A1lculo_de_la_ra%C3%ADz_cuadrada",
            "/wiki/C%C3%A1lculo_de_la_ra%C3%ADz_cuadrada",
            "/wiki/C%C3%A1lculo_de_la_ra%C3%ADz_cuadrada",
            "/wiki/Ra%C3%ADz_cuadrada",
            "/wiki/Exponencial",
            "/wiki/Logaritmo_natural",
            "/wiki/Regla_de_c%C3%A1lculo",
            "/wiki/Sistema_de_numeraci%C3%B3n",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Cuadrado",
            "/wiki/Algoritmo",
            "/wiki/Cuadrado",
            "/wiki/%C3%81rea",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/%C3%81rea",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/N%C3%BAmero_irracional",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Fracci%C3%B3n_continua",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Cuadrado_perfecto",
            "/wiki/Cuadrado_perfecto",
            "/wiki/Serie_de_Taylor",
            "/wiki/Ra%C3%ADz_cuadrada",
            "/wiki/M%C3%A9todo_iterativo",
            "/wiki/Orden_de_convergencia",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/Ra%C3%ADz_cuadrada",
            "/wiki/CORDIC",
            "/wiki/Ra%C3%ADz_cuadrada_de_2#Notas",
            "/wiki/Internet_Archive",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_computabilidad",
        "titulo": "Teoría de la computabilidad",
        "contenido": "la teoria de la computabilidad o teoria de la recursion es la parte de la computacion que estudia los problemas de decision que se pueden resolver con un algoritmo o equivalentemente con una maquina de turing. las preguntas fundamentales de la teoria de la computabilidad son:  la teoria de la complejidad computacional clasifica las funciones computables segun el uso que hacen de diversos recursos en diversos tipos de maquina.  la teoria de la computabilidad es el estudio matematico de los modelos de computacion. como tal estudio teorico, se origino en la decada de los años 30 con los trabajos de los logicos church, godel, kleene, post y turing.  tengase en cuenta que en aquellos años el avance tecnologico ni siquiera podia prever la revolucion que en la decada de los 60 traerian los ordenadores, y sin embargo, conceptos habituales hoy en dia (computadores universales, programas como listas de instrucciones de un lenguaje formal, interpretes, ...) ya fueron definidos desde un punto de vista teorico por esos matematicos.  la teoria de la computabilidad, tambien denominada teoria de la recursion, es una de las cuatro partes que constituyen la logica matematica, siendo las otras tres, la teoria de conjuntos, la teoria de modelos y la teoria de la demostracion, y se ocupa del estudio y clasificacion de las relaciones y aplicaciones computables. ademas, la teoria de la computabilidad, junto con la teoria de automatas, de la informacion, de los lenguajes y maquinas, y es el fundamento de la informatica teorica y esta, a su vez, de la industria de los ordenadores.  desde tiempo inmemorial se sabe que cierta clase de problemas, e.g., la determinacion del maximo comun divisor de dos numeros enteros, mediante el algoritmo de euclides, o la determinacion de los numeros primos, mediante la criba de eratostenes, son algoritmicamente solubles, i.e., hay algoritmos o procedimientos mecanicos que permiten obtener la solucion del problema en cuestion. de manera que hasta principios del siglo xx se daba por hecho que existian algoritmos y que el unico problema residia en determinarlos. asi pues, si lo que se desea es determinar un algoritmo, no hay ninguna necesidad de definir la clase de todos los algoritmos; eso solo es necesario si se pretende demostrar que algun problema no es algoritmicamente soluble, i.e., que para dicho problema no hay ningun algoritmo que lo resuelva.  es posible que el primero en afirmar la no existencia de un algoritmo fuera tietze en 1908, quien dijo de los grupos de presentacion finita:  “. . . la cuestion acerca de cuando dos grupos son isomorfos no es soluble en general.”​  pero parece ser que fue, por una parte, el problema de la decidibilidad de la logica de predicados planteado por hilbert y ackermann en su libro sobre logica, publicado en 1928, y, por otra, el asunto de la solubilidad de todo problema matematico, lo que indujo, en aras a resolverlos, a diversos investigadores a partir de 1930, y entre los que cabe mencionar a godel, church y turing, a proponer diversas formalizaciones del concepto informal de funcion mecanicamente computable. debido a que de todas esas formalizaciones, y de otras propuestas por kleene, post y markoff, se demostro que eran dos a dos equivalentes, se propuso la hipotesis, conocida como hipotesis de church-turing-post-kleene, que afirma la coincidencia entre el concepto informal de funcion parcial mecanica o algoritmicamente computable, y el concepto formal, matematico, de aplicacion parcial recursiva. naturalmente, esa hipotesis, de caracter similar a otras hipotesis propuestas en las ciencias empiricas, no es demostrable, y su fundamento ultimo reside en las equivalencias antes mencionadas.  hay cursos dedicados, en primer lugar, al estudio de diferentes clases de aplicaciones recursivas, desde las recursivas primitivas, hasta las parciales recursivas, pasando por las recursivas generales, asi como al de diversas clases de relaciones, entre las que cabe citar a las recursivas primitivas, las recursivamente enumerables y a las recursivas, demostrando ademas, ciertos teoremas fundamentales de la teoria de la recursion, debidos en gran medida a kleene; y, en segundo lugar, a la aplicacion de la teoria de la recursion a la demostracion de la indecidibilidad de la logica de predicados de primer orden, i.e., a la demostracion de que el conjunto de los numeros de godel de los teoremas de la logica de predicados de primer orden no es recursivo, aunque si sea recursivamente enumerable; y de los teoremas de incompletitud de godel, de los cuales, el primero da cuenta, esencialmente, de la diferencia, en la aritmetica, entre las nociones de verdad y demostrabilidad, mientras que el segundo afirma que, bajo ciertas condiciones, no es posible demostrar desde una teoria, la consistencia de la misma, i.e., esencialmente que el infinito no es eliminable en las matematicas.  la teoria de la recursion se origino en la decada de 1930, con el trabajo de kurt godel, alonzo church, alan turing, stephen kleene y emil post.​  los resultados fundamentales que obtuvieron los investigadores estabilizaron el concepto de funcion computable como la manera correcta de formalizar la idea sobre calculos efectivos.  estos resultados llevaron a stephen kleene (1952) a acuñar dos nombres, \"tesis de church\" (kleene 1952:300) y \"tesis de turing\" (kleene 1952:376). hoy en dia ambos se consideran como una unica hipotesis, la tesis de church-turing, la cual establece que cualquier funcion que sea computable por un cierto algoritmo es una funcion computable. aunque en un principio era algo un tanto esceptico, alrededor del año 1946, godel defendio esta tesis:  con una definicion sobre calculos efectivos aparecieron las primeras pruebas de que hay ciertos problemas en las matematicas que no pueden ser decididos de una manera eficaz. church (1936p, 1936f) y turing (1936), inspirados por las tecnicas usadas por godel (1931) para probar sus teoremas sobre la incompletitud, demostraron por separado que no es posible decidir el entscheidungsproblem de una manera eficaz. este resultado demostro que no existe un procedimiento algoritmico que pueda decidir de manera correcta si ciertas proposiciones matematicas son verdaderas o no.  muchos problemas en las matematicas han sido demostrados ser indecidibles una vez se establecieron estos primeros ejemplos. en 1947, markov y post publicaron por separado sus trabajos mostrando que el problema de las palabras para los semigrupos no puede ser decidido de una manera eficaz. ampliando este resultado, pyotr novikov y william boone demostraron independientemente en la decada de 1950 que el problema de las palabras para los semigrupos no se puede resolver de una manera efectiva: no hay ningun procedimiento eficaz que, dada una palabra en un grupo, decida si el elemento representado por la palabra es el elemento identidad del grupo. en 1970, yuri matiyasevich demostro (usando los resultados de julia robinson) el teorema de matiyasevich, el cual implica que el decimo problema de hilbert no tiene una solucion eficaz; este problema preguntaba si habia o no un procedimiento mediante el cual se pudiera decidir si una ecuacion diofantica sobre los numeros enteros tiene una solucion entera. la lista de problemas indecidibles contiene ejemplos adicionales sobre problemas sin soluciones computables.  el estudio sobre que construcciones matematicas pueden ser llevadas a cabo de una forma eficaz se denomina a veces matematica recursiva; el handbook of recursive mathematics (ershov et al. 1998) cubre muchos de los resultados conocidos en este campo.  el origen de los modelos abstractos de computacion se encuadra en los años 1930 (antes de que existieran los ordenadores modernos), para el trabajo de los logicos alonzo church, kurt godel, stephen kleene, emil leon post, y alan turing. estos trabajos iniciales han tenido una profunda influencia, tanto en el desarrollo teorico como en abundantes aspectos de la practica de la computacion; previendo incluso la existencia de ordenadores de proposito general, la posibilidad de interpretar programas, la dualidad entre software y hardware, y la representacion de lenguajes por estructuras formales basados en reglas de produccion.  el punto inicial de estos primeros trabajos fueron las cuestiones fundamentales que david hilbert formulo en 1900, durante el transcurso de un congreso internacional.  lo que hilbert pretendia era crear un sistema matematico formal completo y consistente en el cual todas las aseveraciones fueran  planteadas con precision. su intencion era encontrar un algoritmo que determinara la verdad o falsedad de cualquier proposicion en el sistema formal. al problema en cuestion se le denomino entscheidungsproblem. en caso de que hilbert hubiese cumplido su objetivo, cualquier problema bien definido se resolveria simplemente al ejecutar dicho algoritmo.  pero fueron otros los que mediante una serie de investigaciones mostraron que esto no era posible. en contra de esta idea k. godel saco a la luz su conocido primer teorema de incompletitud. este viene a expresar que todo sistema de primer orden consistente que contenga los teoremas de la aritmetica y cuyo conjunto de axiomas sea recursivo no es completo. godel construyo una formula que es satisfactoria pero que no puede ser probada en el sistema. como consecuencia, no es posible encontrar el sistema formal deseado por hilbert en el marco de la logica de primer orden, a no ser que se tome un conjunto no recursivo de axiomas.  una posterior version, que resulta mas general, del teorema de incompletitud de godel, indica que ningun sistema deductivo que contenga los teoremas de la aritmetica, y con los axiomas recursivamente enumerables puede ser consistente y completo a la vez. esto hace pensar, a nivel intuitivo, que no va a ser posible definir un sistema formal.  no todos los problemas pueden ser resueltos. un problema indecidible es uno que no puede ser resuelto con un algoritmo aun si se dispone de espacio y tiempo ilimitado. actualmente se conocen muchos problemas indecidibles, como por ejemplo:  los lenguajes formales que son aceptados por una maquina de turing son exactamente aquellos que pueden ser generados por una gramatica formal. el calculo lambda es una forma de definir funciones. las funciones que pueden ser computadas con el calculo lambda son exactamente aquellas que pueden ser computadas con una maquina de turing. estos tres formalismos, las maquinas de turing, los lenguajes formales y el calculo lambda son formalismos muy disimiles y fueron desarrollados por diferentes personas. sin embargo, todos ellos son equivalentes y tienen el mismo poder de expresion. generalmente se toma esta notable coincidencia como evidencia de que la tesis de church-turing es cierta, que la afirmacion de que la nocion intuitiva de algoritmo o procedimiento efectivo de computo corresponde a la nocion de computo en una maquina de turing.  los computadores electronicos, basados en la arquitectura de von neumann asi como las maquinas cuanticas tendrian exactamente el mismo poder de expresion que el de una maquina de turing si dispusieran de recursos ilimitados de tiempo y espacio. como consecuencia, los lenguajes de programacion tienen a lo sumo el mismo poder de expresion que el de los programas para una maquina de turing y en la practica no todos lo alcanzan. los lenguajes con poder de expresion equivalente al de una maquina de turing se denominan turing completos.  entre los formalismos equivalentes a una maquina de turing estan:  los ultimos tres ejemplos utilizan una definicion ligeramente diferente de aceptacion de un lenguaje. ellas aceptan una palabra si cualquiera, computo acepta (en el caso de no determinismo), o la mayoria de los computos aceptan (para las versiones probabilistica y cuantica). con estas definiciones, estas maquinas tienen el mismo poder de expresion que una maquina de turing.  se considera que algunas maquinas tienen mayor poder que las maquinas de turing. por ejemplo, una maquina oraculo que utiliza una caja negra que puede calcular una funcion particular que no es calculable con una maquina de turing. la fuerza de computo de una maquina oraculo viene descrita por su grado de turing. la teoria de computos reales estudia maquinas con precision absoluta en los numeros reales. dentro de esta teoria, es posible demostrar afirmaciones interesantes, tales como «el complemento de un conjunto de mandelbrot es solo parcialmente decidible».  ejemplo 1. sea k ∈, y sea k la funcion constante. definido por k (x) = k para todo x ∈. demuestre que k esta en prim.  solucion lo mostramos por induccion sobre k. puesto que 0 es una funcion inicial, tenemos 0 ∈ prim. digase k ∈ prim, algo dado k. entonces (k + 1) (x) = (k (x)) 0, para cada x ∈ ℕ. asi que k + 1 ∈ prim (por sustitucion de k en 0).  ejemplo 2. demuestre que la diferencia absoluta, definida por  solucion. en este caso, obtenemos la funcion mediante la sustitucion usando ya funciones recursivas primitivas probadas: |m − n| = (m−· n) + (n−· m). ¡no todos los ejemplos necesitan un esquema recursivo primitivo!  podemos esperar que este proceso de construccion cada vez sea mas complicado. debemos usar funciones anteriores hasta que tengamos todas las funciones computables, en la medida en que a partir de 1928 wilhelm ackermann definio una funcion computable que no es primitivo recursivo. para definir la funcion de ackermann a, utilizo un anidado recursivo. aqui esta una version simplificada debido al matematico hungaro r'osza p'eter, un cofundador en gran medida olvidado de la teoria de la computabilidad:  a(m, 0) = m + 1 a(0, n + 1) = a(1, n) a(m + 1, n + 1) = a(a(m, n + 1), n).  el anidamiento en la ultima linea conduce a que a (m, m) sea mucho mas rapido que el crecimiento de cualquier funcion recursiva primitiva f (m) podria ser. uno puede obtener una impresion de la rapidez con la computacion solo unos pocos valores. para ello, utilice el hecho de que la recursion anidada antedicha da las ecuaciones equivalentes:  a(m, 0) = m + 1 a(m, 1) = 2 + (m + 3) − 3 a(m, 2) = 2 × (m + 3) − 3 a(m, 3) = 2(m+3) − 3 a(4, n) = 22 ... 2− 3 (m + 3 terms)  de donde obtendremos los valores: a(0,0)=1, a(1,1)=3, a(2,2)=7, a(3,3)=61, a(4,4)= 65536. podemos remediar esta insuficiencia de prim añadiendo solo una regla mas para obtener nuevas funciones.  ​​​​",
        "snippet": "La teoría de la computabilidad o teoría de la recursión es la parte de la computación que estudia los problemas de decisión que se pueden resolver con un algoritmo o equivalentemente con una máquina de Turing. Las preguntas fundamentales de la teoría de la computabilidad son:",
        "enlaces_salientes": [
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Problema_de_decisi%C3%B3n",
            "/wiki/Algoritmo",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Complejidad_computacional",
            "/wiki/Alonzo_Church",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Stephen_Kleene",
            "/wiki/Emil_Leon_Post",
            "/wiki/Alan_Turing",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Teor%C3%ADa_de_modelos",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/M%C3%A1quina",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Industria",
            "/wiki/Computadora",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/N%C3%BAmero_primo",
            "/wiki/Criba_de_Erat%C3%B3stenes",
            "/wiki/Decidibilidad",
            "/wiki/L%C3%B3gica_de_predicados",
            "/wiki/David_Hilbert",
            "/wiki/Wilhelm_Ackermann",
            "/wiki/L%C3%B3gica",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/Hip%C3%B3tesis_(m%C3%A9todo_cient%C3%ADfico)",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Ciencias_f%C3%A1cticas",
            "/wiki/Indecidibilidad",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/L%C3%B3gica_de_predicados",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/Stephen_Kleene",
            "/wiki/Emil_Post",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Stephen_Kleene",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Algoritmo",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Alfred_Tarski",
            "/wiki/Epistemol%C3%B3gica",
            "/wiki/Conjunto_recursivo",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Entscheidungsproblem",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Independencia_(l%C3%B3gica_matem%C3%A1tica)",
            "/wiki/Emil_Leon_Post",
            "/wiki/Pyotr_Novikov",
            "/wiki/Grupo_(matem%C3%A1tica)",
            "/wiki/Elemento_identidad",
            "/wiki/Yuri_Matiyasevich",
            "/wiki/Julia_Robinson",
            "/wiki/D%C3%A9cimo_problema_de_Hilbert",
            "/wiki/Ecuaci%C3%B3n_diof%C3%A1ntica",
            "/wiki/Problema_indecidible#Ejemplos_de_problemas_indecidibles",
            "/wiki/L%C3%B3gica",
            "/wiki/Alonzo_Church",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Stephen_Kleene",
            "/wiki/Emil_Leon_Post",
            "/wiki/Alan_Turing",
            "/wiki/Software",
            "/wiki/Hardware",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/David_Hilbert",
            "/wiki/1900",
            "/wiki/Sistema_formal",
            "/wiki/Completitud_(l%C3%B3gica)",
            "/wiki/Consistencia_(l%C3%B3gica)",
            "/wiki/Algoritmo",
            "/wiki/Entscheidungsproblem",
            "/wiki/Teoremas_de_la_incompletitud_de_G%C3%B6del",
            "/wiki/Teorema",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Axioma",
            "/wiki/Recursi%C3%B3n",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/Independencia_(l%C3%B3gica_matem%C3%A1tica)",
            "/wiki/Entscheidungsproblem",
            "/wiki/Problema_de_decisi%C3%B3n",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Problema_de_la_parada",
            "/wiki/N%C3%BAmero_computable",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Constante_de_Chaitin",
            "/wiki/Lenguaje_formal",
            "/wiki/Gram%C3%A1tica_formal",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Ordenador",
            "/wiki/Arquitectura_de_von_Neumann",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Turing_completo",
            "/wiki/Turmite",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/Gram%C3%A1tica_formal",
            "/wiki/M%C3%A1quina_de_Post",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Aut%C3%B3mata_celular",
            "/wiki/Juego_de_la_vida",
            "/wiki/John_Horton_Conway",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing_probabil%C3%ADstica",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/M%C3%A1quina_or%C3%A1culo",
            "/wiki/Caja_negra_(sistemas)",
            "/wiki/Conjunto_de_Mandelbrot",
            "/wiki/Cambridge_University_Press",
            "/wiki/Yuri_Matiyasevich",
            "/wiki/MIT_Press",
            "/wiki/Stephen_Kleene",
            "/wiki/Piergiorgio_Odifreddi",
            "/wiki/ISSN",
            "/wiki/Mathematical_Reviews",
            "/wiki/OCLC",
            "/wiki/Martin_Davis",
            "/wiki/Oxford_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Camino_hamiltoniano",
        "titulo": "Camino hamiltoniano",
        "contenido": "en teoria de grafos, un camino hamiltoniano en un grafo es un camino (es decir, una sucesion de aristas adyacentes), que visita todos los vertices del grafo una sola vez. si ademas el primer y ultimo vertice visitado coincide, el camino es un ciclo hamiltoniano.  el problema de encontrar un ciclo (o camino) hamiltoniano en un grafo arbitrario se sabe que es np-completo​ y como tal aparece en la lista de los 21 problemas np-completos de karp.  el nombre proviene del matematico irlandes sir william rowan hamilton (1805-65), que propuso viajar a veinte ciudades del mundo, representadas como los vertices de un dodecaedro regular, siguiendo las aristas del dodecaedro.  no obstante, los ciclos y caminos actualmente denominados hamiltonianos aparecieron mucho antes. al parecer, ya en el siglo ix el poeta indio rudrata nombra el llamado camino del caballo. se trata de una sucesion de movimientos del caballo sobre un arcidriche de manera que esta pieza, el caballo, visite todos y cada uno de los escaques una sola vez. se trata, en consecuencia, de encontrar un camino hamiltoniano en un grafo cuyos vertices son los escaques de un arcidriche de manera que dos vertices son adyacentes si y solo si se puede pasar de uno a otro mediante un movimiento de caballo.  para grafos dirigidos, o digrafos, las definiciones correspondientes tienen en cuenta que las aristas estan dirigidas.  al contrario que en el caso de los grafos eulerianos, no se conoce ninguna caracterizacion de los grafos hamiltonianos.  desde luego, todos los grafos hamiltonianos son conexos pero no todos los grafos conexos son hamiltonianos.    podemos, no obstante, anotar algunas condiciones necesarias para que un grafo sea hamiltoniano.  teorema.  si un grafo g es hamiltoniano entonces para cualquier subconjunto no vacio de vertices s de g, el numero de componentes conexas del subgrafo g − s es menor o igual que el cardinal de s.(cf. [theorem 6.3.4​])  en particular, un grafo hamiltoniano no puede poseer vertices de corte, esto es, un vertice tal que si lo eliminamos junto a todas las aristas que confluyen en el, el subgrafo resultante tiene mas componentes conexas que el grafo original.  el reciproco no es cierto.  existen muchos resultados que proporcionan condiciones suficientes que garanticen el caracter hamiltoniano de un grafo. de entrada, para poder analizar si un grafo de mas de 2 vertices es hamiltoniano podemos suprimir los lazos y las aristas paralelas. ademas un grafo con 2 vertices es hamiltoniano si y solo si tiene al menos dos aristas entre ambos vertices. por tanto nos concentramos en el analisis de grafos simples, sin lazos y con mas de 2 vertices. la mejor aportacion en este sentido es un teorema publicado en 1976 debido a j. a. bondy y a v. chvatal, que generaliza los resultados anteriormente encontrados por g. a. dirac (1952) y ø. ore (1960). todos estos resultados afirman, basicamente, que un grafo es hamiltoniano si existen “suficientes aristas”. para enunciar el teorema de bondy-chvatal es menester definir primero que es la clausura de un grafo.  definicion. dado un grafo g con n vertices, la clausura de g es el grafo que tiene los mismos vertices que g y que aparece al agregar todas las aristas de la forma {u, v} para cualquier par de vertices u y v que no sean adyacentes y cumplan que grado(v) + grado(u) ≥ n.  teorema.  un grafo es hamiltoniano si y solo si lo es su clausura.​  puede consultarse una demostracion del teorema de bondy-chvatal en [theorem 7.20​].  como todos los grafos completos son hamiltonianos, todos los grafos cuya clausura sea un grafo completo son hamiltonianos. esto nos permite deducir algunas condiciones suficientes para que un grafo sea hamiltoniano; en particular aparece el teorema de ore y el teorema de dirac.  teorema.  si g es un grafo conexo, simple y sin lazos con n vertices, con n ≥ 3, en el cual grado(u) + grado(v) ≥ n para todo par de vertices no adyacentes u, v, entonces g es hamiltoniano.​  se puede consultar una demostracion directa del teorema de ore en [theorem 6.2.5​].  teorema.  si g es un grafo conexo, simple, sin lazos y con n vertices en el cual grado(u) ≥ n/2 para todo vertice u, entonces g es hamiltoniano.​  corolario. si g es un grafo conexo, simple y sin lazos con n vertices, con n ≥ 3, en el cual grado(u) + grado(v) ≥ n − 1 para todo par de vertices no adyacentes u, v, entonces g posee un camino hamiltoniano.  ejemplo. consideremos el siguiente grafo, al que se suele denominar como “grafo casa”, que es claramente hamiltoniano: una consecuencia del teorema de ore es el resultado siguiente. su demostracion puede consultarse en [theorem 6.2.14​].  corolario. si g es un grafo conexo, simple y sin lazos con n vertices, con n ≥ 3, en el cual grado(u) + grado(v) ≥ n − 1 para todo par de vertices no adyacentes u, v, entonces g posee un camino hamiltoniano.  ejemplo. si g es un grafo simple, sin lazos y con n vertices en el cual grado(u) + grado(v) ≥ n − 1 para todo par de vertices u, v, entonces g no es necesariamente hamiltoniano. esto se aprecia en muchos ejemplos; en particular, en los siguientes. para grafos dirigidos mencionemos un resultado de h. meyniel que proporciona tambien una condicion suficiente para que un digrafo fuertemente conexo sea hamiltoniano.  teorema.  si d es un grafo dirigido fuertemente conexo de n vertices en el cual grado(u) + grado(v) ≥ 2n − 1 para toda pareja u, v de vertices no adyacentes entonces d es grafo dirigido hamiltoniano.​ ",
        "snippet": "En teoría de grafos, un camino hamiltoniano en un grafo es un camino (es decir, una sucesión de aristas adyacentes), que visita todos los vértices del grafo una sola vez. Si además el primer y último vértice visitado coincide, el camino es un ciclo hamiltoniano.",
        "enlaces_salientes": [
            "/wiki/Camino_hamiltoniano",
            "/wiki/Camino_hamiltoniano",
            "/wiki/Camino_hamiltoniano",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Grafo",
            "/wiki/Camino_(teor%C3%ADa_de_grafos)",
            "/wiki/NP-completo",
            "/wiki/Lista_de_21_problemas_NP-completos_de_Karp",
            "/wiki/William_Rowan_Hamilton",
            "/wiki/Problema_del_caballo",
            "/wiki/Grafo",
            "/wiki/Grafo_dirigido",
            "/wiki/Ciclo_euleriano",
            "/wiki/Grafo_ciclo",
            "/wiki/Grafo_completo",
            "/wiki/Torneo_(teor%C3%ADa_de_grafos)",
            "/wiki/S%C3%B3lidos_plat%C3%B3nicos",
            "/wiki/Tetraedro",
            "/wiki/Grafo_euleriano",
            "/wiki/Subconjunto",
            "/wiki/V%C3%A9rtice_de_corte",
            "/wiki/V%C3%A1clav_Chv%C3%A1tal",
            "/wiki/Grafo_conexo",
            "/wiki/Componente_fuertemente_conexo",
            "/wiki/Control_de_autoridades",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Funci%C3%B3n_matem%C3%A1tica",
        "titulo": "Función (matemática)",
        "contenido": "en matematica, se dice que una magnitud es funcion de otra si el valor de la primera depende del valor de la segunda. por ejemplo, el area a de un circulo es funcion de su radio r (el valor del area es proporcional al cuadrado del radio, a = π·r2). del mismo modo, la duracion t de un viaje en tren entre dos ciudades separadas por una distancia d depende de la velocidad v a la que se desplace el tren (a saber, la duracion es inversamente proporcional a la velocidad, t = d / v). a la primera magnitud (el area, la duracion) se la denomina variable dependiente, y la magnitud de la que depende (el radio y la velocidad) es la variable independiente.  en analisis matematico, el concepto general de funcion,  se refiere a una regla que asigna a cada elemento de un primer conjunto un unico elemento de un segundo conjunto. las funciones son relaciones entre los elementos de dos conjuntos. por ejemplo, cada numero entero posee un unico cuadrado, que resulta ser un numero natural (incluyendo el cero):​  esta asignacion constituye una funcion entre el conjunto de los numeros enteros z y el conjunto de los numeros naturales n. aunque las funciones que manipulan numeros son las mas conocidas, no son el unico ejemplo: puede imaginarse una funcion que a cada palabra del español le asigne su letra inicial:  esta es una funcion entre el conjunto de las palabras del español y el conjunto de las letras del alfabeto español.  la manera habitual de denotar una funcion f es:  donde a es el dominio de la funcion f; su primer conjunto, o conjunto de partida, y b es el codominio de f; su segundo conjunto, o conjunto de llegada. por f(a) se denota la regla o algoritmo para obtener la imagen de un cierto objeto arbitrario a del dominio a, es decir, el (unico) objeto de b que le corresponde. en ocasiones esta expresion es suficiente para especificar la funcion por completo, infiriendo el dominio y codominio por el contexto. en el ejemplo anterior, las funciones «cuadrado» e «inicial», llameseles f y g , se denotarian entonces como:  si se conviene v = {palabras del español} y a = {alfabeto español}.  una funcion puede representarse de diversas formas: mediante el citado algoritmo o ecuaciones para obtener la imagen de cada elemento, mediante una tabla de valores que empareje cada valor de la variable independiente con su imagen —como las mostradas arriba—, o como una grafica que de una imagen de la funcion.  el concepto de funcion como un objeto matematico independiente, susceptible de ser estudiado por si solo, no aparecio hasta los inicios del calculo en el siglo xvii.​ rene descartes, isaac newton y gottfried leibniz establecieron la idea de funcion como dependencia entre dos cantidades variables. leibniz en particular acuño los terminos «funcion», «variable», «constante» y «parametro». la notacion f(x) fue utilizada por primera vez por el frances alexis claude clairaut, y por el suizo leonhard euler en su obra commentarii de san petersburgo en 1736.​​​  inicialmente, una funcion se identificaba, a efectos practicos, con una expresion analitica que permitia calcular sus valores. sin embargo, esta definicion tenia algunas limitaciones: expresiones distintas pueden arrojar los mismos valores, y no todas las «dependencias» entre dos cantidades pueden expresarse de esta manera. en 1837, el matematico aleman johann peter gustav lejeune dirichlet propuso la definicion moderna de funcion numerica como una correspondencia cualquiera entre dos conjuntos de numeros, que asocia a cada numero en el primer conjunto un unico numero del segundo.  la intuicion sobre el concepto de funcion tambien evoluciono. inicialmente la dependencia entre dos cantidades se imaginaba como un proceso fisico, de modo que su expresion algebraica capturaba la ley fisica que correspondia a este. la tendencia a una mayor abstraccion se vio reforzada a medida que se encontraron ejemplos de funciones sin expresion analitica o representacion geometrica sencillas, o sin relacion con ningun fenomeno natural; y por los ejemplos «patologicos» como funciones continuas sin derivada en ningun punto.  durante el siglo xix los matematicos alemanes julius wilhelm richard dedekind, karl weierstrass y georg cantor, partiendo de un estudio profundo de los numeros reales, desarrollaron la teoria de funciones, siendo esta teoria independiente del sistema de numeracion empleado.[cita requerida] con el desarrollo de la teoria de conjuntos, en los siglos xix y xx surgio la definicion actual de funcion, como una correspondencia entre dos conjuntos de objetos cualesquiera, no necesariamente numericos.​ tambien se asocio con otros conceptos vinculados como el de relacion binaria.  una funcion es un objeto matematico que se utiliza para expresar la dependencia entre dos magnitudes, y puede presentarse a traves de varios aspectos complementarios. un ejemplo habitual de funcion numerica es la relacion entre la posicion y el tiempo en el movimiento de un cuerpo.  un movil que se desplaza con una aceleracion de 0,66 m/s2 recorre una distancia d que esta en funcion del tiempo transcurrido t. se dice que d es la variable dependiente y t la variable independiente. estas magnitudes, calculadas a priori o medidas en un experimento, pueden consignarse de varias maneras. (se supone que el cuerpo parte en un instante en el que se conviene que el tiempo es t = 0 s.)  los valores de las variables pueden recogerse en una tabla, anotando la distancia recorrida d en un cierto instante t, para varios momentos distintos:  la grafica en la imagen es una manera equivalente de presentar la misma informacion. cada punto de la curva roja representa una pareja de datos tiempo-distancia, utilizando la correspondencia entre puntos y coordenadas del plano cartesiano. tambien puede utilizarse una regla o algoritmo que dicte como se ha de calcular d a partir de t. en este caso, la distancia que recorre un cuerpo con esta aceleracion esta dada por la expresion:  donde las magnitudes se expresan unidades del si. de estos tres modos se refleja que existe una dependencia entre ambas magnitudes.  una funcion tambien puede reflejar la relacion de una variable dependiente con varias variables independientes. si el cuerpo del ejemplo se mueve con una aceleracion constante pero indeterminada a, la distancia recorrida es una funcion entonces de a y t; en particular, d = a × t 2 2 }{2}}} . las funciones tambien se utilizan para expresar la dependencia entre otros objetos cualesquiera, no solo los numeros. por ejemplo, existe una funcion que a cada poligono le asigna su numero de lados; o una funcion que a cada dia de la semana le asigna el siguiente:  la definicion general de funcion hace referencia a la dependencia entre los elementos de dos conjuntos dados.  dados dos conjuntos a y b, una funcion (tambien aplicacion o mapeo) entre ellos es una asociacion​ f que a cada elemento de a le asigna un unico elemento de b.  se dice entonces que a es el dominio (tambien conjunto de partida o conjunto inicial) de f y que b es su  codominio (tambien conjunto de llegada o conjunto final).  un objeto o valor generico a en el dominio a se denomina la variable independiente; y un objeto generico b del codominio b es la variable dependiente. tambien se les llama valores de entrada y de salida, respectivamente. esta definicion es precisa, aunque en matematica se utiliza una definicion formal mas rigurosa, que construye las funciones como un objeto concreto a partir de la idea de pares ordenados. es decir, una funcion es un conjunto de pares ordenados en el cual el primer elemento de cada par no se repite.  existen muchos ejemplos de funciones que «necesitan dos valores» para ser calculadas, como la funcion «tiempo de viaje» t, que viene dada por el cociente entre la distancia d y la velocidad media v: cada pareja de numeros reales positivos (una distancia y una velocidad) tiene asociada un numero real positivo (el tiempo de viaje). por tanto, una funcion puede tener dos (o mas) variables independientes.  la nocion de funcion de multiples variables independientes no necesita de una definicion especifica separada de la de funcion «ordinaria». la generalidad de la definicion anterior, en la que se contempla que el dominio sea un conjunto de objetos matematicos arbitrarios, permite omitir la especificacion de dos (o mas) conjuntos de variables independientes, a1 y a2, por ejemplo. en lugar de ello, el dominio se toma como el conjunto de las parejas (a1, a2), con primera componente en a1 y segunda componente en a2. este conjunto se denomina el producto cartesiano de a1 y a2, y se denota por a1 × a2.  de este modo las dos variables independientes quedan reunidas en un solo objeto. por ejemplo, en el caso de la funcion t, su dominio es el conjunto r + ^{+}} × r + ^{+}} , el conjunto de parejas de numeros reales positivos. en el caso de mas de dos variables, la definicion es la misma, usando un conjunto ordenado de multiples objetos, (a1,..., an), una n-tupla. tambien el caso de multiples variables dependientes se contempla de esta manera. por ejemplo, una funcion division puede tomar dos numeros naturales como valores de entrada (dividendo y divisor) y arrojar dos numeros naturales como valores de salida (cociente y resto). se dice entonces que esta funcion tiene como dominio y codominio el conjunto n × n \\times \\mathbb {n} } .  la notacion habitual para presentar una funcion f con dominio a y codominio b es:   f : a ⟶ b a ↦ b = f ( a ) {rrcl}f:&a&\\longrightarrow &b\\\\&a&\\mapsto &b=f(a)\\end{array}}}  tambien se dice que f es una funcion «de a a b» o «entre a y b». el dominio de una funcion f se denota tambien por dom(f), d(f), df, etc. por f(a) se resume la operacion o regla que permite obtener el elemento de b asociado a un cierto a ∈ a, denominado la imagen de a.​  la notacion utilizada puede ser un poco mas laxa, como por ejemplo f ( n ) = n }} . en dicha expresion, no se especifica que conjuntos se toman como dominio y codominio. en general, estos vendran dados por el contexto en el que se especifique dicha funcion. en el caso de funciones de varias variables (dos, por ejemplo), la imagen del par ( a 1 , a 2 ) ,a_{2})} no se denota por f ( ( a 1 , a 2 ) ) ,a_{2}))} , sino por f ( a 1 , a 2 ) ,a_{2})} , y similarmente para mas variables.  existen ademas terminologias diversas en distintas ramas de la matematica para referirse a funciones con determinados dominios y codominios:  tambien las sucesiones infinitas de elementos tales como a, b, c, ... son funciones, cuyo dominio en este caso son los numeros naturales. las palabras «funcion», «aplicacion», «mapeo», u otras como «operador», «funcional», etc., pueden designar tipos concretos de funcion segun el contexto. adicionalmente, algunos autores restringen la palabra «funcion» para el caso en el que los elementos del conjunto inicial y final son numeros.​  los elementos del codominio b asociados con algun elemento del dominio a constituyen la imagen de la funcion.  dada una funcion f : a → b, el elemento de b que corresponde a un cierto elemento a del dominio a se denomina la imagen de a, f(a).  el conjunto de las imagenes de cada elemento del dominio es la imagen de la funcion f (tambien rango o recorrido de f). el conjunto de las imagenes de un subconjunto cualquiera del dominio, x ⊆ a, se denomina la imagen de x.  la imagen de una funcion f se denota por im ( f ) }(f)} o f ( a ) , mientras que la imagen de un subconjunto x ⊆ a se denota, a su vez, por f ( x ) o f [ x ] . en notacion conjuntista las imagenes de f y x se denotan:   im ( f ) = f ( a ) = { b ∈ b : existe a ∈ a tal que f ( a ) = b } f ( x ) = { b ∈ b : existe a ∈ x ⊆ a tal que f ( a ) = b } &}(f)=f(a)=\\{b\\in b:}a\\in a}f(a)=b\\}\\\\&f(x)=\\{b\\in b:}a\\in x\\subseteq a}f(a)=b\\}\\end{aligned}}}  la imagen de una funcion f es un subconjunto del codominio de la misma, pero no son necesariamente iguales: pueden existir elementos en el codominio que no son la imagen de ningun elemento del dominio, es decir, que no tienen preimagen.  la imagen inversa (tambien anti-imagen o preimagen) de un elemento b del codominio b es el conjunto de elementos del dominio a que tienen a b por imagen. se denota por f−1(b).  la imagen inversa de un subconjunto cualquiera del codominio, y ⊆ b, es el conjunto de las preimagenes de cada elemento de y, y se escribe f−1(y).  asi, la preimagen de un elemento del codominio puede no contener ningun objeto o, por el contrario, contener uno o mas objetos, cuando a uno o varios elementos del dominio se les asigna dicho elemento del codominio. en notacion conjuntista, se escriben:   f − 1 ( b ) = { a ∈ a : f ( a ) = b } f − 1 ( y ) = { a ∈ a : existe b ∈ y con f ( a ) = b } &f^{-1}(b)=\\{a\\in a:f(a)=b\\}\\\\&f^{-1}(y)=\\{a\\in a:}b\\in y}f(a)=b\\}\\end{aligned}}}  dadas dos funciones, para que sean identicas han de tener el mismo dominio y codominio, y asignar la misma imagen a cada elemento del dominio:  dadas dos funciones f : a → b y g : c → d, son iguales o identicas si se cumple:  la imagen inversa de un elemento del codominio puede ser vacia, o contener varios objetos del dominio. esto da lugar a la siguiente clasificacion:     si a , a ′ ∈ a y a = a ′ , entonces f ( a ) = f ( a ′ ) }a,a'\\in a}a\\neq a',}f(a)\\neq f(a')}   si a , a ′ ∈ a y f ( a ) = f ( a ′ ) , entonces a = a ′ }a,a'\\in a}f(a)=f(a'),}a=a'}   im ( f ) = b }(f)=b\\!}   para cada b ∈ b existe un a ∈ a con f ( a ) = b }b\\in b}a\\in a}f(a)=b}  las funciones inyectivas no repiten las imagenes: si b = f(a), ningun otro a' tiene por imagen a b, por lo que la anti-imagen de este ultimo solo contiene al elemento a. las funciones suprayectivas recorren todo el codominio, por lo que ninguna anti-imagen puede estar vacia. la definicion de funcion suprayectiva asume que esta tiene un codominio especificado previamente. de lo contrario, la nocion de suprayectividad no tiene sentido.  cuando una funcion tiene ambas propiedades a la vez, se dice que es una biyeccion entre ambos conjuntos:  una funcion f : a → b se dice biyectiva si es inyectiva y suprayectiva.  las funciones biyectivas constituyen un «emparejamiento perfecto» entre los elementos del dominio y el codominio: cada elemento en a tiene una unica «pareja» en b —como todas las funciones—, y a cada elemento de b le corresponde uno solo en a —al menos uno por ser suprayectiva, y como mucho uno por ser inyectiva—.  con las funciones puede realizarse una operacion de composicion con propiedades similares a las de la multiplicacion.  dadas dos funciones, bajo ciertas condiciones podemos usar los valores de salida de una de ellas como valores de entrada para la otra, creando una nueva funcion.  sean dos funciones f : a → b y g : c → d, tales que el recorrido de la primera este contenido en el dominio de la segunda, im(f) ⊆ c. entonces puede formarse la composicion de g con f, la funcion g ∘ f : a → d que a cada a en el dominio a le asocia el elemento (g ∘ f)(a) = g(f(a)).  es decir, la composicion g ∘ f hace actuar primero la funcion f sobre un elemento de a, y luego g sobre la imagen que se obtenga:   x ↦ f ( x ) ↦ g ( f ( x ) )  la condicion im(f) ⊆ c asegura precisamente que este segundo paso se pueda llevar a cabo.  en cualquier conjunto puede definirse una funcion identidad, que teniendo como dominio y codominio al propio conjunto, asocia cada elemento consigo mismo.  dado un conjunto a, la funcion identidad de a es la funcion ida : a → a que a cada a ∈ a le asocia ida(a) = a.  tambien se denota como ia. la funcion identidad actua como un elemento neutro al componer funciones, ya que no «hace nada». la funcion unica sobre un conjunto x que asigna cada elemento a si mismo se denomina funcion de identidad para x y, tipicamente, se indica con idx. cada conjunto tiene su propia funcion de identidad, por lo que el subindice no puede omitirse a menos que el conjunto pueda deducirse del contexto. bajo composicion, una funcion de identidad es «neutral»: si f es cualquier funcion de x a y, entonces:  dada una funcion cualquiera f : a → b se tiene:   f ∘ id a = f id b ∘ f = f &f\\circ }_{a}=f\\\\&}_{b}\\circ f=f\\end{aligned}}}  es decir, dado un elemento x ∈ a, se tiene que:   x ⟼ id a x ⟼ f f ( x ) x ⟼ f f ( x ) ⟼ id b f ( x ) &x\\ }_{a}}}\\ x\\ }\\ f(x)\\\\&x\\ }\\ f(x)\\ }_{b}}}\\ f(x)\\end{aligned}}}  una funcion puede tener inversa, es decir, otra funcion que al componerla con ella resulte en la identidad, del mismo modo que un numero multiplicado por su inverso da 1.  dada una funcion f : a → b, se dice que g : b → a es la inversa o reciproca de f si se cumple:   f ∘ g = id b g ∘ f = id a &f\\circ g=}_{b}\\\\&g\\circ f=}_{a}\\end{aligned}}}  la inversa se denota por g = f−1, y tanto f como f−1 se dicen invertibles.  no todas las funciones son invertibles, sino que solo aquellas que sean biyectivas poseen inversa:  toda funcion biyectiva f es invertible, y su inversa f−1 es biyectiva a su vez. reciprocamente, toda funcion invertible f es biyectiva.  la notacion para funciones inversas puede ser confusa. para un elemento del codominio b, f−1(b) puede denotar tanto la anti-imagen de b (un subconjunto del dominio), como a la imagen de b por la funcion inversa de f (un elemento del dominio), en el caso de que f sea invertible.  la restriccion de una funcion dada es otra funcion definida en una parte del dominio de la original, pero que «actua igual» que esta. se dice tambien que la primera es una extension de la segunda. informalmente, una restriccion de una funcion f es el resultado de recortar su dominio. de manera mas precisa, si s es un subconjunto de x, la restriccion de f a s es la funcion f | s de s a y tal que f | s (s) = f (s) para todo s en s. si g es a restriccion de f, entonces se dice que f es una extension de g.  dadas dos funciones f : a → b y g : c → d, de forma que el dominio de g sea un subconjunto del dominio de f, c ⊆ a, y cuyas imagenes coinciden en este subconjunto:   f ( x ) = g ( x ) , para cada x ∈ c , }x\\in c\\,,}  se dice entonces que g es la restriccion de f al subconjunto c, y que f es una extension de g.  la restriccion de una funcion f: a → b a un subconjunto c ⊆ a se denota por f|c.  las funciones se pueden presentar de distintas maneras:  el conjunto de todas las funciones desde un conjunto x a un conjunto y se denota x -> y, por [x -> y] o por y^x. esta ultima notacion esta motivada por el hecho de que cuando x e y son finitos y de tamaño |x| y |y| entonces el numero de funciones de x -> y es |y^x| = |y|^|x| este es un ejemplo de la convencion de la combinatoria enumerativa que proporciona anotaciones para conjuntos basados en sus cardinalidades. si x es infinito y hay mas de un elemento en y entonces hay innumerables funciones de x a y, aunque solo contablemente muchas de ellas pueden expresarse con una formula o un algoritmo.  un enfoque alternativo para manejar funciones con multiples argumentos es transformarlas en una cadena de funciones que cada una toma un solo argumento. por ejemplo, se puede interpretar add (3,5) para significar \"producir primero una funcion que añade 3 a su argumento, y luego aplicar la funcion 'añadir 3' a 5\". esta transformacion se llama currying: add 3 es curry (add) aplicado a 3. hay una biyeccion entre los espacios de funcion ca × b y (cb) a.  cuando se trabaja con funciones con curry, es habitual usar la notacion de prefijo con la aplicacion de funcion considerada asociativa a la izquierda, ya que la yuxtaposicion de multiples argumentos —como en f(x, y)— normalmente se correlaciona con la evaluacion de una funcion curry. por el contrario, los simbolos → y \"are\" se consideran asociativos a la derecha, de modo que las funciones curry pueden definirse mediante una notacion como f: ℤ → ℤ → ℤ = x ⟼ y ⟼ x · y.  las funciones pueden definirse en terminos de otros objetos matematicos, como los conjuntos y los pares ordenados. en particular, una funcion es un caso particular de relacion binaria, luego esta definicion esta basada en la que se adopte para las relaciones. en el enfoque «extensivo» se identifica una funcion con su grafica:  una funcion es un conjunto f de pares ordenados tal que no contiene dos pares distintos con la misma primera componente:   ( a , b ) , ( a , c ) ∈ f ⇒ b = c  el dominio (la imagen) de la funcion es entonces el conjunto de primeras (segundas) componentes:   dom ( f ) = { a ∈ a : existe b con ( a , b ) ∈ f } im ( f ) = { b ∈ b : existe a con ( a , b ) ∈ f } &}(f)=\\{a\\in a:}b}(a,b)\\in f\\}\\\\&}(f)=\\{b\\in b:}a}(a,b)\\in f\\}\\end{aligned}}}  en la definicion extensiva no aparece el concepto de codominio como conjunto potencial donde esta contenido el recorrido. en algunas areas de la matematica es importante preservar esta distincion, y por tanto se usa una definicion distinta:​  una funcion es una terna de conjuntos f = (a, b, g(f)), el dominio, el codominio y el grafo de f, tales que:  con esta definicion, dos funciones con el mismo grafo son distintas si su codominio no coincide. tambien se habla en ocasiones de funciones parciales, para las que no necesariamente cada elemento del dominio posee una imagen, en contraste con las funciones como se han definido antes, que se denominan totales. a las funciones parciales tambien se las llama correspondencias o relaciones univocas.​ ",
        "snippet": "En matemática, se dice que una magnitud es función de otra si el valor de la primera depende del valor de la segunda. Por ejemplo, el área A de un círculo es función de su radio r (el valor del área es proporcional al cuadrado del radio, A = π·r2). Del mismo modo, la duración T de un viaje en tren entre dos ciudades separadas por una distancia d depende de la velocidad v a la que se desplace el tren (a saber, la duración es inversamente proporcional a la velocidad, T = d / v). A la primera magnitud (el área, la duración) se la denomina variable dependiente, y la magnitud de la que depende (el radio y la velocidad) es la variable independiente.",
        "enlaces_salientes": [
            "/wiki/Funci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Funci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Funci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Grafo_bipartito",
            "/wiki/Relaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Pol%C3%ADgono",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Correspondencia_matem%C3%A1tica",
            "/wiki/Lado_(geometr%C3%ADa)",
            "/wiki/Caja_negra_(sistemas)",
            "/wiki/Grafica_de_una_funcion",
            "/wiki/Prueba_de_la_l%C3%ADnea_vertical",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Magnitud_(matem%C3%A1tica)",
            "/wiki/%C3%81rea",
            "/wiki/C%C3%ADrculo",
            "/wiki/Catenaria",
            "/wiki/Radio_(geometr%C3%ADa)",
            "/wiki/Proporcional",
            "/wiki/Cuadrado_(%C3%A1lgebra)",
            "/wiki/Proporcionalidad",
            "/wiki/Variable_(matem%C3%A1tica)",
            "/wiki/Variable_independiente",
            "/wiki/An%C3%A1lisis_matem%C3%A1tico",
            "/wiki/Correspondencia_matem%C3%A1tica",
            "/wiki/Relaci%C3%B3n_matem%C3%A1tica",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Cuadrado_(%C3%A1lgebra)",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Cero",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Letra",
            "/wiki/Alfabeto_espa%C3%B1ol",
            "/wiki/Dominio_de_una_funci%C3%B3n",
            "/wiki/Codominio",
            "/wiki/Algoritmo",
            "/wiki/Imagen_(matem%C3%A1tica)",
            "/wiki/Ecuaci%C3%B3n",
            "/wiki/Gr%C3%A1fica_de_una_funci%C3%B3n",
            "/wiki/Gottfried_Leibniz",
            "/wiki/C%C3%A1lculo",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Isaac_Newton",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Alexis_Claude_Clairaut",
            "/wiki/Leonhard_Euler",
            "/wiki/Peter_Gustav_Lejeune_Dirichlet",
            "/wiki/F%C3%ADsica",
            "/wiki/Funci%C3%B3n_continua",
            "/wiki/Derivada",
            "/wiki/Funci%C3%B3n_de_Weierstrass",
            "/wiki/Julius_Wilhelm_Richard_Dedekind",
            "/wiki/Karl_Weierstrass",
            "/wiki/Georg_Cantor",
            "/wiki/N%C3%BAmeros_reales",
            "/wiki/Sistema_de_numeraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Relaci%C3%B3n_binaria",
            "/wiki/Gr%C3%A1fica_de_una_funci%C3%B3n",
            "/wiki/Posici%C3%B3n",
            "/wiki/Movimiento_uniformemente_acelerado",
            "/wiki/Posici%C3%B3n",
            "/wiki/Tiempo",
            "/wiki/Movimiento_(f%C3%ADsica)",
            "/wiki/Aceleraci%C3%B3n",
            "/wiki/Tabla_(informaci%C3%B3n)",
            "/wiki/Gr%C3%A1fica_de_una_funci%C3%B3n",
            "/wiki/Coordenadas",
            "/wiki/Plano_cartesiano",
            "/wiki/Algoritmo",
            "/wiki/Sistema_Internacional_de_Unidades",
            "/wiki/Pol%C3%ADgono",
            "/wiki/Pol%C3%ADgono#Elementos_de_un_polígono",
            "/wiki/Definici%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Conjuntos",
            "/wiki/Variable_(matem%C3%A1tica)",
            "/wiki/N%C3%BAmeros_reales",
            "/wiki/Cubo_(%C3%A1lgebra)",
            "/wiki/Elemento_inverso",
            "/wiki/Mam%C3%ADfero",
            "/wiki/G%C3%A9nero_(taxonom%C3%ADa)",
            "/wiki/Homo",
            "/wiki/Sus",
            "/wiki/Loxodonta",
            "/wiki/Tri%C3%A1ngulo",
            "/wiki/%C3%81rea",
            "/wiki/Elecciones",
            "/wiki/Par_ordenado",
            "/wiki/Producto_cartesiano",
            "/wiki/N-tupla",
            "/wiki/Funci%C3%B3n_real",
            "/wiki/Funci%C3%B3n_compleja",
            "/wiki/Funci%C3%B3n_escalar",
            "/wiki/Funci%C3%B3n_vectorial",
            "/wiki/Sucesi%C3%B3n_matem%C3%A1tica",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Operador",
            "/wiki/Conjunto_imagen",
            "/wiki/Votante",
            "/wiki/Partido_pol%C3%ADtico",
            "/wiki/Elecciones",
            "/wiki/Subconjunto",
            "/wiki/Ra%C3%ADz_c%C3%BAbica",
            "/wiki/Canis",
            "/wiki/Funci%C3%B3n_inyectiva",
            "/wiki/Funci%C3%B3n_sobreyectiva",
            "/wiki/Funci%C3%B3n_biyectiva",
            "/wiki/Bos",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Composici%C3%B3n_de_funciones",
            "/wiki/Orden_(biolog%C3%ADa)",
            "/wiki/Guanaco",
            "/wiki/Funci%C3%B3n_identidad",
            "/wiki/Elemento_neutro",
            "/wiki/Funci%C3%B3n_inversa",
            "/wiki/Elemento_inverso",
            "/wiki/Inverso_(multiplicaci%C3%B3n)",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/Divisas",
            "/wiki/Rupia_india",
            "/wiki/Quetzal_(moneda)",
            "/wiki/India",
            "/wiki/Guatemala",
            "/wiki/Restricci%C3%B3n_de_una_funci%C3%B3n",
            "/wiki/Representaci%C3%B3n_gr%C3%A1fica_de_una_funci%C3%B3n",
            "/wiki/Relaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Ecuaci%C3%B3n",
            "/wiki/Par_ordenado",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Gr%C3%A1fica_de_una_funci%C3%B3n",
            "/wiki/Gr%C3%A1fica",
            "/wiki/Funci%C3%B3n_continua",
            "/wiki/C%C3%A1lculo",
            "/wiki/Funci%C3%B3n_discreta",
            "/wiki/Conjunto",
            "/wiki/Par_ordenado",
            "/wiki/Relaci%C3%B3n_binaria",
            "/wiki/Gr%C3%A1fica",
            "/wiki/Codominio",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Funci%C3%B3n_total",
            "/wiki/Correspondencia_matem%C3%A1tica",
            "/wiki/Relaci%C3%B3n_binaria",
            "/wiki/Sucesi%C3%B3n_matem%C3%A1tica",
            "/wiki/Funci%C3%B3n_lineal",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/Funci%C3%B3n_cuadr%C3%A1tica",
            "/wiki/Representaci%C3%B3n_gr%C3%A1fica_de_una_funci%C3%B3n",
            "/wiki/Funci%C3%B3n_multivaluada",
            "/wiki/Curva",
            "/wiki/Academia_Colombiana_de_Ciencias_Exactas,_F%C3%ADsicas_y_Naturales",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Funciones_de_elecci%C3%B3n",
            "/wiki/ISBN",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Problema_abstracto",
        "titulo": "Problema computacional",
        "contenido": "en ciencia computacional teorica, un problema computacional o problema abstracto es una relacion entre un conjunto de instancias y un conjunto de soluciones. un problema abstracto permite establecer formalmente la relacion deseada entre cada instancia del problema y su correspondiente solucion. una solucion algoritmica a un problema abstracto consiste de un algoritmo que por cada instancia del problema calcula al menos una solucion correspondiente –en caso de haberla– o expide un certificado de que no existe solucion alguna. un problema abstracto se convierte en un problema concreto cuando las instancias y soluciones estan codificadas en forma de lenguajes formales.  los problemas abstractos suelen definirse en dos partes: en la primera se describe al conjunto de instancias y en la segunda se describe la solucion esperada para cada instancia. por ejemplo, el problema de ordenacion de numeros enteros se suele definir como sigue:  aqui tanto el conjunto de instancias y el de soluciones es el mismo, pues se trata del conjunto de todas las sucesiones finitas de numeros enteros. la relacion que hay entre ellos asigna a cada sucesion ( a 1 , a 2 , … , a n ) ,a_{2},\\ldots ,a_{n}\\right)} la unica permutacion ( a 1 ′ , a 2 ′ , … , a n ′ ) ^,a_{2}^,\\ldots ,a_{n}^\\right)} tal que a 1 ′ ≤ a 2 ′ ≤ ⋯ ≤ a n ′ ^\\leq a_{2}^\\leq \\cdots \\leq a_{n}^} . por ejemplo, ( 6 , 9 , 4 , 5 ) tiene como solucion a ( 4 , 5 , 6 , 9 ) . una solucion algoritmica al problema de ordenamiento es el ordenamiento de burbuja porque este algoritmo produce una solucion como salida cada vez que se le suministra una instancia como entrada.   en un problema de decision cada instancia tiene asociada exactamente una solucion \"si\" o \"no\". los problemas de decision quedan completamente determinados por el conjunto y de instancias que tienen asociada la solucion \"si\". por ejemplo, el problema de decidir si una grafica tiene o no un ciclo hamiltoniano queda completamente determinado su conjunto de soluciones \"si\":  h a m = { g ∣ g es una grafica hamiltoniana } =\\left\\{g\\mid g}\\right\\}}  con esta representacion el problema equivale a preguntar si una instancia i pertenece o no al conjunto h a m } . en general, los problemas de decision siempre equivalen a decidir la proposicion i ∈ y donde y es el conjunto de instancias con solucion \"si\". una solucion algoritmica para un problema de decision es un algoritmo que calcula la funcion caracteristica de y o equivalente:   χ y ( i ) = { 1 si i ∈ y 0 si i ∈ y (i)=1&}i\\in y\\\\0&}i\\notin y\\end{cases}}}  en los problemas de busqueda la relacion entre el conjunto de instancias y el de soluciones queda determinado por un predicado logico p ( i , s ) que determina si s es una solucion de i . dada una instancia i el problema consiste en encontrar, si es que existe, una solucion s de i . es decir, buscar el elemento s que haga verdadera la proposicion ∃ s ∈ s . p ( i , s ) . cuando se fija el valor de i y la solucion es unica, se dice que es un problema matematico. por ejemplo, el problema de factorizacion de un numero entero n consiste en encontrar un factor no trivial de n ; es decir, numero entero m diferente de 1 y de n tal que m divida exactamente a n . en simbolos   ∃ m ∈ z . m = 1 ∧ m = n ∧ n m ∈ z .m\\neq 1\\wedge m\\neq n\\wedge {m}}\\in \\mathbf {z} }  esta formula simplemente esta preguntando la existencia de un factor no trivial de n . una solucion algoritmica a un problema de busqueda viene dador por un algoritmo f tal que p ( i , f ( i ) ) es verdadera siempre y cuando exista solucion para i , es decir, f siempre calcula una solucion si es que esta existe. en el caso del problema de la factorizacion de enteros se cuenta con el algoritmo de la division por tentativa.  en un problema de optimizacion no solo se busca una solucion, sino que se busca \"la mejor\" de todas. cada problema de optimizacion puede concebirse como un problema de busqueda y una funcion g , comunmente conocida como funcion objetivo, que determina la calidad de las soluciones. el problema de optimizacion (que a su vez es de busqueda) consiste en encontrar la solucion maximice o minimice el valor de g . por ejemplo, el problema del viajante no solamente exige determinar si una grafica tiene o no un ciclo hamiltoniano, sino que ademas pregunta cual es el ciclo hamiltoniano mas corto. en este caso el problema de busqueda subyacente es encontrar un ciclo hamiltoniano cualquiera y la funcion objetivo mide la distancia recorrida por ese ciclo.   ",
        "snippet": "En ciencia computacional teórica, un problema computacional o problema abstracto es una relación entre un conjunto de instancias y un conjunto de soluciones. Un problema abstracto permite establecer formalmente la relación deseada entre cada instancia del problema y su correspondiente solución. Una solución algorítmica a un problema abstracto consiste de un algoritmo que por cada instancia del problema calcula al menos una solución correspondiente –en caso de haberla– o expide un certificado de que no existe solución alguna. Un problema abstracto se convierte en un problema concreto cuando las instancias y soluciones están codificadas en forma de lenguajes formales.",
        "enlaces_salientes": [
            "/wiki/Problema_computacional",
            "/wiki/Problema_computacional",
            "/wiki/Problema_computacional",
            "/wiki/Ciencia_computacional_te%C3%B3rica",
            "/wiki/Relaci%C3%B3n_binaria",
            "/wiki/Lenguaje_formal",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/Problema_de_decisi%C3%B3n",
            "/wiki/Camino_hamiltoniano",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/Problema_matem%C3%A1tico",
            "/wiki/Factorizaci%C3%B3n",
            "/wiki/Divisibilidad",
            "/wiki/Divisi%C3%B3n_por_tentativa",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Problema_del_viajante",
            "/wiki/Thomas_H._Cormen",
            "/wiki/MIT_Press",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Bit",
        "titulo": "Bit",
        "contenido": "en informatica o teoria de la informacion, el bit corresponde a un digito del sistema de numeracion binario y representa la unidad minima de informacion. el termino es un acronimo de binary digit (‘digito binario’; en menor medida llamado bitio).​ la capacidad de almacenamiento de una memoria digital tambien se mide en bits, pues esta palabra tiene varias acepciones.​  lo usual es que un registro digital u otras memorias digitales vinculadas con la computacion y/o con las telecomunicaciones, tengan una capacidad de representacion de informaciones de por ejemplo 8 bits,  16 bits, 32 bits, 64 bits, etc; una memoria binaria tiene una capacidad efectiva de representacion de un bit.​  mientras que en el sistema de numeracion decimal se usan diez digitos (diez simbolos), en el binario se usan solo dos digitos, el 0 y el 1. un bit puede representar uno de esos dos valores: 0 o 1. asi, se puede ejemplificar un bit como una bombilla que puede estar en uno de los siguientes dos estados:  asimismo, un bit puede representar dos valores cualesquiera, como verdadero o falso, abierto o cerrado, blanco o negro, norte o sur, etc.  con un bit podemos representar solamente dos valores o dos diferentes estados, que suelen representarse como 0, 1.​ para representar o codificar mas informacion en un dispositivo digital, necesitamos una mayor cantidad de bits. si usamos dos bits, tendremos cuatro variaciones con repeticion posibles:   v r 2 2 = 2 2 ^{2}=2^{2}}  con estas cuatro variaciones podemos representar hasta cuatro valores o estados diferentes, como por ejemplo, los colores azul, verde, rojo, y magenta.  a traves de secuencias de bits, se puede codificar cualquier valor discreto como numeros, palabras, e imagenes. cuatro bits forman un nibble, y pueden representar hasta 24 = 16 valores diferentes; ocho bits forman un octeto, y se pueden representar hasta 28 = 256 valores diferentes. en general, con un numero n de bits pueden representarse hasta 2n valores o estados diferentes.  nota: un byte y un octeto no son lo mismo. mientras que un octeto siempre tiene 8 bits, un byte contiene un numero fijo de bits, que no necesariamente deben ser 8. en los computadores antiguos, el byte podria estar conformado por 6, 7, 8, o 9 bits. hoy en dia, en la inmensa mayoria de los computadores, y en la mayoria de los campos, un byte tiene 8 bits, siendo equivalente al octeto, pero hay excepciones.​  en cualquier sistema de numeracion posicional, el valor de los digitos depende de la posicion en que se encuentren.  en el sistema decimal, por ejemplo, el digito 5 puede valer 5 si esta en la posicion de las unidades, pero vale 50 si esta en la posicion de las decenas, y 500 si esta en la posicion de las centenas. generalizando, cada vez que nos movemos una posicion hacia la izquierda el digito vale 10 veces mas, y cada vez que nos movemos una posicion hacia la derecha, vale 10 veces menos. esto tambien es aplicable a numeros con decimales.  por ejemplo, el numero 153 , 7 7} puede representarse de la siguiente manera:   153 , 7 = 1 ⋅ 10 2 + 5 ⋅ 10 1 + 3 ⋅ 10 0 + 7 ⋅ 10 − 1 = 100 + 50 + 3 + 0 , 7 7=1\\cdot 10^{2}+5\\cdot 10^{1}+3\\cdot 10^{0}+7\\cdot 10^{-1}=100+50+3+0{,}7}  el sistema binario funciona similarmente, excepto que cada vez que un digito binario (bit) se desplaza una posicion hacia la izquierda vale el doble (2 veces mas), y hacia la derecha vale la mitad (2 veces menos).  por lo tanto, el numero 19 (en binario 10011 ) puede representarse de la siguiente manera:   10011 2 = 1 ⋅ 2 4 + 0 ⋅ 2 3 + 0 ⋅ 2 2 + 1 ⋅ 2 1 + 1 ⋅ 2 0 = 16 + 2 + 1 = 19 =1\\cdot 2^{4}+0\\cdot 2^{3}+0\\cdot 2^{2}+1\\cdot 2^{1}+1\\cdot 2^{0}=16+2+1=19} .  tambien se pueden representar valores fraccionarios. los numeros reales se pueden representar con formato de coma fija o de coma flotante. el numero 5,25 puede representarse en binario de coma fija de la siguiente manera:   4 + 1 + 0 , 25 = 5 , 25  la de arriba es una representacion en coma fija de un numero real en sistema binario. aunque la representacion de numeros reales en coma flotante es diferente de lo que aqui se muestra, el esquema da una idea una parte del concepto. la representacion en coma flotante es similar a la notacion cientifica en una calculadora de mano, solo que en vez numeros decimales se usan numeros binarios y el exponente no esta en base 10 sino en base 2.  cuando se trabaja con varios sistemas de numeracion o cuando no esta claro con cual se esta trabajando, es tipico usar un subindice para indicar el sistema de numeracion con el que se ha representado un numero. el 10 es el subindice para los numeros en el sistema decimal y el 2 para los del sistema binario. en los ejemplos de abajo se muestran dos numeros en el sistema decimal y su equivalente en binario. esta igualdad se representa de la siguiente manera:  un conjunto o grupo de bits, como por ejemplo un byte, representa un conjunto de elementos ordenados. se llama bit mas significativo (msb) al bit que tiene un mayor peso (mayor valor) dentro del conjunto. analogamente, se llama bit menos significativo (lsb) al bit con menor peso dentro del conjunto. por ejemplo, en un octeto el bit mas significativo es el de la posicion 7, y el menos significativo es el de la posicion 0:  tomemos, por ejemplo, el numero decimal 27 en forma de un octeto binario:  aqui, el primer 0, el de la izquierda, (que corresponde con el coeficiente de 27), es el bit mas significativo, siendo el ultimo 1, el de la derecha, (que corresponde con 20), el menos significativo.  en cualquier caso, el bit mas significativo es el que generalmente se representa en el extremo izquierdo y el menos significativo el del extremo derecho. esto es analogo al sistema decimal, en donde el digito mas significativo es el de la izquierda y el menos significativo el de la derecha.  little endian y big endian se refieren al orden que las maquinas asignan a los bytes que representan numeros o valores numericos. una maquina little endian asigna los bytes menos significativos en el extremo mas bajo de la memoria, mientras que una maquina big endian asigna los bytes mas significativos en el extremo mas alto. en los computadores, cada byte se identifica con su posicion en la memoria (direccion). cuando se manejan numeros de mas de un byte, estos bytes tambien deben estar ordenados de menor a mayor, indicando la posicion del byte menos significativo y del byte mas significativo. de este modo, un byte con el numero decimal 27 se almacenaria en una maquina little endian igual que en una maquina big endian, ya que solo ocupa un byte. sin embargo, para numeros mas grandes los bytes que los representan se almacenarian en distinto orden en cada arquitectura. este aspecto es particularmente importante en la programacion en lenguaje ensamblador o en codigo maquina, ya que algunas maquinas consideran el byte situado en la direccion mas baja de la memoria el menos significativo (arquitectura little endian, como los procesadores intel) mientras que otras consideran que ese es el byte mas significativo (arquitectura big endian, como los procesadores motorola).  por ejemplo, consideremos el numero hexadecimal entero aabbccdd, de 32 bits (4 bytes), localizado en la direccion 100 de la memoria. el numero ocuparia las posiciones desde la 100 a la 103, pero dependiendo de si la maquina es little o big endian, los bytes se almacenarian de diferente manera:  little endian (como intel)  big endian (como motorola)  en las imagenes de arriba, en donde se representan las posiciones de memoria 100, 101, 102 y 103 creciendo de izquierda a derecha, «parece» que la representacion big endian es mas natural, ya que el numero aabbccdd lo podemos leer correctamente (ver figura), mientras que en la representacion little endian parece que el numero esta al reves, o «patas arriba». sin embargo, no hay nada que nos impida imaginar que las direcciones de memoria «crecen» de derecha a izquierda, y al observar la memoria de esta manera, la representacion little endian «se ve natural» y es la big endian la que «parece» al reves, como se muestra en las figuras de abajo.  little endian (como intel)  big endian (como motorola)  independiente de si la maquina es de arquitectura little endian o big endian, los bits dentro de cada byte siempre estan en el mismo orden, con el bit mas significativo a la izquierda y el menos significativo a la derecha. los registros del procesador, que pueden ser de 4 a 64 bits, y mas, tambien tienen sus bits en el mismo orden en ambos tipos de maquina. la diferencia entre little y big endian solo existe externamente, en el orden en que los bytes se representan en memoria.  cuando se habla de cpus o microprocesadores de 4, 8, 16, 32, 64 bits, se refiere al tamaño, en numero de bits, que tienen los registros internos del procesador y tambien a la capacidad de procesamiento de la unidad aritmetico logica (alu). un microprocesador de 4 bits tiene registros de 4 bits y la alu hace operaciones con los datos en esos registros de 4 bits, mientras que un procesador de 8 bits tiene registros y procesa los datos en grupos de 8 bits.  los procesadores de 16, 32 y 64 bits tienen registros y alu de 16, 32 y 64 bits respectivamente, y generalmente pueden procesar los datos, tanto en el tamaño en bits de sus registros como, dependiendo de su diseño, en determinados submultiplos de estos. asi, un procesador de 16 bits puede procesar los datos en grupos de 8 y 16 bits, comportandose como si fuera un procesador tanto de 8 como de 16 bits. un procesador de 32 bits puede procesar los datos en grupos de 8, 16 y 32 bits, y el procesador de 64 bits puede procesar los datos en grupos de 8, 16, 32 y 64 bits. para poder hacer esto, los procesadores de 16, 32 y 64 bits generalmente tienen sus registros divididos en otros registros mas pequeños. asi, los registros de un procesador de 32 bits, por ejemplo, pueden estar divididos a su vez en registros de 16 y 8 bits y puede hacer operaciones aritmeticas, logicas, de comparaciones, y otras, con cualquiera de sus registros en cualquiera de estos tamaños.  cuando se habla de procesadores de, digamos 32 bits, nos referimos a su capacidad de procesar datos en hasta 32 bits simultaneamente (tambien puede procesar datos en 8 y 16 bits). la denominacion de \"microprocesador de 32 bits\" no se refiere al tamaño del bus de datos del cpu ni del bus de direcciones, sino a su capacidad de trabajar normalmente con los datos en el numero maximo de bits (salvo alguna excepcion).  por ejemplo, los primeros procesadores de la arquitectura x86, el intel 8086 y el intel 8088, eran procesadores de 16 bits, porque tenian registros de 16 bits (y de 8 bits) y sus unidades aritmetico logicas podian realizar operaciones de 16 bits (y de 8 bits). sin embargo, exteriormente, el 8086 tenia un bus de datos de 16 bits y podia mover datos desde y hacia el cpu en bloques de 8 y 16 bits), mientras que el 8088 tenia un bus de datos de solo 8 bits, y tambien podia mover datos de 8 y 16 bits desde y hacia el cpu, sin embargo, como su bus de datos era de solo 8 bits, para mover 16 bits de datos tenia que hacer dos operaciones de lectura o escritura, de 8 bits, por su limitado bus de datos. esto era completamente transparente, los dos procesadores ejecutaban exactamente el mismo conjunto de instrucciones de 16 bits, solo que el 8088 era mas lento cada vez que tenia que leer o escribir 16 bits de datos hacia o desde la memoria. ",
        "snippet": "En informática o teoría de la información, el bit corresponde a un dígito del sistema de numeración binario y representa la unidad mínima de información. El término es un acrónimo de binary digit (‘dígito binario’; en menor medida llamado bitio).[1]​ La capacidad de almacenamiento de una memoria digital también se mide en bits, pues esta palabra tiene varias acepciones.[2]​",
        "enlaces_salientes": [
            "/wiki/Bit",
            "/wiki/Bit",
            "/wiki/Bit",
            "/wiki/Unidades_de_medida",
            "/wiki/Unidades_de_informaci%C3%B3n",
            "/wiki/Shannon_(unidad)",
            "/wiki/N%C3%BAmero_binario",
            "/wiki/Nat_(unidad)",
            "/wiki/Logaritmo_natural",
            "/wiki/Sistema_ternario",
            "/wiki/Hartley_(unidad)",
            "/wiki/Ban_(informaci%C3%B3n)",
            "/wiki/Dit_(informaci%C3%B3n)",
            "/wiki/Sistema_de_numeraci%C3%B3n_decimal",
            "/wiki/Qubit",
            "/wiki/Informaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Prefijos_del_Sistema_Internacional",
            "/wiki/Sistema_Internacional_de_Unidades",
            "/wiki/Prefijo_binario",
            "/wiki/Kilobit",
            "/wiki/Kilo_(prefijo)",
            "/wiki/Kibibit",
            "/wiki/Megabit",
            "/wiki/Mega_(prefijo)",
            "/wiki/Mebibit",
            "/wiki/Gigabit",
            "/wiki/Giga",
            "/wiki/Gibibit",
            "/wiki/Terabit",
            "/wiki/Tera_(prefijo)",
            "/wiki/Tebibit",
            "/wiki/Petabit",
            "/wiki/Peta_(prefijo)",
            "/wiki/Pebibit",
            "/wiki/Exabit",
            "/wiki/Exa",
            "/wiki/Exbibit",
            "/wiki/Zettabit",
            "/wiki/Zetta",
            "/wiki/Zebibit",
            "/wiki/Yottabit",
            "/wiki/Yotta",
            "/wiki/Yobibit",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Sistema_de_numeraci%C3%B3n",
            "/wiki/Sistema_binario",
            "/wiki/Unidades_de_informaci%C3%B3n",
            "/wiki/Acr%C3%B3nimo",
            "/wiki/Acepci%C3%B3n",
            "/wiki/Sistema_de_numeraci%C3%B3n_decimal",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/Falso_(l%C3%B3gica)",
            "/wiki/Codificaci%C3%B3n_digital",
            "/wiki/Variaci%C3%B3n_(combinatoria)",
            "/wiki/Codificaci%C3%B3n_digital",
            "/wiki/Discreto",
            "/wiki/Nibble",
            "/wiki/Octeto",
            "/wiki/Byte",
            "/wiki/Octeto",
            "/wiki/Sistema_de_numeraci%C3%B3n_posicional",
            "/wiki/Sistema_de_numeraci%C3%B3n_decimal",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Coma_fija",
            "/wiki/Coma_flotante",
            "/wiki/Coma_flotante",
            "/wiki/Byte",
            "/wiki/Bit_m%C3%A1s_significativo",
            "/wiki/Bit_menos_significativo",
            "/wiki/Endianness",
            "/wiki/Byte",
            "/wiki/Memoria_de_computadora",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/C%C3%B3digo_m%C3%A1quina",
            "/wiki/Intel",
            "/wiki/Motorola",
            "/wiki/CPU",
            "/wiki/Microprocesador",
            "/wiki/Unidad_aritm%C3%A9tico_l%C3%B3gica",
            "/wiki/Registro_del_procesador",
            "/wiki/X86",
            "/wiki/Intel_8086",
            "/wiki/Intel_8088",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/Nibble",
            "/wiki/Byte",
            "/wiki/Tipo_de_dato",
            "/wiki/Tipos_de_datos_m%C3%A1quina",
            "/wiki/C%C3%BAbit",
            "/wiki/Sistema_binario",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/Operador_a_nivel_de_bits",
            "/wiki/Registro_de_desplazamiento",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/N%C3%BAmero_natural",
        "titulo": "Número natural",
        "contenido": "en matematicas, un numero natural es cualquiera de los numeros que se usan para contar los elementos de ciertos conjuntos.​​​ los numeros naturales se representan con la ℕ = {1, 2, 3, 4, …}.​ de dos numeros vecinos, el que se encuentra a la derecha se llama siguiente o sucesivo,​ por lo que el conjunto de los numeros naturales es ordenado e infinito.  el conjunto de todos los numeros naturales iguales o menores que cierto numero natural k , es decir, el conjunto { 1 , 2 , … , k − 1 , k } } , se llama segmento de una sucesion natural y se denota | 1 , k | o bien [ k ] .​  puesto que los numeros naturales se utilizan para contar elementos —6 niños en fila—, o numerarlos —el niño 6 de la fila—, el cero no es un numero natural. sin embargo, se hizo necesario considerar el numero que corresponde a la ausencia de los mismos. asi, dependiendo del area de la ciencia, el conjunto de los numeros naturales puede presentarse entonces de dos maneras distintas:  n = {1, 2, 3, 4,... }  n = {0, 1, 2, 3, 4,... }  historicamente, el uso del cero como numeral fue introducido en europa en el siglo xii. esto no quiere decir que antes no se utilizara el numero cero como numeral, ya que con la invencion del sistema de numeracion hindi, se incluyo el numero cero como numeral, que tambien se usaba en la numeracion maya. con el tiempo, el sistema de numeracion hindi tambien fue usado por los arabes; de este hecho viene que pasara de llamarse sistema de numeracion hindi a denominarse sistema de numeracion arabigo-indico. con la conquista musulmana de la peninsula iberica en el siglo xii, el sistema de numeracion arabigo-indico empezo a usarse en europa y paso a llamarse sistema de numeracion arabigo-indico occidental o sistema de numeracion decimal, el cual incluye el cero como numeral, pero aun asi no se consideraba a este como un numero natural.  sin embargo, con el desarrollo de la teoria de conjuntos en el siglo xix, el cero se incluyo en las definiciones conjuntistas de los numeros naturales. esta convencion prevalece en dicha disciplina,​ y en otras, como la teoria de la computacion.​ en particular, el estandar din 5473 adopta esta definicion.​ sin embargo, en la actualidad ambos convenios conviven.​  para distinguir ambas definiciones a veces se introducen simbolos distintos. por ejemplo, si no se incluye el cero en los naturales, al conjunto de los numeros naturales sin el cero se les llama conjunto de los enteros positivos y se lo denota como n 1 _{1}} , n + ^{+}} , o n ∗ ^{*}} .​  por el contrario, cuando el 0 se considera un numero natural (cosa que es conveniente, por ejemplo, en divisibilidad y teoria de numeros), al conjunto de los naturales con el cero se lo llama conjunto de los numeros cardinales y se lo denota n 0 _{0}} .  antes de que surgieran los numeros naturales para la representacion de cantidades, las personas usaban otros metodos para contar, utilizando para ello objetos como piedras, palitos de madera, nudos de cuerdas, o simplemente los dedos (ver sistema de numeracion unario). mas adelante comenzaron a aparecer los simbolos graficos como señales para contar, por ejemplo marcas en una vara o simplemente trazos especificos sobre la arena (vease hueso de ishango). pero fue en mesopotamia alrededor del año 4000 a. c. donde aparecen los primeros vestigios de los numeros que consistieron en grabados de señales en forma de cuñas sobre pequeños tableros de arcilla empleando para ello un palito aguzado. de aqui el nombre de escritura cuneiforme. este sistema de numeracion fue adoptado mas tarde, aunque con simbolos graficos diferentes, en la grecia antigua y en la antigua roma. en la grecia antigua se empleaban simplemente las letras de su alfabeto, mientras que en la antigua roma, ademas de las letras, se utilizaron algunos simbolos.  quien coloco al conjunto de los numeros naturales sobre lo que comenzaba a ser una base solida, fue richard dedekind en el siglo xix. este los derivo de una serie de postulados (lo que implicaba que la existencia del conjunto de numeros naturales se daba por cierta), que despues preciso peano dentro de una logica de segundo orden, resultando asi los famosos cinco postulados que llevan su nombre. frege fue superior a ambos, demostrando la existencia del sistema de numeros naturales partiendo de principios mas fuertes. lamentablemente, la teoria de frege perdio, por asi decirlo, su credibilidad, y hubo que buscar un nuevo metodo. fue zermelo quien demostro la existencia del conjunto de los naturales, dentro de su teoria de conjuntos y principalmente mediante el uso del axioma de infinitud, con una modificacion de este hecha por adolf fraenkel, permite construir el conjunto de numeros naturales como ordinales segun von neumann.  algunas caracteristicas de los numeros naturales son:  historicamente, se han realizado propuestas para axiomatizar la nocion habitual de numeros naturales, de entre las que destacan las de peano y la construccion a partir de la teoria de conjuntos.  el sistema de peano ha sido simplificado.​  con teoria de conjuntos se define al conjunto de los numeros naturales como el minimo conjunto que es inductivo. la idea es que se pueda contar haciendo una biyeccion desde un numero natural hasta el conjunto de objetos que se quiere contar. es decir, para dar la definicion de numero 2, se requiere dar un ejemplo de un conjunto que contenga precisamente dos elementos. esta definicion fue proporcionada por bertrand russell, y mas tarde simplificada por von neumann quien propuso que el candidato para 2 fuera el conjunto que contiene solo a 1 y a 0.  formalmente, un conjunto x se dice que es un numero natural si cumple:  se intenta pues, definir un conjunto de numeros naturales donde cada elemento respete las convenciones anteriores. primero se busca un conjunto que sea el representante del 0, lo cual es facil, ya que sabemos que ∅ no contiene elementos. luego se definen los siguientes elementos de una manera ingeniosa con el uso del concepto de sucesor.  se define —segun halmos— entonces que el conjunto vacio es un numero natural que se denota por 0 y que cada numero natural n tiene un sucesor denotado como n+. estas ideas quedan formalizadas mediante las siguientes expresiones:  de esta manera, cada elemento de algun numero natural es un numero natural; a saber, un antecesor de el. por ejemplo:  esto permite establecer una relacion de orden entre los elementos del conjunto a pesar de que un conjunto es por naturaleza un agregado de elementos desordenados. se define esta relacion mediante la expresion:  es decir que un numero a es menor o igual que b si y solo si b contiene a todos los elementos de a.  tambien se puede usar otra definicion mas inmediata a partir del hecho de que cada numero natural consta de sus antecesores. asi a < b si y solo si a ∈ b.  esa es la construccion formal de los naturales que garantiza su existencia como conjunto a la luz del desarrollo axiomatico zermelo-fraenkel. el postulado de los conjuntos infinitos asegura la validez de la tecnica de demostracion conocida como induccion matematica.  un teorema demuestra que cualquier conjunto que sea inductivo contiene a todos los numeros naturales, es decir que si a es un conjunto inductivo, entonces ℕ ⊆ a. esto significa que, en efecto, ℕ es el minimo conjunto inductivo.  se define la suma por induccion mediante:  lo que convierte a los numeros naturales (ℕ, +) en un monoide conmutativo con elemento neutro 0, el llamado monoide libre con un generador. este monoide satisface la propiedad cancelativa y por lo tanto puede incluirse en un grupo matematico. el menor grupo que contiene a los naturales es el de los numeros enteros.  de manera analoga, la multiplicacion × se define mediante las expresiones:  esto convierte (ℕ, ×) (esto es, ℕ con esta nueva operacion), en un monoide conmutativo.  otra forma de construccion de ℕ es la siguiente: sea ℱ la clase de todos los conjuntos y definiremos una relacion binaria r \"ser equipotente\" de la siguiente manera: dados a y b ∈ ℱ se dice que a r b ↔ existe una aplicacion biyectiva de a sobre b, es decir, existe f : a → b biyectiva. claramente se puede demostrar que esta relacion verifica las propiedades reflexiva, simetrica y transitiva luego es una relacion de equivalencia al conjunto cociente ℱ/r = {[a]/a ∈ ℱ} los llamaremos cardinales y a los cardinales finitos se les llamara numeros naturales.las operaciones de suma y producto de cardinales se definen como el cardinal de la union y el producto cartesiano de los conjuntos representantes y verifica todas las propiedades para que (ℕ, +, ×) sea un semianillo conmutativo y unitario.  las operaciones matematicas que se definen en el conjunto de los numeros naturales son la suma y la multiplicacion.  la suma y la multiplicacion de numeros naturales son operaciones conmutativas y asociativas, es decir:  al construir la operacion de multiplicacion de numeros naturales, se puede observar claramente que la adicion o suma y la multiplicacion son operaciones compatibles, pues la multiplicacion seria una adicion de cantidades iguales y gracias a esta compatibilidad se puede desarrollar la propiedad distributiva, que se expresa de la forma:  aparte, estas dos operaciones cumplen con las propiedades de:  los numeros naturales estan totalmente ordenados. la relacion de orden ≤ se puede redefinir asi: a ≤ b si y solo si existe otro numero natural c que cumple a + c = b. este orden es compatible con todas las operaciones aritmeticas puesto que si a, b y c son numeros naturales y a ≤ b, entonces se cumple:  una propiedad importante del conjunto de los numeros naturales es que es un conjunto bien ordenado  en los numeros naturales existe el algoritmo de la division. dados dos numeros naturales a y b, si b = 0, podemos encontrar otros dos numeros naturales q y r, denominados cociente y resto respectivamente, tales que:  los numeros q y r estan univocamente determinados por a y b.  otras propiedades mas complejas de los numeros naturales, como la distribucion de los numeros primos por ejemplo, son estudiadas por la teoria de numeros.  la relacion sucesor le da una estructura de orden.​   ℵ 0 < ω 0 <\\omega _{0}}  los numeros naturales, son usados para dos propositos fundamentalmente: para describir la posicion de un elemento en una secuencia ordenada, como se generaliza con el concepto de numero ordinal, y para especificar el tamaño de un conjunto infinito, que a su vez se generaliza en el concepto de numero cardinal. en el mundo de lo finito, ambos conceptos son coincidentes: los ordinales infinitos son iguales a n asi como los cardinales infinitos. cuando nos movemos mas alla de lo infinito, ambos conceptos son diferentes.  asumase que ℕ = {0, 1, 2, 3, ...} y sea h = {(m, n) / m, n ∈ ℕ; m ≥ n}, sea g una aplicacion de h en ℕ, tal que g(m, n) = m - n = d ↔ m = d + n, donde m, n estan en h y d esta en ℕ. a la aplicacion g de h sobre ℕ se llama sustraccion  o resta en ℕ. la diferencia d = m - n, solo es posible en el caso de que m ≥ n.  en el conjunto ℕ de los naturales cabe la topologia discreta y la cofinita, tambien alguna topologia de orden.​  es un teorema vinculado al sistema de los numeros naturales y sus ampliaciones aplicativas. esta proposicion expresa que las propiedades de calculo usuales para los numeros naturales, tambien son legitimas para los numeros estructurados mediante operaciones inversas. como ejemplo: segun el principio de permanencia, las propiedades de la potenciacion siguen validas aun en el caso de numeros con exponentes fraccionarios. ",
        "snippet": "En matemáticas, un número natural es cualquiera de los números que se usan para contar los elementos de ciertos conjuntos.[1]​[2]​[2]​ Los números naturales se representan con la ℕ = {1, 2, 3, 4, …}.[3]​ De dos números vecinos, el que se encuentra a la derecha se llama siguiente o sucesivo,[4]​ por lo que el conjunto de los números naturales es ordenado e infinito.",
        "enlaces_salientes": [
            "/wiki/N%C3%BAmero_natural",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Numerable",
            "/wiki/Conjunto",
            "/wiki/Cero",
            "/wiki/Numeraci%C3%B3n_india",
            "/wiki/Numeraci%C3%B3n_maya",
            "/wiki/N%C3%BAmeros_ar%C3%A1bigos",
            "/wiki/Sistema_de_numeraci%C3%B3n_decimal",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/DIN",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/Divisibilidad",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/N%C3%BAmeros_cardinales",
            "/wiki/Hueso_de_Ishango",
            "/wiki/Real_Instituto_Belga_de_Ciencias_Naturales",
            "/wiki/N%C3%BAmeros",
            "/wiki/Cuenta_(matem%C3%A1ticas)",
            "/wiki/Piedra",
            "/wiki/Madera",
            "/wiki/Nudo_(lazo)",
            "/wiki/Dedos",
            "/wiki/Sistema_de_numeraci%C3%B3n_unario",
            "/wiki/Contar",
            "/wiki/Hueso_de_Ishango",
            "/wiki/Mesopotamia",
            "/wiki/Arcilla",
            "/wiki/Escritura_cuneiforme",
            "/wiki/Grecia_Antigua",
            "/wiki/Antigua_Roma",
            "/wiki/Letra",
            "/wiki/Alfabeto",
            "/wiki/Richard_Dedekind",
            "/wiki/Peano",
            "/wiki/Frege",
            "/wiki/Zermelo",
            "/wiki/Conjunto",
            "/wiki/Axioma",
            "/wiki/Adolf_Fraenkel",
            "/wiki/N%C3%BAmero_ordinal_(teor%C3%ADa_de_conjuntos)",
            "/wiki/Von_Neumann",
            "/wiki/Giuseppe_Peano",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Axiomas_de_Peano",
            "/wiki/Sucesor",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Funci%C3%B3n_biyectiva",
            "/wiki/Bertrand_Russell",
            "/wiki/Von_Neumann",
            "/wiki/Paul_Halmos",
            "/wiki/Relaci%C3%B3n_de_orden",
            "/wiki/Conjunto",
            "/wiki/Bicondicional",
            "/wiki/Sistema_formal",
            "/wiki/Axioma",
            "/wiki/Axiomas_de_Zermelo-Fraenkel",
            "/wiki/Postulado",
            "/wiki/Inducci%C3%B3n_matem%C3%A1tica",
            "/wiki/Suma",
            "/wiki/Inducci%C3%B3n_matem%C3%A1tica",
            "/wiki/Monoide",
            "/wiki/Elemento_neutro",
            "/wiki/Cancelativo",
            "/wiki/Grupo_(matem%C3%A1tica)",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Semianillo",
            "/wiki/Operaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Suma",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Conmutatividad",
            "/wiki/Asociatividad_(%C3%A1lgebra)",
            "/wiki/Propiedad_distributiva",
            "/wiki/Operaci%C3%B3n_interna",
            "/wiki/Elemento_neutro",
            "/wiki/Divisor_de_cero",
            "/wiki/Orden_total",
            "/wiki/Conjunto_bien_ordenado",
            "/wiki/Algoritmo_de_la_divisi%C3%B3n",
            "/wiki/N%C3%BAmero_primo",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Semigrupo",
            "/wiki/N%C3%BAmero_ordinal_(teor%C3%ADa_de_conjuntos)",
            "/wiki/N%C3%BAmero_cardinal",
            "/wiki/Mundo",
            "/wiki/Infinito",
            "/wiki/Relaci%C3%B3n_de_equivalencia",
            "/wiki/Virgulilla#Matemática",
            "/wiki/Bicondicional",
            "/wiki/Aproximaci%C3%B3n#Matemáticas",
            "/wiki/Bicondicional",
            "/wiki/Relaci%C3%B3n_de_equivalencia",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Wikcionario",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/N%C3%BAmero_primo",
            "/wiki/N%C3%BAmero_primo_pitag%C3%B3rico",
            "/wiki/N%C3%BAmero_par",
            "/wiki/N%C3%BAmero_impar",
            "/wiki/N%C3%BAmero_triangular",
            "/wiki/N%C3%BAmero_perfecto",
            "/wiki/N%C3%BAmero_abundante",
            "/wiki/N%C3%BAmero_defectivo",
            "/wiki/N%C3%BAmero_capic%C3%BAa",
            "/wiki/Sucesi%C3%B3n_matem%C3%A1tica",
            "/wiki/N%C3%BAmero",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/N%C3%BAmero_real",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Cero",
            "/wiki/N%C3%BAmero_negativo",
            "/wiki/Fracci%C3%B3n",
            "/wiki/N%C3%BAmero_irracional",
            "/wiki/N%C3%BAmero_imaginario",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/MathWorld",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Sistema_binario",
        "titulo": "Sistema binario",
        "contenido": "el sistema binario, tambien  llamado sistema diadico​ en ciencias de la computacion, es un sistema de numeracion en el que los numeros son representados utilizando unicamente dos cifras: 0 (cero) y 1 (uno). es uno de los sistemas que se utilizan en las computadoras, debido a que estas trabajan internamente con dos niveles de voltaje (0 apagado, 1 conectado), por lo cual su sistema de numeracion natural es el sistema binario.​  el sistema numerico binario moderno fue estudiado en europa en los siglos xvi y xvii por thomas harriot, juan caramuel lobkowitz y  gottfried leibniz. sin embargo, los sistemas relacionados con numeros binarios han aparecido antes en multiples culturas, incluido el antiguo egipto, china e india. leibniz se inspiro especificamente en el i ching chino.  los escribas del antiguo egipto usaban dos sistemas diferentes para sus fracciones, las fracciones egipcias (no relacionadas con el sistema numerico binario) y las fracciones del ojo de horus (llamadas asi porque muchos historiadores de las matematicas creen que los simbolos usados para este sistema podrian organizarse para formar el ojo de horus, aunque esto ha sido discutido). las fracciones del ojo de horus son un sistema de numeracion binaria para cantidades fraccionarias de granos, liquidos u otras medidas, en el que una fraccion de hekat se expresa como una suma de las fracciones binarias 1/2, 1/4, 1/8, 1/16, 1/32 y 1/64. las primeras formas de este sistema se pueden encontrar en documentos de la quinta dinastia de egipto, aproximadamente en el 2400 a. c., y su forma jeroglifica completamente desarrollada data de la decimonovena dinastia de egipto, aproximadamente en el 1200 a.​  en la antigua china, en el texto clasico del i ching, se describe una serie completa de 8 trigramas y 64 hexagramas (analogos a 3 bits) y numeros binarios de 6 bits.​  el erudito y filosofo chino shao yong en el siglo xi desarrollo un arreglo binario ordenado de los hexagramas del i ching, representando la secuencia decimal de 0 a 63, y un metodo para generar el mismo.​  el antiguo matematico indio pingala desarrollo un sistema binario para describir la prosodia. utilizo numeros binarios en forma de silabas cortas y largas (estas ultimas iguales en longitud a dos silabas cortas), haciendolo similar al codigo morse. eran conocidas como silabas laghu (ligeras) y guru (pesadas).​  los residentes de la isla de mangareva en la polinesia francesa usaban un sistema hibrido binario-decimal antes de 1450.​ tambien han sido utilizadas series similares de combinaciones binarias en sistemas de adivinacion tradicionales africanos, como el ifa, asi como en la geomancia medieval occidental.​  en 1605 francis bacon hablo de un sistema por el cual las letras del alfabeto podrian reducirse a secuencias de digitos binarios, las cuales podrian ser codificadas como variaciones apenas visibles en la fuente de cualquier texto arbitrario.  en 1670 juan caramuel publica su libro mathesis biceps; y en las paginas xlv a xlviii da una descripcion del sistema binario.  el sistema binario moderno fue documentado en su totalidad por leibniz, en el siglo xviii, en su articulo \"explication de l'arithmetique binaire\". en el se mencionan los simbolos binarios usados por matematicos chinos. leibniz utilizo un sistema matematico de dos variables - 0/1 - para transformar terminos linguisticos y, de esta manera, distribuir informacion, al igual que el sistema binario actual​.  en 1854, el matematico britanico george boole publico un articulo que marco un antes y un despues, detallando un sistema de logica que terminaria denominandose algebra de boole. dicho sistema desempeñaria un papel fundamental en el desarrollo del sistema binario actual, particularmente en el desarrollo de circuitos electronicos.  en 1937, claude shannon realizo su tesis doctoral en el mit, en la cual implantaba el algebra de boole y la aritmetica binaria utilizando reles y conmutadores por primera vez en la historia. titulada un analisis simbolico de circuitos conmutadores y reles, la tesis de shannon basicamente fundo el diseño practico de circuitos digitales.  en noviembre de 1937, george stibitz, trabajando por aquel entonces en los laboratorios bell, construyo una calculadora basada en reles —a la cual apodo \"modelo k\" (porque la construyo en una cocina, en ingles \"kitchen\")— que utilizaba la suma binaria para realizar los calculos. los laboratorios bell autorizaron un completo programa de investigacion a finales de 1939, con stibitz al mando.  el 8 de enero de 1940 terminaron el diseño de una \"calculadora de numeros complejos\", la cual era capaz de realizar calculos con numeros complejos. en una demostracion en la conferencia de la sociedad estadounidense de matematica, el 11 de septiembre de 1940, stibitz logro enviar comandos de manera remota a la calculadora de numeros complejos a traves de la linea telefonica mediante un teletipo. fue la primera maquina computadora utilizada de manera remota a traves de la linea de telefono. algunos participantes de la conferencia que presenciaron la demostracion fueron john von neumann, john mauchly y norbert wiener, quien escribio acerca de dicho suceso en sus diferentes tipos de memorias en la cual alcanzo diferentes logros.  en el sistema binario solo se necesitan dos cifras.  en informatica, un numero binario puede ser representado por cualquier secuencia de bits (digitos binarios), que suelen representar cualquier mecanismo capaz de usar dos estados mutuamente excluyentes. las siguientes secuencias de simbolos podrian ser interpretadas como el mismo valor numerico binario:  el valor numerico representado en cada caso depende del valor asignado a cada simbolo. en una computadora, los valores numericos pueden representar dos voltajes diferentes; tambien pueden indicar polaridades magneticas sobre un disco magnetico. un \"positivo\", \"si\", o \"sobre el estado\" no es necesariamente el equivalente al valor numerico de uno; esto depende de la nomenclatura usada.  de acuerdo con la representacion mas habitual, que es usando numeros arabigos, los numeros binarios comunmente son escritos usando los simbolos 0 y 1. los numeros binarios se escriben a menudo con subindices, prefijos o sufijos para indicar su base. las notaciones siguientes son equivalentes:  se divide el numero del sistema decimal entre 2, cuyo resultado entero se vuelve a dividir entre 2, y asi sucesivamente hasta que el dividendo sea menor que el divisor, 2. es decir, cuando el numero a dividir sea 1 finaliza la division. a continuacion se ordena desde el ultimo cociente hasta el primer resto, simplemente se colocan en orden inverso a como aparecen en la division. este sera el numero binario que buscamos.  -> ordenamos los residuos, del ultimo al primero: 10000011 en sistema binario, 131 se escribe 10000011.    otra forma de conversion consiste en un metodo parecido a la factorizacion en numeros primos. es relativamente facil dividir cualquier numero entre 2. este metodo consiste tambien en divisiones sucesivas. dependiendo de si el numero es par o impar, colocaremos un cero o un uno en la columna de la derecha. si es impar, le restaremos uno y seguiremos dividiendo entre dos, hasta que ya no sea posible y se coloca el numero 1. despues solo nos queda tomar el ultimo resultado de la columna izquierda y todos los de la columna de la derecha y ordenar los digitos de abajo arriba.  ejemplo​  para convertir al sistema binario el numero decimal 77 haremos una serie de divisiones que arrojaran los siguientes resultados:  existe un ultimo metodo denominado de distribucion. consiste en distribuir los unos necesarios entre las potencias sucesivas de 2 de modo que su suma resulte ser el numero decimal a convertir. sea por ejemplo el numero 151, para el que se necesitaran las 8 primeras potencias de 2, ya que la siguiente, 28=256, es superior al numero a convertir. se comienza poniendo un 1 en 128, por lo que aun faltaran 23, 151-128 = 23, para llegar al 151. este valor se conseguira distribuyendo unos entre las potencias cuya suma de el resultado buscado y poniendo ceros en el resto. en el ejemplo resultan ser las potencias 4, 2, 1 y 0, esto es, 16, 4, 2 y 1, respectivamente.  para transformar un numero del sistema decimal al sistema binario:    para realizar la conversion de binario a decimal, realice lo siguiente:  ejemplos:   1 5 1 4 0 3 1 2 0 1 1 0 2 = 1 ⋅ 2 5 + 1 ⋅ 2 4 + 0 ⋅ 2 3 + 1 ⋅ 2 2 + 0 ⋅ 2 1 + 1 ⋅ 2 0 = 32 + 16 + 0 + 4 + 0 + 1 = 53 }}\\, }}\\, }}\\, }}\\, }}\\, }}\\,_{2}=1\\cdot 2^{5}+1\\cdot 2^{4}+0\\cdot 2^{3}+1\\cdot 2^{2}+0\\cdot 2^{1}+1\\cdot 2^{0}=32+16+0+4+0+1=53}   1 7 0 6 0 5 1 4 0 3 1 2 1 1 1 0 2 = 1 ⋅ 2 7 + 0 ⋅ 2 6 + 0 ⋅ 2 5 + 1 ⋅ 2 4 + 0 ⋅ 2 3 + 1 ⋅ 2 2 + 1 ⋅ 2 1 + 1 ⋅ 2 0 = 128 + 0 + 0 + 16 + 0 + 4 + 2 + 1 = 151 }}\\, }}\\, }}\\, }}\\, }}\\, }}\\, }}\\, }}\\,_{2}=1\\cdot 2^{7}+0\\cdot 2^{6}+0\\cdot 2^{5}+1\\cdot 2^{4}+0\\cdot 2^{3}+1\\cdot 2^{2}+1\\cdot 2^{1}+1\\cdot 2^{0}=128+0+0+16+0+4+2+1=151}   1 5 1 4 0 3 1 2 1 1 1 0 2 = 1 ⋅ 2 5 + 1 ⋅ 2 4 + 0 ⋅ 2 3 + 1 ⋅ 2 2 + 1 ⋅ 2 1 + 1 ⋅ 2 0 = 32 + 16 + 0 + 4 + 2 + 1 = 55 }}\\, }}\\, }}\\, }}\\, }}\\, }}\\,_{2}=1\\cdot 2^{5}+1\\cdot 2^{4}+0\\cdot 2^{3}+1\\cdot 2^{2}+1\\cdot 2^{1}+1\\cdot 2^{0}=32+16+0+4+2+1=55}  tambien se puede optar por utilizar los valores que presenta cada posicion del numero binario a ser transformado, comenzando de derecha a izquierda, y sumando los valores de las posiciones que tienen un 1.  el numero binario 1010010 corresponde en decimal al 82. se puede representar de la siguiente manera:   1 64 0 32 1 16 0 8 0 4 1 2 0 1 2 }}\\, }}\\, }}\\, }}\\, }}\\, }}\\, }}\\,_{2}}  entonces se suman los numeros 64, 16 y 2:   1 64 0 32 1 16 0 8 0 4 1 2 0 1 2 = 64 + 16 + 2 = 82 }}\\, }}\\, }}\\, }}\\, }}\\, }}\\, }}\\,_{2}=64+16+2=82}  para cambiar de binario con decimales a decimal se hace exactamente igual, salvo que la posicion cero (en la que el dos es elevado a la cero) es la que esta a la derecha de la coma y se cuenta hacia la izquierda a partir de -1:   1 5 1 4 0 3 1 2 0 1 1 0 , 1 − 1 0 − 2 1 − 3 = 1 ⋅ 2 5 + 1 ⋅ 2 4 + 0 ⋅ 2 3 + 1 ⋅ 2 2 + 0 ⋅ 2 1 + 1 ⋅ 2 0 + 1 ⋅ 2 − 1 + 0 ⋅ 2 − 2 + 1 ⋅ 2 − 3 = = 32 + 16 + 0 + 4 + 0 + 1 + 1 2 1 + 0 2 2 + 1 2 3 = 32 + 16 + 0 + 4 + 0 + 1 + 0 , 5 + 0 + 0 , 125 = 53 , 625 & }}\\, }}\\, }}\\, }}\\, }}\\, }}\\,, }}\\, }}\\, }}\\,=1\\cdot 2^{5}+1\\cdot 2^{4}+0\\cdot 2^{3}+1\\cdot 2^{2}+0\\cdot 2^{1}+1\\cdot 2^{0}+1\\cdot 2^{-1}+0\\cdot 2^{-2}+1\\cdot 2^{-3}=\\\\&=32+16+0+4+0+1+{2^{1}}}+{2^{2}}}+{2^{3}}}=32+16+0+4+0+1+0,5+0+0,125=53,625\\\\\\end{aligned}}}  1. inicie por el lado izquierdo (la primera cifra a la derecha de la coma), cada numero debera ser multiplicado por 2 elevado a la potencia consecutiva a la inversa (comenzando por la potencia -1, 2-1).  2. despues de realizar cada una de las multiplicaciones, sume todas y el numero resultante sera el equivalente al sistema decimal.  la tabla de sumar para numeros binarios es la siguiente:  las posibles combinaciones al sumar dos bits son:  note que al sumar 1 + 1 es 102, es decir, llevamos 1 a la siguiente posicion de la izquierda (acarreo). esto es equivalente en el sistema decimal a sumar 9 + 1, que da 10: cero en la posicion que estamos sumando y un 1 de acarreo a la siguiente posicion.  se puede convertir la operacion binaria en una operacion decimal, resolver la decimal, y despues transformar el resultado en un (numero) binario. operamos como en el sistema decimal: comenzamos a sumar desde la derecha, en nuestro ejemplo, 1 + 1 = 10, entonces escribimos 0 en la fila del resultado y llevamos 1 (este \"1\" se llama acarreo o arrastre). a continuacion se suma el acarreo a la siguiente columna: 1 + 0 + 0 = 1, y seguimos hasta terminar todas las columnas (exactamente como en decimal).​  el algoritmo de la resta en sistema binario es el mismo que en el sistema decimal. pero conviene repasar la operacion de restar en decimal para comprender la operacion binaria, que es mas sencilla. los terminos que intervienen en la resta se llaman minuendo, sustraendo y diferencia.  las restas basicas 0 - 0, 1 - 0 y 1 - 1 son evidentes:  la resta 0 - 1 se resuelve igual que en el sistema decimal, tomando una unidad prestada de la posicion siguiente: 0 - 1 = 1 y me llevo 1 (este valor se resta al resultado que obtenga, entre el minuendo y el sustraendo de la siguiente columna), lo que equivale a decir en el sistema decimal, 2 - 1 = 1.  en sistema decimal seria: 17 - 10 = 7 y 217 - 171 = 46.  para simplificar las restas y reducir la posibilidad de cometer errores hay varios metodos:  la siguiente resta, 91 - 46 = 45, en binario es:  en el resultado nos sobra un bit, que se desborda por la izquierda. pero, como el numero resultante no puede ser mas largo que el minuendo, el bit sobrante se desprecia.  un ultimo ejemplo: vamos a restar 219 - 23 = 196, directamente y utilizando el complemento a dos:  y, despreciando el bit que se desborda por la izquierda, llegamos al resultado correcto: 11000100 en binario, 196 en decimal.  la tabla de multiplicar para numeros binarios es la siguiente:  el algoritmo del producto en binario es igual que en numeros decimales; aunque se lleva a cabo con mas sencillez, ya que el 0 multiplicado por cualquier numero da 0, y el 1 es el elemento neutro del producto.  por ejemplo, multipliquemos 10110 por 1001:  en sistemas electronicos, donde suelen usarse numeros mayores, se utiliza el metodo llamado algoritmo de booth.  la division en binario es similar a la decimal; la unica diferencia es que a la hora de hacer las restas, dentro de la division, estas deben ser realizadas en binario.  dividir 100010010 (274) entre 1101 (13):  debido a que el sistema octal tiene como base 8, que es la tercera potencia de 2, y que dos es la base del sistema binario, es posible establecer un metodo directo para convertir de la base dos a la base ocho, sin tener que convertir de binario a decimal y luego de decimal a octal. este metodo se describe a continuacion:  para realizar la conversion de binario a octal, realice lo siguiente:  1) agrupe la cantidad binaria en grupos de 3 en 3 iniciando por el lado derecho. si al terminar de agrupar no completa 3 digitos, entonces agregue ceros a la izquierda.  2) posteriormente vea el valor que corresponde de acuerdo a la tabla:  3) la cantidad correspondiente en octal se agrupa de izquierda a derecha.  si el numero binario tiene parte decimal, se agrupa de tres en tres desde el punto decimal hacia la derecha siguiendo los mismos criterios establecidos anteriormente para numeros enteros.  por ejemplo:  0.01101 (binario) = 0.32 (octal) proceso: 011 = 3 01 entonces agregue 010 = 2 agrupe de izquierda a derecha: 32 agregue la parte entera: 0.32  cada digito octal se convierte en su binario equivalente de 3 bits y se juntan en el mismo orden.  para realizar la conversion de binario a hexadecimal, realice lo siguiente:  1) agrupe la cantidad binaria en grupos de 4 en 4 iniciando por el lado derecho. si al terminar de agrupar no completa 4 digitos, entonces agregue ceros a la izquierda.  2) posteriormente vea el valor que corresponde de acuerdo a la tabla:  3) la cantidad correspondiente en hexadecimal se agrupa de derecha a izquierda.  note que para pasar de hexadecimal a binario, se remplaza el numero hexadecimal por el equivalente de 4 bits, de forma similar a como se hace de octal a binario.   ",
        "snippet": "El sistema binario, también llamado sistema diádico[1]​ en ciencias de la computación, es un sistema de numeración en el que los números son representados utilizando únicamente dos cifras: 0 (cero) y 1 (uno). Es uno de los sistemas que se utilizan en las computadoras, debido a que estas trabajan internamente con dos niveles de voltaje (0 apagado, 1 conectado), por lo cual su sistema de numeración natural es el sistema binario.[2]​",
        "enlaces_salientes": [
            "/wiki/Sistema_binario",
            "/wiki/Sistema_binario",
            "/wiki/Sistema_binario",
            "/wiki/Sistema_binario_(astronom%C3%ADa)",
            "/wiki/Manuscrito",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Sistema_de_numeraci%C3%B3n",
            "/wiki/N%C3%BAmero",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/Cero",
            "/wiki/Uno",
            "/wiki/Computadora",
            "/wiki/Tensi%C3%B3n_(electricidad)",
            "/wiki/Thomas_Harriot",
            "/wiki/Juan_Caramuel",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Horus",
            "/wiki/I_Ching",
            "/wiki/Pa_kua",
            "/wiki/Hexagrama_(I_Ching)",
            "/wiki/Bit",
            "/wiki/Shao_Yong",
            "/wiki/Hexagrama_(I_Ching)",
            "/wiki/Matem%C3%A1tico",
            "/wiki/India",
            "/wiki/Pingala",
            "/wiki/If%C3%A1",
            "/wiki/Geomancia",
            "/wiki/1605",
            "/wiki/Francis_Bacon",
            "/wiki/Juan_Caramuel",
            "/wiki/Gottfried_Leibniz",
            "/wiki/1854",
            "/wiki/George_Boole",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/Claude_Elwood_Shannon",
            "/wiki/Instituto_Tecnol%C3%B3gico_de_Massachusetts",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/Rel%C3%A9",
            "/wiki/Conmutador_(dispositivo)",
            "/wiki/George_Robert_Stibitz",
            "/wiki/Laboratorios_Bell",
            "/wiki/Rel%C3%A9",
            "/wiki/Laboratorios_Bell",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/Sociedad_Estadounidense_de_Matem%C3%A1tica",
            "/wiki/Teletipo",
            "/wiki/John_von_Neumann",
            "/wiki/John_William_Mauchly",
            "/wiki/Norbert_Wiener",
            "/wiki/C%C3%B3digo_binario",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Divisi%C3%B3n_entre_dos",
            "/wiki/N%C3%BAmero_primo",
            "/wiki/Potencia_de_dos",
            "/wiki/Suma",
            "/wiki/Acarreo",
            "/wiki/Acarreo",
            "/wiki/Complemento_a_dos",
            "/wiki/Complemento_a_uno",
            "/wiki/Tabla_de_multiplicar",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Elemento_neutro",
            "/wiki/Algoritmo_de_Booth",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Sistema_hexadecimal",
            "/wiki/Sistema_octal",
            "/wiki/Decimal_codificado_en_binario",
            "/wiki/Exceso_3",
            "/wiki/C%C3%B3digo_Gray",
            "/wiki/Sistema_hexadecimal",
            "/wiki/Sistema_octal",
            "/wiki/Sistema_octal",
            "/wiki/Sistema_duodecimal",
            "/wiki/Sistema_hexadecimal",
            "/wiki/Bit",
            "/wiki/Nibble",
            "/wiki/Byte",
            "/wiki/Operador_a_nivel_de_bits",
            "/wiki/Aritm%C3%A9tica_de_saturaci%C3%B3n",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Teor%C3%ADa_de_c%C3%B3digos",
        "titulo": "Teoría de códigos",
        "contenido": "la teoria de codigos es una especialidad matematica que trata de las leyes de la codificacion de la informacion. a grandes rasgos, codificar es transformar una informacion en una señal convenida para su comunicacion. decodificar seria el proceso inverso y complementario del anterior por el cual la señal comunicada es transformada en la informacion original. el auge de las comunicaciones a partir de la segunda mitad del siglo xx motivo un fuerte desarrollo de la teoria de codigos.  puesto que los codigos se usan para comunicar informacion, uno de los problemas a los que todo codigo se enfrenta es el error sistematico y, tambien, el fortuito. la redundancia es el unico medio de prevenir el error. los lenguajes humanos tienen una gran redundancia que les da flexibilidad a costa, eso si, de eficacia. los codigos matematicos utilizan una redundancia mas racional.  hay codigos llamados de deteccion de errores, que permiten detectar alteraciones en un mensaje codificado. se utilizan sobre todo en entornos donde el mensaje puede ser reenviado tantas veces como se necesite. los protocolos de internet, por ejemplo, estan formados por un anidamiento de codificaciones desde el nivel de transporte hasta el nivel fisico, teniendo cada nivel su propio sistema de deteccion de errores.  este tipo de codigos resulta inadecuado en entornos donde la comunicacion no se puede repetir y se necesita asegurar hasta cierto punto que se va a recibir la informacion correcta. un ejemplo tipico y vistoso es cuando se envia una nave espacial a los confines del sistema solar y desde alli debe enviar una serie de fotografias antes de que se le acaben, digamos, las pilas. se trata de una situacion delicada, porque si las ondas electromagneticas que portan la informacion llegan distorsionadas toda la mision fracasa. un codigo que solo detectase que la informacion es incorrecta no serviria para nada. es necesario algo mas, un codigo no solo detector sino corrector de errores.  por ejemplo, el sistema de codificacion mas sencillo puede consistir en que un \"0\" se representa un \"no\" y con un \"1\" un si. en este caso, si quiero transmitir un \"si\", y se comete un error al transmitir un \"0\" en vez del \"1\", el receptor del mensaje hara lo opuesto a lo pedido. pero si en cambio se conviene que \"00\" sea \"no\" y \"11\" sea \"si\", entonces, si se comete un error en un digito, y por ejemplo el receptor recibe un \"01\", detectara que hubo un error, aunque no sabra cual es el mensaje correcto. en cambio si la convencion es que \"000\" es \"no\" y \"111\" un si, y se supiese que al transmitir un mensaje solo es posible, por la metodologia utilizada, cometer un solo error de digito, entonces, si al recibir un \"001\", el receptor sabra que se trata de un \"no\". asi siguiendo, si transmitimos un bloque de ceros, o un bloque de unos, aunque se cometan algunos errores en la transmision de algunos digitos, se tendra la casi certeza de cual es el error cometido en el mensaje recibido, y corregirlo.​  en la actualidad, los avances que se estan produciendo en esta disciplina estan encaminados hacia la utilizacion de las bases de groebner como herramienta para la codificacion y decodificacion en los codigos detectores de errores.  uno de los principales problemas de la teoria de codigos es el siguiente. supongamos que tenemos una fuente de informacion que emite o transmite \"simbolos\" de cierto conjunto w = { w 1 , … , w n } ,\\dots ,w_{n}\\}} que por propositos pedagogicos llamaremos simplemente \"palabras\", de forma que la probabilidad de emision de una palabra sea independiente del simbolo anterior p ( w ( t ) ) = w k | w ( t − 1 ) = w j = p ( w = w k ) )=w_{k}|w^{(t-1)}=w_{j}=p(w=w_{k})} , siendo p i = p ( w = w i ) =p(w=w_{i})} . si σ es un alfabeto de d \"letras\", ¿que codigo debe asignarsele a la palabra w i } usando \"letras\" del alfabeto de tal manera que se consiga una codificacion tan economica como sea posible?​ formalmente una codificacion es una aplicacion e : w → p 0 ( σ ) }_{0}(\\sigma )} del conjunto de \"palabras\" en el conjunto de secuencias finitas de \"letras\" del alfabeto. un mensaje es una secuencia finita de palabras, m = w i 1 … w i n }\\dots w_{i_{n}}} , si se dispone de una codificacion de palabras, esta se extiende inmediatamente a mensajes mediante concatenacion:   e ( m ) = e ( w i 1 ) … e ( w i n ) })\\dots e(w_{i_{n}})}  algunos tipos de codificaciones interesantes son:  la criptografia o codificacion criptografica es la practica y el estudio de tecnicas de comunicacion segura en presencia de terceros (llamados adversarios).​ en terminos mas generales, se trata de construir y analizar protocolos que bloquean a los adversarios;​ diversos aspectos de la seguridad de la informacion, como la confidencialidad, la integridad de los datos, la autenticacion y el no repudio​ son fundamentales para la criptografia moderna. la criptografia moderna existe en la interseccion de las disciplinas de matematicas, informatica e ingenieria electrica. las aplicaciones de la criptografia incluyen tarjetas de cajero automatico, contraseñas de ordenador y comercio electronico.  la criptografia antes de la era moderna era efectivamente sinonimo de cifrado, la conversion de informacion de un estado legible a aparentes nonsense. el autor de un mensaje cifrado compartio la tecnica de decodificacion necesaria para recuperar la informacion original solo con los destinatarios previstos, evitando asi que personas no deseadas hicieran lo mismo. desde la primera guerra mundial y el advenimiento del ordenador, los metodos utilizados para llevar a cabo la criptologia se han vuelto cada vez mas complejos y su aplicacion mas extendida.  la criptografia moderna se basa en gran medida en la teoria matematica y la practica informatica; los algoritmos criptograficos estan diseñados en torno a suposiciones de dureza computacional, lo que hace que dichos algoritmos sean dificiles de romper en la practica por parte de cualquier adversario. en teoria, es posible romper un sistema de este tipo, pero no es factible hacerlo por ningun medio practico conocido. por lo tanto, estos esquemas se denominan computacionalmente seguros; los avances teoricos, por ejemplo, las mejoras en los algoritmos de factorizacion de enteros y la tecnologia informatica mas rapida requieren que estas soluciones se adapten continuamente. existen esquemas de seguridad teorica de la informacion que probablemente no se pueden descifrar ni siquiera con un poder de computo ilimitado; un ejemplo es la libreta de un solo uso, pero estos esquemas son mas dificiles de implementar que los mejores mecanismos teoricamente rompibles pero computacionalmente seguros.  un codigo de linea (tambien llamado modulacion de banda base digital o metodo de transmision de banda base digital) es un codigo elegido para su uso dentro de un sistema de comunicaciones para propositos de transmision de banda base. la codificacion de linea se utiliza a menudo para el transporte de datos digitales.  la codificacion de linea consiste en representar la señal digital para ser transportada por una señal discreta de amplitud y tiempo que esta sintonizada de manera optima para las propiedades especificas del canal fisico (y del equipo receptor). el patron  deforma de onda de voltaje o corriente que se utiliza para representar los 1 y 0 de datos digitales en un enlace de transmision se denomina \"codificacion de linea\". los tipos comunes de codificacion de linea son unipolar, polar, bipolar y codificacion manchester.  otra preocupacion de la teoria de la codificacion es diseñar codigos que ayuden a la sincronizacion. se puede diseñar un codigo para que un cambio de fase se pueda detectar y corregir facilmente y que se puedan enviar multiples señales en el mismo canal.  otra aplicacion de codigos, utilizada en algunos sistemas de telefonia movil, es el acceso multiple por division de codigo (cdma). a cada telefono se le asigna una secuencia de codigo que no tiene correlacion con los codigos de otros telefonos. al transmitir, la palabra clave se utiliza para modular los bits de datos que representan el mensaje de voz. en el receptor se realiza un proceso de demodulacion para recuperar los datos. las propiedades de esta clase de codigos permiten que muchos usuarios (con diferentes codigos) utilicen el mismo canal de radio al mismo tiempo. para el receptor, las señales de otros usuarios apareceran en el demodulador solo como un ruido de bajo nivel.  otra clase general de codigos son los codigos de solicitud de repeticion automatica (arq). en estos codigos, el remitente agrega redundancia a cada mensaje para verificar errores, generalmente agregando bits de verificacion. si los bits de verificacion no son consistentes con el resto del mensaje cuando llega, el receptor le pedira al remitente que retransmita el mensaje. todos los protocolos de red de area amplia excepto los mas simples utilizan arq. los protocolos comunes incluyen sdlc (ibm), tcp (internet), x.25 (internacional) y muchos otros. existe un amplio campo de investigacion sobre este tema debido al problema de hacer coincidir un paquete rechazado con un paquete nuevo. normalmente se utilizan esquemas de numeracion, como en tcp.​  para las pruebas en grupo se usa codigos de una manera diferente. hay que considerar un gran grupo de articulos en los que muy pocos son diferentes de una manera particular (por ejemplo, productos defectuosos o sujetos de prueba infectados). la idea de las pruebas grupales es determinar que elementos son \"diferentes\" utilizando la menor cantidad de pruebas posible. el origen del problema tiene sus raices en la segunda guerra mundial cuando las fuerzas aereas del ejercito de los estados unidos necesitaban examinar a sus soldados para detectar sifilis.​  la informacion se codifica de manera analoga en las redes neuronales de los cerebros, en el procesamiento de señales analogicas y la electronica analogica. los aspectos de la codificacion analogica incluyen la correccion de errores analogicos,​ compresion de datos analogicos​ y cifrado analogico.​  la codificacion neuronal es un campo relacionado con la neurociencia que se ocupa de como la informacion sensorial y de otros tipos se representa en el cerebro mediante redes de neuronas. el objetivo principal de estudiar la codificacion neuronal es caracterizar la relacion entre el estimulo y las respuestas neuronales individuales o grupales y la relacion entre la actividad electrica de las neuronas en el conjunto.​ se cree que las neuronas pueden codificar informacion tanto digital como analogica,​ y que las neuronas siguen los principios de la teoria de la informacion y comprimen la informacion,​ y detectar y corregir errores​ en las señales que se envian por todo el cerebro y el sistema nervioso mas amplio.  el analisis de codigo es util para intentar decodificar texto cifrado, si el codigo de proteccion utilizado es debil (por ejemplo, el codigo caesar o vigenere). la deteccion de las caracteristicas estadisticas de un texto tambien permite verificar, incluso sin entender su lenguaje, si un texto ha tenido mas de un autor (puede decirse que el todavia indescifrado manuscrito voynich tenia dos autores distintos). tambien permite analizar los textos de victor hugo y, por estas caracteristicas estadisticas, detectar la decada de su escritura. el centro cientifico de ibm (ibm la gaude, francia) tambien estudio los discursos de charles de gaulle y mostro que estos discursos se extendieron con el tiempo, a excepcion de algunos discursos «criticos» (como el del 30 de mayo de 1968). la universidad de stanford tambien comparo los vocabularios respectivos de marcel proust y paul valery. el ingeniero jean-jacques walter tambien llevo a cabo este analisis sobre el texto del coran y defendio una tesis segun la cual le atribuyo varias docenas de autores (al menos 30 autores diferentes, probablemente 50, como maximo 100), inicialmente en varios idiomas, durante un periodo de doscientos años.​·​. ",
        "snippet": "La teoría de códigos es una especialidad matemática que trata de las leyes de la codificación de la información. A grandes rasgos, codificar es transformar una información en una señal convenida para su comunicación. Decodificar sería el proceso inverso y complementario del anterior por el cual la señal comunicada es transformada en la información original. El auge de las comunicaciones a partir de la segunda mitad del siglo XX motivó un fuerte desarrollo de la teoría de códigos.",
        "enlaces_salientes": [
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Julio_C%C3%A9sar",
            "/wiki/1750",
            "/wiki/D._C.",
            "/wiki/Leonhard_Euler",
            "/wiki/Teorema_de_Euler",
            "/wiki/1844",
            "/wiki/Samuel_Morse",
            "/wiki/C%C3%B3digo_morse",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/1950",
            "/wiki/Richard_Hamming",
            "/wiki/Informaci%C3%B3n",
            "/wiki/Lenguaje",
            "/wiki/S%C3%ADmbolo",
            "/wiki/Concatenaci%C3%B3n",
            "/wiki/C%C3%B3digo_un%C3%ADvocamente_descodificable",
            "/wiki/Funci%C3%B3n_inyectiva",
            "/wiki/Desigualdad_de_Kraft",
            "/wiki/Desigualdad_de_McMillan",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Adversario_(criptograf%C3%ADa)",
            "/wiki/Protocolos_de_comunicaciones",
            "/wiki/Seguridad_de_la_informaci%C3%B3n",
            "/wiki/Confidencialidad",
            "/wiki/Integridad_de_los_datos",
            "/wiki/Autenticaci%C3%B3n",
            "/wiki/No_repudio",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Ingenier%C3%ADa_el%C3%A9ctrica",
            "/wiki/Cajero_autom%C3%A1tico",
            "/wiki/Contrase%C3%B1a",
            "/wiki/Comercio_electr%C3%B3nico",
            "/wiki/Cifrado",
            "/wiki/Nonsense",
            "/wiki/Primera_Guerra_Mundial",
            "/wiki/Ordenador",
            "/wiki/Criptolog%C3%ADa",
            "/wiki/Factorizaci%C3%B3n_de_enteros",
            "/wiki/Libreta_de_un_solo_uso",
            "/wiki/C%C3%B3digos_en_l%C3%ADnea",
            "/wiki/C%C3%B3digo",
            "/wiki/Transmisi%C3%B3n_(telecomunicaciones)",
            "/wiki/Banda_base",
            "/wiki/Codificaci%C3%B3n_bipolar",
            "/wiki/Codificaci%C3%B3n_Manchester",
            "/wiki/Sincronizaci%C3%B3n",
            "/wiki/Acceso_m%C3%BAltiple_por_divisi%C3%B3n_de_c%C3%B3digo",
            "/wiki/Red_de_%C3%A1rea_amplia",
            "/wiki/Protocolo_de_control_de_transmisi%C3%B3n",
            "/wiki/X.25",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Fuerzas_A%C3%A9reas_del_Ej%C3%A9rcito_de_los_Estados_Unidos",
            "/wiki/S%C3%ADfilis",
            "/wiki/Redes_neuronales",
            "/wiki/Electr%C3%B3nica_anal%C3%B3gica",
            "/wiki/Neurociencia",
            "/wiki/Cerebro",
            "/wiki/Redes_neuronales",
            "/wiki/Neuronas",
            "/wiki/Datos_digitales",
            "/wiki/Se%C3%B1al_anal%C3%B3gica",
            "/wiki/Manuscrito_Voynich",
            "/wiki/V%C3%ADctor_Hugo",
            "/wiki/Charles_de_Gaulle",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Marcel_Proust",
            "/wiki/Paul_Val%C3%A9ry",
            "/wiki/Cor%C3%A1n",
            "/wiki/Ron_Rivest",
            "/wiki/ISBN",
            "/wiki/Internet_Engineering_Task_Force",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Semantic_Scholar",
            "/wiki/ArXiv",
            "/wiki/Digital_object_identifier",
            "/wiki/PubMed_Identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/PubMed_Identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/ArXiv",
            "/wiki/Digital_object_identifier",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Bucle_infinito",
        "titulo": "Bucle infinito",
        "contenido": "bucle infinito en programacion es un error que consiste en realizar un ciclo que se repite de forma indefinida ya que su condicion para finalizar nunca se cumple.​  por definicion un bucle debe contener condiciones que establezcan cuando empieza y cuando acaba, de manera que, mientras las condiciones se cumplan, ejecute una secuencia de codigo de manera repetitiva. en el caso de ciclo infinito, como la condicion de finalizacion no se alcanza, el bucle sigue ejecutando el segmento de codigo indefinidamente.  los bucles infinitos salen en peliculas para referir a confinamientos del espacio tiempo de humanos con cualidades especial  la programacion en automatizacion y robotica puede basarse en un bucle infinito, como por ejemplo la funcion void loop() en arduino, en este caso el bucle infinito deja de ser un error para pasar a ser una virtud, ya que puede reconocerse el estado de un sensor generando una respuesta miles de veces por segundo.  se observa que la sentencia printf(\"\\x¡no acabare nunca!\\n\"); siempre se ejecuta porque la condicion del bucle while() siempre es cierta, no existe una condicion de salida que obligue al bucle a finalizar. exactamente, no se alcanza la condicion de salida. si en el ejemplo anterior, dentro del bloque de codigo del bucle while, se encontrase la instruccion  el bucle hubiera ejecutado 10 veces y hubiera terminado.  tambien existe esta posibilidad con el while (true). en c:  en la sentencia \"printf\" se muestra en pantalla 0,1,2,3,0,1,2,3,0,.... y tambien podemos crear un ciclo infinito con el for de esta forma:  como siempre la variable i va a ser igual a ella misma, se incrementa e itera infinitas veces.  en el siguiente caso, por cada vez que se incrementa la variable, como es menor a 5 se decrementa dentro del cuerpo del bucle. luego se vuelve a incrementar y de esa manera infinitas veces.  siempre que la suma de a y b sea superior o igual a 10.  la variable \"suma\" se sumara infinitamente 1 unidad.  una forma de hacer un bucle infinito en pascal es con un ciclo repeat como se muestra a continuacion:  ya que 2 nunca es igual a 3, el codigo se repite hasta el infinito.  en pascal se puede realizar un bucle infinito sin necesidad de establecer una condicion equivoca.  tambien se puede crear un bucle infinito genuino.  en este ejemplo olvide incrementar el valor de i.  en este ejemplo se muestra como utilizamos el bucle \"contar\" para hacer que la variable i alcance el valor 1, pero por x motivo olvidamos establecer la instruccion \"dec\" para que el bucle decremente valores.  en este codigo, la variable $variable nunca cambia, siempre vale cero. por lo tanto, se entra en bucle infinito al ser $variable siempre <500.  aqui la variable \"num\" tiene el valor de 2, entonces dentro del while la condicion es: si \"num\" no es igual a 3 imprime (print) \"mas alla del universo\"; como el valor de \"num\" es constante (igual a 2), entonces dentro de while la condicion sera verdadera, y el bucle nunca terminara. ",
        "snippet": "Bucle infinito en programación es un error que consiste en realizar un ciclo que se repite de forma indefinida ya que su condición para finalizar nunca se cumple.[1]​",
        "enlaces_salientes": [
            "/wiki/Bucle_infinito",
            "/wiki/Bucle_infinito",
            "/wiki/Bucle_infinito",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Error_de_software",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Automatizaci%C3%B3n",
            "/wiki/Rob%C3%B3tica",
            "/wiki/Arduino",
            "/wiki/Bloque_de_c%C3%B3digo",
            "/wiki/For",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Funci%C3%B3n_parcial",
        "titulo": "Función parcial",
        "contenido": "las funciones se pueden clasificar en funcion de su conjunto de partida (o dominio). dando lugar a dos tipos, parciales y totales.  una funcion parcial es una relacion que asocia elementos de un conjunto (a veces denominado dominio) con, como maximo, uno de los elementos de otro conjunto (que puede ser el mismo), llamado codominio. en cualquier caso, no es necesario que todos los elementos del dominio esten asociados con algun elemento del codominio.  si todos los elementos de un conjunto x se asocian con un elemento de y mediante una funcion parcial f:x→y , entonces se dice que f es una funcion total, o simplemente una funcion, como se entiende tradicionalmente este concepto en matematicas. no todas las funciones parciales son funciones totales.  en matematicas, una funcion se dice que es total si esta definida para todo el conjunto de partida. para comprender esto, debemos saber que:  sea f: a → b, diremos que f esta definida para un elemento a ∈ a si existe un par ( a , f ( a ) ) ∈ f a,&f(a)\\end{pmatrix}}\\in f} . esto se escribe como f(a) = ↓. por el contrario, escribiremos f(a) = ↑ cuando f no esta definida para a.  una funcion que no es total, es decir, que esta indefinida para algun/os elemento/s, se conoce como parcial.  el primero de los diagramas mostrados representa una funcion parcial; no es una funcion total porque el elemento 2 en el conjunto de la izquierda no esta asociado con ningun elemento del conjunto de la derecha.  considerese la funcion del logaritmo natural, que relaciona el conjunto de los numeros reales consigo mismo. el logaritmo de un numero real negativo no es un numero real, asi que el logaritmo natural no asocia a todos los elementos del codominio con un elemento del dominio. por lo tanto, el logaritmo natural no es una funcion total cuando se la considera como una funcion del conjunto de numeros reales consigo misma, sino una funcion parcial. si el dominio se restringiera al conjunto de los reales positivos, entonces si se trataria de una funcion total. ",
        "snippet": "Las funciones se pueden clasificar en función de su conjunto de partida (o dominio). Dando lugar a dos tipos, parciales y totales.",
        "enlaces_salientes": [
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Conjunto",
            "/wiki/Dominio_de_definici%C3%B3n",
            "/wiki/Codominio",
            "/wiki/Funci%C3%B3n_total",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Conjunto",
            "/wiki/Logaritmo_natural",
            "/wiki/N%C3%BAmeros_Reales",
            "/wiki/Correspondencia_matem%C3%A1tica",
            "/wiki/Funci%C3%B3n_multivaluada",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Dominio_de_definici%C3%B3n",
        "titulo": "Dominio de una función",
        "contenido": "en matematicas, el dominio (conjunto de definicion o conjunto de partida) de una funcion f : x → y es el conjunto de existencia de ella misma, es decir, los valores para los cuales la funcion esta definida. es el conjunto de todos los objetos que puede transformar, se denota dom f _{f}} , dom ⁡ ( f ) (f)} o d f \\,} . en r n ^{n}} se denomina dominio a un conjunto conexo, abierto y cuyo interior sea no vacio.  por otra parte, el conjunto de todos los resultados posibles de una funcion dada se denomina codominio de esa funcion.  dadas dos funciones reales:   f : x 1 → r y g : x 2 → r \\to \\mathbb {r} \\,\\qquad }\\quad g\\colon x_{2}\\to \\mathbb {r} \\,}  se tienen las siguientes propiedades:  para el calculo certero del dominio de una funcion, se debe introducir el concepto de restriccion en el cuerpo real. estas restricciones ayudaran a identificar la existencia del dominio de una funcion. las mas usadas son:  los logaritmos no estan definidos para numeros negativos ni para el cero, por tanto toda funcion contenida dentro de un logaritmo debe ser necesariamente mayor estricto de cero. por ejemplo:  por la propiedad anteriormente citada, se observa que para que esta funcion este bien definida, necesariamente x 2 − 9 > 0 -9>0} ; despejando, se obtienen dos soluciones x > 3 y x < − 3 . la union de ambas soluciones representa el dominio de la funcion, que esta definida como el conjunto (-∞, -3) u (3, +∞).  otras propiedades de las matematicas pueden ayudar a obtener el dominio de una funcion y excluir puntos donde esta no este definida. por ejemplo, una funcion que tenga forma de fraccion no estara definida cuando el denominador valga cero.  algunos dominios de funciones reales de variable real: ",
        "snippet": "En matemáticas, el dominio (conjunto de definición o conjunto de partida) de una función f : X → Y {\\displaystyle f:X\\to Y} es el conjunto de existencia de ella misma, es decir, los valores para los cuales la función está definida. Es el conjunto de todos los objetos que puede transformar, se denota Dom f {\\displaystyle \\operatorname {Dom} _{f}} , Dom ⁡ ( f ) {\\displaystyle \\operatorname {Dom} (f)} o D f {\\displaystyle D_{f}\\,} . En R n {\\displaystyle \\mathbb {R} ^{n}} se denomina dominio a un conjunto conexo, abierto y cuyo interior sea no vacío.",
        "enlaces_salientes": [
            "/wiki/Dominio_de_una_funci%C3%B3n",
            "/wiki/Dominio_de_una_funci%C3%B3n",
            "/wiki/Dominio_de_una_funci%C3%B3n",
            "/wiki/Codominio",
            "/wiki/Imagen_de_una_funci%C3%B3n",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Operando",
            "/wiki/Conjunto_conexo",
            "/wiki/Conjunto_abierto",
            "/wiki/Codominio",
            "/wiki/Restricci%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Uni%C3%B3n_de_conjuntos",
            "/wiki/Divisi%C3%B3n_por_cero",
            "/wiki/Funci%C3%B3n_real",
            "/wiki/Funci%C3%B3n_polin%C3%B3mica",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/Divisi%C3%B3n_por_cero",
            "/wiki/Conjunto_imagen",
            "/wiki/Recorrido",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Encyclopaedia_of_Mathematics",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Funci%C3%B3n_computable",
        "titulo": "Función computable",
        "contenido": "las funciones computables son el objeto basico de estudio de la teoria de la computabilidad y son, especificamente, las funciones que pueden ser calculadas por una maquina de turing.  las funciones computables se utilizan para hablar de computabilidad sin hacer referencia a ningun modelo de computacion concreto, como las  maquinas de turing o las  maquinas de registro. cualquier definicion, sin embargo, debe hacer referencia a algun modelo especifico de computacion, pero todas las definiciones validas producen la misma clase de funciones. los modelos particulares de computabilidad que dan lugar al conjunto de funciones computables son las  funciones computables de turings y las  funciones recursivas generales.  antes de la definicion precisa de funcion computable, los matematicos utilizaban a menudo el termino informal efectivamente calculable.   desde entonces, este termino se identifica con las funciones computables. notese que la computabilidad efectiva de estas funciones no implica que puedan ser eficientemente calculadas (es decir, calculadas en un tiempo razonable). de hecho, para algunas funciones efectivamente calculables se puede demostrar que cualquier algoritmo que las compute sera muy ineficiente en el sentido de que el tiempo de ejecucion del algoritmo aumenta exponencialmente (o incluso  superexponencialmente) con la longitud de la entrada. los campos de  computabilidad factible y complejidad computacional estudian funciones que pueden ser computadas eficientemente.  segun la tesis de church-turing, las funciones computables son exactamente las funciones que pueden calcularse utilizando un dispositivo de calculo mecanico dadas cantidades ilimitadas de tiempo y espacio de almacenamiento. equivalentemente, esta tesis afirma que una funcion es computable si y solo si tiene un algoritmo.  notese que un algoritmo en este sentido se entiende como una secuencia de pasos que una persona con tiempo ilimitado y un suministro ilimitado de lapiz y papel podria seguir.  los axiomas de blum pueden utilizarse para definir una teoria de la complejidad computacional abstracta sobre el conjunto de funciones computables. en la teoria de la complejidad computacional, el problema de determinar la complejidad de una funcion computable se conoce como problema de funcion.  las funciones computables son una formalizacion de la nocion intuitiva de algoritmo y, segun la tesis de church-turing, son exactamente las funciones que pueden ser calculadas con una maquina de turing. la nocion de la computabilidad de una funcion puede ser relativizada a un conjunto arbitrario de numeros naturales a, o equivalentemente a una funcion arbitraria f de los naturales a los naturales, por medio de maquinas de turing extendidas con un oraculo por a o f. tales funciones pueden ser llamadas a-computable o f-computable respectivamente. antes de la definicion precisa de una funcion computable los matematicos usaban el termino informal efectivamente computable.  las funciones computables son usadas para discutir sobre computabilidad sin referirse a ningun modelo de computacion concreto, como el de la maquina de turing o el de la maquina de registros. los axiomas de blum pueden ser usados para definir una teoria de complejidad computacional abstracta sobre el conjunto de funciones computables.  segun la tesis de church-turing, la clase de funciones computables es equivalente a la clase de funciones definidas por funciones recursivas, calculo lambda, o algoritmos de markov .  alternativamente se pueden definir como los algoritmos que pueden ser calculados por una maquina de turing, una maquina de post, o una maquina de registros.  en teoria de la complejidad computacional, el problema de determinar la complejidad de una funcion computable es conocido como un problema de funciones.  la computabilidad de una funcion es una nocion informal. una forma de describirla es decir que una funcion es computable si su valor puede obtenerse mediante un procedimiento efectivo. con mas rigor, una funcion f : n k → n ^{k}\\rightarrow \\mathbb {n} } es computable si y solo si existe un procedimiento efectivo que, dada cualquier k-tupla x } de numeros naturales, producira el valor f ( x ) )} .​ de acuerdo con esta definicion, el resto de este articulo supone que las funciones computables toman finitamente muchos numeros naturales como argumentos y producen un valor que es un unico numero natural.  como contrapartida a esta descripcion informal, existen multiples definiciones formales y matematicas. la clase de funciones computables se puede definir en muchos modelos de computacion equivalentes, incluyendo  aunque estos modelos utilizan diferentes representaciones para las funciones, sus entradas y sus salidas, existen traducciones entre dos modelos cualesquiera, por lo que cada modelo describe esencialmente la misma clase de funciones, dando lugar a la opinion de que la computabilidad formal es a la vez natural y no demasiado estrecha.​ estas funciones se denominan a veces \"recursivas\", en contraste con el termino informal \"computables\",​ una distincion derivada de una discusion de 1934 entre kleene y godel.​p.6  por ejemplo, se pueden formalizar funciones computables como  funciones μ-recursivas, que son  funciones parciales que toman tuplas finitas de  numeros naturales y devuelven un unico numero natural.  son la clase mas pequeña de funciones parciales que incluye las funciones constante, sucesora y de proyeccion, y es cerrada bajo composicion, recurrencia primitiva y el operador μ.  equivalentemente, las funciones computables pueden formalizarse como funciones que pueden ser calculadas por un agente computacional idealizado como una maquina de turing o una maquina de registro. formalmente hablando, una funcion parcial f : n k → n ^{k}\\rightarrow \\mathbb {n} } puede ser calculada si y solo si existe un programa de ordenador con las siguientes propiedades:  una funcion parcial  se llama parcialmente computable si el grafico f es un conjumerable. el conjunto de funciones parcialmente computables con un parametro es normalmente escrito p ( 1 ) ^{(1)}} o ath> si el numero de parametros puede deducirse del contexto.  una funcion total  se llama computable si el grafico de f es un conjunto recursivo. el conjunto de funciones totalmente computables con un parametro normalmente se escribe r ( 1 ) ^{(1)}} o r } .  una funcion computable f se llama predicado computable si es una funcion con valor booleano, es decir:  la caracteristica basica de una funcion computable es que debe existir un procedimiento finito (un algoritmo) que diga como calcular la funcion.  los modelos de computacion enumerados anteriormente dan diferentes interpretaciones de lo que es un procedimiento y como se utiliza, pero estas interpretaciones comparten muchas propiedades.  el hecho de que estos modelos den clases equivalentes de funciones computables proviene del hecho de que cada modelo es capaz de leer e imitar un procedimiento para cualquiera de los otros modelos, del mismo modo que un compilador es capaz de leer instrucciones en un lenguaje informatico y emitir instrucciones en otro lenguaje.  enderton  da las siguientes caracteristicas de un procedimiento para computar una funcion computable; caracterizaciones similares han sido dadas por turing , rogers , y otros.  enderton pasa a enumerar varias aclaraciones de estos 3 requisitos del procedimiento para una funcion computable:  en resumen, desde este punto de vista, una funcion es computable si:   el campo de la complejidad computacional estudia funciones con limites prescritos en el tiempo y/o espacio permitidos en una computacion exitosa.  un conjunto a de numeros naturales se llama computable (sinonimos: recursivo, decidible) si existe una funcion computable, total f} tal que para cualquier numero natural n, f(n) = 1 si n esta en a y f(n) = 0 si n no esta en a.  un conjunto de numeros naturales se llama computablemente enumerable (sinonimos: recursivamente enumerable', semidecidible) si existe una funcion computable f} tal que para cada numero n, f(n) esta definida si y solo si. n esta en el conjunto.  asi, un conjunto es computablemente enumerable si y solo si es el dominio de alguna funcion computable.  la palabra enumerable se utiliza porque los siguientes son equivalentes para un subconjunto no vacio b de los numeros naturales:  si un conjunto b es el rango de una funcion f entonces la funcion puede verse como una enumeracion de b, porque la lista f(0), f(1), ... incluira cada elemento de b.  dado que cada relacion matematica sobre los numeros naturales puede identificarse con un conjunto correspondiente de secuencias finitas de numeros naturales, las nociones de relacion computable y relacion computablemente enumerable pueden definirse a partir de sus analogas para conjuntos.    en teoria de la computabilidad en informatica, es comun considerar lenguajes formales.   un alfabeto es un conjunto arbitrario.  una palabra en un alfabeto es una secuencia finita de simbolos del alfabeto; el mismo simbolo puede usarse mas de una vez.  por ejemplo, las cadenas binarias son exactamente las palabras del alfabeto plantilla:0, 1. .  un lenguaje es un subconjunto de la coleccion de todas las palabras de un alfabeto fijo. por ejemplo, la coleccion de todas las cadenas binarias que contienen exactamente 3 unos es un lenguaje sobre el alfabeto binario.  una propiedad clave de un lenguaje formal es el nivel de dificultad necesario para decidir si una palabra dada esta en el lenguaje.  debe desarrollarse algun sistema de codificacion que permita a una funcion computable tomar como entrada una palabra arbitraria del lenguaje; esto suele considerarse rutina.  un lenguaje se llama computable (sinonimos: recursivo, decidible) si existe una funcion computable f tal que para cada palabra w sobre el alfabeto, f(w) = 1 si la palabra esta en la lengua y f(w) = 0 si la palabra no esta en el lenguaje. asi, un lenguaje es computable solo en el caso de que exista un procedimiento capaz de decir correctamente si palabras arbitrarias estan en el lenguaje.  un lenguaje es computablemente enumerable (sinonimos: recursivamente enumerable, semidecidible) si existe una funcion computable f tal que f(w) esta definida si y solo si la palabra w esta en el lenguaje.  el termino enumerable tiene la misma etimologia que en conjuntos computablemente enumerables de numeros naturales.  a veces, por razones de claridad, se escribe una funcion computable como  se puede facilmente codificar g en una nueva funcion  usando una funcion de pares.  las siguientes funciones son computables:  si f y g son computables, entonces tambien lo son: f + g, f * g, f ∘ g f\\circ g} si f es unaria, max(f,g), min(f,g), arg max{y ≤ f(x)} y muchas mas combinaciones.  los siguientes ejemplos ilustran que una funcion puede ser computable aunque no se sepa que algoritmo la computa. ",
        "snippet": "Las funciones computables son el objeto básico de estudio de la teoría de la computabilidad y son, específicamente, las funciones que pueden ser calculadas por una máquina de Turing.",
        "enlaces_salientes": [
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Modelo_de_computaci%C3%B3n",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Matem%C3%A1ticos",
            "/wiki/Crecimiento_exponencial",
            "/wiki/Tetraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Algoritmo",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Conjunto",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Modelo_de_computaci%C3%B3n",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Recursi%C3%B3n_primitiva",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_Post",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/M%C3%A9todo_efectivo",
            "/wiki/Tupla",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Modelo_de_computaci%C3%B3n",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/M%C3%A1quina_de_Post",
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Tupla",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Composici%C3%B3n_de_funciones",
            "/wiki/Funci%C3%B3n_recursiva_primitiva",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_registro",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Funci%C3%B3n_total",
            "/wiki/Conjunto_recursivo",
            "/wiki/Algoritmo",
            "/wiki/Algoritmo",
            "/wiki/Compilador",
            "/wiki/Herbert_Enderton",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Si_y_s%C3%B3lo_si",
            "/wiki/Inyectiva",
            "/wiki/Relaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Lenguaje_formal",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Lenguajes_formales",
            "/wiki/Dominio_de_una_funci%C3%B3n",
            "/wiki/Funci%C3%B3n_constante",
            "/wiki/Suma",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/Identidad_de_B%C3%A9zout",
            "/wiki/Factor_primo",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Composici%C3%B3n_de_funciones",
            "/wiki/Operaci%C3%B3n_unaria",
            "/wiki/Funci%C3%B3n_constante",
            "/wiki/Adici%C3%B3n",
            "/wiki/Conjunto",
            "/wiki/Numerable",
            "/wiki/Lenguaje_recursivo",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Problema_de_la_parada",
        "titulo": "Problema de la parada",
        "contenido": "el problema de la parada o problema de la detencion para maquinas de turing consiste en lo siguiente: dada una maquina de turing m y una palabra w , determinar si m terminara en un numero finito de pasos cuando es ejecutada usando w como dato de entrada. alan turing, en su famoso articulo «on computable numbers, with an application to the entscheidungsproblem» (1936), demostro que el problema de la parada de la maquina de turing es indecidible (no computable o no recursivo), en el sentido de que ninguna maquina de turing lo puede resolver.  al ejecutar un conjunto de programas, este puede terminar despues de un numero finito de pasos o puede no terminar nunca. en la practica, este ultimo caso se manifiesta como programas que se quedan «trabados» o que entran a un bucle infinito. por esta razon seria de gran utilidad resolver la siguiente pregunta en la practica:  conocer si existe el programa p es, en terminos resumidos, el problema de la parada.  sin embargo hay que hacer notar que la sabiduria popular acerca de este problema hace pensar que nunca es posible demostrar que un programa termina. esto es falso.  lo que se afirma es que no existe una manera automatica computable de saber si todos los programas posibles terminan. no se niega que exista la prueba para programas concretos. de hecho, la construccion de pruebas para programas concretos es un paso obligatorio para demostrar su correctitud.  el procedimiento para construir estas pruebas no es automatico; sin embargo, existen heuristicas que facilitan encontrar las pruebas de los programas. el area de conocimiento que estudia la construccion sistematica de pruebas se denomina analisis de terminacion.  la evaluacion o ejecucion del programa con las entradas sin embargo no constituye una prueba de que siempre termine, sino de que en las circunstancias de la ejecucion, termino.  la irresolubilidad del problema se puede mostrar de varias formas, pero en esencia todas equivalen a un argumento diagonal de cantor. a continuacion se muestra el argumento en terminos modernos de programacion:  supongamos que este problema si se puede resolver algoritmicamente; entonces hay un programa, que llamaremos termina, que cada vez que se le suministra el codigo de un programa p y sus datos de entrada x, hace un numero finito de operaciones y responde «true» cuando el programa termina o «false» cuando el programa nunca termina. en lenguaje python:  bajo la suposicion de que existe este programa, se puede usar como subrutina de otro programa mas grande, al que llamaremos «diagonal» (en referencia a la diagonal de cantor). este programa recibira como dato de entrada el codigo de un programa cualquiera w, y usara el programa termina para decidir si el programa w termina cuando se le suministra ella misma como entrada (no hay nada de raro en esto, pues en la practica hay programas como los compiladores que pueden suministrarse a si mismos como dato de entrada). a continuacion, diagonal hace lo opuesto: si w termina entonces diagonal entra en un ciclo infinito y si w entra en un ciclo infinito entonces diagonal termina. en lenguaje python:  resumiendo, el programa diagonal esta diseñado para tener la siguiente propiedad (entiendase la flecha como «siempre y cuando»):   d i a g o n a l ( w ) termina ⟺ w ( w ) nunca termina (w)}\\iff w(w)}}}}  como w puede ser el codigo de cualquier programa, particularmente puede ser el del mismo diagonal:  en este caso se tiene w = d i a g o n a l , y por lo tanto   d i a g o n a l ( d i a g o n a l ) termina ⟺ d i a g o n a l ( d i a g o n a l ) nunca termina ()}\\iff ()}}}}}}}}}}  es decir que bajo la suposicion de que existe el algoritmo termina se llega a la paradojica conclusion de que hay una instruccion que termina siempre y cuando no termine. como esta conclusion es absurda, entonces no puede existir el algoritmo termina; es decir que es imposible resolver el problema de la parada algoritmicamente.  es mas comun encontrar en los libros de texto la demostracion anterior en terminos de maquinas de turing como sigue:  supongamos que el problema de la parada tiene solucion. es decir, supongamos que existe una maquina de turing que es capaz de determinar si otra maquina de turing parara (terminara) con una entrada determinada. llamemos termina a esta maquina. esta maquina recibiria como entrada la cadena m , w , donde m es la codificacion de una maquina de turing y w es la codificacion de la cadena que se le alimenta a m . la maquina t e r m i n a terminara en un estado de aceptacion si m para ante la entrada w , y en otro caso terminara en un estado de rechazo, pero nunca entrara en un ciclo infinito.  es posible crear una maquina copia que al recibir una cadena cualquiera w termine en un estado de aceptacion con w , w en su cinta. ahora crearemos una maquina diagonal que recibe de entrada una cadena w , que presuntamente sera la codificacion de una maquina de turing m . primero diagonal utilizara la maquina copia para duplicar la cadena w , convirtiendola en w , w . a continuacion, diagonal pasara este resultado a traves de termina para decidir si la maquina representada por w para ante la cadena w y realiza lo opuesto: si termina acepta, entonces diagonal entra en un bucle infinito (que consiste de un solo estado al que se regresa una y otra vez) y en otro caso, si termina rechaza entonces diagonal termina en estado de aceptacion.  resumiendo, la maquina diagonal esta diseñada para tener la siguiente propiedad:  diagonal para ante la entrada w ⟺ la maquina codificada en w no para ante la entrada w .  por ultimo, tomaremos la codificacion de la maquina diagonal, y la aplicaremos como entrada a la propia maquina diagonal. como w es la codificacion de diagonal, de lo anterior se sigue que diagonal para ante si misma como entrada si y solo si diagonal no para ante si misma como entrada. esta conclusion es paradojica, pero todas las maquinas que hemos usado en la demostracion, exceptuando termina, son construibles; por lo tanto la clave de la demostracion se encuentra, por reduccion al absurdo, en la supuesta existencia de la maquina termina. al ser imposible la existencia de tal maquina termina, que resolvia el problema de la parada, el problema de la parada no puede ser solucionado por ninguna maquina de turing. ",
        "snippet": "El problema de la parada o problema de la detención para máquinas de Turing consiste en lo siguiente: dada una Máquina de Turing M {\\displaystyle M} y una palabra w {\\displaystyle w} , determinar si M {\\displaystyle M} terminará en un número finito de pasos cuando es ejecutada usando w {\\displaystyle w} como dato de entrada. Alan Turing, en su famoso artículo «On Computable Numbers, with an Application to the Entscheidungsproblem» (1936), demostró que el problema de la parada de la Máquina de Turing es indecidible (no computable o no recursivo), en el sentido de que ninguna máquina de Turing lo puede resolver.",
        "enlaces_salientes": [
            "/wiki/Problema_de_la_parada",
            "/wiki/Problema_de_la_parada",
            "/wiki/Problema_de_la_parada",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Crash_(inform%C3%A1tica)",
            "/wiki/Bucle_infinito",
            "/wiki/Correctitud",
            "/wiki/Heur%C3%ADstica",
            "/wiki/Diagonalizaci%C3%B3n_de_Cantor",
            "/wiki/Subrutina",
            "/wiki/Compilador",
            "/wiki/Si_y_solo_si",
            "/wiki/Paradoja",
            "/wiki/Constante_de_Chaitin",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/An%C3%A1lisis_de_algoritmos",
        "titulo": "Análisis de algoritmos",
        "contenido": "el termino analisis de algoritmos fue acuñado por donald knuth​ y se refiere al proceso de encontrar la complejidad computacional de un algoritmo que resuelva un problema computacional dado, con el objetivo de proveer estimaciones teoricas de los recursos que necesita. usualmente, los recursos a los cuales se hace referencia son el tiempo (complejidad temporal) y el almacenamiento (complejidad espacial). mientras que la complejidad temporal involucra determinar una funcion que relaciona la longitud o el tamaño de la entrada del algoritmo con el numero de pasos que realiza, la complejidad espacial busca la cantidad de ubicaciones de almacenamiento que utiliza.  distintos algoritmos pueden utilizarse para resolver un mismo problema y a su vez los algoritmos pueden estudiarse de forma independiente del lenguaje de programacion a utilizar y de la maquina donde se ejecutara.​ esto significa que se necesitan tecnicas que permitan comparar la eficiencia de los algoritmos antes de su implementacion.  este analisis es conocido tambien con el nombre de analisis del tiempo de ejecucion. a continuacion, se presenta una explicacion intuitiva utilizando el ejemplo del algoritmo de busqueda para luego profundizar en forma mas teorica.  si se piensa en el problema de encontrar una clave en un conjunto de registros ubicados dentro de un vector devolviendo la posicion donde se encuentra, se tienen distintos algoritmos de busquedas que se pueden aplicar. el mas sencillo es la busqueda secuencial pero si el conjunto de elementos se encuentran ordenados (segun su clave) dentro del vector se podria aplicar la busqueda binaria. de este ejemplo se pueden sacar varias conclusiones.  por un lado, dependiendo el algoritmo utilizado el proceso de busqueda sera mas o menos eficiente en el sentido de cantidad de comparaciones realizadas. por ejemplo, segun la figura 1 para buscar \"morin, arthur\" la busqueda secuencial debe realizar 28 comparaciones mientras que la busqueda binaria realiza solo 5 comparaciones. esto confirma que para la resolucion de un determinado problema existe mas de un algoritmo y que estos suelen tener distintos niveles de eficiencia, necesitandose una forma de elegirlos antes de programarlos como se menciono en la introduccion.  si se continua analizando la busqueda secuencial y  si la intencion es encontrar a  \"zeeman, pieter\" se deben realizar 33 comparaciones pero si se intenta encontrar a \"abt, antal\" solo dos comparaciones son necesarias. es decir, si se busca el ultimo elemento la cantidad de comparaciones es equivalente a n, donde n es la cantidad de elementos presentes en el vector; pero por otro, tambien depende de la clave a buscar. en consecuencia, la cantidad de comparaciones necesarias depende de la cantidad de elementos que posea el vector y su orden; y del elemento a buscar, esto es, depende de las entradas del algoritmo. de aqui se puede concluir que para analizar el tiempo de ejecucion se podria contar la cantidad de comparaciones realizadas y se la multiplica por el tiempo requerido por cada comparacion.  pero aqui se presenta otro inconveniente ¿el tiempo que toma una comparacion depende de la computadora en donde se este ejecutando? seria conveniente encontrar una funcion que dado el tamaño de entrada acote los pasos realizados por el algoritmo para encontrar la solucion en un tiempo que dependa de una constante c que representa el tiempo en diferentes computadoras.  diferentes entradas de la misma longitud pueden causar que el algoritmo se comporte distinto, por lo que se podria analizar el algoritmo desde tres perspectivas: el mejor caso, el caso promedio y el peor caso.​ en la figura 2 se muestra dichos casos de manera grafica.  cuando no se especifica lo contrario, la funcion que describe el rendimiento de un algoritmo suele este caso, dado que este caso garantiza que el algoritmo no tardara mayor cantidad de tiempo, es decir acota superiormente la cantidad de pasos.  a la hora de realizar un analisis teorico de algoritmos es comun calcular su complejidad en un sentido asintotico, es decir, para un tamaño de entrada suficientemente grande. la cota superior asintotica, y las notaciones omega (cota inferior) y theta (caso promedio) se usan con esa finalidad. por ejemplo, la busqueda binaria decimos que se ejecuta en una cantidad de pasos proporcional a un logaritmo, en o ( l o g ( n ) ) , coloquialmente \"en tiempo logaritmico\". normalmente, las estimaciones asintoticas se utilizan porque diferentes implementaciones del mismo algoritmo no tienen por que tener la misma eficiencia. no obstante, la eficiencia de dos implementaciones \"razonables\" cualesquiera de un algoritmo dado estan relacionadas por una constante multiplicativa llamada constante oculta.  de manera informal, se puede decir que un algoritmo exhibe una tasa de crecimiento del orden de una funcion matematica si mas alla de un cierto tamaño de entrada n , la funcion f ( n ) multiplicada por una constante positiva proporciona un limite superior o limite para el tiempo de ejecucion de ese algoritmo. en otras palabras, para un tamaño de entrada dado n mayor que algun n 0 } y una constante c , el tiempo de ejecucion de ese algoritmo nunca sera mayor que f ( n ) . este concepto se expresa con frecuencia utilizando la notacion o grande, que brinda una forma conveniente de expresar el peor de los casos para un algoritmo dado.  por ejemplo, el ordenamiento por insercion crece cuadraticamente a medida que aumenta su tamaño de entrada, entonces se puede decir que este tipo de ordenamiento es del orden de n cuadrado, en notacion o grande seria: o ( n 2 ) )} . otro tipo de funciones que pueden ser utilizadas para acotar un algoritmo son las mostradas en la figura 3.  la medida exacta (no asintotica) de la eficiencia a veces puede ser computada, pero para ello suele hacer falta aceptar supuestos acerca de la implementacion concreta del algoritmo, llamada modelo de computacion. un modelo de computacion puede definirse en terminos de un ordenador abstracto, como la maquina de turing, y/o postulando que ciertas operaciones se ejecutan en una unidad de tiempo. por ejemplo, si al conjunto ordenado al que aplicamos una busqueda binaria tiene n elementos, y podemos garantizar que una unica busqueda binaria puede realizarse en un tiempo unitario, entonces se requieren, como mucho, l o g 2 n + 1 n+1} unidades de tiempo para devolver una respuesta.  las medidas exactas de eficiencia son utiles para quienes verdaderamente implementan y usan algoritmos porque tienen mas precision y, asi, les permite saber cuanto tiempo pueden suponer que tomara la ejecucion. para algunas personas, como los desarrolladores de videojuegos, una constante oculta puede significar la diferencia entre exito y fracaso.  las estimaciones de tiempo dependen de como definamos un paso. para que el analisis tenga sentido, debemos garantizar que el tiempo requerido para realizar un paso se encuentra acotado superiormente por una constante. hay que mantenerse precavido en este terreno; por ejemplo, algunos analisis cuentan con que la suma de dos numeros se hace en un paso. este supuesto puede no estar garantizado en ciertos contextos. si, por ejemplo, los numeros involucrados en la computacion pueden ser arbitrariamente grandes, dejamos de poder asumir que la adicion requiere un tiempo constante (usando papel y lapiz, compara el tiempo que necesitas para sumar dos enteros de 2 digitos cada uno y el necesario para hacerlo con dos enteros pero de 1000 digitos cada uno).  en la practica el analisis de algoritmos es importante porque el uso accidental o no intencional de un algoritmo ineficiente puede afectar significativamente el rendimiento de un sistema. en aplicaciones de tiempo real, un algoritmo que tarda demasiado en ejecutarse puede hacer que sus resultados sean obsoletos o inutiles. un algoritmo ineficiente tambien puede terminar requiriendo una cantidad antieconomica de potencia de calculo o almacenamiento para funcionar, volviendolo practicamente inutil. ",
        "snippet": "El término análisis de algoritmos fue acuñado por Donald Knuth[1]​ y se refiere al proceso de encontrar la complejidad computacional de un algoritmo que resuelva un problema computacional dado, con el objetivo de proveer estimaciones teóricas de los recursos que necesita. Usualmente, los recursos a los cuales se hace referencia son el tiempo (complejidad temporal) y el almacenamiento (complejidad espacial). Mientras que la complejidad temporal involucra determinar una función que relaciona la longitud o el tamaño de la entrada del algoritmo con el número de pasos que realiza, la complejidad espacial busca la cantidad de ubicaciones de almacenamiento que utiliza. Distintos algoritmos pueden utilizarse para resolver un mismo problema y a su vez los algoritmos pueden estudiarse de forma independiente del lenguaje de programación a utilizar y de la máquina donde se ejecutará.[2]​ Esto significa que se necesitan técnicas que permitan comparar la eficiencia de los algoritmos antes de su implementación.",
        "enlaces_salientes": [
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/B%C3%BAsqueda_lineal",
            "/wiki/B%C3%BAsqueda_binaria",
            "/wiki/Donald_Knuth",
            "/wiki/Algoritmo",
            "/wiki/Problema_computacional",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Registro_(estructura_de_datos)",
            "/wiki/Vector_(inform%C3%A1tica)",
            "/wiki/B%C3%BAsqueda_lineal",
            "/wiki/B%C3%BAsqueda_binaria",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/B%C3%BAsqueda_binaria",
            "/wiki/Logaritmo",
            "/wiki/Implementaci%C3%B3n",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Ordenamiento_por_inserci%C3%B3n",
            "/wiki/As%C3%ADntota",
            "/wiki/Modelo_de_computaci%C3%B3n",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/B%C3%BAsqueda_binaria",
            "/wiki/Videojuego",
            "/wiki/Donald_Knuth",
            "/wiki/Algoritmos",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Teorema_maestro",
            "/wiki/Optimizaci%C3%B3n_de_software",
            "/wiki/Complejidad_temporal",
            "/wiki/ISBN",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Ronald_L._Rivest",
            "/wiki/Clifford_Stein",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/MIT_Press",
            "/wiki/Gilles_Brassard",
            "/wiki/Control_de_autoridades",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Ciencias_de_la_computacion",
        "titulo": "Ciencias de la computación",
        "contenido": "las ciencias de la computacion o ciencias de la informatica son las ciencias formales que abarcan las bases teoricas de la informacion y la computacion, asi como su aplicacion en los sistemas informaticos.​​​ el cuerpo de conocimiento de las ciencias de la computacion es frecuentemente descrito como el estudio sistematico de los procesos algoritmicos que describen y transforman informacion: su teoria, analisis, diseño, eficiencia, implementacion, algoritmos sistematizados y aplicacion.​ en terminos mas especificos se trata del estudio sistematico de la factibilidad, estructura, expresion y mecanizacion de procedimientos metodicos (o algoritmos) que subyacen en la adquisicion, representacion, procesamiento, almacenamiento, comunicacion y acceso a la informacion. la informacion puede estar codificada en forma de bits en una memoria de computadora, o en algun otro objeto, como los genes y proteinas en una celula biologica.​  existen diversas ramas o disciplinas dentro de las ciencias de la computacion; algunos resaltan los resultados especificos del computo (como los graficos por computadora), mientras que otros (como la teoria de la complejidad computacional) se relacionan con propiedades de los algoritmos usados al realizar computo; y otros se enfocan en los problemas que requieren la implementacion de sistemas informaticos. por ejemplo, los estudios de la teoria de lenguajes de programacion describen un computo, mientras que la programacion de computadoras aplica lenguajes de programacion especificos para desarrollar una solucion a un problema computacional especifico. un computologo se especializa en teoria de la computacion y en el diseño e implementacion de sistemas computacionales.​  segun peter j. denning, la cuestion fundamental en que se basa la ciencia de la computacion es: «¿que puede ser (eficientemente) automatizado?».​  la historia de la ciencia de la computacion antecede a la invencion del computador digital moderno. antes de la decada de 1920, el termino computador se referia a un ser humano que realizaba calculos.​ los primeros cimientos de lo que se convertiria en ciencias de la computacion son anteriores a la invencion de la computadora digital moderna. se trataba de maquinas para el calculo de las tareas numericas fijas, como el abaco han existido desde la antiguedad, ayudando en calculos tales como la multiplicacion y la division. ademas, los algoritmos para realizar calculos han existido desde la antiguedad, incluso antes de que se crearan equipos de computacion sofisticados. los antiguos sanscritos tratadistas shulba sutras, o \"reglas de la cuerda\", es un libro de algoritmos escritos en 800 a. c. para la construccion de objetos geometricos como altares utilizando una clavija y cuerda, un precursor temprano del campo moderno de la geometria computacional.  blaise pascal diseño y construyo la primera calculadora mecanica de trabajo, la pascalina, en 1642.​ en 1673 gottfried leibniz creo una calculadora mecanica digital, llamada stepped reckoner.​ el puede ser considerado el primer computologo y teorico de la informacion, entre otras razones, porque fue el primero en documentar el sistema numerico binario. en 1820, charles xavier thomas de colmar lanzo la calculadora mecanica industrial​ cuando lanzo su simplificado aritmometro, que fue la primera maquina de calcular lo suficientemente fuerte y lo suficientemente fiable para ser usada a diario en un entorno industrial. charles babbage inicio el diseño de la primera calculadora automatica mecanica, su maquina diferencial, en 1822, que finalmente le dio la idea de la primera calculadora mecanica programable, su maquina analitica.​ el comenzo a desarrollar esta maquina en 1834 y en menos de dos años habia esbozado muchas de las caracteristicas mas destacadas del moderno equipo. un paso fundamental fue la adopcion de un sistema de tarjetas perforadas derivado del telar de jacquard​ haciendolo infinitamente programable.​ en 1843, durante la traduccion de un articulo frances sobre la maquina analitica, ada lovelace escribio, en una de las muchas notas que incluye el articulo, un algoritmo para calcular los numeros de bernoulli, que es considerado como el primer programa de ordenador.​ alrededor de 1885, herman hollerith invento la maquina tabuladora, que usaba tarjetas perforadas para procesar informacion estadistica; finalmente, su compañia se convirtio en parte de ibm. en 1937, cien años despues del sueño imposible de babbage, howard aiken fue convencido por ibm (que estaban manufacturando todo tipo de equipos de tarjetas perforadas y asi como la calculadora de negocio​) para desarrollar su calculadora programable gigante, el ascc/harvard mark i. se baso en la maquina analitica de babbage, que a su vez utiliza las tarjetas perforadas y una unidad central de calculo. cuando se termino de construir la maquina, algunas personas lo aclamaron como «el sueño de babbage hecho realidad».​  durante la decada de 1940, conforme se desarrollaban las nuevas y mas poderosas maquinas para computar, el termino computador se comenzo a utilizar para referirse a las maquinas y ya no a sus antecesores humanos.​ cuando se hizo evidente que las computadoras no solamente podrian utilizarse para realizar calculos matematicos, el campo de las ciencias de la computacion se amplio para estudiar computo en general. las ciencias de la computacion empezaron a establecerse como una disciplina academica distinta de las demas en la decada de 1950 y principios de 1960.​​ entonces surgio el primer programa de grado universitario del mundo, el cambridge diploma in computer science, del cambridge computer lab (departamento de ciencias de la computacion) de la universidad de cambridge, en 1953. el primer programa de grado universitario en ciencias de la informatica en estados unidos se formo en la universidad de purdue en 1962.​ desde que se dispone ordenadores practicos, muchas aplicaciones la de las ciencias de la computacion se convirtieron en diferentes areas de estudio en sus propios terminos.  aunque inicialmente muchos creyeron que era imposible que las computadoras en si mismas podrian constituir en realidad un campo cientifico de estudio, a finales de los años cincuenta se fue volviendo gradualmente aceptada entre la poblacion mayor academica.​​  la disciplina cientifica de las ciencias de la computacion nace a principios de 1940 con la confluencia de la teoria de algoritmos, logica matematica y la invencion del programa almacenado en una computadora electronica.​ ejemplos de esto son los trabajos de alan turing, alonzo church y kurt godel en 1930 acerca de los algoritmos y su trabajo en sistemas de reglas (vease calculo lambda, maquina de turing y problemas indecidibles), los algoritmos creados por augusta ada sesenta años antes, la computadora analogica construida por vannevar bush en 1920 y las computadoras electricas construidas por howard aiken y konrad zuse en 1930. los escritos de john von neumann dieron una profundidad intelectual considerable a esta disciplina emergente a mediados de la decada de 1940.  en 1960, habia suficientemente cuerpo de conocimiento que ameritaba la creacion de departamentos academicos y programas de grado universitario para esta disciplina.​ ibm es reconocida como la marca que formo parte de la revolucion de las ciencias de la computacion durante ese tiempo. ibm (abreviacion de international business machines) lanzo la ibm 704​ y mas tarde la ibm 709​ computadoras, que fueron ampliamente utilizadas durante el periodo de exploracion de este tipo de dispositivos. \"sin embargo, el trabajo con la ibm [equipo] era frustrante ... si te equivocas en una letra de alguna instruccion, el programa se arruinaria, y se tendria que empezar todo el proceso otra vez\".​ durante la decada de 1950, la disciplina de las ciencias de la computacion estaba en su etapa de desarrollo, y estos problemas eran algo comun.  el tiempo ha dado mejoras significativas en la capacidad de uso y la eficacia de la tecnologia de la computacion. la sociedad moderna ha presenciado un cambio significativo en los usuarios de la tecnologia en computo, de ser utilizada unicamente por expertos, profesionales y cientificos, a una base de usuarios que es casi omnipresente a la teoria con la cual se desarrollo y funciona este tipo de tecnologia. inicialmente, las computadoras eran bastante costosas, y era necesario un cierto grado de ayuda humana para el uso eficiente - en parte de operadores de computadoras profesionales. como la adopcion equipo se hizo mas generalizado y asequible, se necesitaba menos asistencia humana en el uso comun.  a pesar de su corto tiempo de ser una disciplina cientifica formal, las ciencias de la computacion han hecho un gran numero de contribuciones importantes a la ciencia y la sociedad –de hecho, junto con la electronica, es una ciencia fundacional de la epoca actual de la historia humana llamada era de la informacion y la revolucion de la informacion, visto como el tercer gran salto en el progreso tecnologico humano despues de la revolucion industrial (1750-1850) y la revolucion neolitica (8000-5000 a. c.).  estas contribuciones a la humanidad incluyen:  algunos cientificos de la computacion han argumentado a favor de la distincion de tres paradigmas diferentes en ciencias de la computacion. peter wegner ha argumentado que esos paradigmas son la ciencia, la tecnologia y las matematicas.​ el grupo de investigacion de peter denning argumento que son la abstraccion (modelado), y diseño. amnon h. eden lo describe como el «paradigma racionalista» (el cual trata a las ciencias de la computacion como una rama de las matematicas, la cual prevalece en ciencias de la computacion teorica y principalmente emplea el razonamiento deductivo), el paradigma tecnocratico (que podria ser encontrado en enfoques ingenieriles, mas prominente en la ingenieria de software) y el paradigma cientifico (que se enfoca a objetos relacionados con la computacion desde la perspectiva empirica de las ciencias naturales identificable en algunas ramas de la inteligencia artificial).  a pesar de su primera proposicion en 1956,​ la locucion «ciencias de la computacion» aparece en 1959 en un articulo de la revista communications of the acm (prestigiada publicacion cientifica destinada a lectores con experiencia en todos los ambitos de la computacion y los sistemas de informacion),​ en el cual louis fein discute sobre la creacion de una escuela de estudios de posgrado en ciencias computacionales analoga a la creacion de harvard business school en 1921,​ justificando el nombre con el argumento de que: como la ciencia administrativa, el tema o area de conocimiento puede ser aplicado, es de caracter interdisciplinario y que cuenta con las caracteristicas tipicas de una disciplina academica.​ sus esfuerzos y los de otros, como el analista numerico george forsythe, fueron recompensados: universidades pasaron a crear este tipo de programas de estudio, a partir de 1962 en purdue.​ a pesar del nombre de esta disciplina academica, una cantidad significativa de topicos en ciencias de la computacion no involucran el estudio de las computadoras, por esta razon muchos nombres alternativos han sido propuestos.​  algunos departamentos de universidades prefieren la locucion «ciencias de la computacion» para hacer enfasis en esta diferencia. el cientifico danes peter naur sugirio el termino datologia,​ para reflejar el hecho de que esta disciplina cientifica gira en torno a los datos y a al tratamiento de estos, mientras que no necesariamente involucra a las computadoras. la primera institucion cientifica en usar el termino fue el departamento de datologia de la universidad de copenhague, fundado en 1969, con peter naur como profesor de datologia. el termino es usado en paises escandinavos. en los primeros años de la computacion, un numero de terminus para los practicantes del campo de la computacion fueron propuestos en la revista communications of the acm – turingeniero, turologo, hombre de los diagramas de flujo, matematico meta-aplicado, y epistemologo aplicado.​ tres meses despues en esa misma publicacion cientifica, el termino computologo fue sugerido. el siguiente año en la misma publicacion surgio el termino hypologo.​ el termino computica tambien ha sido sugerido.​ en europa, terminos derivados de traducciones de la expresion \"automatic information\" (e.g. \"informazione automatica\" en italiano) or \"informacion y matematicas\" son frecuentemente usados, e.g. informatique (frances), informatik (aleman), informatica (italia, paises bajos), informatica (españa y portugal), informatika (lenguas eslavas) o pliroforiki (πληροφορκη, que significa informatica) en griego. palabras similares han sido adoptadas en algunos lugares del reino unido, por ejemplo en la universidad de edimburgo.​ pero estas no reflejan el aspecto de la computabilidad, por esta razon en un contexto de investigacion cientifica tanto academica como industrial el termino ciencias de la computacion es mayormente usado en publicaciones y conferencias cientificas.  como disciplina cientifica, las ciencias de la computacion abarca una gama de temas, desde los estudios teoricos de los algoritmos y los limites de la computacion a los problemas practicos de la implementacion de sistemas computacionales en hardware y software.​​ computing sciences acreditation board o la junta de acreditacion en ciencias de la computacion. –compuesta por representantes de la association for computing machinery (acm), y la sociedad de computacion ieee (ieee-cs)​– identifica cuatro areas que considera cruciales para la disciplina de ciencias de la computacion: teoria de la computacion, algoritmos y estructuras de datos, metodologia y lenguajes de programacion, y arquitectura de computadoras. ademas de estas cuatro areas, c.s.a.b. tambien identifica ambitos como la ingenieria de software, inteligencia artificial, redes de computadoras, sistemas de bases de datos, computacion paralela, computacion distribuida, la interaccion persona-computador, graficos por ordenador, sistemas operativos, calculo numerico y simbolico siendo importantes areas de las ciencias de la computacion.​  el campo mas amplio de la ciencia de la computacion teorica abarca tanto la teoria clasica de la computacion y una amplia gama de otros temas que se centran en los aspectos mas abstractos, logicos y matematicos de la computacion.  de acuerdo a peter j. denning, la pregunta fundamental en ciencias de la computacion es, «¿que puede ser eficientemente automatizado?»​ el estudio de la teoria de la computacion esta enfocado en responder preguntas fundamentales acerca de que puede ser computado y que cantidad de recursos son requeridos para ejecutar tales computos. en un esfuerzo por resolver esta pregunta, la teoria de la computabilidad examina que problemas computacionales se pueden resolver en varios modelos teoricos de computo. la segunda pregunta esta dirigida por la teoria de la complejidad computacional, que estudia los costos de tiempo y espacio asociados a diferentes enfoques para resolver una multitud de problemas computacionales.  el famoso problema \"¿p=np?\" es uno de los problemas del milenio,​ es un problema abierto en ciencias de la computacion.  la teoria de la informacion esta relacionada con la cuantificacion de la informacion. fue desarrollada por claude e. shannon para desarrollar los limites fundamentales del procesamiento de señales asi como sus operaciones, tales como compresion y almacenamiento de datos asi como la comunicacion de los datos de manera fiable.​ la teoria de codigos es un area de las matematicas que busca resolver el problema de detectar y corregir errores al momento de transmitir informacion.​ los codigos son usados para comprimir datos, criptografia y mas recientemente para la codificacion de redes. los codigos son estudiados para el proposito de diseñar metodos eficientes y seguros para la transmision de datos.  los algoritmos y las estructuras de datos son el estudio de metodos computacionales comunmente usados asi como su eficiencia computacional.  la teoria del lenguaje de programacion es una rama de las ciencias de la computacion que se ocupa del diseño, activacion, analisis, caracterizacion y clasificacion de los lenguaje de programacion y sus caracteristicas individuales, cae dentro de la disciplina de las ciencias de la computacion, tanto en dependencia de las matematicas y la linguistica. es un area de investigacion activa, con numerosas revistas academicas y conferencias especializadas en el tema.  los metodos formales son un tipo particular de la tecnica basada en las matematicas para la especificacion formal, desarrollo y verificacion formal de los sistemas de software y hardware. el uso de metodos formales para el diseño de soportes logico y fisico esta motivado por la expectativa de que, la realizacion de un analisis matematico adecuado puede contribuir a la fiabilidad y robustez de un diseño. estos forman una importante base teorica para la ingenieria de software, especialmente cuando esta involucrado la seguridad o robustez. los metodos formales son un complemento util para las pruebas de software, ya que ayudan a evitar errores y tambien pueden dar un marco para hacer pruebas. para su uso industrial, se requiere el apoyo de herramientas. sin embargo, el alto costo de la utilizacion de metodos formales significa que por lo general solo se utilizan en el desarrollo de sistemas criticos de alta integridad donde la vida o la seguridad es de muy alta importancia.  los metodos formales se describen mejor como la aplicacion de una amplia variedad de fundamentos teoricos de las ciencias de la computacion, en particular la logica computacional, lenguajes formales, teoria de automatas y semantica de lenguajes de programacion pero tambien areas como sistemas de tipos y tipos de datos algebraicos a problemas en la especificacion y verificacion de software y hardware.  las ciencias de la computacion aplicadas tratan de identificar ciertos aspectos conceptuales y teoricos de las ciencias de la informatica que pueden ser aplicados directamente para resolver problemas del mundo real.  esta rama de las ciencias de la computacion pretende o es requerida para la sintesis de procesos metaorientados tales como la resolucion de problemas, toma de decisiones, la adaptacion del medio ambiente, el aprendizaje y la comunicacion que se encuentran en los seres humanos y los animales. desde sus origenes en la cibernetica y en la conferencia de dartmouth (1956), la investigacion en inteligencia artificial (ia) ha sido necesariamente multidisciplinaria, aprovechando areas de especializacion, tales como las matematicas, la logica simbolica, la semiotica, la ingenieria electrica, la filosofia de la mente, la neurofisiologia, y la inteligencia social. la ia erroneamente es asociada en la mente popular con el desarrollo robotico, pero el principal campo de aplicacion practica ha sido como un componente integrado en las areas de desarrollo de programas informaticos que requieren la comprension y la modelacion computacional, tales como las finanzas y la economia, la mineria de datos y las ciencias fisicas. el termino fue acuñado por el cientifico de la computacion y matematico john mccarthy en 1955.  la arquitectura de computadores u organizacion de computadoras digitales es el diseño conceptual y la estructura operacional fundamental de un sistema computo. se centra en gran medida de la manera en que la unidad central de procesamiento realiza internamente y accede a las direcciones en la memoria.​ el campo involucra disciplinas de la ingenieria en computacion y la ingenieria electrica, la seleccion y la interconexion de los componentes fisicos para crear los equipos que cumplen funciones, de rendimiento, y costes.  analisis de rendimiento del equipo es el estudio del trabajo que fluye a traves de los equipos con el objetivo general de mejora de rendimiento y control de tiempo de respuesta, utilizando los recursos de manera eficiente, la eliminacion de los cuellos de botella, y la prediccion de rendimiento bajo cargas maximas previstas.​  la ciencia computacional (o computacion cientifica) es el campo de estudio que trata con la construccion de modelos matematicos y tecnicas de analisis cuantitativos, asi como el uso de computadoras para analizar y resolver problemas cientificos. en el uso practico, es tipicamente la aplicacion de simulacion por ordenador y otras formas de calculo a los problemas en diversas disciplinas cientificas.  esta rama de las ciencias de la computacion tiene como objetivo gestionar la conectividad entre redes (lan / wan) de computadoras a nivel mundial.  concurrencia es una propiedad de los sistemas en los que varios calculos estan ejecutando de forma simultanea, y, potencialmente, que interactuan entre si. un numero de modelos matematicos han sido desarrollados para el calculo concurrente general, incluyendo las redes de petri, calculos de proceso y del modelo de maquina de acceso aleatorio en paralelo. un sistema distribuido se extiende la idea de la simultaneidad en varios ordenadores conectados a traves de una red. las computadoras dentro del mismo sistema distribuido tienen su propia memoria privada, y la informacion es a menudo intercambiada entre si para lograr un objetivo comun.  una base de datos tiene la intencion de organizar, almacenar y recuperar grandes cantidades de datos de forma sencilla. bases de datos digitales se gestionan mediante sistemas de gestion de base de datos para almacenar, crear, mantener y consultar los datos, a traves de modelos de bases de datos y lenguajes de consulta. una base de datos es un conjunto de datos interrelacionados entre ellos mismos.  el campo estudia la estructura, algoritmos, comportamiento e interacciones de los sistemas naturales y artificiales que guardan, procesan, acceden a y comunican informacion. tambien desarrolla sus propios fundamentos conceptuales y teoricos y emplea fundamentos desarrollados en otros campos. una aplicacion moderna es el big data, que consiste en el procesamiento de un conjunto de datos (provenientes de fuentes como por ejemplo: transacciones comerciales, formularios web, imagenes, videos, correos electronicos, redes sociales, entre otros), los cuales son sometidos a herramientas informaticas de analisis que permiten extraer informacion valiosa para predecir comportamientos futuros y formular estrategias de toma decisiones.​  ingenieria de software consiste en el estudio del diseño, activacion y modificacion del software con la finalidad de asegurarse de que es de alta calidad, asequible, facil de mantener, y rapido de construir. es un enfoque sistematico para el diseño de software, que implica la aplicacion de practicas de ingenieria de software. los ingenieros de software comercian con la organizacion y analisis de software — no solo lidian con la creacion o fabricacion de un nuevo soporte logico, sino tambien con su mantenimiento y disposicion interna. se preve que esten entre las ocupaciones de mas rapido crecimiento entre 2008 y 2018. debido a la novedad de este subcampo, la educacion formal en ingenieria de software generalmente es parte de los planes de estudio de ciencias de la computacion, la gran mayoria de ingenieros de software tienen un grado academico en ciencias de la computacion sin tener relacion con la ingenieria.​  por ser una disciplina reciente, existen varias definiciones alternativas para la ciencia de la computacion. esta puede ser vista como una forma de ciencia, matematicas o una nueva disciplina que no puede ser categorizada siguiendo los modelos actuales.  las ciencias de la computacion frecuentemente se cruzan con otras areas de investigacion, tales como la fisica y la linguistica. pero es con las matematicas con las que se considera que tiene un grado mayor de relacion. eso es evidenciado por el hecho de que los primeros trabajos en el area fueran fuertemente influenciados por matematicos como kurt godel y alan turing. en la actualidad sigue habiendo un intercambio de ideas util entre ambos campos en areas como la logica matematica, la teoria de categorias, la teoria de dominios, el algebra y la geometria.  otro punto a destacar es que, a pesar de su nombre, las ciencias de la computacion raramente involucran el estudio mismo de las maquinas conocidas como computadoras. de hecho, el renombrado cientifico edsger dijkstra es muy citado por la frase «las ciencias de la computacion estan tan poco relacionadas con los ordenadores como la astronomia con los telescopios». la investigacion en ciencias de la computacion tambien suele relacionarse con otras disciplinas, como la ciencia cognitiva, la fisica (vease computacion cuantica), la linguistica, etc.  la relacion entre las ciencias de la computacion y la ingenieria de software es un tema muy discutido, por disputas sobre lo que realmente significa la lucion «ingenieria de software» y sobre como se define a las ciencias de la computacion. algunas personas creen que la ingenieria de software seria un subconjunto de las ciencias de la informatica. otras, tomando en cuenta la relacion entre otras disciplinas cientificas y de la ingenieria, creen que el principal objetivo de las ciencias de la computacion seria estudiar las propiedades del computo en general, mientras que el objetivo de la ingenieria de software seria diseñar computos especificos para lograr objetivos practicos, con lo que se convertiria en disciplinas diferentes. este punto de vista es el que sostiene, por ejemplo, parnas (1998). incluso hay otros que sostienen que no podria existir una ingenieria de software.  los aspectos academicos, politicos y de financiamiento en las areas de ciencias de la computacion tienden a verse influidos drasticamente por el criterio del departamento encargado de la investigacion y la educacion en cada universidad, que puede estar orientado a las matematica o a la ingenieria. los departamentos de ciencias de la computacion orientados a las matematicas teoricas suelen alinearse del lado de la computacion cientifica y las aplicaciones de calculo numerico.  la locucion «computacion cientifica», que no debe confundirse con ciencia de la computacion, designa a todas aquellas practicas destinadas a modelar, plantear experimentos y validar teorias cientificas sirviendose de medios informaticos. en estos casos la computacion es una mera herramienta y el esfuerzo se dirige a avanzar en los campos objetivo (fisica, biologia, mecanica de fluidos, radiotransmision...), mas que en la propia ciencia de la computacion.  finalmente, el publico en general algunas veces confunde la ciencia de la computacion con areas vocacionales que trabajan con computadoras o piensan que trata acerca de su propia experiencia con las computadoras, lo cual suele incluir actividades como los juegos, la navegacion web y el procesamiento de texto. sin embargo, el punto central de la ciencia de la computacion va mas alla de entender las propiedades de los programas que se emplean para ejecutar aplicaciones de software como juegos y navegadores web, y utiliza ese entendimiento para crear nuevos programas o mejorar los existentes.​     ",
        "snippet": "Las ciencias de la computación o ciencias de la informática son las ciencias formales que abarcan las bases teóricas de la información y la computación, así como su aplicación en los sistemas informáticos.[1]​[2]​[3]​ El cuerpo de conocimiento de las ciencias de la computación es frecuentemente descrito como el estudio sistemático de los procesos algorítmicos que describen y transforman información: su teoría, análisis, diseño, eficiencia, implementación, algoritmos sistematizados y aplicación.[4]​ En términos más específicos se trata del estudio sistemático de la factibilidad, estructura, expresión y mecanización de procedimientos metódicos (o algoritmos) que subyacen en la adquisición, representación, procesamiento, almacenamiento, comunicación y acceso a la información. La información puede estar codificada en forma de bits en una memoria de computadora, o en algún otro objeto, como los genes y proteínas en una célula biológica.[5]​",
        "enlaces_salientes": [
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Computaci%C3%B3n_gr%C3%A1fica",
            "/wiki/Interacci%C3%B3n_persona-computador",
            "/wiki/Ciencias_formales",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Sistemas_de_informaci%C3%B3n",
            "/wiki/Factibilidad",
            "/wiki/Estructura_de_datos",
            "/wiki/Expresi%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Algoritmos",
            "/wiki/Grafo",
            "/wiki/Proceso_(inform%C3%A1tica)",
            "/wiki/Dispositivo_de_almacenamiento_de_datos",
            "/wiki/Comunicaci%C3%B3n",
            "/wiki/Acceso",
            "/wiki/Informaci%C3%B3n",
            "/wiki/Bit",
            "/wiki/Gr%C3%A1ficos_por_computadora",
            "/wiki/Complejidad_computacional",
            "/wiki/Algoritmos",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Peter_J._Denning",
            "/wiki/Charles_Babbage",
            "/wiki/Turing_completo",
            "/wiki/Alan_Turing",
            "/wiki/Ada_Lovelace",
            "/wiki/Algoritmo",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Computadora_electr%C3%B3nica",
            "/wiki/A%C3%B1os_1920",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Blaise_Pascal",
            "/wiki/Pascalina",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Stepped_Reckoner",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Charles_Xavier_Thomas_de_Colmar",
            "/wiki/Calculadora_mec%C3%A1nica",
            "/wiki/Aritm%C3%B3metro",
            "/wiki/Charles_Babbage",
            "/wiki/M%C3%A1quina_diferencial",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Ada_Lovelace",
            "/wiki/Bernoulli",
            "/wiki/Herman_Hollerith",
            "/wiki/Tabuladora",
            "/wiki/IBM",
            "/wiki/Howard_Aiken",
            "/wiki/Harvard_Mark_I",
            "/wiki/A%C3%B1os_1940",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Universidad_de_Purdue",
            "/wiki/Disciplina_acad%C3%A9mica",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Alan_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/1930",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Problema_indecidible",
            "/wiki/Ada_Lovelace",
            "/wiki/Vannevar_Bush",
            "/wiki/Howard_Aiken",
            "/wiki/Konrad_Zuse",
            "/wiki/A%C3%B1os_1930",
            "/wiki/John_Von_Neumann",
            "/wiki/1960",
            "/wiki/IBM",
            "/wiki/Wehrmacht",
            "/wiki/M%C3%A1quina_Enigma",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Alan_Turing",
            "/wiki/Bletchley_Park",
            "/wiki/Disciplina_acad%C3%A9mica",
            "/wiki/Ciencia",
            "/wiki/Sociedad",
            "/wiki/Electr%C3%B3nica",
            "/wiki/Era_de_la_informaci%C3%B3n",
            "/wiki/Revoluci%C3%B3n_Industrial",
            "/wiki/Revoluci%C3%B3n_neol%C3%ADtica",
            "/wiki/Revoluci%C3%B3n_digital",
            "/wiki/Era_de_la_informaci%C3%B3n",
            "/wiki/Internet",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Problema_indecidible",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Criptolog%C3%ADa",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Computaci%C3%B3n_cient%C3%ADfica",
            "/wiki/Clase_de_complejidad",
            "/wiki/Proyecto_Genoma_Humano",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Folding@home",
            "/wiki/Plegamiento_de_prote%C3%ADnas",
            "/wiki/Computaci%C3%B3n_gr%C3%A1fica",
            "/wiki/Imagen_generada_por_computadora",
            "/wiki/Entretenimiento",
            "/wiki/Televisi%C3%B3n",
            "/wiki/Cine",
            "/wiki/Publicidad",
            "/wiki/Animaci%C3%B3n",
            "/wiki/Videojuegos",
            "/wiki/Simulaci%C3%B3n",
            "/wiki/Din%C3%A1mica_de_fluidos",
            "/wiki/SPICE",
            "/wiki/Circuito_integrado",
            "/wiki/Inteligencia_artificial",
            "/wiki/Peter_Wegner",
            "/wiki/Peter_J._Denning",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Ciencias_naturales",
            "/wiki/Inteligencia_artificial",
            "/wiki/Harvard_Business_School",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Peter_Naur",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/Lenguas_eslavas",
            "/wiki/Idioma_griego",
            "/wiki/Universidad_de_Edimburgo",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Disciplina_acad%C3%A9mica",
            "/wiki/Algoritmos",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/IEEE",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Algoritmos",
            "/wiki/Estructuras_de_datos",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Arquitectura_de_computadoras",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Inteligencia_artificial",
            "/wiki/Redes_de_computadoras",
            "/wiki/Bases_de_datos",
            "/wiki/Computaci%C3%B3n_paralela",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Interacci%C3%B3n_persona-computador",
            "/wiki/Gr%C3%A1ficos_por_ordenador",
            "/wiki/Sistemas_operativos",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/C%C3%A1lculo_simb%C3%B3lico",
            "/wiki/Ciencia_computacional_te%C3%B3rica",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Peter_J._Denning",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Clases_de_complejidad_P_y_NP",
            "/wiki/Problemas_del_milenio",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Claude_Shannon",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Transmisi%C3%B3n_de_datos",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Algoritmo",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Algoritmos",
            "/wiki/Estructuras_de_datos",
            "/wiki/Optimizaci%C3%B3n_combinatoria",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Teor%C3%ADa_de_tipos",
            "/wiki/Compiladores",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/M%C3%A9todos_formales",
            "/wiki/Especificaci%C3%B3n_formal",
            "/wiki/Verificaci%C3%B3n_formal",
            "/wiki/Lenguajes_formales",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Sem%C3%A1ntica_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Sistema_de_tipos",
            "/wiki/Inteligencia_artificial",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Visi%C3%B3n_artificial",
            "/wiki/Procesamiento_de_im%C3%A1genes",
            "/wiki/Reconocimiento_de_patrones",
            "/wiki/Ciencia_cognitiva",
            "/wiki/Miner%C3%ADa_de_datos",
            "/wiki/Computaci%C3%B3n_evolutiva",
            "/wiki/B%C3%BAsqueda_y_recuperaci%C3%B3n_de_informaci%C3%B3n",
            "/wiki/Representaci%C3%B3n_del_conocimiento",
            "/wiki/Procesamiento_de_lenguaje_natural",
            "/wiki/Rob%C3%B3tica",
            "/wiki/Arquitectura_de_computadoras",
            "/wiki/L%C3%B3gica_digital",
            "/wiki/Microarquitectura",
            "/wiki/Multiprocesamiento",
            "/wiki/Sistemas_operativos",
            "/wiki/Redes_de_computadoras",
            "/wiki/Sistema_de_gesti%C3%B3n_de_bases_de_datos",
            "/wiki/Seguridad_inform%C3%A1tica",
            "/wiki/Computaci%C3%B3n_ubicua",
            "/wiki/Arquitectura_de_software",
            "/wiki/Compiladores",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/F%C3%ADsica_computacional",
            "/wiki/Qu%C3%ADmica_computacional",
            "/wiki/Bioinform%C3%A1tica",
            "/wiki/Redes_de_computadoras",
            "/wiki/Red_de_%C3%A1rea_local",
            "/wiki/Red_de_%C3%A1rea_amplia",
            "/wiki/Computaci%C3%B3n_concurrente",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Bases_de_datos",
            "/wiki/Sistema_de_gesti%C3%B3n_de_bases_de_datos",
            "/wiki/Inform%C3%A1tica_en_salud",
            "/wiki/Inform%C3%A1tica_en_salud",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Software_m%C3%A9dico",
            "/wiki/Tecnolog%C3%ADas_sanitarias",
            "/wiki/Big_Data",
            "/wiki/Toma_de_decisiones",
            "/wiki/Ciencias_de_la_informaci%C3%B3n_(tecnolog%C3%ADa)",
            "/wiki/B%C3%BAsqueda_y_recuperaci%C3%B3n_de_informaci%C3%B3n",
            "/wiki/Representaci%C3%B3n_del_conocimiento",
            "/wiki/Procesamiento_de_lenguaje_natural",
            "/wiki/Interacci%C3%B3n_persona-computador",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Software",
            "/wiki/Categor%C3%ADa",
            "/wiki/F%C3%ADsica",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Alan_Turing",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_categor%C3%ADas",
            "/wiki/Teor%C3%ADa_de_dominios",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Edsger_Dijkstra",
            "/wiki/Ciencia_cognitiva",
            "/wiki/F%C3%ADsica",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Software",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Ciencias_de_la_informaci%C3%B3n_(tecnolog%C3%ADa)",
            "/wiki/Ingenier%C3%ADa_en_computaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Problema_de_la_cena_de_los_fil%C3%B3sofos",
            "/wiki/Problemas_no_resueltos_de_las_Ciencias_de_la_Computaci%C3%B3n",
            "/wiki/Mujeres_en_inform%C3%A1tica",
            "/wiki/Premio_Turing",
            "/wiki/Ciencia_web",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Peter_J._Denning",
            "/wiki/Princeton_University_Press",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Steven_Levy",
            "/wiki/ISBN",
            "/wiki/Hal_Abelson",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Donald_Knuth",
            "/wiki/Wayback_Machine",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/University_of_Cambridge",
            "/wiki/Bertrand_Meyer",
            "/wiki/CiteSeerX",
            "/wiki/Digital_Bibliography_%26_Library_Project",
            "/wiki/Universit%C3%A4t_Trier",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Historical_Dictionary_of_Switzerland",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Lenguaje_de_programaci%C3%B3n",
        "titulo": "Lenguaje de programación",
        "contenido": "un lenguaje de programacion es un lenguaje formal (o artificial, es decir, un lenguaje con reglas gramaticales bien definidas) que proporciona a una persona, en este caso el programador, la capacidad y habilidad de escribir (o programar) una serie de instrucciones o secuencias de ordenes en forma de algoritmos con el fin de controlar el comportamiento fisico o logico de un sistema informatico, para que de esa manera se puedan obtener diversas clases de datos o ejecutar determinadas tareas. a todo este conjunto de ordenes escritas mediante un lenguaje de programacion se le denomina programa informatico.​​​​  programar viene a ser el proceso de crear un software fiable mediante la escritura, prueba, depuracion, compilacion o interpretacion, y mantenimiento del codigo fuente de dicho programa informatico. basicamente, este proceso se define aplicando logicamente los siguientes pasos:  los lenguajes de programacion estan formados por un conjunto de simbolos (llamado alfabeto), reglas gramaticales (lexico/morfologicas y sintacticas) y semanticas, que en conjunto definen las estructuras validas del lenguaje y su significado. existe el error comun de tratar como sinonimos los terminos 'lenguaje de programacion' y 'lenguaje informatico'. los lenguajes informaticos engloban a los lenguajes de programacion y a otros mas, como por ejemplo html (lenguaje para el marcado de paginas web, que no es propiamente un lenguaje de programacion, sino un conjunto de instrucciones que permiten estructurar el contenido de los documentos).  el lenguaje de programacion permite especificar de manera precisa sobre que datos debe operar un software especifico, como deben ser almacenados o transmitidos dichos datos, y que acciones debe tomar el software bajo una variada gama de circunstancias. todo esto, a traves de un lenguaje que intenta estar relativamente proximo al lenguaje humano o natural. una caracteristica relevante de los lenguajes de programacion es precisamente que mas de un programador pueda usar un conjunto comun de instrucciones que sean comprendidas entre ellos para realizar la construccion de un programa de forma colaborativa.  para que la computadora entienda nuestras instrucciones debe usarse un lenguaje especifico conocido como codigo maquina, que la maquina lee facilmente, pero que es excesivamente complicado para las personas. de hecho, solo consiste en cadenas extensas de numeros 0 y 1(numeros binarios).  para facilitar el trabajo, los primeros operadores de computadoras decidieron crear un traductor para reemplazar los 0 y 1 por palabras o abstraccion de palabras y letras provenientes del ingles; este se conoce como lenguaje ensamblador. por ejemplo, para sumar se usa la letra a de la palabra inglesa add (sumar). el lenguaje ensamblador sigue la misma estructura del lenguaje maquina, pero las letras y palabras son mas faciles de recordar y entender que los numeros.  la necesidad de recordar secuencias de programacion para las acciones usuales llevo a denominarlas con nombres faciles de memorizar y asociar: add (sumar), sub (restar), mul (multiplicar), call (ejecutar subrutina), etc. a esta secuencia de posiciones se le denomino \"instrucciones\", y a este conjunto de instrucciones se le llamo lenguaje ensamblador. posteriormente aparecieron diferentes lenguajes de programacion, los cuales reciben su denominacion porque tienen una estructura sintactica semejante a la de los lenguajes escritos por los humanos, denominados tambien lenguajes de alto nivel.​  a finales de 1953, john backus sometio una propuesta a sus superiores en ibm para desarrollar una alternativa mas practica al lenguaje ensamblador, para programar la computadora central ibm 704. el historico equipo fortran de john backus consistio en los programadores richard goldberg, sheldon f. best, harlan herrick, peter sheridan, roy nutt, robert nelson, irving ziller, lois haibt y david sayre.​  el primer manual para el lenguaje fortran aparecio en octubre de 1956, con el primer compilador fortran entregado en abril de 1957. esto era un compilador optimizado, porque los clientes eran reacios a usar un lenguaje de alto nivel a menos que su compilador pudiera generar codigo cuyo desempeño fuera comparable al de un codigo hecho a mano en lenguaje ensamblador.  en 1960 se creo cobol, uno de los lenguajes usados aun en la actualidad, en informatica de gestion.  a medida que la complejidad de las tareas que realizaban las computadoras aumentaba, se hizo necesario disponer de un metodo mas eficiente para programarlas. entonces se crearon los lenguajes de alto nivel, como lo fue basic en las versiones introducidas en los microordenadores de la decada de 1980. mientras que una tarea tan sencilla como sumar dos numeros puede necesitar varias instrucciones en lenguaje ensamblador, en un lenguaje de alto nivel bastara una sola sentencia.  los lenguajes de programacion han sido historicamente clasificados atendiendo a distintos criterios:  en algunas ocasiones los lenguajes de programacion son tambien clasificados en familias que comparten ciertas caracteristicas comunes como el estilo general de la sintaxis que emplean. habitualmente estas caracteristicas suelen ser heredadas de lenguajes de programacion anteriores que sirvieron de inspiracion a los creadores de dicho lenguaje.  los equipos de ordenador (el hardware) han pasado por cuatro generaciones, de las que las tres primeras (ordenadores con valvulas, transistores y circuitos integrados) estan muy claras; la cuarta (circuitos integrados a gran escala) es mas discutible.  algo parecido ha ocurrido con la programacion de los ordenadores (el software), que se realiza en lenguajes que suelen clasificarse en cinco generaciones, de las que las tres primeras son evidentes, mientras no todo el mundo esta de acuerdo en las otras dos. estas generaciones no coincidieron exactamente en el tiempo con las de hardware, pero si de forma aproximada, y son las siguientes:  algunos ejemplos de lenguajes de programacion de quinta generacion son:  un paradigma de programacion consiste en un metodo para llevar a cabo computos y la forma en la que deben estructurarse y organizarse las tareas que debe realizar un programa.​ se trata de una propuesta tecnologica adoptada por una comunidad de programadores, y desarrolladores cuyo nucleo central es incuestionable en cuanto que unicamente trata de resolver uno o varios problemas claramente delimitados; la resolucion de estos problemas debe suponer consecuentemente un avance significativo en al menos un parametro que afecte a la ingenieria de software. representa un enfoque particular o filosofia para diseñar soluciones. los paradigmas difieren unos de otros, en los conceptos y la forma de abstraer los elementos involucrados en un problema, asi como en los pasos que integran su solucion del problema, en otras palabras, el computo. tiene una estrecha relacion con la formalizacion de determinados lenguajes en su momento de definicion. es un estilo de programacion empleado.  un paradigma de programacion esta delimitado en el tiempo en cuanto a aceptacion y uso, porque nuevos paradigmas aportan nuevas o mejores soluciones que lo sustituyen parcial o totalmente.  el paradigma de programacion que actualmente es mas utilizado es la \"orientacion a objetos\" (oo). el nucleo central de este paradigma es la union de datos y procesamiento en una entidad llamada \"objeto\", relacionable a su vez con otras entidades \"objeto\".  tradicionalmente, datos y procesamiento se han separado en areas diferente del diseño y la implementacion de software. esto provoco que grandes desarrollos tuvieran problemas de fiabilidad, mantenimiento, adaptacion a los cambios y escalabilidad. con la oo y caracteristicas como el encapsulado, polimorfismo o la herencia, se permitio un avance significativo en el desarrollo de software a cualquier escala de produccion. la oo parece estar ligada en sus origenes con lenguajes como lisp y simula, aunque el primero que acuño el titulo de \"programacion orientada a objetos\" fue smalltalk.  en general, la mayoria de paradigmas son variantes de los dos tipos principales de programacion, imperativa y declarativa. en la programacion imperativa se describe paso a paso un conjunto de instrucciones que deben ejecutarse para variar el estado del programa y hallar la solucion, es decir, un algoritmo en el que se describen los pasos necesarios para solucionar el problema.  en la programacion declarativa las sentencias que se utilizan lo que hacen es describir el problema que se quiere solucionar; se programa diciendo lo que se quiere resolver a nivel de usuario, pero no las instrucciones necesarias para solucionarlo. esto ultimo se realizara mediante mecanismos internos de inferencia de informacion a partir de la descripcion realizada.  a continuacion se describen algunas de las distintas variantes de paradigmas de programacion:  las variables son titulos asignados a espacios en memoria para almacenar datos especificos. son contenedores de datos y por ello se diferencian segun el tipo de dato que son capaces de almacenar. en la mayoria de lenguajes de programacion se requiere especificar un tipo de variable concreto para guardar un dato especifico. por ejemplo, en java, si deseamos guardar una cadena de texto debemos especificar que la variable es del tipo string. por otra parte, en lenguajes como php o javascript este tipo de especificacion de variables no es necesario. ademas, existen variables compuestas llamadas vectores. un vector no es mas que un conjunto de bytes consecutivas en memoria y del mismo tipo guardadas dentro de una variable contenedor. a continuacion, un listado con los tipos de variables y vectores mas comunes:  en el caso de variables booleanas, el cero es considerado para muchos lenguajes como el literal falso (\"false\"), mientras que el uno se considera verdadero (\"true\").  las sentencias condicionales son estructuras de codigo que indican que, para que cierta parte del programa se ejecute, deben cumplirse ciertas premisas; por ejemplo: que dos valores sean iguales, que un valor exista, que un valor sea mayor que otro… estos condicionantes por lo general solo se ejecutan una vez a lo largo del programa. los condicionantes mas conocidos y empleados en programacion son:  los bucles son parientes cercanos de los condicionantes, pero ejecutan constantemente un codigo mientras se cumpla una determinada condicion. los mas frecuentes son:  hay que decir que a pesar de que existan distintos tipos de bucles, todos son capaces de realizar exactamente las mismas funciones. el empleo de uno u otro depende, por lo general, del gusto del programador.  las funciones se crearon para evitar tener que repetir constantemente fragmentos de codigo. una funcion podria considerarse como una variable que encierra codigo dentro de si. por lo tanto, cuando accedemos a dicha variable (la funcion) en realidad lo que estamos haciendo es ordenar al programa que ejecute un determinado codigo predefinido anteriormente.  todos los lenguajes de programacion tienen algunos elementos de formacion primitivos para la descripcion de los datos y de los procesos o transformaciones aplicadas a estos datos (tal como la suma de dos numeros o la seleccion de un elemento que forma parte de una coleccion). estos elementos primitivos son definidos por reglas sintacticas y semanticas que describen su estructura y significado respectivamente.  a la forma visible de un lenguaje de programacion se la conoce como sintaxis. la mayoria de los lenguajes de programacion son puramente textuales, es decir, utilizan secuencias de texto que incluyen palabras, numeros y puntuacion, de manera similar a los lenguajes naturales escritos. por otra parte, hay algunos lenguajes de programacion que son mas graficos en su naturaleza, utilizando relaciones visuales entre simbolos para especificar un programa.  la sintaxis de un lenguaje de programacion describe las combinaciones posibles de los simbolos que forman un programa sintacticamente correcto. el significado que se le da a una combinacion de simbolos es manejado por su semantica (ya sea formal o como parte del codigo duro de la referencia de implementacion). dado que la mayoria de los lenguajes son textuales, este articulo trata de la sintaxis textual.  la sintaxis de los lenguajes de programacion es definida generalmente utilizando una combinacion de expresiones regulares (para la estructura lexica/morfologica) y la notacion de backus-naur (para la estructura sintactica). este es un ejemplo de una gramatica simple, tomada del lenguaje lisp:  con esta gramatica se especifica lo siguiente:  algunos ejemplos de secuencias bien formadas de acuerdo a esta gramatica:  '12345', '()', '(a b c232 (1))'  no todos los programas sintacticamente correctos son semanticamente correctos. muchos programas sintacticamente correctos tienen inconsistencias con las reglas del lenguaje; y pueden (dependiendo de la especificacion del lenguaje y la solidez de la implementacion) resultar en un error de traduccion o ejecucion. en algunos casos, tales programas pueden exhibir un comportamiento indefinido. ademas, incluso cuando un programa esta bien definido dentro de un lenguaje, todavia puede tener un significado que no es el que la persona que lo escribio estaba tratando de construir.  usando el lenguaje natural, por ejemplo, puede no ser posible asignarle significado a una oracion gramaticalmente valida o la oracion puede ser falsa:  el siguiente fragmento en el lenguaje c es sintacticamente correcto, pero ejecuta una operacion que no esta definida semanticamente (dado que p es un apuntador nulo, las operaciones p->real y p->im no tienen ningun significado):  si la declaracion de tipo de la primera linea fuera omitida, el programa dispararia un error de compilacion, pues la variable \"p\" no estaria definida. pero el programa seria sintacticamente correcto todavia, dado que las declaraciones de tipo proveen informacion semantica solamente.  la gramatica necesaria para especificar un lenguaje de programacion puede ser clasificada por su posicion en la jerarquia de chomsky. la sintaxis de la mayoria de los lenguajes de programacion puede ser especificada utilizando una gramatica tipo-2, es decir, son gramaticas libres de contexto. algunos lenguajes, incluyendo a perl y a lisp, contienen construcciones que permiten la ejecucion durante la fase de analisis. los lenguajes que permiten construcciones que permiten al programador alterar el comportamiento de un analizador hacen del analisis de la sintaxis un problema sin decision unica, y generalmente oscurecen la separacion entre analisis y ejecucion. en contraste con el sistema de macros de lisp y los bloques begin de perl, que pueden tener calculos generales, las macros de c son meros reemplazos de cadenas, y no requieren ejecucion de codigo.  la semantica estatica define las restricciones sobre la estructura de los textos validos que resulta imposible o muy dificil expresar mediante formalismos sintacticos estandar. para los lenguajes compilados, la semantica estatica basicamente incluye las reglas semanticas que se pueden verificar en el momento de compilar. por ejemplo el chequeo de que cada identificador sea declarado antes de ser usado (en lenguajes que requieren tales declaraciones) o que las etiquetas en cada brazo de una estructura case sean distintas. muchas restricciones importantes de este tipo, como la validacion de que los identificadores sean usados en los contextos apropiados (por ejemplo no sumar un entero al nombre de una funcion), o que las llamadas a subrutinas tengan el numero y tipo de parametros adecuado, pueden ser implementadas definiendolas como reglas en una logica conocida como sistema de tipos. otras formas de analisis estaticos, como los analisis de flujo de datos, tambien pueden ser parte de la semantica estatica. otros lenguajes de programacion como java y c# tienen un analisis definido de asignaciones, una forma de analisis de flujo de datos, como parte de su semantica estatica.  un sistema de tipos de datos define la manera en la cual un lenguaje de programacion clasifica los valores y expresiones en tipos, como pueden ser manipulados dichos tipos y como interactuan. el objetivo de un sistema de tipos es verificar y normalmente poner en vigor un cierto nivel de exactitud en programas escritos en el lenguaje en cuestion, detectando ciertas operaciones invalidas. cualquier sistema de tipos decidible tiene sus ventajas y desventajas: mientras por un lado rechaza muchos programas incorrectos, tambien prohibe algunos programas correctos aunque poco comunes. para poder minimizar esta desventaja, algunos lenguajes incluyen lagunas de tipos, conversiones explicitas no verificadas que pueden ser usadas por el programador para permitir explicitamente una operacion normalmente no permitida entre diferentes tipos. en la mayoria de los lenguajes con tipos, el sistema de tipos es usado solamente para verificar los tipos de los programas, pero varios lenguajes, generalmente funcionales, llevan a cabo lo que se conoce como inferencia de tipos, que le quita al programador la tarea de especificar los tipos. al diseño y estudio formal de los sistemas de tipos se le conoce como teoria de tipos.  se dice que un lenguaje es tipado si la especificacion de cada operacion debe definir los tipos de datos para los cuales es aplicable, con la implicacion de que no es aplicable a otros tipos. por ejemplo, \"este texto entre comillas\" es una cadena de caracteres. en la mayoria de los lenguajes de programacion, dividir un numero por una cadena de caracteres no tiene ningun significado. por tanto, la mayoria de los lenguajes de programacion modernos rechazarian cualquier intento de ejecutar dicha operacion por parte de algun programa. en algunos lenguajes, estas operaciones sin significado son detectadas cuando el programa es compilado (validacion de tipos \"estatica\") y son rechazadas por el compilador, mientras en otros son detectadas cuando el programa es ejecutado (validacion de tipos \"dinamica\") y se genera una excepcion en tiempo de ejecucion.  un caso especial de lenguajes de tipo son los lenguajes de tipo sencillo. estos son con frecuencia lenguajes de marcado o de scripts, como rexx o sgml, y solamente cuentan con un tipo de datos; comunmente cadenas de caracteres que luego son usadas tanto para datos numericos como simbolicos.  en contraste, un lenguaje sin tipos, como la mayoria de los lenguajes ensambladores, permiten que cualquier operacion se aplique a cualquier dato, que por lo general se consideran secuencias de bits de varias longitudes. lenguajes de alto nivel sin datos incluyen bcpl y algunas variedades de forth.  en la practica, aunque pocos lenguajes son considerados con tipo desde el punto de vista de la teoria de tipos (es decir, que verifican o rechazan todas las operaciones), la mayoria de los lenguajes modernos ofrecen algun grado de manejo de tipos. si bien muchos lenguajes de produccion proveen medios para evitar o rodear el sistema de tipado.  en lenguajes con tipos estaticos se determina el tipo de todas las expresiones antes de la ejecucion del programa (tipicamente al compilar). por ejemplo, 1 y (2+2) son expresiones enteras; no pueden ser pasadas a una funcion que espera una cadena, ni pueden guardarse en una variable que esta definida como fecha.  los lenguajes con tipos estaticos pueden manejar tipos explicitos o tipos inferidos. en el primer caso, el programador debe escribir los tipos en determinadas posiciones textuales. en el segundo caso, el compilador infiere los tipos de las expresiones y las declaraciones de acuerdo al contexto. la mayoria de los lenguajes populares con tipos estaticos, tales como c++, c# y java, manejan tipos explicitos. inferencia total de los tipos suele asociarse con lenguajes menos populares, tales como haskell y ml. sin embargo, muchos lenguajes de tipos explicitos permiten inferencias parciales de tipo; tanto java y c#, por ejemplo, infieren tipos en un numero limitado de casos.  los lenguajes con tipos dinamicos determinan la validez de los tipos involucrados en las operaciones durante la ejecucion del programa. en otras palabras, los tipos estan asociados con valores en ejecucion en lugar de expresiones textuales. como en el caso de lenguajes con tipos inferidos, los lenguajes con tipos dinamicos no requieren que el programador escriba los tipos de las expresiones. entre otras cosas, esto permite que una misma variable se pueda asociar con valores de tipos distintos en diferentes momentos de la ejecucion de un programa. sin embargo, los errores de tipo no pueden ser detectados automaticamente hasta que se ejecuta el codigo, dificultando la depuracion de los programas, no obstante, en lenguajes con tipos dinamicos se suele dejar de lado la depuracion en favor de tecnicas de desarrollo como por ejemplo bdd y tdd. ruby, lisp, javascript y python son lenguajes con tipos dinamicos.  los lenguajes debilmente tipados permiten que un valor de un tipo pueda ser tratado como de otro tipo, por ejemplo una cadena puede ser operada como un numero. esto puede ser util a veces, pero tambien puede permitir ciertos tipos de fallas que no pueden ser detectadas durante la compilacion o a veces ni siquiera durante la ejecucion.  los lenguajes fuertemente tipados evitan que pase lo anterior. cualquier intento de llevar a cabo una operacion sobre el tipo equivocado dispara un error. a los lenguajes con tipos fuertes se les suele llamar de tipos seguros.  lenguajes con tipos debiles como perl y javascript permiten un gran numero de conversiones de tipo implicitas. por ejemplo en javascript la expresion 2 * x convierte implicitamente x a un numero, y esta conversion es exitosa inclusive cuando x es null, undefined, un array o una cadena de letras. estas conversiones implicitas son utiles con frecuencia, pero tambien pueden ocultar errores de programacion.  las caracteristicas de estaticos y fuertes son ahora generalmente consideradas conceptos ortogonales, pero su trato en diferentes textos varia. algunos utilizan el termino de tipos fuertes para referirse a tipos fuertemente estaticos o, para aumentar la confusion, simplemente como equivalencia de tipos estaticos. de tal manera que c ha sido llamado tanto lenguaje de tipos fuertes como lenguaje de tipos estaticos debiles.  la implementacion de un lenguaje es la que provee una manera de que se ejecute un programa para una determinada combinacion de software y hardware. existen basicamente dos maneras de implementar un lenguaje: compilacion e interpretacion.  se puede tambien utilizar una alternativa para traducir lenguajes de alto nivel. en lugar de traducir el programa fuente y grabar en forma permanente el codigo objeto que se produce durante la compilacion para utilizarlo en una ejecucion futura, el programador solo carga el programa fuente en la computadora junto con los datos que se van a procesar. a continuacion, un programa interprete, almacenado en el sistema operativo del disco, o incluido de manera permanente dentro de la maquina, convierte cada proposicion del programa fuente en lenguaje de maquina conforme vaya siendo necesario durante el procesamiento de los datos. el codigo objeto no se graba para utilizarlo posteriormente.  la siguiente vez que se utilice una instruccion, se la debera interpretar otra vez y traducir a lenguaje maquina. por ejemplo, durante el procesamiento repetitivo de los pasos de un ciclo o bucle, cada instruccion del bucle tendra que volver a ser interpretada en cada ejecucion repetida del ciclo, lo cual hace que el programa sea mas lento en tiempo de ejecucion (porque se va revisando el codigo en tiempo de ejecucion) pero mas rapido en tiempo de diseño (porque no se tiene que estar compilando a cada momento el codigo completo). el interprete elimina la necesidad de realizar una compilacion despues de cada modificacion del programa cuando se quiere agregar funciones o corregir errores; pero es obvio que un programa objeto compilado con antelacion debera ejecutarse con mucha mayor rapidez que uno que se debe interpretar a cada paso durante una ejecucion del codigo.  la mayoria de lenguajes de alto nivel permiten la programacion multiproposito, aunque muchos de ellos fueron diseñados para permitir programacion dedicada, como lo fue el pascal con las matematicas en su comienzo. tambien se han implementado lenguajes educativos infantiles como logo mediante una serie de simples instrucciones. en la actualidad son muy populares algunos lenguajes especialmente indicados para aplicaciones web, como perl, php, ruby, python o javascript.  un dialecto de un lenguaje de programacion es una variacion o extension (relativamente pequeña) del lenguaje que no cambia su naturaleza intrinseca. con lenguajes como scheme y forth, los implementadores pueden considerar que los estandares son insuficientes, inadecuados o ilegitimos, por lo que a menudo se desviaran del estandar, haciendo un nuevo dialecto. en otros casos, se crea un dialecto para su uso en un lenguaje especifico de dominio, a menudo un subconjunto. en el mundo lisp, la mayoria de los lenguajes que utilizan la sintaxis basica de una expresion s y la semantica similar a lisp se consideran dialectos lisp, aunque varian enormemente, al igual que, digamos, raqueta y clojure. como es comun que un lenguaje tenga varios dialectos, puede resultar bastante dificil para un programador sin experiencia encontrar la documentacion correcta. el lenguaje de programacion basic tiene muchos dialectos.  para escribir programas que proporcionen los mejores resultados, cabe tener en cuenta una serie de detalles.  los programas se pueden clasificar por el paradigma del lenguaje que se use para producirlos. los principales paradigmas son: imperativos, declarativos y orientacion a objetos.  los programas que usan un lenguaje imperativo especifican un algoritmo, usan declaraciones, expresiones y sentencias.​ una declaracion asocia un nombre de variable con un tipo de dato, por ejemplo: var x: integer;. una expresion contiene un valor, por ejemplo: 2 + 2 contiene el valor 4. finalmente, una sentencia debe asignar una expresion a una variable o usar el valor de una variable para alterar el flujo de un programa, por ejemplo: x := 2 + 2; if x == 4 then haz_algo();. una critica comun en los lenguajes imperativos es el efecto de las sentencias de asignacion sobre una clase de variables llamadas \"no locales\".​  los programas que usan un lenguaje declarativo especifican las propiedades que la salida debe conocer y no especifican cualquier detalle de implementacion. dos amplias categorias de lenguajes declarativos son los lenguajes funcionales y los lenguajes logicos. los lenguajes funcionales no permiten asignaciones de variables no locales, asi, se hacen mas facil, por ejemplo, programas como funciones matematicas.​ el principio detras de los lenguajes logicos es definir el problema que se quiere resolver (el objetivo) y dejar los detalles de la solucion al sistema.​ el objetivo es definido dando una lista de sub-objetivos. cada sub-objetivo tambien se define dando una lista de sus sub-objetivos, etc. si al tratar de buscar una solucion, una ruta de sub-objetivos falla, entonces tal sub-objetivo se descarta y sistematicamente se prueba otra ruta.  la forma en la cual se programa puede ser por medio de texto o de forma visual. en la programacion visual los elementos son manipulados graficamente en vez de especificarse por medio de texto. ",
        "snippet": "Un lenguaje de programación es un lenguaje formal (o artificial, es decir, un lenguaje con reglas gramaticales bien definidas) que proporciona a una persona, en este caso el programador, la capacidad y habilidad de escribir (o programar) una serie de instrucciones o secuencias de órdenes en forma de algoritmos con el fin de controlar el comportamiento físico o lógico de un sistema informático, para que de esa manera se puedan obtener diversas clases de datos o ejecutar determinadas tareas. A todo este conjunto de órdenes escritas mediante un lenguaje de programación se le denomina programa informático.[1]​[2]​[3]​[4]​",
        "enlaces_salientes": [
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Microcomputadora",
            "/wiki/Commodore_International",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Lenguaje_de_programaci%C3%B3n_de_alto_nivel",
            "/wiki/BASIC",
            "/wiki/Emulador",
            "/wiki/VICE",
            "/wiki/GNU/Linux",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/Compilado",
            "/wiki/Ejecutable",
            "/wiki/Lenguaje_formal",
            "/wiki/Instrucci%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Algoritmo",
            "/wiki/Sistema_inform%C3%A1tico",
            "/wiki/Software",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Beta_tester",
            "/wiki/Depurador",
            "/wiki/Compilador",
            "/wiki/Int%C3%A9rprete_(inform%C3%A1tica)",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Compilador",
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Beta_tester",
            "/wiki/Depuraci%C3%B3n_de_programas",
            "/wiki/Palabra_(matem%C3%A1ticas)",
            "/wiki/Token_(inform%C3%A1tica)",
            "/wiki/Morfolog%C3%ADa_ling%C3%BC%C3%ADstica",
            "/wiki/Sintaxis",
            "/wiki/Sem%C3%A1ntica",
            "/wiki/Lenguaje_inform%C3%A1tico",
            "/wiki/HTML",
            "/wiki/Lenguaje_de_marcado",
            "/wiki/P%C3%A1gina_web",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/Software",
            "/wiki/Lenguaje",
            "/wiki/Historia_de_los_lenguajes_de_programaci%C3%B3n",
            "/wiki/Fortran",
            "/wiki/Tarjeta_perforada",
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Sistema_binario",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Sintaxis",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/1953",
            "/wiki/John_Backus",
            "/wiki/IBM",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Computadora_central",
            "/wiki/IBM_704",
            "/wiki/Fortran",
            "/wiki/John_Backus",
            "/wiki/Lois_Haibt",
            "/wiki/Fortran",
            "/wiki/1956",
            "/wiki/Compilador",
            "/wiki/Fortran",
            "/wiki/Abril",
            "/wiki/1957",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/1960",
            "/wiki/COBOL",
            "/wiki/Inform%C3%A1tica_de_gesti%C3%B3n",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/BASIC",
            "/wiki/1980",
            "/wiki/Arquitectura_de_computaci%C3%B3n",
            "/wiki/Computadora_electr%C3%B3nica",
            "/wiki/Hardware",
            "/wiki/V%C3%A1lvula_termoi%C3%B3nica",
            "/wiki/Transistor",
            "/wiki/Circuito_integrado",
            "/wiki/Circuito_integrado",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Software",
            "/wiki/Hardware",
            "/wiki/C%C3%B3digo_de_m%C3%A1quina",
            "/wiki/Sistema_binario",
            "/wiki/Lenguajes_de_bajo_nivel",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/Abstracci%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Sistemas_operativos",
            "/wiki/Controlador_de_dispositivo",
            "/wiki/Lenguaje_simb%C3%B3lico",
            "/wiki/Ensamblador",
            "/wiki/Lenguajes_de_alto_nivel",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Fortran",
            "/wiki/Smalltalk",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Ada",
            "/wiki/C%2B%2B",
            "/wiki/C_sharp",
            "/wiki/Cobol",
            "/wiki/Embarcadero_Delphi",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/PHP",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Base_de_datos",
            "/wiki/Visual_Basic",
            "/wiki/SQL",
            "/wiki/ISO",
            "/wiki/ANSI",
            "/wiki/Natural_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/PL/SQL",
            "/wiki/Programador",
            "/wiki/Desarrollador_de_software",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Paradigma",
            "/wiki/Orientaci%C3%B3n_a_objetos",
            "/wiki/Desarrollo_de_software",
            "/wiki/Lisp",
            "/wiki/Simula",
            "/wiki/Smalltalk",
            "/wiki/Algoritmo",
            "/wiki/Inferencia",
            "/wiki/Programaci%C3%B3n_imperativa",
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Lenguaje_de_programaci%C3%B3n_C",
            "/wiki/BASIC",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/C_Sharp",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Smalltalk",
            "/wiki/Programaci%C3%B3n_dirigida_por_eventos",
            "/wiki/Programaci%C3%B3n_declarativa",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Computadora",
            "/wiki/Transparencia_referencial",
            "/wiki/Lisp",
            "/wiki/Prolog",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Scheme",
            "/wiki/Lisp",
            "/wiki/Haskell",
            "/wiki/Python",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Prolog",
            "/wiki/Programaci%C3%B3n_con_restricciones",
            "/wiki/Prolog",
            "/wiki/Lisp",
            "/wiki/Python",
            "/wiki/PHP",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Reflexi%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Bjarne_Stroustrup",
            "/wiki/C%2B%2B",
            "/wiki/Genie_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Delphi",
            "/wiki/Visual_Basic",
            "/wiki/D_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Oz",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Scheme",
            "/wiki/Prolog",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Lenguaje_espec%C3%ADfico_del_dominio",
            "/wiki/SQL",
            "/wiki/Logo_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Variable_(programaci%C3%B3n)",
            "/wiki/Pauscal",
            "/wiki/Variable_(programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/PHP",
            "/wiki/JavaScript",
            "/wiki/Python",
            "/wiki/C%C3%B3digo_duro",
            "/wiki/Expresi%C3%B3n_regular",
            "/wiki/Notaci%C3%B3n_de_Backus-Naur",
            "/wiki/Lisp",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/Perl",
            "/wiki/Lisp",
            "/wiki/Lisp",
            "/wiki/Perl",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_Sharp",
            "/wiki/Sistema_de_tipos",
            "/wiki/Tipos_de_datos",
            "/wiki/Tipos_de_datos",
            "/wiki/Decidibilidad",
            "/wiki/Scripts",
            "/wiki/REXX",
            "/wiki/SGML",
            "/wiki/BCPL",
            "/wiki/Forth",
            "/wiki/C%2B%2B",
            "/wiki/C_Sharp",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Haskell",
            "/wiki/ML_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_Sharp",
            "/wiki/Diagrama_de_decisi%C3%B3n_binario",
            "/wiki/TDD",
            "/wiki/Ruby",
            "/wiki/Lisp",
            "/wiki/JavaScript",
            "/wiki/Python",
            "/wiki/Tipado_fuerte",
            "/wiki/Perl",
            "/wiki/JavaScript",
            "/wiki/JavaScript",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/Software",
            "/wiki/Hardware",
            "/wiki/Compilador",
            "/wiki/Interpretaci%C3%B3n_(l%C3%B3gica)",
            "/wiki/Compilaci%C3%B3n",
            "/wiki/Compilador",
            "/wiki/Interpretaci%C3%B3n",
            "/wiki/F%C3%B3rmula_bien_formada",
            "/wiki/Lenguaje_formal",
            "/wiki/Sintaxis",
            "/wiki/Cadena_de_caracteres",
            "/wiki/Int%C3%A9rprete_(inform%C3%A1tica)",
            "/wiki/C%C3%B3digo_objeto",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Pascal",
            "/wiki/Logo_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Aplicaci%C3%B3n_web",
            "/wiki/Perl",
            "/wiki/PHP",
            "/wiki/Ruby",
            "/wiki/Python",
            "/wiki/JavaScript",
            "/wiki/Scheme",
            "/wiki/Forth",
            "/wiki/Dialecto",
            "/wiki/Lenguaje_espec%C3%ADfico_de_dominio",
            "/wiki/Common_Lisp",
            "/wiki/Expresi%C3%B3n_S",
            "/wiki/Racket_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Clojure",
            "/wiki/BASIC",
            "/wiki/Programador",
            "/wiki/Arte_ASCII",
            "/wiki/C%C3%B3digo_ofuscado",
            "/wiki/GNU/Linux",
            "/wiki/Sistemas_operativos",
            "/wiki/Microsoft_Windows",
            "/wiki/Paradigma_de_programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n_imperativa",
            "/wiki/Programaci%C3%B3n_declarativa",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Programaci%C3%B3n_l%C3%B3gica",
            "/wiki/Programaci%C3%B3n_visual",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/Programaci%C3%B3n_modular",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Programaci%C3%B3n_orientada_a_aspectos",
            "/wiki/Programaci%C3%B3n_con_restricciones",
            "/wiki/Programaci%C3%B3n_a_nivel_funcional",
            "/wiki/Programaci%C3%B3n_a_nivel_de_valores",
            "/wiki/Lenguaje_de_programaci%C3%B3n_esot%C3%A9rico",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/D_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Control_de_autoridades",
            "/wiki/MediaWiki",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/MediaWiki"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Pseudoc%C3%B3digo",
        "titulo": "Pseudocódigo",
        "contenido": "en ciencias de la computacion, y analisis numerico, el pseudocodigo​ (o lenguaje de descripcion algoritmico) es una descripcion de alto nivel compacta e informal​ del principio operativo de un programa informatico u otro algoritmo.  utiliza las convenciones estructurales de un lenguaje de programacion real,​ pero esta diseñado para la lectura humana en lugar de la lectura mediante maquina,​ y con independencia de cualquier otro lenguaje de programacion.​ normalmente, el pseudocodigo omite detalles que no son esenciales para la comprension humana del algoritmo, tales como declaraciones de variables, codigo especifico del sistema y algunas subrutinas. el lenguaje de programacion se complementa, donde sea conveniente, con descripciones detalladas en lenguaje natural, o con notacion matematica compacta. se utiliza pseudocodigo pues este es mas facil de entender para las personas que el codigo del lenguaje de programacion convencional, ya que es una descripcion eficiente y con un entorno independiente de los principios fundamentales de un algoritmo. se utiliza comunmente en los libros de texto y publicaciones cientificas que se documentan varios algoritmos, y tambien en la planificacion del desarrollo de programas informaticos, para esbozar la estructura del programa antes de realizar la efectiva codificacion. es comunmente utilizado por los programadores para omitir secciones de codigo o para dar una explicacion del paradigma que tomo el mismo programador para hacer sus codigos, esto quiere decir que el pseudocodigo no es programable, sino facilita la programacion.  el principal objetivo del pseudocodigo es el de representar la solucion a un algoritmo de la forma mas detallada posible, y a su vez lo mas parecida posible al lenguaje que posteriormente se utilizara para la codificacion del mismo.  no existe una sintaxis estandar para el pseudocodigo, aunque los cinco ide's que manejan pseudocodigo en español tengan su sintaxis propia. aunque sea parecido, el pseudocodigo no debe confundirse con los programas esqueleto que incluyen codigo ficticio, que pueden ser compilados sin errores. los diagramas de flujo y uml pueden ser considerados como una alternativa grafica al pseudocodigo, aunque sean mas amplios  generalmente se utiliza pseudocodigo en los libros de texto y publicaciones cientificas relacionadas con la informatica y la computacion numerica, para la descripcion de algoritmos, de manera que todos los programadores puedan entenderlo, aunque no todos conozcan el mismo lenguaje de programacion. generalmente, en los libros de texto se adjunta una explicacion que acompaña a la introduccion y que explica las convenciones particulares en uso. el nivel de detalle del seudocientifico puede, en algunos casos, acercarse a la de formalizar los idiomas de proposito general.  un programador que tiene que aplicar un algoritmo especifico, sobre todo uno desfamiliarizado, generalmente comienza con una descripcion en pseudocodigo, y luego \"traduce\" esa descripcion en el lenguaje de programacion meta y lo modifica para que interactue correctamente con el resto del programa. los programadores tambien pueden iniciar un proyecto describiendo la forma del codigo en pseudocodigo en el papel antes de escribirlo en su lenguaje de programacion, como ocurre en la estructuracion de un enfoque de top-down y bottom-up arriba hacia abajo.  en la actualidad y por lo general, el pseudocodigo, como su nombre lo indica, no obedece a las reglas de sintaxis de ningun idioma en particular ni es de forma estandar sistematica, a pesar de que cualquier escritor en particular vaya a pedir prestado las estructuras de control general, la sintaxis y el estilo, por ejemplo, de algun lenguaje de programacion convencional. pero en caso de que se quiera ejecutar, se debe llevar a forma tipo, para que no genere mensajes de error. las fuentes populares incluyen la sintaxis de pascal, basic, c, c++, java, lisp, y algol. por lo general, se omiten las declaraciones de variables. a veces, las llamadas a funciones, los bloques de codigo y el codigo contenido dentro de un loop se remplazan por una sentencia de una linea en lenguaje natural.  este es un ejemplo de pseudocodigo (para el juego matematico bizz buzz):  pseudocodigo estilo fortran:  pseudocodigo estilo pascal:  pseudocodigo estilo c:  la definicion de datos se da por supuesta, sobre todo en las variables sencillas, si se emplea formaciones: pilas, colas, vectores o registros, se pueden definir en la cabecera del algoritmo, y naturalmente cuando empleemos el pseudocodigo para definir estructuras de datos, esta parte la desarrollaremos adecuadamente.  cada autor usa su propio pseudocodigo con sus respectivas convenciones. por ejemplo, la instruccion \"reemplace el valor de la variable x por el valor de la variable y \" puede ser representado como:  las operaciones aritmeticas se representan de la forma usual en matematicas.  en la redaccion de pseudocodigo se utiliza tres tipos de estructuras de control: las secuenciales, las selectivas y las iterativas.  las instrucciones se siguen en una secuencia fija que normalmente viene dada por el numero de renglon. es decir que las instrucciones se ejecutan de arriba hacia abajo.  las instrucciones selectivas representan instrucciones que pueden o no ejecutarse, segun el cumplimiento de una condicion.    la condicion es una expresion booleana. instrucciones es ejecutada solo si la condicion es verdadera.  la instruccion alternativa realiza una instruccion de dos posibles, segun el cumplimiento de una condicion.    la condicion es una variable booleana o una funcion reducible a booleana (logica, verdadero/falso). si esta condicion es cierta se ejecuta instrucciones1, si no es asi, entonces se ejecuta instrucciones2.  tambien es comun el uso de una seleccion multiple que equivaldria a anidar varias funciones de seleccion.  en este caso hay una serie de condiciones que tienen que ser mutuamente excluyentes, si una de ellas se cumple las demas tienen que ser falsas necesariamente, hay un caso si no que sera cierto cuando las demas condiciones sean falsas.  en esta estructura si condicion1 es cierta, entonces se ejecuta solo instrucciones1. en general, si condicioni es verdadera, entonces solo se ejecuta instruccionesi  una construccion similar a la anterior (equivalente en algunos casos) es la que se muestra a continuacion.  en este caso hay un indicador es una variable o una funcion cuyo valor es comparado en cada caso con los valores \"valori\", si en algun caso coinciden ambos valores, entonces se ejecutaran las instruccionesi correspondientes. la seccion en otro caso es analoga a la seccion si no del ejemplo anterior.  las instrucciones iterativas representan la ejecucion de instrucciones en mas de una vez.  el bucle se repite mientras la condicion sea cierta, si al llegar por primera vez al bucle mientras la condicion es falsa, el cuerpo del bucle no se ejecuta alguna vez.    existen otras variantes que se derivan a partir de la anterior. la estructura de control repetir se utiliza cuando es necesario que el cuerpo del bucle se ejecuten al menos una vez y hasta que se cumpla la condicion:  la estructura anterior equivaldria a escribir:  el bucle hacer se utiliza para repetir un bloque de codigo mientras se cumpla cierta condicion.  una estructura de control muy comun es el ciclo for, la cual se usa cuando se desea iterar un numero conocido de veces, empleando como indice una variable que se incrementa (o decrementa):  la cual se define como:  por ultimo, tambien es comun usar la estructura de control para cada. esta sentencia se usa cuando se tiene una lista o un conjunto l y se quiere iterar por cada uno de sus elementos:  si asumimos que los elementos de l son l 0 , l 1 , … , l n ,l_{1},\\dots ,l_{n}} , entonces esta sentencia equivaldria a:  que es lo mismo que:  sin embargo, en la practica existen mejores formas de implementar esta instruccion dependiendo del problema.  es importante recalcar que el pseudocodigo no es un lenguaje estandarizado. eso significa que diferentes autores podrian dar otras estructuras de control o bien usar estas mismas estructuras, pero con una notacion diferente. sin embargo, las funciones matematicas y logicas toman el significado usual que tienen en matematica y logica, con las mismas expresiones.  cualquier instruccion puede ser sustituida por una estructura de control. el siguiente ejemplo muestra el pseudocodigo del ordenamiento de burbuja, que tiene varias estructuras anidadas. este algoritmo ordena de menor a mayor los elementos de una lista l .   p r o c e d i m i e n t o o r d e n a r ( l ) ↕ / / c o m e n t a r i o : l = ( l 1 , l 2 , … , l n ) e s u n a l i s t a c o n n e l e m e n t o s / / k ← 0 ; r e p e t i r ↕ i n t e r c a m b i o ← f a l s o ; k ← k + 1 ; p a r a i ← 1 h a s t a n − k c o n p a s o 1 h a c e r ↕ s i l i > l i + 1 e n t o n c e s ↕ i n t e r c a m b i a r ( l i , l i + 1 ) i n t e r c a m b i o ← v e r d a d e r o ; f i n s i f i n p a r a h a s t a q u e i n t e r c a m b i o = f a l s o ; f i n p r o c e d i m i e n t o {l}\\mathrm {procedimiento} }\\;\\mathrm {ordenar} }\\;(l}\\;)\\\\\\left\\updownarrow {l}//comentario:\\;l=(l_{1},l_{2},\\dots ,l_{n})\\;es\\;una\\;lista\\;con\\;n\\;elementos//}\\\\k}\\;\\gets }\\;0;}\\\\\\mathrm {repetir} }\\\\\\left\\updownarrow {l}\\mathrm {intercambio} }\\;\\gets }\\;\\mathrm {falso} ;}\\\\k}\\;\\gets }\\;k+1;}\\\\\\mathrm {para} }\\;i}\\;\\gets }\\;1}\\;\\mathrm {hasta} }\\;n-k}\\;\\mathrm {con\\;paso} }\\;1}\\;\\mathrm {hacer} }\\\\\\left\\updownarrow {l}\\mathrm {si} }\\;l_{i}}\\;>}\\;l_{i+1}}\\;\\mathrm {entonces} }\\;\\\\\\left\\updownarrow {l}\\mathrm {intercambiar} }\\;(l_{i},l_{i+1}}\\;)\\\\\\mathrm {intercambio} }\\;\\gets }\\;\\mathrm {verdadero} ;}\\end{array}}\\right.\\\\\\mathrm {fin\\;si} }\\;\\\\\\end{array}}\\right.\\\\\\mathrm {fin\\;para} }\\\\\\end{array}}\\right.\\\\\\mathrm {hasta\\;que} }\\;\\mathrm {intercambio} }\\;=}\\;\\mathrm {falso} ;}\\end{array}}\\right.\\\\\\mathrm {fin\\;procedimiento} }\\;\\\\\\end{array}}}  en general, las estructuras anidadas se muestran indentadas, para hacer mas sencilla su identificacion a simple vista. en el ejemplo, ademas de la sangria, se ha conectado con flechas los pares de delimitadores de cada nivel de anidamiento.  muchas personas prefieren distinguir entre funciones y procedimientos. una funcion, al igual que una funcion matematica, recibe uno o varios valores de entrada y regresa una salida mientras que un procedimiento recibe una entrada y no genera alguna salida aunque en algun caso podria devolver resultados a traves de sus parametros de entrada si estos se han declarado por referencia (ver formas de pasar argumentos a una funcion o procedimiento).  en ambos casos es necesario dejar en claro cuales son las entradas para el algoritmo, esto se hace comunmente colocando estos valores entre parentesis al principio o bien declarandolo explicitamente con un enunciado. en el caso de las funciones, es necesario colocar una palabra como regresar o devolver para indicar cual es la salida generada por el algoritmo. por ejemplo, el pseudocodigo de una funcion que permite calcular a n } (un numero a elevado a potencia n ).  un ejemplo de procedimiento seria el algoritmo de ordenamiento de burbuja, por el que partiendo de una lista de valores estos se ordenan, notese que en un procedimiento, no se calcula el valor de una funcion, sino que se realiza una accion, en este caso ordenar la lista.  con el pseudocodigo se puede desarrollar cualquier algoritmo que:  los pseudocodigos presentan los siguientes beneficios: ",
        "snippet": "En ciencias de la computación, y análisis numérico, el pseudocódigo[1]​ (o lenguaje de descripción algorítmico) es una descripción de alto nivel compacta e informal[2]​ del principio operativo de un programa informático u otro algoritmo.",
        "enlaces_salientes": [
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Lenguaje",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Algoritmo",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Subrutina",
            "/wiki/Lenguaje_natural",
            "/wiki/Sintaxis",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Compilador",
            "/wiki/Diagrama_de_flujo",
            "/wiki/UML",
            "/wiki/Programador",
            "/wiki/Top-down_y_Bottom-up",
            "/wiki/Estructuras_de_control",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/BASIC",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%2B%2B",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Lisp",
            "/wiki/ALGOL",
            "/wiki/Fortran",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Bucle_while",
            "/wiki/Bloque_de_c%C3%B3digo",
            "/wiki/Bucle_for",
            "/wiki/Lista_enlazada",
            "/wiki/Conjunto",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Argumento_(inform%C3%A1tica)#Paso_de_Argumentos",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/PSeInt",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Resoluci%C3%B3n_de_problemas_de_programaci%C3%B3n",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Estructuras_de_control",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Bucle_for",
            "/wiki/Bucle_do",
            "/wiki/Bucle_while",
            "/wiki/Bucle_repetir",
            "/wiki/Bucle_infinito",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Lexico",
        "titulo": "Lexico",
        "contenido": "lexico es un lenguaje de programacion didactico en español para facilitar el aprendizaje y la enseñanza de la programacion orientada a objetos.  las investigaciones realizadas con el asi lo han comprobado que puede mejorar el desempeño y la habilidad logica de los estudiantes pues les permite experimentar con los algoritmos diseñados,[cita requerida] sin tener que dedicar meses a aprender un lenguaje de produccion que les permita \"ver\" sus creaciones.  su forma exterior es sencilla aunque versatil. el compilador, disponible en su portal, es distribuible y se ejecuta sobre la plataforma .net de microsoft. esta ultima tambien es distribuible y soporta las caracteristicas exigidas internacionalmente para considerarse puro respecto al paradigma. posee una interfaz simple que evita dificultades para iniciar.  permite la suficiente sencillez para entrenarse con los conceptos basicos en algoritmos para que la persona practique las estructuras fundamentales en logica (secuencia con {....}, decision con es ? y ciclo de repeticiones con mientras) y la clasica estructura de representacion de informacion compuesta llamada  arreglo.  el centro medular es su orientacion a la programacion orientada a objetos para lo cual posee el soporte apropiado y se ha simplificado al maximo de manera que ayude a la inmersion en los conceptos.  los objetos pueden ser construidos con base en las dos clases fundamentales, cantidad y caracteres, con base en las clases establecidas por el programador, con base en las 7000  definiciones de la plataforma .net de microsoft y otros ensamblados en forma de dll (bibliotecas de enlaces dinamicos) producidos por terceros, lo que permite desarrollar  aplicaciones complejas que incluyan controles, el manejo grafico y el manejo de eventos.  las clases pueden ser definidas en el programa o en archivos externos y por la via de la herencia con base en la biblioteca fcl (biblioteca de clases del marco de trabajo) de microsoft. aquellas que no hayan sido definidas dentro del archivo principal de trabajo son incorporadas con la instruccion incluya.  la version lexico 3.0, ademas de poder generar codigo ejecutable para ser corrido sobre la plataforma .net completa, genera codigo ejecutable para la plataforma cf .net (compact framework) lo que le hace util para producir programas destinados a windows mobile (wm) que corre sobre el sistema operativo windowsce existente en los moviles conocidos como ppc (sigla en ingles para computadores personales de bolsillo) y los smartphone (o telefonos inteligentes).  la version lexico 3.1 ha sido creada para las maquinas de 64 bits con sistema operativo windows version 7 o superior y ha sido probada durante varios años en un curso universitario.  el inconveniente didactico es que solo funciona en la plataforma windows .net de manera muy estricta dejando fuera a todas las instituciones educativas que estan implementando (o estan en vias de implementar) linux u otros sistemas operativos.  no queda clara su licencia ni existe codigo fuente de la plataforma, ademas de no existir un documento unificado y formal de la definicion del lenguaje (solo paginas sueltas explicando algunos aspectos del lenguaje). ",
        "snippet": "Lexico es un lenguaje de programación didáctico en español para facilitar el aprendizaje y la enseñanza de la programación orientada a objetos.",
        "enlaces_salientes": [
            "/wiki/Lexico",
            "/wiki/Lexico",
            "/wiki/Lexico",
            "/wiki/L%C3%A9xico",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Algoritmo",
            "/wiki/Compilador",
            "/wiki/Microsoft_.NET",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Biblioteca_(inform%C3%A1tica)",
            "/wiki/Sistema_operativo",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/C%C3%B3digo_binario",
        "titulo": "Código binario",
        "contenido": "el codigo binario es una codificacion usada para la representacion de textos, o procesadores de instrucciones de computadora, utilizando el sistema binario (sistema numerico de dos digitos, o bit: el \"0\" y el \"1\"). en informatica y telecomunicaciones, el codigo binario se utiliza  en la codificacion de datos, tales como cadenas de caracteres, o cadenas de bits por ejemplo en el caso de un cd, las señales que reflejaran el \"laser\" que rebotara en el cd y sera recepcionado por un sensor de distinta forma indicando asi, si es un cero o un uno.  en un codigo binario de ancho fijo, cada letra, digito, u otros simbolos, estan representados por una cadena de bits de la misma longitud, como un numero binario que, por lo general, aparece en las tablas en notacion octal, decimal o hexadecimal.  el codigo binario, utilizado en computadoras digitales, esta basado en un sistema numerico binario en el que solo hay dos estados posibles: apagado y encendido, generalmente simbolizados por 0 y 1. mientras que en un sistema decimal, que emplea 10 digitos, cada posicion de digito representa una potencia de 10 (100, 1000, etc.), en un sistema binario cada posicion de digito representa una potencia de 2 (4, 8, 16, etc.). una señal de codigo binario es una serie de pulsos electricos que representan numeros, caracteres y operaciones a realizar. un dispositivo llamado reloj envia pulsos regulares y componentes como los transistores se encienden (1) o se apagan (0) para pasar o bloquear los pulsos. en codigo binario, cada numero decimal (0–9) esta representado por un conjunto de cuatro digitos binarios o bits. las cuatro operaciones aritmeticas fundamentales (suma, resta, multiplicacion y division) se pueden reducir a combinaciones de operaciones algebraicas booleanas fundamentales en numeros binarios.  segun anton glaser, en su history of binary and other nondecimal numeration, comenta que los primeros codigos binarios se utilizaron en el año 1932: c.e. wynn-williams (\"scale of two\"), posteriormente en 1938: atanasoff-berry computer, y en 1939: stibitz (\"excess three\") el codigo en complex computer.  es frecuente tambien ver la palabra bit referida bien a la ausencia de señal, expresada con el digito \"0\", o bien referida a la existencia de la misma, expresada con el digito \"1\". el byte es un grupo de 8 bits, es decir en el tenemos 256 posibles estados binarios.  la mayoria de los sistemas de numeracion actuales son ponderados, es decir, cada posicion de una secuencia de digitos tiene asociado un peso. el sistema binario es, de hecho, un sistema de codigo de numeracion posicional ponderado. sin embargo, algunos codigos binarios, como el codigo gray no son ponderados es decir, no tienen un peso asociado a cada posicion. otros, como el mismo codigo binario natural o el bcd natural si lo son.  la distancia es una caracteristica solo aplicable a las combinaciones binarias. la distancia entre dos combinaciones es el numero de bits que cambian de una a otra. por ejemplo: si se tienen las combinaciones de cuatro bits 0010 y 0111 correspondientes al 2 y al 7 en binario natural, se dira que la distancia entre ellas es igual a dos ya que de una a otra cambian dos bits.  ademas, con el concepto de distancia se puede definir la distancia minima de un codigo. esta no es mas que la distancia menor que haya entre dos de las combinaciones de ese codigo.  la distancia es una caracteristica que, ademas, solo se aplica a las combinaciones binarias. en resumen, la distancia entre dos combinaciones es el numero de bits que cambian de una a otra.  se dice que un codigo binario es autocomplementario cuando el complemento a 9 del equivalente decimal de cualquier combinacion del codigo puede hallarse invirtiendo los valores de cada uno de los bits (operacion logica unaria de negacion) y el resultado sigue siendo una combinacion valida en ese codigo. esta caracteristica se observa en algunos codigos bcd, como el codigo aiken o el codigo bcd exceso 3. los codigos autocomplementarios facilitan las operaciones aritmeticas.  en un codigo binario de ancho fijo, cada letra, digito, u otros simbolos, estan representados por una cadena de bits de la misma longitud, como un numero binario que, por lo general, aparece en las tablas en notacion octal, decimal o hexadecimal. ",
        "snippet": "El código binario es una codificación usada para la representación de textos, o procesadores de instrucciones de computadora, utilizando el sistema binario (sistema numérico de dos dígitos, o bit: el \"0\" y el \"1\"). En informática y telecomunicaciones, el código binario se utiliza en la codificación de datos, tales como cadenas de caracteres, o cadenas de bits Por ejemplo en el caso de un CD, las señales que reflejarán el \"láser\" que rebotará en el CD y será recepcionado por un sensor de distinta forma indicando así, si es un cero o un uno.",
        "enlaces_salientes": [
            "/wiki/C%C3%B3digo_binario",
            "/wiki/C%C3%B3digo_binario",
            "/wiki/C%C3%B3digo_binario",
            "/wiki/Computadora",
            "/wiki/Sistema_binario",
            "/wiki/Bit",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Telecomunicaciones",
            "/wiki/Octal",
            "/wiki/Sistema_de_numeraci%C3%B3n",
            "/wiki/Hexadecimal",
            "/wiki/Byte",
            "/wiki/Sistema_de_numeraci%C3%B3n",
            "/wiki/C%C3%B3digo_Gray",
            "/wiki/Sistema_binario",
            "/wiki/C%C3%B3digo_BCD",
            "/wiki/Complemento_a_9",
            "/wiki/Operaci%C3%B3n_unaria",
            "/wiki/C%C3%B3digo_Aiken",
            "/wiki/Sistema_binario",
            "/wiki/Sistema_octal",
            "/wiki/Sistema_de_numeraci%C3%B3n_decimal",
            "/wiki/Sistema_hexadecimal",
            "/wiki/Control_de_autoridades",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_de_Euclides",
        "titulo": "Algoritmo de Euclides",
        "contenido": "en matematicas, el algoritmo de euclides, o algoritmo euclidiano, es un metodo eficiente para calcular el maximo comun divisor (mcd) de dos numeros enteros, el numero mas grande que los divide a ambos sin dejar resto. lleva el nombre del antiguo matematico griego euclides, quien lo describio por primera vez en elementos (ca. 300 a. c.). es un ejemplo de un algoritmo, un procedimiento paso a paso para realizar un calculo de acuerdo con reglas bien definidas, y es uno de los algoritmos mas antiguos que se siguen utilizando. se puede usar para reducir fracciones a su forma mas simple y es parte de muchos otros calculos teorico-numericos y criptograficos.  el algoritmo euclidiano se basa en el principio de que el maximo comun divisor de dos numeros no cambia si el numero mas grande se reemplaza por su diferencia con el numero mas pequeño. por ejemplo, 21 es el mcd de 252 y 105 (ya que 252 = 21 × 12 y 105 = 21 × 5), y el mismo numero 21 tambien es el mcd de 105 y 252 − 105 = 147. dado que este reemplazo reduce el mas grande de los dos numeros, al repetir este proceso se obtienen pares de numeros sucesivamente mas pequeños hasta que los dos numeros se vuelven iguales. cuando eso ocurre, son el mcd de los dos numeros originales. al invertir los pasos o usar el algoritmo de euclides extendido, el mcd se puede expresar como una combinacion lineal de los dos numeros originales, es decir, la suma de los dos numeros, cada uno multiplicado por un numero entero (por ejemplo, 21 = 5 × 105 + (−2) × 252). el hecho de que el mcd siempre se pueda expresar de esta manera se conoce como la identidad de bezout.  la version del algoritmo euclidiano descrita anteriormente (y por euclides) puede requerir muchos pasos de resta para encontrar el mcd cuando uno de los numeros dados es mucho mas grande que el otro. una version mas eficiente del algoritmo acorta estos pasos, en lugar de reemplazar el mas grande de los dos numeros por su resto al dividirlo por el mas pequeño de los dos (con esta version, el algoritmo se detiene al alcanzar un resto cero). con esta mejora, el algoritmo nunca requiere mas pasos que cinco veces el numero de digitos (base 10) del numero entero mas pequeño. esto fue demostrado por gabriel lame en 1844 (teorema de lame),​​ y marca el comienzo de la teoria de la complejidad informatica. se desarrollaron metodos adicionales para mejorar la eficiencia del algoritmo en el siglo xx.  el algoritmo euclidiano tiene muchas aplicaciones teoricas y practicas. se utiliza para reducir fracciones a su forma mas simple y para realizar divisiones en aritmetica modular. los calculos que utilizan este algoritmo forman parte de los protocolos criptograficos que se usan para proteger las comunicaciones de internet, y en los metodos para romper estos sistemas criptograficos mediante la factorizacion de grandes numeros compuestos. el algoritmo euclidiano se puede usar para resolver ecuaciones diofanticas, como encontrar numeros que satisfagan multiples congruencias de acuerdo con el teorema chino del resto, para construir fracciones continuas y para encontrar aproximaciones racionales precisas a numeros reales. finalmente, se puede utilizar como una herramienta basica para demostrar teoremas en la teoria de numeros, como el teorema de los cuatro cuadrados de lagrange y la unicidad de las factorizaciones primas.  en la concepcion griega de la matematica, los numeros se entendian como magnitudes geometricas. un tema recurrente en la geometria griega es el de la conmensurabilidad de dos segmentos: dos segmentos (numeros) ab y cd son conmensurables cuando existe un tercer segmento pq que cabe exactamente un numero entero de veces en los primeros dos; es decir, pq «mide» (mensura: medida) a los segmentos ab y cd.  no cualquier par de segmentos es conmensurable, como encontraron los pitagoricos cuando establecen que el lado y la diagonal de un cuadrado no son conmensurables, pero en el caso de dos segmentos conmensurables se desea hallar la mayor medida comun posible.  euclides describe en la proposicion i.2 en su libro vii de sus elementos un metodo que permite hallar la mayor medida comun posible de dos numeros (segmentos) que no sean primos entre si, aunque de acuerdo a la epoca tal metodo se explica en terminos geometricos, lo que se ilustra en la siguiente transcripcion.  sean ab y cd los dos numeros que no son primos uno al otro. se necesita entonces encontrar la maxima medida comun de ab y cd.  si cd mide ab entonces es una medida comun puesto que cd se mide a si mismo. y es manifiesto que tambien es la mayor medida pues nada mayor a cd puede medir a cd. pero si cd no mide a ab entonces algun numero quedara de ab y cd, el menor siendo continuamente restado del mayor y que medira al numero que le precede. porque una unidad no quedara pues si no es asi, ab y cd seran primos uno del otro [prop. vii.1], lo cual es lo contrario de lo que se supuso.  por tanto, algun numero queda que medira el numero que le precede. y sea cd midiendo be dejando ea menor que si mismo y sea ea midiendo  df dejando fc menor que si mismo y sea fc medida de ae. entonces, como fc mide ae y ae mide df, fc sera entonces medida de df. y tambien se mide a si mismo. por tanto tambien medira todo cd. y cd mide a be. entonces cf mide a be y tambien mide a ea. asi mide a todo ba y tambien mide a cd. esto es, cf mide tanto a ab y cd por lo que es una medida comun de ab y cd.  afirmo que tambien es la mayor medida comun posible porque si no lo fuera, entonces un numero mayor que cf mide a los numeros ab y cd, sea este g. dado que g mide a cd y cd mide a be, g tambien mide a be. ademas, mide a todo ba por lo que mide tambien al residuo ae. y ae mide a df por lo que g tambien mide a df. mide tambien a todo dc por lo que mide tambien al residuo cf, es decir el mayor mide al menor, lo cual es imposible.  en lenguaje moderno, el algoritmo se describe como sigue:  el hecho de que los segmentos son conmesurables es clave para asegurar que el proceso termina tarde o temprano  al dividir a entre b (numeros enteros), se obtiene un cociente q y un resto r . es posible demostrar que el maximo comun divisor de a y b es el mismo que el de b y r . sea c el maximo comun divisor de a y b , como a = b q + r y c divide a a y a b ,  divide tambien a r . si existiera otro numero mayor que c que divide a b y a r , tambien dividiria a a , por lo que c no seria el mcd de a y b , lo que contradice la hipotesis). este es el fundamento principal del algoritmo. tambien es importante tener en cuenta que el maximo comun divisor de cualquier numero a y 0 es precisamente a . para fines practicos, la notacion m c d ( a , b ) (a,b)} significa maximo comun divisor de a y b .  segun lo antes mencionado, para calcular el maximo comun divisor de 2366 y 273 se puede proseguir de la siguiente manera:  la secuencia de igualdades m c d ( 2366 , 273 ) = m c d ( 273 , 182 ) = m c d ( 182 , 91 ) = m c d ( 91 , 0 ) (2366,273)=\\mathrm {mcd} (273,182)=\\mathrm {mcd} (182,91)=\\mathrm {mcd} (91,0)} implican que m c d ( 2366 , 273 ) = m c d ( 91 , 0 ) (2366,273)=\\mathrm {mcd} (91,0)} . dado que m c d ( 91 , 0 ) = 91 (91,0)=91} , entonces se concluye que m c d ( 2366 , 273 ) = 91 (2366,273)=91} . este mismo procedimiento se puede aplicar a cualesquiera dos numeros naturales. en general, si se desea encontrar el maximo comun divisor de dos numeros naturales a y b , se siguen las siguientes reglas:  asuma que llamamos a = r 0 } y b = r 1 } . aplicando estas reglas se obtiene la siguiente secuencia de operaciones:  como la sucesion de residuos va disminuyendo, al final un residuo tiene que ser cero y es en ese momento cuando el algoritmo termina. el maximo comun divisor es precisamente r n + 1 } (el ultimo residuo que no es cero).  en realidad, el algoritmo de euclides funciona no solo para los numeros naturales, sino para cualquier elemento en el que exista una \"division con residuo\". a este tipo de divisiones se les llama divisiones euclidianas y a los conjuntos donde se puede definir dicha division se les llama dominios euclideos. por ejemplo, el conjunto de los numeros enteros y el de los polinomios con coeficientes racionales son dominios euclideos porque podemos definir una division con residuo (vease division polinomial). de esta manera, se puede calcular el maximo comun divisor de dos numeros enteros o de dos polinomios.  por ejemplo, para calcular el maximo comun divisor de los polinomios p ( x ) = x 5 + 2 x 3 + x +2x^{3}+x} y q ( x ) = x 4 − 1 -1} el algoritmo de euclides sugiere la siguiente secuencia de operaciones:  de esta manera se concluye que su maximo comun divisor es − x 2 − 1 -1} .  se puede expresar este algoritmo de manera mas formal usando pseudocodigo. en este caso la expresion \" x mod y }y} \" significa \"el residuo de dividir x entre y \" (vease aritmetica modular).  entrada: valores a y b pertenecientes a un dominio euclideo  salida: un maximo comun divisor de a y b  vale la pena notar que este algoritmo no es eficiente ser implementado directamente en una computadora, ya que requeriria memorizar todos los valores de r i } .  el algoritmo de euclides extendido permite, ademas de encontrar un maximo comun divisor de dos numeros enteros a y b , expresarlo como la minima combinacion lineal de esos numeros, es decir, encontrar numeros enteros s y t tales que m c d ( a , b ) = a s + b t (a,b)=as+bt} . esto se generaliza tambien hacia cualquier dominio euclidiano.  existen varias maneras de explicar el algoritmo de euclides extendido, una de las mas comunes consiste en la siguiente:  sin embargo, en aras de la comprension y memorizacion de este algoritmo, es conveniente conocer la siguiente caracterizacion. para multiplicar dos matrices de tamaño 2 × 2 se usa la siguiente formula (vease producto de matrices):  (1) [ e f g h ] × [ a b c d ] = [ e a + f c e b + f d g a + h c g b + h d ] e&f\\\\g&h\\end{bmatrix}}\\times a&b\\\\c&d\\end{bmatrix}}=ea+fc&eb+fd\\\\ga+hc&gb+hd\\end{bmatrix}}}  supongase que se utiliza el algoritmo de euclides tradicional para calcular los valores q i } y r i } que ahi se describen. por cada valor q i } calculado se puede formar la matriz q i = [ 0 1 1 − q i ] =0&1\\\\1&-q_{i}\\end{bmatrix}}} . usando la ecuacion (1) de manera repetida se puede calcular el producto de las primeras i matrices de este tipo:   [ s i t i s i + 1 t i + 1 ] = [ 0 1 1 − q i ] × [ 0 1 1 − q i − 1 ] × ⋯ × [ 0 1 1 − q 1 ] s_{i}&t_{i}\\\\s_{i+1}&t_{i+1}\\end{bmatrix}}=0&1\\\\1&-q_{i}\\end{bmatrix}}\\times 0&1\\\\1&-q_{i-1}\\end{bmatrix}}\\times \\cdots \\times 0&1\\\\1&-q_{1}\\end{bmatrix}}}  resulta ser que los valores s i } y t i } tienen la propiedad de que r i = a s i + b t i =as_{i}+bt_{i}} , es decir, expresan a r i } como una combinacion lineal de a y b . particularmente, como m c d ( a , b ) = r n + 1 (a,b)=r_{n+1}} entonces se tiene m c d ( a , b ) = a s n + 1 + b t n + 1 (a,b)=as_{n+1}+bt_{n+1}} , lo cual es la solucion del problema. esta propiedad no deberia ser sorprendente, pues esta multiplicacion de matrices equivale al metodo antes descrito donde se substituye cada ecuacion en la anterior. es importante calcular q i × ⋯ × q 3 × q 2 × q 1 \\times \\cdots \\times q_{3}\\times q_{2}\\times q_{1}} en ese mismo orden. la matriz q 1 } aparece en el extremo derecho y la matriz q i } en el izquierdo.  regresando al primer ejemplo, la sucesion de cocientes es q 1 = 8 =8} , q 2 = 1 =1} y q 3 = 2 =2} . entonces se puede calcular   [ − 1 9 3 − 26 ] = [ 0 1 1 − 2 ] × [ 0 1 1 − 1 ] × [ 0 1 1 − 8 ] -1&9\\\\3&-26\\end{bmatrix}}=0&1\\\\1&-2\\end{bmatrix}}\\times 0&1\\\\1&-1\\end{bmatrix}}\\times 0&1\\\\1&-8\\end{bmatrix}}}  utilizando el primer renglon de esta matriz se puede leer que 91 = 2366 ( − 1 ) + 273 ( 9 ) , es decir, se ha encontrado la manera de expresar al maximo comun divisor de 2366 y 273 como una combinacion lineal.  para expresar el algoritmo de euclides extendido es conveniente notar la manera en que se calculan los valores s i } y t i } con la multiplicacion de matrices:   [ s i t i s i + 1 t i + 1 ] = [ s i t i s i − 1 − q i s i t i − 1 − q i t i ] = [ 0 1 1 − q i ] × [ s i − 1 t i − 1 s i t i ] s_{i}&t_{i}\\\\s_{i+1}&t_{i+1}\\end{bmatrix}}=s_{i}&t_{i}\\\\s_{i-1}-q_{i}s_{i}&t_{i-1}-q_{i}t_{i}\\end{bmatrix}}=0&1\\\\1&-q_{i}\\end{bmatrix}}\\times s_{i-1}&t_{i-1}\\\\s_{i}&t_{i}\\end{bmatrix}}}  de esta manera s i + 1 = s i − 1 − q i s i =s_{i-1}-q_{i}s_{i}} y ademas t i + 1 = t i − 1 − q i t i =t_{i-1}-q_{i}t_{i}} . por lo tanto el algoritmo en pseudocodigo se puede expresar como sigue:  entrada: valores a y b pertenecientes a un dominio euclideo  salida: un maximo comun divisor de a y b , y valores s y t tales que m c d ( a , b ) = a s + b t (a,b)=as+bt}  al momento de hacer calculos con fracciones, es de gran importancia saber como simplificarlas. por ejemplo, la fraccion 65 91 {91}}} es equivalente con 5 7 {7}}} (vease numero racional). de manera mas general, a b = c a c b {b}}={cb}}} siempre que c = 0 . para reducir una fraccion cualquiera a b {b}}} , solo se necesita dividir a y b entre su maximo comun divisor.  por ejemplo, si se desea reducir 166 249 {249}}} , primero se usa el algoritmo de euclides para encontrar m c d ( 166 , 249 ) = 83 (166,249)=83} . se hacen las divisiones 166 ÷ 83 = 2 y 249 ÷ 83 = 3 . luego entonces se concluye que 166 249 = 2 3 {249}}={3}}} .  la sucesion de divisiones que se efectuan al seguir el algoritmo de euclides puede ser utilizada para expresar una fraccion cualquiera a b {b}}} como fraccion continua. esto se debe a que si a = b q + r y r = 0 , entonces  (3) a b = q + 1 b r {b}}=q+{r}}}}  por ejemplo, para encontrar el maximo comun divisor de 93164 y 5826 el algoritmo genera la siguiente secuencia de divisiones:  todas estas ecuaciones las podemos hacer parecidas a la ecuacion (3  3):  si se sustituye la segunda ecuacion en la primera, se obtiene   93164 5826 = 15 + 1 1 + 1 5774 52 {5826}}=15+{1+{52}}}}}}  si se repite este proceso de substitucion entonces se obtiene la expresion deseada:   93164 5826 = 15 + 1 1 + 1 111 + 1 26 {5826}}=15+{1+{111+{26}}}}}}}  de manera mas general, la fraccion continua encontrada con este algoritmo siempre es de la forma   a b = q 1 + 1 q 2 + 1 q 3 + 1 ⋱ q n − 1 + 1 q n {b}}=q_{1}+{q_{2}+{q_{3}++{q_{n}}}}}}}}}}    decimos que dos numeros enteros son congruentes modulo m (aunque tambien se puede generalizar para cualquier otro dominio euclideo) si al dividirlos entre m obtenemos el mismo residuo (vease congruencia). por ejemplo, 7 es congruente con 12 modulo 5 porque al dividir 7 entre 5 y 12 entre 5, en ambos casos obtenemos el mismo residuo (que es 2). cuando a es congruente con b modulo m se escribe a ≡ b ( mod m ) }} , en el ejemplo anterior se tiene 7 ≡ 12 ( mod 5 ) }} . supongase que se conocen los valores de a , b y m , pero que se desconoce el valor x en la siguiente congruencia:  (2) a x ≡ b ( mod m ) }}  basta  encontrar un valor a − 1 } que satisfaga: a − 1 a ≡ 1 ( mod m ) a\\equiv 1}} , pues de esta manera al multiplicar la ecuacion (2) por a − 1 } se tendra la solucion deseada:   x ≡ a − 1 b ( mod m ) b}}  al elemento a − 1 } se le llama \"inverso modulo m \" de a . desafortunadamente este valor no siempre existe. por ejemplo, con a = 4 y m = 6 no existe ningun numero entero a − 1 } tal que a − 1 4 ≡ 1 ( mod 6 ) 4\\equiv 1}} . de hecho este valor existe si y solo si m c d ( a , m ) = 1 (a,m)=1} (la   existencia de soluciones depende de la condicion m c d ( a , m ) | b (a,m)|b} , mientras que la unicidad depende de que el m c d ( a , m ) = 1 (a,m)=1} ). mas aun, si al usar el algoritmo de euclides extendido (ahora con b = m ) se obtiene 1 = a s + m t , entonces el valor s es el inverso modulo m de a . por ejemplo, se desea resolver la ecuacion   5 x ≡ 2 ( mod 9 ) }}  entonces con el algoritmo de euclides extendido se obtiene que m c d ( 5 , 9 ) = 1 = 5 ( 2 ) + 9 ( − 1 ) (5,9)=1=5(2)+9(-1)} . como m c d ( 5 , 9 ) = 1 (5,9)=1} entonces 5 tiene un inverso modulo 9 . mas aun, como 1 = 5 ( 2 ) + 9 ( − 1 ) , entonces ese inverso es 2. entonces   x ≡ 2 ( 2 ) ( mod 9 ) }}  es decir que el valor de x es 4 .  el teorema de lame afirma que el caso peor para este algoritmo es cuando se le pide calcular el maximo comun divisor de dos numeros consecutivos de la sucesion de fibonacci. por ejemplo, si se desea calcular el maximo comun divisor de f 10 = 55 =55} y f 11 = 89 =89} se obtiene la siguiente secuencia de operaciones:  en este ejemplo se observa que con estos dos numeros de dos digitos decimales, se necesita hacer 9 divisiones. en general, el numero de divisiones efectuadas por el algoritmo nunca supera 5 veces el numero de digitos que tienen estos numeros. en terminos de complejidad computacional, esto significa que se requieren o ( log ⁡ n ) divisiones para calcular el maximo comun divisor de n y m donde n > m .  el numero promedio de divisiones efectuadas por el algoritmo se estuvo investigando desde 1968, pero solo hasta apenas el año 2002, brigitte vallee demostro que si los dos numeros se pueden representar con n bits, entonces el numero promedio de divisiones necesarias es π 2 6 n }{6}}n}} .  sin embargo, no basta con saber el numero de divisiones. hay que recordar que el algoritmo de euclides funciona tanto para polinomios como para numeros enteros, y en general, cualquier dominio euclideo. en cada caso, la complejidad del algoritmo depende del numero de divisiones efectuadas y del costo de cada division. en el caso de los polinomios, el numero de divisiones es o ( log ⁡ n ) donde n es el grado de los polinomios.  en general, los algoritmos 1 y 2 no son muy apropiados para implementarse directamente en un lenguaje de programacion, especialmente porque consumen mucha memoria. si no se necesitan los valores intermedios, y solo se desea calcular el maximo comun divisor de dos numeros enteros, conviene usar estas variantes:  funcion m c d ( a , b ) (a,b)} :  funcion m c d ( a , b ) (a,b)} :  funcion e u c l i d e s ( a , b ) }(a,b)} :  funcion e u c l i d e s ( a , b ) }(a,b)} :  funcion e u c l i d e s ( a , b ) }(a,b)} :  acerca de la notacion empleada: ",
        "snippet": "En matemáticas, el algoritmo de Euclides, o algoritmo euclidiano, es un método eficiente para calcular el máximo común divisor (MCD) de dos números enteros, el número más grande que los divide a ambos sin dejar resto. Lleva el nombre del antiguo matemático griego Euclides, quien lo describió por primera vez en Elementos (ca. 300 a. C.). Es un ejemplo de un algoritmo, un procedimiento paso a paso para realizar un cálculo de acuerdo con reglas bien definidas, y es uno de los algoritmos más antiguos que se siguen utilizando. Se puede usar para reducir fracciones a su forma más simple y es parte de muchos otros cálculos teórico-numéricos y criptográficos.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/M%C3%A1ximo_com%C3%BAn_divisor",
            "/wiki/Resto",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Euclides",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Algoritmo",
            "/wiki/Fracci%C3%B3n",
            "/wiki/Fracci%C3%B3n_irreducible",
            "/wiki/Combinaci%C3%B3n_lineal",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Identidad_de_B%C3%A9zout",
            "/wiki/Gabriel_Lam%C3%A9",
            "/wiki/Teor%C3%ADa_de_la_complejidad_inform%C3%A1tica",
            "/wiki/Fracci%C3%B3n",
            "/wiki/Fracci%C3%B3n_irreducible",
            "/wiki/Divisi%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Aritm%C3%A9tica_modular",
            "/wiki/Protocolo_criptogr%C3%A1fico",
            "/wiki/Internet",
            "/wiki/Factorizaci%C3%B3n_de_enteros",
            "/wiki/Ecuaciones_diof%C3%A1nticas",
            "/wiki/Teorema_chino_del_resto",
            "/wiki/Fracciones_continuas",
            "/wiki/Aproximaci%C3%B3n_diof%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Teorema_de_los_cuatro_cuadrados_de_Lagrange",
            "/wiki/Teorema_fundamental_de_la_aritm%C3%A9tica",
            "/wiki/Conmensurabilidad",
            "/wiki/Segmento",
            "/wiki/Proposici%C3%B3n",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Euclides",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Algoritmo_de_la_divisi%C3%B3n",
            "/wiki/Cociente_(aritm%C3%A9tica)",
            "/wiki/Resto",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Divisi%C3%B3n_euclidiana",
            "/wiki/Dominio_eucl%C3%ADdeo",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/Polinomio",
            "/wiki/Divisi%C3%B3n_polinomial",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Aritm%C3%A9tica_modular",
            "/wiki/Algoritmo_de_la_divisi%C3%B3n",
            "/wiki/Producto_de_matrices",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/Fracci%C3%B3n_continua",
            "/wiki/Inverso_multiplicativo_(aritm%C3%A9tica_modular)",
            "/wiki/Congruencia",
            "/wiki/Sucesi%C3%B3n_de_Fibonacci",
            "/wiki/Complejidad_computacional",
            "/wiki/Lenguaje_C",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Java",
            "/wiki/C_Sharp",
            "/wiki/Python",
            "/wiki/Visual_Basic",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Pascal",
            "/wiki/Maxima",
            "/wiki/R-project",
            "/wiki/APL",
            "/wiki/Ruby",
            "/wiki/Parte_fraccionaria",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Universidad_de_La_Laguna",
            "/wiki/Cambridge_University_Press",
            "/wiki/MIT_Press",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/YouTube",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Conjunto",
        "titulo": "Conjunto",
        "contenido": "en matematicas, un conjunto es una coleccion de elementos considerada en si misma como un objeto matematico. los elementos de un conjunto, pueden ser las siguientes: personas, numeros, colores, letras, figuras, etc. se dice que un elemento (o miembro) pertenece al conjunto si esta definido como incluido de algun modo dentro de el.  ejemplo: el conjunto de los colores del arcoiris es:  un conjunto suele definirse mediante una propiedad que todos sus elementos poseen. por ejemplo, para los numeros naturales, si se considera la propiedad de ser un numero primo, el conjunto de los numeros primos es:  formalmente, un conjunto es el tipo de objeto matematico del que tratan los axiomas de zermelo-fraenkel.  el concepto de conjunto como objeto abstracto no comenzo a emplearse en matematicas hasta el siglo xix, a medida que se despejaban las dudas sobre la nocion de infinito.​ los trabajos de bernard bolzano y bernhard riemann ya contenian ideas relacionadas con una vision conjuntista de la matematica. las contribuciones de richard dedekind al algebra estaban formuladas en terminos claramente conjuntistas, que aun prevalecen en la matematica moderna: relaciones de equivalencia, particiones, homomorfismos, etc., y el mismo explicito las hipotesis y operaciones relativas a conjuntos que necesito en su trabajo.  la teoria de conjuntos como disciplina independiente se atribuye usualmente a georg cantor. comenzando con sus investigaciones sobre conjuntos numericos, desarrollo un estudio sobre los conjuntos infinitos y sus propiedades. la influencia de dedekind y cantor empezo a ser determinante a finales del siglo xix, en el proceso de «axiomatizacion» de la matematica, en el que todos los objetos matematicos, como los numeros, las funciones y las diversas estructuras, fueron construidos con base en los conjuntos.  un conjunto es una coleccion bien definida de objetos,dichos objetos pueden ser cualquier cosa: numeros, personas, letras, etc. algunos ejemplos son:  los conjuntos se denotan habitualmente por letras mayusculas. los objetos que componen el conjunto se llaman elementos o miembros. se dice que «pertenecen» al conjunto y se denota mediante el simbolo ∈:[n 1]​ la expresion a ∈ a se lee entonces como «a esta en a», «a pertenece a a», «a contiene a a», etc. para la nocion contraria se usa el simbolo ∈. por ejemplo:  existen varias maneras de referirse a un conjunto. en el ejemplo anterior, para los conjuntos a y d se usa una definicion intensiva o por comprension, donde se especifica una propiedad que todos sus elementos poseen. sin embargo, para los conjuntos b y c se usa una definicion extensiva, listando todos sus elementos explicitamente.  es habitual usar llaves para escribir los elementos de un conjunto, de modo que:  esta notacion mediante llaves tambien se utiliza cuando los conjuntos se especifican de forma intensiva mediante una propiedad:  otra notacion habitual para denotar por comprension es:  en estas expresiones los dos puntos («:») significan «tal que». asi, el conjunto f es el conjunto de «los numeros de la forma n2 tal que n es un numero entero entre 1 y 10 (ambos inclusive)», o sea, el conjunto de los diez primeros cuadrados de numeros naturales. en lugar de los dos puntos se utiliza tambien la barra vertical («|») u oblicua «/» .  un conjunto esta totalmente determinado por sus elementos. por ello, la igualdad de conjuntos se establece como:  propiedad de la extensionalidad dos conjuntos a y b que tengan los mismos elementos son el mismo conjunto, a = b.  esta propiedad tiene varias consecuencias. un mismo conjunto puede especificarse de muchas maneras distintas, en particular extensivas o intensivas. por ejemplo, el conjunto a de los numeros naturales menores que 5 es el mismo conjunto que a′, el conjunto de los numeros 1, 2, 3 y 4. tambien:  el orden en el que se precisan los elementos tampoco se tiene en cuenta para comparar dos conjuntos:  ademas, un conjunto no puede tener elementos «repetidos», ya que un objeto solo puede o bien ser un elemento de dicho conjunto o no serlo. se da entonces que, por ejemplo:  en ausencia de alguna caracteristica adicional que distinga los «1» repetidos, lo unico que puede decirse del conjunto de la derecha es que «1» es uno de sus elementos.  el conjunto que no contiene ningun elemento se llama el conjunto vacio y se denota por ∅ o simplemente {}. algunas teorias axiomaticas de conjuntos aseguran que el conjunto vacio existe incluyendo un axioma del conjunto vacio. en otras teorias, su existencia puede deducirse. muchas posibles propiedades de conjuntos son trivialmente validas para el conjunto vacio.  en la teoria de conjuntos axiomatica estandar, por el axioma de extensionalidad, dos conjuntos son iguales si tienen los mismos elementos; por lo tanto solo puede haber un conjunto sin ningun elemento. por consiguiente, solo hay un unico conjunto vacio, y hablamos de \"el conjunto vacio\" en lugar de \"un conjunto vacio\".  para cualquier conjunto a:  (ver operaciones con conjuntos)  el conjunto vacio tiene las siguientes propiedades:  un subconjunto a de un conjunto b, es un conjunto que contiene algunos de los elementos de b (o quiza todos):  un conjunto a es un subconjunto del conjunto b si cada elemento de a es a su vez un elemento de b.  cuando a es un subconjunto de b, se denota como a ⊆ b y se dice que «a esta contenido en b». tambien puede escribirse b ⊇ a, y decirse que b es un superconjunto de a y tambien «b contiene a a» o «b incluye a a».  todo conjunto a es un subconjunto de si mismo, ya que siempre se cumple que «cada elemento de a es a su vez un elemento de a». es habitual establecer una distincion mas fina mediante el concepto de subconjunto propio: a es un subconjunto propio de b si es un subconjunto de b pero no es igual a b. se denota como a ⊊ b, es decir: a ⊆ b pero a = b (y equivalentemente, para un superconjunto propio, b ⊋ a).[n 2]​  ejemplos.  dos conjuntos a y b son disjuntos si no tienen ningun elemento en comun. por ejemplo, los conjuntos de los numeros racionales y los numeros irracionales son disjuntos: no hay ningun numero que sea a la vez racional e irracional. la interseccion de dos conjuntos disjuntos es el conjunto vacio.    los conjuntos pueden ser finitos o infinitos. en el caso de un conjunto finito se pueden contar los elementos del conjunto:  el numero de elementos de un conjunto finito es su cardinal.  el cardinal se denota por |a|, card(a) o #a. asi, en los ejemplos anteriores, se tiene que |a| = 4 (cuatro numeros), |b| = 3 (tres colores) y |f| = 10 (diez cuadrados). el unico conjunto cuyo cardinal es 0 es el conjunto vacio ∅.  existen, a su vez, determinadas propiedades de cardinalidad. si tomamos como ejemplo dos conjuntos, a y b:  y en el caso de tres conjuntos, a, b y c:  en un conjunto infinito no hay un numero finito de elementos. es el caso por ejemplo de los numeros naturales: n = {1, 2, 3, …}. sin embargo, existe una manera de comparar conjuntos infinitos entre si, y se obtiene que existen conjuntos infinitos «mas grandes» que otros. el «numero de elementos» de un conjunto infinito es un numero transfinito.  uno de los resultados mas importantes de georg cantor fue que la cardinalidad de los reales ( c }} ) es mas grande que la de los numeros naturales ( ℵ 0 } ). esto es, que hay mas numeros reales r que numeros enteros n. concretamente, cantor mostro que c = 2 ℵ 0 > ℵ 0 }=2^}>}\\,} .  la hipotesis del continuo afirma que no existen conjuntos con cardinalidades intermedias entre los naturales y los reales:  si se asume el axioma de eleccion, la estructura de los cardinales infinitos es mas clara: todos los cardinales infinitos son alefs y estan bien ordenados, por lo que existe solo un cardinal inmediatamente superior a ℵ0, denotado por ℵ1. la hipotesis es equivalente entonces a:  existen varias operaciones basicas que pueden realizarse, partiendo de ciertos conjuntos dados, para obtener nuevos conjuntos: ",
        "snippet": "En matemáticas, un conjunto es una colección de elementos considerada en sí misma como un objeto matemático. Los elementos de un conjunto, pueden ser las siguientes: personas, números, colores, letras, figuras, etc. Se dice que un elemento (o miembro) pertenece al conjunto si está definido como incluido de algún modo dentro de él.",
        "enlaces_salientes": [
            "/wiki/Conjunto",
            "/wiki/Conjunto",
            "/wiki/Conjunto",
            "/wiki/Conjunto_(desambiguaci%C3%B3n)",
            "/wiki/Pol%C3%ADgonos",
            "/wiki/Diagrama_de_Venn",
            "/wiki/Pol%C3%ADgono_regular",
            "/wiki/Subconjunto",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Teor%C3%ADa_de_categor%C3%ADas",
            "/wiki/Personas",
            "/wiki/N%C3%BAmero",
            "/wiki/Color",
            "/wiki/Letra",
            "/wiki/Figura_geom%C3%A9trica",
            "/wiki/Elemento_de_un_conjunto",
            "/wiki/Arco%C3%ADris",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/N%C3%BAmero_primo",
            "/wiki/Axiomas_de_Zermelo-Fraenkel",
            "/wiki/Siglo_XIX",
            "/wiki/Conjunto_infinito",
            "/wiki/Bernard_Bolzano",
            "/wiki/Bernhard_Riemann",
            "/wiki/Richard_Dedekind",
            "/wiki/Relaci%C3%B3n_de_equivalencia",
            "/wiki/Partici%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Homomorfismo",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Georg_Cantor",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Estructura_matem%C3%A1tica",
            "/wiki/Georg_Cantor",
            "/wiki/N%C3%BAmero",
            "/wiki/Palo_(naipe)",
            "/wiki/Baraja_francesa",
            "/wiki/Elemento_de_un_conjunto",
            "/wiki/Pol%C3%ADgono",
            "/wiki/Intenci%C3%B3n",
            "/wiki/Extensi%C3%B3n_(sem%C3%A1ntica)",
            "/wiki/Par%C3%A9ntesis",
            "/wiki/Dos_puntos",
            "/wiki/Cuadrado_(%C3%A1lgebra)",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Barra_vertical",
            "/wiki/Barra_(tipograf%C3%ADa)",
            "/wiki/Elemento_de_un_conjunto",
            "/wiki/Par%C3%A9ntesis",
            "/wiki/Diagrama_de_Venn",
            "/wiki/Axioma_de_extensionalidad",
            "/wiki/Vocales",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Conjunto_vac%C3%ADo",
            "/wiki/Teor%C3%ADa_de_conjuntos#Teor.C3.ADa_axiom.C3.A1tica_de_conjuntos",
            "/wiki/Teor%C3%ADa_de_conjuntos#Teoría_axiomática_de_conjuntos",
            "/wiki/Axioma_de_extensionalidad",
            "/wiki/Subconjunto",
            "/wiki/Subconjunto",
            "/wiki/Subconjunto",
            "/wiki/Subconjunto_propio",
            "/wiki/Conjuntos_disjuntos",
            "/wiki/N%C3%BAmeros_racionales",
            "/wiki/N%C3%BAmeros_irracionales",
            "/wiki/Intersecci%C3%B3n_de_conjuntos",
            "/wiki/N%C3%BAmero_cardinal",
            "/wiki/Conjunto_finito",
            "/wiki/Conjunto_infinito",
            "/wiki/Conjunto_vac%C3%ADo",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/N%C3%BAmero_transfinito",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Georg_Cantor",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/Numero_real",
            "/wiki/Axioma_de_elecci%C3%B3n",
            "/wiki/%C3%81lef_(cardinales)",
            "/wiki/Buen_orden",
            "/wiki/%C3%81lgebra_de_conjuntos",
            "/wiki/Uni%C3%B3n_de_conjuntos",
            "/wiki/Intersecci%C3%B3n_de_conjuntos",
            "/wiki/Diferencia_de_conjuntos",
            "/wiki/Complemento_de_un_conjunto",
            "/wiki/Conjunto_universal",
            "/wiki/Diferencia_sim%C3%A9trica",
            "/wiki/Producto_cartesiano",
            "/wiki/Pares_ordenados",
            "/wiki/Axiomas_de_Zermelo-Fraenkel",
            "/wiki/Relaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Correspondencia_matem%C3%A1tica",
            "/wiki/Conjunto_de_Borel",
            "/wiki/Equipotencia",
            "/wiki/Diagrama_de_Venn",
            "/wiki/Estructura_algebraica",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Grupo_(matem%C3%A1tica)",
            "/wiki/Georg_Cantor",
            "/wiki/Morfismo",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Subconjunto",
            "/wiki/The_Stanford_Encyclopedia_of_Philosophy",
            "/wiki/Georg_Cantor",
            "/wiki/ISBN",
            "/wiki/Oxford_University_Press",
            "/wiki/ISBN",
            "/wiki/The_Stanford_Encyclopedia_of_Philosophy",
            "/wiki/ISBN",
            "/wiki/Eric_W._Weisstein",
            "/wiki/MathWorld",
            "/wiki/Wolfram_Research",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Pseudoc%C3%B3digo",
        "titulo": "Pseudocódigo",
        "contenido": "en ciencias de la computacion, y analisis numerico, el pseudocodigo​ (o lenguaje de descripcion algoritmico) es una descripcion de alto nivel compacta e informal​ del principio operativo de un programa informatico u otro algoritmo.  utiliza las convenciones estructurales de un lenguaje de programacion real,​ pero esta diseñado para la lectura humana en lugar de la lectura mediante maquina,​ y con independencia de cualquier otro lenguaje de programacion.​ normalmente, el pseudocodigo omite detalles que no son esenciales para la comprension humana del algoritmo, tales como declaraciones de variables, codigo especifico del sistema y algunas subrutinas. el lenguaje de programacion se complementa, donde sea conveniente, con descripciones detalladas en lenguaje natural, o con notacion matematica compacta. se utiliza pseudocodigo pues este es mas facil de entender para las personas que el codigo del lenguaje de programacion convencional, ya que es una descripcion eficiente y con un entorno independiente de los principios fundamentales de un algoritmo. se utiliza comunmente en los libros de texto y publicaciones cientificas que se documentan varios algoritmos, y tambien en la planificacion del desarrollo de programas informaticos, para esbozar la estructura del programa antes de realizar la efectiva codificacion. es comunmente utilizado por los programadores para omitir secciones de codigo o para dar una explicacion del paradigma que tomo el mismo programador para hacer sus codigos, esto quiere decir que el pseudocodigo no es programable, sino facilita la programacion.  el principal objetivo del pseudocodigo es el de representar la solucion a un algoritmo de la forma mas detallada posible, y a su vez lo mas parecida posible al lenguaje que posteriormente se utilizara para la codificacion del mismo.  no existe una sintaxis estandar para el pseudocodigo, aunque los cinco ide's que manejan pseudocodigo en español tengan su sintaxis propia. aunque sea parecido, el pseudocodigo no debe confundirse con los programas esqueleto que incluyen codigo ficticio, que pueden ser compilados sin errores. los diagramas de flujo y uml pueden ser considerados como una alternativa grafica al pseudocodigo, aunque sean mas amplios  generalmente se utiliza pseudocodigo en los libros de texto y publicaciones cientificas relacionadas con la informatica y la computacion numerica, para la descripcion de algoritmos, de manera que todos los programadores puedan entenderlo, aunque no todos conozcan el mismo lenguaje de programacion. generalmente, en los libros de texto se adjunta una explicacion que acompaña a la introduccion y que explica las convenciones particulares en uso. el nivel de detalle del seudocientifico puede, en algunos casos, acercarse a la de formalizar los idiomas de proposito general.  un programador que tiene que aplicar un algoritmo especifico, sobre todo uno desfamiliarizado, generalmente comienza con una descripcion en pseudocodigo, y luego \"traduce\" esa descripcion en el lenguaje de programacion meta y lo modifica para que interactue correctamente con el resto del programa. los programadores tambien pueden iniciar un proyecto describiendo la forma del codigo en pseudocodigo en el papel antes de escribirlo en su lenguaje de programacion, como ocurre en la estructuracion de un enfoque de top-down y bottom-up arriba hacia abajo.  en la actualidad y por lo general, el pseudocodigo, como su nombre lo indica, no obedece a las reglas de sintaxis de ningun idioma en particular ni es de forma estandar sistematica, a pesar de que cualquier escritor en particular vaya a pedir prestado las estructuras de control general, la sintaxis y el estilo, por ejemplo, de algun lenguaje de programacion convencional. pero en caso de que se quiera ejecutar, se debe llevar a forma tipo, para que no genere mensajes de error. las fuentes populares incluyen la sintaxis de pascal, basic, c, c++, java, lisp, y algol. por lo general, se omiten las declaraciones de variables. a veces, las llamadas a funciones, los bloques de codigo y el codigo contenido dentro de un loop se remplazan por una sentencia de una linea en lenguaje natural.  este es un ejemplo de pseudocodigo (para el juego matematico bizz buzz):  pseudocodigo estilo fortran:  pseudocodigo estilo pascal:  pseudocodigo estilo c:  la definicion de datos se da por supuesta, sobre todo en las variables sencillas, si se emplea formaciones: pilas, colas, vectores o registros, se pueden definir en la cabecera del algoritmo, y naturalmente cuando empleemos el pseudocodigo para definir estructuras de datos, esta parte la desarrollaremos adecuadamente.  cada autor usa su propio pseudocodigo con sus respectivas convenciones. por ejemplo, la instruccion \"reemplace el valor de la variable x por el valor de la variable y \" puede ser representado como:  las operaciones aritmeticas se representan de la forma usual en matematicas.  en la redaccion de pseudocodigo se utiliza tres tipos de estructuras de control: las secuenciales, las selectivas y las iterativas.  las instrucciones se siguen en una secuencia fija que normalmente viene dada por el numero de renglon. es decir que las instrucciones se ejecutan de arriba hacia abajo.  las instrucciones selectivas representan instrucciones que pueden o no ejecutarse, segun el cumplimiento de una condicion.    la condicion es una expresion booleana. instrucciones es ejecutada solo si la condicion es verdadera.  la instruccion alternativa realiza una instruccion de dos posibles, segun el cumplimiento de una condicion.    la condicion es una variable booleana o una funcion reducible a booleana (logica, verdadero/falso). si esta condicion es cierta se ejecuta instrucciones1, si no es asi, entonces se ejecuta instrucciones2.  tambien es comun el uso de una seleccion multiple que equivaldria a anidar varias funciones de seleccion.  en este caso hay una serie de condiciones que tienen que ser mutuamente excluyentes, si una de ellas se cumple las demas tienen que ser falsas necesariamente, hay un caso si no que sera cierto cuando las demas condiciones sean falsas.  en esta estructura si condicion1 es cierta, entonces se ejecuta solo instrucciones1. en general, si condicioni es verdadera, entonces solo se ejecuta instruccionesi  una construccion similar a la anterior (equivalente en algunos casos) es la que se muestra a continuacion.  en este caso hay un indicador es una variable o una funcion cuyo valor es comparado en cada caso con los valores \"valori\", si en algun caso coinciden ambos valores, entonces se ejecutaran las instruccionesi correspondientes. la seccion en otro caso es analoga a la seccion si no del ejemplo anterior.  las instrucciones iterativas representan la ejecucion de instrucciones en mas de una vez.  el bucle se repite mientras la condicion sea cierta, si al llegar por primera vez al bucle mientras la condicion es falsa, el cuerpo del bucle no se ejecuta alguna vez.    existen otras variantes que se derivan a partir de la anterior. la estructura de control repetir se utiliza cuando es necesario que el cuerpo del bucle se ejecuten al menos una vez y hasta que se cumpla la condicion:  la estructura anterior equivaldria a escribir:  el bucle hacer se utiliza para repetir un bloque de codigo mientras se cumpla cierta condicion.  una estructura de control muy comun es el ciclo for, la cual se usa cuando se desea iterar un numero conocido de veces, empleando como indice una variable que se incrementa (o decrementa):  la cual se define como:  por ultimo, tambien es comun usar la estructura de control para cada. esta sentencia se usa cuando se tiene una lista o un conjunto l y se quiere iterar por cada uno de sus elementos:  si asumimos que los elementos de l son l 0 , l 1 , … , l n ,l_{1},\\dots ,l_{n}} , entonces esta sentencia equivaldria a:  que es lo mismo que:  sin embargo, en la practica existen mejores formas de implementar esta instruccion dependiendo del problema.  es importante recalcar que el pseudocodigo no es un lenguaje estandarizado. eso significa que diferentes autores podrian dar otras estructuras de control o bien usar estas mismas estructuras, pero con una notacion diferente. sin embargo, las funciones matematicas y logicas toman el significado usual que tienen en matematica y logica, con las mismas expresiones.  cualquier instruccion puede ser sustituida por una estructura de control. el siguiente ejemplo muestra el pseudocodigo del ordenamiento de burbuja, que tiene varias estructuras anidadas. este algoritmo ordena de menor a mayor los elementos de una lista l .   p r o c e d i m i e n t o o r d e n a r ( l ) ↕ / / c o m e n t a r i o : l = ( l 1 , l 2 , … , l n ) e s u n a l i s t a c o n n e l e m e n t o s / / k ← 0 ; r e p e t i r ↕ i n t e r c a m b i o ← f a l s o ; k ← k + 1 ; p a r a i ← 1 h a s t a n − k c o n p a s o 1 h a c e r ↕ s i l i > l i + 1 e n t o n c e s ↕ i n t e r c a m b i a r ( l i , l i + 1 ) i n t e r c a m b i o ← v e r d a d e r o ; f i n s i f i n p a r a h a s t a q u e i n t e r c a m b i o = f a l s o ; f i n p r o c e d i m i e n t o {l}\\mathrm {procedimiento} }\\;\\mathrm {ordenar} }\\;(l}\\;)\\\\\\left\\updownarrow {l}//comentario:\\;l=(l_{1},l_{2},\\dots ,l_{n})\\;es\\;una\\;lista\\;con\\;n\\;elementos//}\\\\k}\\;\\gets }\\;0;}\\\\\\mathrm {repetir} }\\\\\\left\\updownarrow {l}\\mathrm {intercambio} }\\;\\gets }\\;\\mathrm {falso} ;}\\\\k}\\;\\gets }\\;k+1;}\\\\\\mathrm {para} }\\;i}\\;\\gets }\\;1}\\;\\mathrm {hasta} }\\;n-k}\\;\\mathrm {con\\;paso} }\\;1}\\;\\mathrm {hacer} }\\\\\\left\\updownarrow {l}\\mathrm {si} }\\;l_{i}}\\;>}\\;l_{i+1}}\\;\\mathrm {entonces} }\\;\\\\\\left\\updownarrow {l}\\mathrm {intercambiar} }\\;(l_{i},l_{i+1}}\\;)\\\\\\mathrm {intercambio} }\\;\\gets }\\;\\mathrm {verdadero} ;}\\end{array}}\\right.\\\\\\mathrm {fin\\;si} }\\;\\\\\\end{array}}\\right.\\\\\\mathrm {fin\\;para} }\\\\\\end{array}}\\right.\\\\\\mathrm {hasta\\;que} }\\;\\mathrm {intercambio} }\\;=}\\;\\mathrm {falso} ;}\\end{array}}\\right.\\\\\\mathrm {fin\\;procedimiento} }\\;\\\\\\end{array}}}  en general, las estructuras anidadas se muestran indentadas, para hacer mas sencilla su identificacion a simple vista. en el ejemplo, ademas de la sangria, se ha conectado con flechas los pares de delimitadores de cada nivel de anidamiento.  muchas personas prefieren distinguir entre funciones y procedimientos. una funcion, al igual que una funcion matematica, recibe uno o varios valores de entrada y regresa una salida mientras que un procedimiento recibe una entrada y no genera alguna salida aunque en algun caso podria devolver resultados a traves de sus parametros de entrada si estos se han declarado por referencia (ver formas de pasar argumentos a una funcion o procedimiento).  en ambos casos es necesario dejar en claro cuales son las entradas para el algoritmo, esto se hace comunmente colocando estos valores entre parentesis al principio o bien declarandolo explicitamente con un enunciado. en el caso de las funciones, es necesario colocar una palabra como regresar o devolver para indicar cual es la salida generada por el algoritmo. por ejemplo, el pseudocodigo de una funcion que permite calcular a n } (un numero a elevado a potencia n ).  un ejemplo de procedimiento seria el algoritmo de ordenamiento de burbuja, por el que partiendo de una lista de valores estos se ordenan, notese que en un procedimiento, no se calcula el valor de una funcion, sino que se realiza una accion, en este caso ordenar la lista.  con el pseudocodigo se puede desarrollar cualquier algoritmo que:  los pseudocodigos presentan los siguientes beneficios: ",
        "snippet": "En ciencias de la computación, y análisis numérico, el pseudocódigo[1]​ (o lenguaje de descripción algorítmico) es una descripción de alto nivel compacta e informal[2]​ del principio operativo de un programa informático u otro algoritmo.",
        "enlaces_salientes": [
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Lenguaje",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Algoritmo",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Subrutina",
            "/wiki/Lenguaje_natural",
            "/wiki/Sintaxis",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Compilador",
            "/wiki/Diagrama_de_flujo",
            "/wiki/UML",
            "/wiki/Programador",
            "/wiki/Top-down_y_Bottom-up",
            "/wiki/Estructuras_de_control",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/BASIC",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%2B%2B",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Lisp",
            "/wiki/ALGOL",
            "/wiki/Fortran",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Bucle_while",
            "/wiki/Bloque_de_c%C3%B3digo",
            "/wiki/Bucle_for",
            "/wiki/Lista_enlazada",
            "/wiki/Conjunto",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Argumento_(inform%C3%A1tica)#Paso_de_Argumentos",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/PSeInt",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Resoluci%C3%B3n_de_problemas_de_programaci%C3%B3n",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Estructuras_de_control",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Bucle_for",
            "/wiki/Bucle_do",
            "/wiki/Bucle_while",
            "/wiki/Bucle_repetir",
            "/wiki/Bucle_infinito",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/C%2B%2B",
        "titulo": "C++",
        "contenido": "c++ es un lenguaje de programacion diseñado en 1980 por bjarne stroustrup. la intencion de su creacion fue extender al lenguaje de programacion c y añadir mecanismos que permiten la manipulacion de objetos. en ese sentido, desde el punto de vista de los lenguajes orientados a objetos, c++ es un lenguaje hibrido.  posteriormente se añadieron facilidades de programacion generica, que se sumaron a los paradigmas de programacion estructurada y programacion orientada a objetos. por esto se suele decir que el c++ es un lenguaje de programacion multiparadigma.  actualmente existe un estandar, denominado iso c++, al que se han adherido la mayoria de los fabricantes de compiladores mas modernos. existen tambien algunos interpretes, tales como root.  el nombre \"c++\" fue propuesto por rick mascitti en el año 1983, cuando el lenguaje fue utilizado por primera vez fuera de un laboratorio cientifico. antes se habia usado el nombre \"c con clases\". en c++, la expresion \"c++\" significa \"incremento de c\" y se refiere a que c++ es una extension de c.  a continuacion se cita un programa de ejemplo hola mundo escrito en c++:  al usar la directiva #include se le dice al compilador que busque e interprete todos los elementos definidos en el archivo que acompaña la directiva (en este caso, iostream). para evitar sobrescribir los elementos ya definidos al ponerles igual nombre, se crearon los espacios de nombres o namespace del singular en ingles. en este caso hay un espacio de nombres llamado std, que es donde se incluyen las definiciones de todas las funciones y clases que conforman la biblioteca estandar de c++. al incluir la sentencia using namespace std le estamos diciendo al compilador que usaremos el espacio de nombres std por lo que no tendremos que incluirlo cuando usemos elementos de este espacio de nombres, como pueden ser los objetos cout y cin, que representan el flujo de salida estandar (tipicamente la pantalla o una ventana de texto) y el flujo de entrada estandar (tipicamente el teclado).  la definicion de funciones es igual que en c, salvo por la caracteristica de que si main no va a recoger argumentos, no tenemos por que ponerselos, a diferencia de c, donde habia que ponerlos explicitamente, aunque no se fueran a usar. queda solo comentar que el simbolo << se conoce como operador de insercion, y grosso modo esta enviando a cout lo que queremos mostrar por pantalla para que lo pinte, en este caso la cadena \"hola mundo\". el mismo operador << se puede usar varias veces en la misma sentencia, de forma que gracias a esta caracteristica podremos concatenar el objeto endl al final, cuyo resultado sera imprimir un retorno de linea.  c++ tiene los siguientes tipos fundamentales:  el modificador unsigned se puede aplicar a enteros para obtener numeros sin signo (por omision los enteros contienen signo), con lo que se consigue un rango mayor de numeros naturales.  segun la maquina y el compilador que se utilice los tipos primitivos pueden ocupar un determinado tamaño en memoria. la siguiente lista ilustra el numero de bits que ocupan los distintos tipos primitivos en la arquitectura x86.  otras arquitecturas pueden requerir distintos tamaños de tipos de datos primitivos. c++ no dice nada acerca de cual es el numero de bits en un byte, ni del tamaño de estos tipos; mas bien, ofrece solamente las siguientes \"garantias de tipos\":  para la version del estandar que se publico en 1998, se decidio añadir el tipo de dato wchar_t, que permite el uso de caracteres unicode, a diferencia del tradicional char, que contempla simplemente al codigo de caracteres ascii extendido. a su vez, se ha definido para la mayoria de las funciones y clases, tanto de c como de c++, una version para trabajar con wchar_t, donde usualmente se prefija el caracter w al nombre de la funcion (en ocasiones el caracter es un infijo). por ejemplo:  cabe resaltar que en c se define wchar_t como:  mientras que en c++ es en si mismo un tipo de dato.  la palabra reservada void define en c++ el concepto de no existencia o no atribucion de un tipo en una variable o declaracion. es decir, una funcion declarada como void no devolvera ningun valor. esta palabra reservada tambien puede usarse para indicar que una funcion no recibe parametros, como en la siguiente declaracion:  aunque la tendencia actual es la de no colocar la palabra \"void\".  ademas se utiliza para determinar que una funcion no retorna un valor, como en:  cabe destacar que void no es un tipo. una funcion como la declarada anteriormente no puede retornar un valor por medio de return: la palabra clave va sola. no es posible una declaracion del tipo:  en este sentido, void se comporta de forma ligeramente diferente a como lo hace en c, especialmente en cuanto a su significado en declaraciones y prototipos de funciones.  sin embargo, la forma especial void * indica que el tipo de datos es un puntero. por ejemplo:  indica que memoria es un puntero a alguna parte, donde se guarda informacion de algun tipo. el programador es responsable de definir estos \"algun\", eliminando toda ambiguedad. una ventaja de la declaracion \"void *\" es que puede representar a la vez varios tipos de datos, dependiendo de la operacion de cast escogida. la memoria que hemos apuntado en alguna parte, en el ejemplo anterior, bien podria almacenar un entero, un flotante, una cadena de texto o un programa, o combinaciones de estos. es responsabilidad del programador recordar que tipo de datos hay y garantizar el acceso adecuado.  ademas de los valores que pueden tomar los tipos anteriormente mencionados, existe un valor llamado null, sea el caso numerico para los enteros, caracter para el tipo char, cadena de texto para el tipo string, etc. el valor null, expresa, por lo regular, la representacion de una macro, asignada al valor \"0\".  tenemos entonces que:  el valor de las variables anteriores nos daria 0. a diferencia de la variable \"caracter\", que nos daria el equivalente a null, '\\0', para caracteres.  para evitar ambiguedad en funciones sobrecargadas, puede emplearse la palabra clave nullptr. esta palabra clave siempre representa un puntero. por ejemplo:  todo programa en c++ debe tener la funcion principal main() (a no ser que se especifique en tiempo de compilacion otro punto de entrada, que en realidad es la funcion que tiene el main())  la funcion principal del codigo fuente main debe tener uno de los siguientes prototipos: int main() int main(int argc, char** argv)  aunque no es estandar algunas implementaciones permiten int main(int argc, char** argv, char** env)  la primera es la forma por omision de un programa que no recibe parametros ni argumentos. la segunda forma tiene dos parametros: argc, un numero que describe el numero de argumentos del programa (incluyendo el nombre del programa mismo), y argv, un puntero a un array de punteros, de argc elementos, donde el elemento argv[i] representa el i-esimo argumento entregado al programa. en el tercer caso se añade la posibilidad de poder acceder a las variables de entorno de ejecucion de la misma forma que se accede a los argumentos del programa, pero reflejados sobre la variable env.  el tipo de retorno de main es un valor entero int. al finalizar la funcion main, debe incluirse el valor de retorno (por ejemplo, return 0;, aunque el estandar preve solamente dos posibles valores de retorno: exit_success y exit_failure, definidas en el archivo cstdlib), o salir por medio de la funcion exit. alternativamente puede dejarse en blanco, en cuyo caso el compilador es responsable de agregar la salida adecuada.  los objetos en c++ son abstraidos mediante una clase. segun el paradigma de la programacion orientada a objetos un objeto consta de:  un ejemplo de clase que podemos tomar es la clase perro. cada perro comparte unas caracteristicas (atributos). su numero de patas, el color de su pelaje o su tamaño son algunos de sus atributos. las funciones que lo hagan ladrar, cambiar su comportamiento... esas son las funciones de la clase.  este es otro ejemplo de una clase:  son unos metodos especiales que se ejecutan automaticamente al crear un objeto de la clase. en su declaracion no se especifica el tipo de dato que devuelven, y poseen el mismo nombre que la clase a la que pertenecen. al igual que otros metodos, puede haber varios constructores sobrecargados, aunque no pueden existir constructores virtuales.  como caracteristica especial a la hora de implementar un constructor, justo despues de la declaracion de los parametros, se encuentra lo que se llama \"lista de inicializadores\". su objetivo es llamar a los constructores de los atributos que conforman el objeto a construir.  cabe destacar que no es necesario declarar un constructor al igual que un destructor, pues el compilador lo puede hacer, aunque no es la mejor forma de programar.  tomando el ejemplo de la clase punto, si deseamos que cada vez que se cree un objeto de esta clase las coordenadas del punto sean igual a cero podemos agregar un constructor como se muestra a continuacion:  si compilamos y ejecutamos el anterior programa, obtenemos una salida que debe ser similar a la siguiente:  coordenada x: 0 coordenada y: 0  existen varios tipos de constructores en c++:  constructores + memoria heap un objeto creado de la forma que se vio hasta ahora, es un objeto que vive dentro del scope(las llaves { }) en el que fue creado. para que un objeto pueda seguir viviendo cuando se saque del scope en el que se creo, se lo debe crear en memoria heap. para esto, se utiliza el operador new, el cual asigna memoria para almacenar al objeto creado, y ademas llama a su constructor(por lo que se le pueden enviar parametros). el operador new se utiliza de la siguiente manera:  ademas, con el operador new[] se pueden crear arrays (colecciones o listas ordenadas) de tamaño dinamico:  los destructores son funciones miembro especiales llamadas automaticamente en la ejecucion del programa, y por tanto no tienen por que ser llamadas explicitamente por el programador. sus principales cometidos son:  los destructores son invocados automaticamente al alcanzar el flujo del programa el fin del ambito en el que esta declarado el objeto. el unico caso en el que se debe invocar explicitamente al destructor de un objeto es cuando este fue creado mediante el operador new, es decir, que este vive en memoria heap, y no en la pila de ejecucion del programa. la invocacion del destructor de un objeto que vive en heap se realiza a traves del operador delete o delete[] para arrays. ejemplo:  si no se utilizara el operador delete y delete[] en ese caso, la memoria ocupada por unentero y arraydeenteros respectivamente, quedaria ocupada sin sentido. cuando una porcion de memoria queda ocupada por una variable que ya no se utiliza, y no hay forma de acceder a ella, se denomina un 'memory leak'. en aplicaciones grandes, si ocurren muchos memory leaks, el programa puede terminar ocupando bastante mas memoria ram de la que deberia, lo que no es para nada conveniente. es por esto, que el manejo de memoria heap debe usarse conscientemente.  existen dos tipos de destructores pueden ser publicos o privados, segun si se declaran:  el uso de destructores es clave en el concepto de adquirir recursos es inicializar.  funcion miembro es aquella que esta declarada en ambito de clase. son similares a las funciones habituales, con la salvedad de que el compilador realizara el proceso de decoracion de nombre (name mangling en ingles): cambiara el nombre de la funcion añadiendo un identificador de la clase en la que esta declarada, pudiendo incluir caracteres especiales o identificadores numericos. este proceso es invisible al programador. ademas, las funciones miembro reciben implicitamente un parametro adicional: el puntero this, que referencia al objeto que ejecuta la funcion.  las funciones miembro se invocan accediendo primero al objeto al cual refieren, con la sintaxis: myobject.mymemberfunction(), esto es un claro ejemplo de una funcion miembro.  caso especial es el de las funciones miembro estaticas. a pesar de que son declaradas dentro de la clase, con el uso de la palabra clave static no recibiran el puntero this. gracias a esto no es necesario crear ninguna instancia de la clase para llamar a esta funcion, sin embargo, solo se podra acceder a los miembros estaticos de la clase dado que estos no estan asociados al objeto sino al tipo. la sintaxis para llamar a esta funcion estatica es mytype::mystaticmember().  las plantillas son el mecanismo de c++ para implantar el paradigma de la programacion generica. permiten que una clase o funcion trabaje con tipos de datos abstractos, especificandose mas adelante cuales son los que se quieren usar. por ejemplo, es posible construir un vector generico que pueda contener cualquier tipo de estructura de datos. de esta forma se pueden declarar objetos de la clase de este vector que contengan enteros, flotantes, poligonos, figuras, fichas de personal, etc.  la declaracion de una plantilla se realiza anteponiendo la declaracion template <typename a,....> a la declaracion de la estructura (clase, estructura o funcion) deseado.  por ejemplo:  la funcion max() es un ejemplo de programacion generica, y dados dos parametros de un tipo t (que puede ser int, long, float, double, etc.) devolvera el mayor de ellos (usando el operador >). al ejecutar la funcion con parametros de un cierto tipo, el compilador intentara \"calzar\" la plantilla a ese tipo de datos, o bien generara un mensaje de error si fracasa en ese proceso.  el siguiente ejemplo:  crea una plantilla bajo la cual pueden ser definidas en el codigo de cabecera cualesquiera funciones especializadas para un tipo de datos como int myfunction(int), int myfunction(std::string), int myfunction(bool), etcetera:  cada una de estas funciones tiene su propia definicion (cuerpo). cada cuerpo diferente, no equivalente (\"no convertible\") corresponde a una especializacion. si una de estas funciones no fuera definida, el compilador tratara de aplicar las conversiones de tipos de datos que le fuesen permitidas para \"calzar\" una de las plantillas, o generara un mensaje de error si fracasa en ese proceso.  todas las definiciones habilitadas de una plantilla deben estar disponibles al momento de la compilacion, por lo cual no es posible actualmente \"compilar\" una plantilla como archivo de objeto, sino simplemente compilar especializaciones de la plantilla. por lo tanto, las plantillas se distribuyen junto con el codigo fuente de la aplicacion. en otras palabras, no es posible compilar la plantilla std::vector< > a codigo objeto, pero si es posible, por ejemplo, compilar un tipo de datos std::vector<std::string>.  en c++ es posible definir clases abstractas. una clase abstracta, o clase base abstracta (abc), es una que esta diseñada solo como clase padre de las cuales se deben derivar clases hijas. una clase abstracta se usa para representar aquellas entidades o metodos que despues se implementaran en las clases derivadas, pero la clase abstracta en si no contiene ninguna implementacion -- solamente representa los metodos que se deben implementar. por ello, no es posible instanciar una clase abstracta, pero si una clase concreta que implemente los metodos definidos en ella.  las clases abstractas son utiles para definir interfaces, es decir, un conjunto de metodos que definen el comportamiento de un modulo determinado. estas definiciones pueden utilizarse sin tener en cuenta la implementacion que se hara de ellos.  en c++ los metodos de las clases abstractas se definen como funciones virtuales puras.  en el ejemplo, la clase concretaa es una implementacion de la clase abstracta, y la clase concretab es otra implementacion. debe notarse que el = 0 es la notacion que emplea c++ para definir funciones virtuales puras.  una adicion a las caracteristicas de c son los espacios de nombre (namespace en ingles), los cuales pueden describirse como areas virtuales bajo las cuales ciertos nombres de variable o tipos tienen validez. esto permite evitar las ocurrencias de conflictos entre nombres de funciones, variables o clases.  el ejemplo mas conocido en c++ es el espacio de nombres std::, el cual almacena todas las definiciones nuevas en c++ que difieren de c (algunas estructuras y funciones), asi como las funcionalidades propias de c++ (streams) y los componentes de la biblioteca stl.  por ejemplo:  como puede verse, las invocaciones directas a mi_valor daran acceso solamente a la variable descrita localmente; para acceder a la variable del espacio de nombres mi_paquete es necesario acceder especificamente el espacio de nombres. un atajo recomendado para programas sencillos es la directiva using namespace, que permite acceder a los nombres de variables del paquete deseado en forma directa, siempre y cuando no se produzca alguna ambiguedad o conflicto de nombres.  existen varios tipos de herencia entre clases en el lenguaje de programacion c++. estos son:  la herencia en c++ es un mecanismo de abstraccion creado para poder facilitar y mejorar el diseño de las clases de un programa. con ella se pueden crear nuevas clases a partir de clases ya hechas, siempre y cuando tengan un tipo de relacion especial.  en la herencia, las clases derivadas \"heredan\" los datos y las funciones miembro de las clases base, pudiendo las clases derivadas redefinir estos comportamientos (polimorfismo) y añadir comportamientos nuevos propios de las clases derivadas. para no romper el principio de encapsulamiento (ocultar datos cuyo conocimiento no es necesario para el uso de las clases), se proporciona un nuevo modo de visibilidad de los datos/funciones: \"protected\". cualquier cosa que tenga visibilidad protected se comportara como publica en la clase base y en las que componen la jerarquia de herencia, y como privada en las clases que no sean de la jerarquia de la herencia.  antes de utilizar la herencia, nos tenemos que hacer una pregunta, y si tiene sentido, podemos intentar usar esta jerarquia: si la frase <claseb> es-un <clasea> tiene sentido, entonces estamos ante un posible caso de herencia donde clase a sera la clase base y clase b la derivada.  ejemplo: clases barco, acorazado, carguero, etc. un acorazado es-un barco, un carguero es-un barco, un trasatlantico es-un barco, etc.  en este ejemplo tendriamos las cosas generales de un barco (en c++)  y ahora las caracteristicas de las clases derivadas, podrian (a la vez que heredan las de barco) añadir cosas propias del subtipo de barco que vamos a crear, por ejemplo:  por ultimo, hay que mencionar que existen 3 clases de herencia que se diferencian en el modo de manejar la visibilidad de los componentes de la clase resultante:  la herencia multiple es el mecanismo que permite al programador hacer clases derivadas a partir, no de una sola clase base, sino de varias. para entender esto mejor, pongamos un ejemplo: cuando ves a quien te atiende en una tienda, como persona que es, podras suponer que puede hablar, comer, andar, pero, por otro lado, como empleado que es, tambien podras suponer que tiene un jefe, que puede cobrarte dinero por la compra, que puede devolverte el cambio, etc. si esto lo trasladamos a la programacion seria herencia multiple (clase empleado_tienda):  por tanto, es posible utilizar mas de una clase para que otra herede sus caracteristicas.  la sobrecarga de operadores es una forma de hacer polimorfismo. es posible definir el comportamiento de un operador del lenguaje para que trabaje con tipos de datos definidos por el usuario. no todos los operadores de c++ son factibles de sobrecargar, y, entre aquellos que pueden ser sobrecargados, se deben cumplir condiciones especiales. en particular, los operadores sizeof y :: no son sobrecargables.  no es posible en c++ crear un operador nuevo.  los comportamientos de los operadores sobrecargados se implementan de la misma manera que una funcion, salvo que esta tendra un nombre especial: tipo de dato de devolucion operator<token del operador>(parametros)  los siguientes operadores pueden ser sobrecargados:  dado que estos operadores son definidos para un tipo de datos definido por el usuario, este es libre de asignarles cualquiera semantica que desee. sin embargo, se considera de primera importancia que las semanticas sean tan parecidas al comportamiento natural de los operadores como para que el uso de los operadores sobrecargados sea intuitivo. por ejemplo, el uso del operador unario - debiera cambiar el \"signo\" de un \"valor\".  los operadores sobrecargados no dejan de ser funciones, por lo que pueden devolver un valor, si este valor es del tipo de datos con el que trabaja el operador, permite el encadenamiento de sentencias. por ejemplo, si tenemos 3 variables a, b y c de un tipo t y sobrecargamos el operador = para que trabaje con el tipo de datos t, hay dos opciones: si el operador no devuelve nada una sentencia como \"a=b=c;\" (sin las comillas) daria error, pero si se devuelve un tipo de datos t al implementar el operador, permitiria concatenar cuantos elementos se quisieran, permitiendo algo como \"a=b=c=d=...;\"  los lenguajes de programacion suelen tener una serie de bibliotecas de funciones integradas para la manipulacion de datos a nivel mas basico. en c++, ademas de poder usar las bibliotecas de c, se puede usar la nativa stl (standard template library), propia del lenguaje. proporciona una serie plantillas (templates) que permiten efectuar operaciones sobre el almacenado de datos, procesado de entrada/salida.  las clases basic_ostream y basic_stream, y los objetos cout y cin, proporcionan la entrada y salida estandar de datos (teclado/pantalla). tambien esta disponible cerr, similar a cout, usado para la salida estandar de errores. estas clases tienen sobrecargados los operadores << y >>, respectivamente, con el objeto de ser utiles en la insercion/extraccion de datos a dichos flujos. son operadores inteligentes, ya que son capaces de adaptarse al tipo de datos que reciben, aunque tendremos que definir el comportamiento de dicha entrada/salida para clases/tipos de datos definidos por el usuario. por ejemplo:  de esta forma, para mostrar un punto, solo habria que realizar la siguiente expresion:  es posible formatear la entrada/salida, indicando el numero de digitos decimales a mostrar, si los textos se pasaran a minusculas o mayusculas, si los numeros recibidos estan en formato octal o hexadecimal, etc.  tipo de flujo para el manejo de ficheros. la definicion previa de ostreams/istreams es aplicable a este apartado. existen tres clases (ficheros de lectura, de escritura o de lectura/escritura): ifstream,ofstream y fstream.  como abrir un fichero: (nombre_variable_fichero).open(\"nombre_fichero.dat/txt\", ios::in); para abrirlo en modo lectura. (nombrevariablefichero).open(\"nombre_fichero.dat/txt\", ios::out); para abrirlo en modo escritura.  ejemplo: f.open(\"datos.txt\", ios::in);  como cerrar el fichero: nombre_variable_fichero.close();  ejemplo: f.close();  leer un fichero:  escribir un fichero:  pueden abrirse pasando al constructor los parametros relativos a la ubicacion del fichero y el modo de apertura:  se destacan dos clases, ostringstream e istringstream. todo lo anteriormente dicho es aplicable a estas clases. tratan a una cadena como si de un flujo de datos se tratase. ostringstream permite elaborar una cadena de texto insertando datos cual flujo, e istringstream puede extraer la informacion contenida en una cadena (pasada como parametro en su constructor) con el operador >>. ejemplos:  son clases plantillas especiales utilizadas para almacenar tipos de datos genericos, sean cuales sean. todos los contenedores son homogeneos, es decir, una vez que se declaran para contener un tipo de dato determinado, en ese contenedor, solo se podran meter elementos de ese tipo. segun la naturaleza del almacenado, disponemos de varios tipos:  para añadir elementos al final del vector, se utiliza el metodo push_back(const t&). por otro lado, para eliminar un elemento del final del vector, se debe usar el metodo pop_back().  ademas de los metodos push_back(const t&) y pop_back(), se agregan los metodos push_front(const t&) y pop_front(), que realizan lo mismo que los ya explicados, pero en el comienzo de la cola.  pueden considerarse como una generalizacion de la clase de \"puntero\". un iterador es un tipo de dato que permite el recorrido y la busqueda de elementos en los contenedores. como las estructuras de datos (contenedores) son clases genericas, y los operadores (algoritmos) que deben operar sobre ellas son tambien genericos (funciones genericas), stepanov y sus colaboradores tuvieron que desarrollar el concepto de iterador como elemento o nexo de conexion entre ambos. el nuevo concepto resulta ser una especie de punteros que señalan a los diversos miembros del contenedor (punteros genericos que como tales no existen en el lenguaje).  combinando la utilizacion de templates y un estilo especifico para denotar tipos y variables, la stl ofrece una serie de funciones que representan operaciones comunes, y cuyo objetivo es \"parametrizar\" las operaciones en que estas funciones se ven involucradas de modo que su lectura, comprension y mantenimiento, sean mas faciles de realizar.   un ejemplo es la funcion copy, la cual simplemente copia variables desde un lugar a otro. mas estrictamente, copia los contenidos cuyas ubicaciones estan delimitadas por dos iteradores, al espacio indicado por un tercer iterador. la sintaxis es:   de este modo, todos los datos que estan entre inicio_origen y fin_origen, excluyendo el dato ubicado en este ultimo, son copiados a un lugar descrito o apuntado por inicio_destino.  un algoritmo muy importante que viene implementado en la biblioteca stl, es el sort. el algoritmo sort, ordena cualquier tipo de contenedor, siempre y cuando se le pasen como argumentos, desde donde y hasta donde se quiere ordenarlo.  entre las funciones mas conocidas estan swap (variable1, variable2), que simplemente intercambia los valores de variable1 y variable2; max (variable1, variable2) y su simil min (variable1, variable2), que retornan el maximo o minimo entre dos valores; find (inicio, fin, valor) que busca valor en el espacio de variables entre inicio y fin; etcetera.  los algoritmos son muy variados, algunos incluso tienen versiones especificas para operar con ciertos iteradores o contenedores, y proveen un nivel de abstraccion extra que permite obtener un codigo mas \"limpio\", que \"describe\" lo que se esta haciendo, en vez de hacerlo paso a paso explicitamente.  el 12 de agosto de 2011, herb sutter, presidente del comite de estandares de c++, informo la aprobacion unanime del nuevo estandar.​ la publicacion del mismo se realizo en algun momento del 2011.  entre las caracteristicas del nuevo estandar se pueden destacar:  ademas se ha actualizado la biblioteca estandar del lenguaje.  en 2011 c++11 inauguro una nueva era en la historia de c++, iniciando un ciclo trienal de lanzamiento de nuevas versiones.  a c++11 le siguio c++14 y luego c++17, que es la version actual en 2019; c++20 se encuentra proximo a estandarizarse, y ya se esta trabajando en la version c++23.  los compiladores intentan adelantarse incorporando de manera experimental algunas novedades antes de los lanzamientos oficiales.  pero cada nueva version de c++ incluye tal cantidad de agregados que los compiladores mas adelantados no suelen terminar de incorporarlos hasta dos o tres años despues del lanzamiento de esa version.  en c++, cualquier tipo de datos que sea declarado completo (fully qualified, en ingles) se convierte en un tipo de datos unico. las condiciones para que un tipo de datos t sea declarado completo son a grandes rasgos las siguientes:  en general, esto significa que cualquier tipo de datos definido haciendo uso de las cabeceras completas, es un tipo de datos completo.  en particular, y, a diferencia de lo que ocurria en c, los tipos definidos por medio de struct o enum son tipos completos. como tales, ahora son sujetos a sobrecarga, conversiones implicitas, etcetera.  los tipos enumerados, entonces, ya no son simplemente alias para tipos enteros, sino que son tipos de datos unicos en c++. el tipo de datos bool, igualmente, pasa a ser un tipo de datos unico, mientras que en c funcionaba en algunos casos como un alias para alguna clase de dato de tipo entero.  uno de los compiladores libres de c++ es el de gnu, el compilador g++ (parte del proyecto gcc, que engloba varios compiladores para distintos lenguajes). otros compiladores comunes son intel c++ compiler, el compilador de xcode, el compilador de borland c++, el compilador de codewarrior c++, el compilador g++ de cygwin, el compilador g++ de mingw, el compilador de visual c++, carbide.c++, entre otros.  a pesar de su adopcion generalizada, muchos programadores han criticado el lenguaje c ++, incluyendo linus torvalds,​ richard stallman,​ y ken thompson.​ los problemas incluyen una falta de reflexion o recolector de basura, tiempos de compilacion lentos, perceived feature creep,​ y mensajes de error detallados, particularmente de la metaprogramacion de plantilla.​  para evitar los problemas que existen en c ++, y para aumentar la productividad,​ algunas personas sugieren lenguajes alternativos mas recientes que c ++, como d, go, rust y vala.​ ",
        "snippet": "C++ es un lenguaje de programación diseñado en 1980 por Bjarne Stroustrup. La intención de su creación fue extender al lenguaje de programación C y añadir mecanismos que permiten la manipulación de objetos. En ese sentido, desde el punto de vista de los lenguajes orientados a objetos, C++ es un lenguaje híbrido.",
        "enlaces_salientes": [
            "/wiki/C%2B%2B",
            "/wiki/C%2B%2B",
            "/wiki/C%2B%2B",
            "/wiki/Bjarne_Stroustrup",
            "/wiki/Laboratorios_Bell",
            "/wiki/Extensi%C3%B3n_de_archivo",
            "/wiki/Paradigma_de_programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n_multiparadigma",
            "/wiki/Programaci%C3%B3n_Estructurada",
            "/wiki/Programaci%C3%B3n_imperativa",
            "/wiki/Programaci%C3%B3n_gen%C3%A9rica",
            "/wiki/1983",
            "/wiki/Bjarne_Stroustrup",
            "/wiki/C%2B%2B17",
            "/wiki/C%2B%2B20",
            "/wiki/Sistema_de_tipos",
            "/wiki/C%2B%2B_Builder",
            "/wiki/Clang",
            "/wiki/GNU_Compiler_Collection",
            "/wiki/Intel_C%2B%2B_Compiler",
            "/wiki/Microsoft_Visual_C%2B%2B",
            "/wiki/ISO/IEC_14882",
            "/wiki/ISO/IEC_14882",
            "/wiki/ISO/IEC_14882",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Simula",
            "/wiki/Ada_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/ALGOL_68",
            "/wiki/CLU_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Perl",
            "/wiki/Lua",
            "/wiki/Ada_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/PHP",
            "/wiki/D_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C99",
            "/wiki/C_Sharp",
            "/wiki/Falcon_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Sistema_operativo",
            "/wiki/Multiplataforma",
            "/wiki/Bjarne_Stroustrup",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Bjarne_Stroustrup",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Objeto_(programaci%C3%B3n)",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Programaci%C3%B3n_gen%C3%A9rica",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Hola_mundo",
            "/wiki/Biblioteca_(inform%C3%A1tica)",
            "/wiki/Tipo_de_datos",
            "/wiki/X86",
            "/wiki/C99",
            "/wiki/UNICODE",
            "/wiki/Programador",
            "/wiki/Conversi%C3%B3n_de_tipos",
            "/wiki/Clase_(inform%C3%A1tica)",
            "/wiki/Constructor_(inform%C3%A1tica)",
            "/wiki/Destructor_(inform%C3%A1tica)",
            "/wiki/RAII",
            "/wiki/Programaci%C3%B3n_gen%C3%A9rica",
            "/wiki/Funci%C3%B3n_virtual",
            "/wiki/Standard_Template_Library",
            "/wiki/Herencia_(programaci%C3%B3n_orientada_a_objetos)",
            "/wiki/Herencia_m%C3%BAltiple",
            "/wiki/Polimorfismo_(programaci%C3%B3n_orientada_a_objetos)",
            "/wiki/Standard_Template_Library",
            "/wiki/Lenguaje_de_programaci%C3%B3n_C",
            "/wiki/Plantillas",
            "/wiki/Sistema_octal",
            "/wiki/Sistema_hexadecimal",
            "/wiki/C%2B%2B11",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Biblioteca_est%C3%A1ndar_de_C%2B%2B",
            "/wiki/C%2B%2B14",
            "/wiki/C%2B%2B17",
            "/wiki/Software_libre",
            "/wiki/GNU",
            "/wiki/G%2B%2B",
            "/wiki/GNU_Compiler_Collection",
            "/wiki/Intel_C%2B%2B_Compiler",
            "/wiki/Xcode",
            "/wiki/Borland_C%2B%2B",
            "/wiki/Cygwin",
            "/wiki/MinGW",
            "/wiki/Visual_C%2B%2B",
            "/wiki/Carbide.c%2B%2B",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Visual_Studio_Code",
            "/wiki/Visual_Studio",
            "/wiki/Dev-C%2B%2B",
            "/wiki/Visual_C%2B%2B",
            "/wiki/WxDev-C%2B%2B",
            "/wiki/Watcom#Open_Watcom",
            "/wiki/CodeLite",
            "/wiki/Xcode",
            "/wiki/Visual_Studio_Code",
            "/wiki/CodeLite",
            "/wiki/Geany",
            "/wiki/Turbo_C",
            "/wiki/C%2B%2BBuilder",
            "/wiki/Visual_Studio_Code",
            "/wiki/NetBeans",
            "/wiki/Eclipse_(software)",
            "/wiki/Geany",
            "/wiki/Emacs",
            "/wiki/Watcom#Open_Watcom",
            "/wiki/CodeLite",
            "/wiki/Microsoft_Edge",
            "/wiki/Google_Chrome",
            "/wiki/Bitcoin",
            "/wiki/%CE%9CTorrent",
            "/wiki/BitTorrent_(programa)",
            "/wiki/Haiku_(sistema_operativo)",
            "/wiki/Windows_Phone_8.1",
            "/wiki/Open_Broadcaster_Software",
            "/wiki/Opera_(navegador)",
            "/wiki/CATIA",
            "/wiki/Linus_Torvalds",
            "/wiki/Richard_Stallman",
            "/wiki/Ken_Thompson",
            "/wiki/Reflexi%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Recolector_de_basura",
            "/wiki/D_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Go_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Rust_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Vala_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/A%2B%2B",
            "/wiki/C%2B%2B/CX",
            "/wiki/C%2B%2B11",
            "/wiki/C%2B%2B14",
            "/wiki/C%2B%2B17",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/MIT_Technology_Review",
            "/wiki/Bjarne_Stroustrup",
            "/wiki/Addison_Wesley",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_de_ordenamiento",
        "titulo": "Algoritmo de ordenamiento",
        "contenido": "en computacion y matematicas un algoritmo de ordenamiento es un algoritmo que pone elementos de una lista o un vector en una secuencia dada por una relacion de orden, es decir, el resultado de salida ha de ser una permutacion —o reordenamiento— de la entrada que satisfaga la relacion de orden dada. las relaciones de orden mas usadas son el orden numerico y el orden lexicografico. ordenamientos eficientes son importantes para optimizar el uso de otros algoritmos (como los de busqueda y fusion) que requieren listas ordenadas para una ejecucion rapida. tambien es util para poner datos en forma canonica y para generar resultados legibles por humanos.  desde los comienzos de la computacion, el problema del ordenamiento ha atraido gran cantidad de investigacion, tal vez debido a la complejidad de resolverlo eficientemente a pesar de su planteamiento simple y familiar. por ejemplo, bubblesort fue analizado desde 1956.​ aunque muchos puedan considerarlo un problema resuelto, nuevos y utiles algoritmos de ordenamiento se siguen inventado hasta el dia de hoy (por ejemplo, el ordenamiento de biblioteca se publico por primera vez en el 2004). los algoritmos de ordenamiento son comunes en las clases introductorias a la computacion, donde la abundancia de algoritmos para el problema proporciona una gentil introduccion a la variedad de conceptos nucleo de los algoritmos, como notacion de o mayuscula, algoritmos divide y venceras, estructuras de datos, analisis de los casos peor, mejor, y promedio, y limites inferiores.  los algoritmos de ordenamiento se pueden clasificar en las siguientes maneras:  los algoritmos se distinguen por las siguientes caracteristicas:  los algoritmos de ordenamiento estable mantienen un relativo preorden total. esto significa que un algoritmo es estable solo cuando hay dos registros r y s con la misma clave y con r apareciendo antes que s en la lista original.  cuando elementos iguales (indistinguibles entre si), como numeros enteros, o mas generalmente, cualquier tipo de dato en donde el elemento entero es la clave, la estabilidad no es un problema. de todas formas, se asume que los siguientes pares de numeros estan por ser ordenados por su primer componente:  en este caso, dos resultados diferentes son posibles, uno de los cuales mantiene un orden relativo de registros con claves iguales, y una en la que no:  los algoritmos de ordenamiento inestable pueden cambiar el orden relativo de registros con claves iguales, pero los algoritmos estables nunca lo hacen. los algoritmos inestables pueden ser implementados especialmente para ser estables. una forma de hacerlo es extender artificialmente el cotejamiento de claves, para que las comparaciones entre dos objetos con claves iguales sean decididas usando el orden de las entradas original. recordar este orden entre dos objetos con claves iguales es una solucion poco practica, ya que generalmente acarrea tener almacenamiento adicional.  ordenar segun una clave primaria, secundaria, terciara, etc., puede ser realizado utilizando cualquier metodo de ordenamiento, tomando todas las claves en consideracion (en otras palabras, usando una sola clave compuesta). si un metodo de ordenamiento es estable, es posible ordenar multiples items, cada vez con una clave distinta. en este caso, las claves necesitan estar aplicadas en orden de aumentar la prioridad.  ejemplo: ordenar pares de numeros, usando ambos valores  por otro lado:  un algoritmo de ordenamiento es natural cuando al intentar ordenar elementos en una lista ordenada o casi ordenada mejora su tiempo de ejecucion considerablemente. es decir, se da cuenta de que los elementos estan ordenados y no realiza operaciones innecesarias. el ejemplo mas claro se encuentra en el metodo de ordenamiento burbuja mejorado, que cuando termina con una pasada y determina que no hubo intercambios finaliza el proceso. no asi el algoritmo de seleccion que realiza igualmente todas las pasadas sin importar que los elementos de la lista esten ordenados o no.  algunos algoritmos de ordenamiento agrupados segun estabilidad tomando en cuenta la complejidad computacional. ",
        "snippet": "En computación y matemáticas un algoritmo de ordenamiento es un algoritmo que pone elementos de una lista o un vector en una secuencia dada por una relación de orden, es decir, el resultado de salida ha de ser una permutación —o reordenamiento— de la entrada que satisfaga la relación de orden dada. Las relaciones de orden más usadas son el orden numérico y el orden lexicográfico. Ordenamientos eficientes son importantes para optimizar el uso de otros algoritmos (como los de búsqueda y fusión) que requieren listas ordenadas para una ejecución rápida. También es útil para poner datos en forma canónica y para generar resultados legibles por humanos.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_de_ordenamiento",
            "/wiki/Algoritmo_de_ordenamiento",
            "/wiki/Algoritmo_de_ordenamiento",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Algoritmo",
            "/wiki/Lista_(estructura_de_datos)",
            "/wiki/Vector_(programaci%C3%B3n)",
            "/wiki/Orden_total",
            "/wiki/Permutaci%C3%B3n",
            "/wiki/Orden_lexicogr%C3%A1fico",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Bubblesort",
            "/wiki/Library_sort",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Algoritmo_divide_y_vencer%C3%A1s",
            "/wiki/Estructura_de_datos",
            "/wiki/Casos_peor,_mejor,_y_promedio",
            "/wiki/Memoria_de_ordenador",
            "/wiki/Ordenador",
            "/wiki/Ordenamiento_externo",
            "/wiki/Disco_duro",
            "/wiki/Algoritmo_de_ordenaci%C3%B3n_natural",
            "/wiki/Algoritmo_de_ordenaci%C3%B3n_no_natural",
            "/wiki/Complejidad_computacional",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Preorden_total",
            "/wiki/Complejidad_computacional",
            "/wiki/Ordenamiento_de_burbuja",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_de_burbuja_bidireccional",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_por_inserci%C3%B3n",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_por_casilleros",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_por_cuentas",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_por_mezcla",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_con_%C3%A1rbol_binario",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_Radix",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Gnome_sort",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_Shell",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Comb_sort",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_por_selecci%C3%B3n",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_por_mont%C3%ADculos",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_r%C3%A1pido",
            "/wiki/Quicksort",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Bogosort",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Ordenamiento_de_panqueques",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/M%C3%A1quina_de_Von_Neumann",
            "/wiki/Algoritmo_Fisher-Yates",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_de_b%C3%BAsqueda",
        "titulo": "Algoritmo de búsqueda",
        "contenido": "un algoritmo de busqueda es un conjunto de instrucciones que estan diseñadas para localizar un elemento con ciertas propiedades dentro de una estructura de datos; por ejemplo, ubicar el registro correspondiente a cierta persona en una base de datos, o el mejor movimiento en una partida de ajedrez.  la variante mas simple del problema es la busqueda de un numero en un vector.  un problema tipico de la inteligencia artificial consiste en buscar un estado concreto entre un conjunto determinado, al que se le llama espacio de estados. imaginemos, por ejemplo, una habitacion con baldosines en la que hay un libro. un robot se desea desplazar por la habitacion con el fin de llegar a dicho libro. ¿de que manera lo hara? en este punto es donde entran en juego las estrategias y los algoritmos de busqueda.  cuando el sistema agente (en este caso, el robot) posee algun tipo de informacion del medio, se utilizan tecnicas de busquedas informadas; sin embargo, si carece de conocimiento alguno, se deberan emplear algoritmos de busqueda no informadas. en nuestro ejemplo, y para este ultimo caso, podemos imaginar un robot que no posea ningun tipo de vision artificial, que unicamente sea capaz de moverse en horizontal o vertical de un baldosin a otro y detectar si en el baldosin se halla el libro.  de esta forma, los algoritmos de busqueda pueden ser:  consiste en ir comparando el elemento a buscar con cada elemento del vector hasta encontrarlo o hasta que se llegue al final, esto hace que la busqueda sea secuencialmente (de ahi su nombre). la existencia se puede asegurar cuando el elemento es localizado, pero no podemos asegurar la no existencia hasta no haber analizado todos los elementos del vector. se utiliza sin importar si el vector esta previamente ordenado o no. a continuacion se muestra el pseudocodigo del algoritmo:​  se utiliza cuando el vector en el que queremos determinar la existencia de un elemento esta previamente ordenado. este algoritmo reduce el tiempo de busqueda considerablemente, ya que disminuye exponencialmente el numero de iteraciones necesarias. en el peor de los casos el numero maximo de comparaciones es ⌊ log 2 ⁡ n + 1 ⌋ n+1\\rfloor } , donde n es el numero de los elementos en el vector. por ejemplo, en uno conteniendo 50.000.000 elementos, el algoritmo realiza como maximo 26 comparaciones.  para implementar este algoritmo se compara el elemento a buscar con un elemento cualquiera del vector (normalmente el elemento central): si el valor de este es mayor que el del elemento buscado se repite el procedimiento en la parte del vector que va desde el inicio de este hasta el elemento tomado, en caso contrario se toma la parte del vector que va desde el elemento tomado hasta el final. de esta manera obtenemos intervalos cada vez mas pequeños, hasta que se obtenga un intervalo indivisible. si el elemento no se encuentra dentro de este ultimo entonces se deduce que el elemento buscado no se encuentra en todo el vector.  a continuacion se presenta el pseudocodigo del algoritmo, tomando como elemento inicial el elemento central del vector. ",
        "snippet": "Un algoritmo de búsqueda es un conjunto de instrucciones que están diseñadas para localizar un elemento con ciertas propiedades dentro de una estructura de datos; por ejemplo, ubicar el registro correspondiente a cierta persona en una base de datos, o el mejor movimiento en una partida de ajedrez.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/B%C3%BAsqueda",
            "/wiki/Algoritmo",
            "/wiki/Estructura_de_datos",
            "/wiki/Base_de_datos",
            "/wiki/Ajedrez",
            "/wiki/Vector_(programaci%C3%B3n)",
            "/wiki/Inteligencia_Artificial",
            "/wiki/Robot",
            "/wiki/B%C3%BAsquedas_no_informadas",
            "/wiki/Algoritmo_voraz",
            "/wiki/Algoritmo_de_b%C3%BAsqueda_A*",
            "/wiki/Algoritmo_hill_climbing",
            "/wiki/Minimax",
            "/wiki/Poda_alfa-beta",
            "/wiki/Orden_total",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Crecimiento_exponencial",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%2B%2B",
            "/wiki/Python",
            "/wiki/Python",
            "/wiki/Python",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_voraz",
        "titulo": "Algoritmo voraz",
        "contenido": "en ciencias de la computacion, un algoritmo voraz (tambien conocido como goloso, avido, devorador o greedy) es  una estrategia de busqueda por la cual se sigue una heuristica consistente en elegir la opcion optima en cada paso local con la esperanza de llegar a una solucion general optima. este esquema algoritmico es el que menos dificultades plantea a la hora de diseñar y comprobar su funcionamiento. normalmente se aplica a los problemas de optimizacion.  dado un conjunto finito de entradas c , un algoritmo voraz devuelve un conjunto s (seleccionados) tal que s ⊆ c y que ademas cumple con las restricciones del problema inicial. a cada conjunto s que satisfaga las restricciones se le suele denominar prometedor, y si este ademas logra que la funcion objetivo se minimice o maximice (segun corresponda) diremos que s es una solucion optima.  se utilizan generalmente para resolver problemas de optimizacion (obtener el maximo o el minimo). toman decisiones en funcion de la informacion que esta disponible en cada momento. una vez tomada la decision, esta no vuelve a replantearse en el futuro. suelen ser rapidos y faciles de implementar. no siempre garantizan alcanzar la solucion optima.  el enfoque “greedy” no nos garantiza obtener soluciones optimas. por lo tanto, siempre habra que estudiar la correccion del algoritmo para demostrar si las soluciones obtenidas son optimas o no.  el algoritmo escoge en cada paso al mejor elemento x ∈ c posible, conocido como el elemento mas prometedor. se elimina ese elemento del conjunto de candidatos ( c ← c ∖ { x } } ) y, acto seguido, comprueba si la inclusion de este elemento en el conjunto de elementos seleccionados ( s ∪ { x } } ) produce una solucion factible.  en caso de que asi sea, se incluye ese elemento en s . si la inclusion no fuera factible, se descarta el elemento. iteramos el bucle, comprobando si el conjunto de seleccionados es una solucion y, si no es asi, pasando al siguiente elemento del conjunto de candidatos.  greedy (conjunto de candidatos c): solucion s  s = ø  while (s no sea una solucion y c = ø) {  x = seleccion(c)  c = c – {x}  if (s∪{x} es factible)  s = s∪{x}  }  if (s es una solucion)  return s;  else  return “no se encontro una solucion”;  hay situaciones en las cuales no podemos encontrar un algoritmo greedy que proporcione una solucion optima…  en muchas ocasiones, se podrian obtener mejores soluciones reconsiderando alternativas desechadas por un algoritmo greedy (cuando, a partir de una solucion optima local no se puede alcanzar una solucion optima global).  pese a ello, resultan utiles los algoritmos greedy que proporcionan una solucion rapida a problemas complejos, aunque esta no sea optima.  en ingles: ",
        "snippet": "En ciencias de la computación, un algoritmo voraz (también conocido como goloso, ávido, devorador o greedy) es una estrategia de búsqueda por la cual se sigue una heurística consistente en elegir la opción óptima en cada paso local con la esperanza de llegar a una solución general óptima. Este esquema algorítmico es el que menos dificultades plantea a la hora de diseñar y comprobar su funcionamiento. Normalmente se aplica a los problemas de optimización.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_voraz",
            "/wiki/Algoritmo_voraz",
            "/wiki/Algoritmo_voraz",
            "/wiki/Problema_de_cambio_de_monedas",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica",
            "/wiki/Programaci%C3%B3n_lineal",
            "/wiki/Euro",
            "/wiki/D%C3%B3lar_estadounidense",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Heur%C3%ADstica",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Algoritmo_de_Kruskal",
            "/wiki/Algoritmo_de_Prim",
            "/wiki/Algoritmo_de_Dijkstra",
            "/wiki/Algoritmo_de_triangulaci%C3%B3n_voraz",
            "/wiki/Algoritmo",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmos_paralelos",
        "titulo": "Algoritmo paralelo",
        "contenido": "en las ciencias de la computacion, un algoritmo paralelo, en oposicion a los algoritmos clasicos o algoritmos secuenciales, es un algoritmo que puede ser ejecutado por partes en el mismo instante de tiempo por varias unidades de procesamiento, para finalmente unir todas las partes y obtener el resultado correcto.  algunos algoritmos son facilmente divisibles en partes; como por ejemplo, un algoritmo que calcule todos los numeros primos entre 1 y 100, donde se podria dividir los numeros originales en subconjuntos y calcular los primos para cada uno de los subconjuntos de los numeros originales; al final, uniriamos todos los resultados y tendriamos la solucion final del algoritmo. otro ejemplo, puede ser el calculo de pi en paralelo.  por el contrario, a veces los problemas no son tan facilmente paralelizables, de ahi que estos problemas se conozcan como problemas inherentemente secuenciales. como ejemplo de estos metodos tendriamos los metodos numericos iterativos como el metodo de newton o el problema de los tres cuerpos. por otro lado, algunos problemas son dificilmente paralelizables, aunque tengan una estructura recursiva. como ejemplo de esto ultimo tendriamos la busqueda primero en profundidad en un grafo.  los algoritmos paralelos son importantes porque es mas rapido tratar grandes tareas de computacion mediante la paralelizacion que mediante tecnicas secuenciales. esta es la forma en que se trabaja en el desarrollo de los procesadores modernos, ya que es mas dificil incrementar la capacidad de procesamiento con un unico procesador que aumentar su capacidad de computo mediante la inclusion de unidades en paralelo, logrando asi la ejecucion de varios flujos de instrucciones dentro del procesador. pero hay que ser cauto con la excesiva paralelizacion de los algoritmos ya que cada algoritmo paralelo tiene una parte secuencial y debido a esto, los algoritmos paralelos puedes llegar a un punto de saturacion (ver ley de amdahl). por todo esto, a partir de cierto nivel de paralelismo, añadir mas unidades de procesamiento puede solo incrementar el coste y la disipacion de calor.  el coste o complejidad de los algoritmos secuenciales se estima en terminos del espacio (memoria) y tiempo (ciclos de procesador) que requiera. los algoritmos paralelos tambien necesitan optimizar la comunicacion entre diferentes unidades de procesamiento. esto se consigue mediante la aplicacion de dos paradigmas de programacion y diseño de procesadores distintos: memoria compartida o paso de mensajes.  la tecnica memoria compartida necesita del uso de cerrojos en los datos para impedir que se modifique simultaneamente por dos procesadores, por lo que se produce un coste extra en ciclos de cpu desperdiciados y ciclos de bus. tambien obliga a serializar alguna parte del algoritmo.  la tecnica paso de mensajes usa canales y mensajes pero esta comunicacion añade un coste al bus, memoria adicional para las colas y los mensajes y latencia en el mensaje. los diseñadores de procesadores paralelos usan buses especiales para que el coste de la comunicacion sea pequeño pero siendo el algoritmo paralelo el que decide el volumen del trafico.  finalmente, una subclase de los algoritmos paralelos, los algoritmos distribuidos son algoritmos diseñados para trabajar en entornos tipo clusters y de computacion distribuida, donde se usan otras tecnicas, fuera del alcance de los algoritmos paralelos clasicos.  evaluacion de tecnicas de deteccion de errores en programas concurrentes, frati, fernando emmanuel. 1 de abril de 2014, 51 paginas. ",
        "snippet": "En las ciencias de la computación, un algoritmo paralelo, en oposición a los algoritmos clásicos o algoritmos secuenciales, es un algoritmo que puede ser ejecutado por partes en el mismo instante de tiempo por varias unidades de procesamiento, para finalmente unir todas las partes y obtener el resultado correcto.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_paralelo",
            "/wiki/Algoritmo_paralelo",
            "/wiki/Algoritmo_paralelo",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/M%C3%A9todos_num%C3%A9ricos",
            "/wiki/M%C3%A9todo_de_Newton",
            "/wiki/Problema_de_los_tres_cuerpos",
            "/wiki/Algoritmo_recursivo",
            "/wiki/Ley_de_Amdahl",
            "/wiki/Memoria_compartida",
            "/wiki/Interfaz_de_Paso_de_Mensajes",
            "/wiki/Memoria_compartida",
            "/wiki/Interfaz_de_Paso_de_Mensajes",
            "/wiki/Cluster_(inform%C3%A1tica)",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Programaci%C3%B3n_paralela",
            "/wiki/Programaci%C3%B3n_concurrente",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_probabil%C3%ADstico",
        "titulo": "Algoritmo probabilista",
        "contenido": "un algoritmo probabilista (o probabilistico) es un algoritmo que basa su resultado en la toma de algunas decisiones al azar, de tal forma que, en promedio, obtiene una buena solucion al problema planteado para cualquier distribucion de los datos de entrada. es decir, al contrario que un algoritmo determinista, a partir de unos mismos datos se pueden obtener distintas soluciones y, en algunos casos, soluciones erroneas.  existen varios tipos de algoritmos probabilisticos dependiendo de su funcionamiento, pudiendose distinguir:  se puede optar por la eleccion aleatoria si se tiene un problema cuya eleccion optima es demasiado costosa frente a la decision aleatoria. un algoritmo probabilista puede comportarse de distinta forma aplicando la misma entrada.  la solucion obtenida es siempre aproximada pero su precision esperada mejora aumentando el tiempo de ejecucion. normalmente, el error es inversamente proporcional a la raiz cuadrada del esfuerzo invertido en el calculo.   en el siglo xviii, georges louis leclerc, conde de buffon enuncio el teorema de buffon  si se tira una aguja de longitud μ a un suelo hecho con tiras de madera de anchura w (w≥μ), la probabilidad de que la aguja toque mas de una tira de madera es p=2μ/wπ.  aplicacion:  una aplicacion  del teorema de buffon es utilizarlo para predecir el valor de π. sea μ=w/2, entonces p=1/π. si se tira la aguja un numero de veces n suficientemente grande y se cuenta el numero k de veces que la aguja toca mas de una tira de madera, se puede estimar el valor de p: k ~ n/p → p ~ n/k.  en la practica, no es un algoritmo util, porque se pueden obtener aproximaciones de π mucho mejores empleando metodos deterministas. a pesar de esto, esta aproximacion fue muy utilizada en el siglo xix, haciendo de este uno de los primeros algoritmos probabilistas que se utilizaron.  el algoritmo probabilista numerico mas conocido es la integracion de monte carlo. cabe destacar que a pesar de su nombre, no es un algoritmo probabilista de monte carlo.  el algoritmo de monte carlo puede ser representado por el siguiente pseudocodigo, en donde se integra la funcion f entre a y b utilizando n iteraciones.  la varianza de la estimacion calculada mediante este algoritmo es inversamente proporcional al numero de puntos de la muestra. el error esperado en la estimacion es inversamente proporcional a la raiz cuadrada de n, de forma que se requieren 100 iteraciones mas para obtener un digito adicional de precision.  en general, se pueden obtener estimaciones de integrales mediante metodos deterministas con mayor precision y con menos iteraciones. sin embargo, a todo algoritmo determinista de integracion, incluso a los mas complejos, le corresponden funciones continuas diseñadas expresamente para engañar al algoritmo. esto no ocurre con el metodo de monte carlo, aunque existe una probabilidad pequeña de que el algoritmo pudiera cometer un error similar aun cuando integre una funcion completamente comun.  la aplicacion de la integracion de monte carlo tiene mas sentido cuando se tiene que evaluar una integral multiple, ya que la dimension de la integral suele tener poco efecto sobre la precision obtenida, aunque la cantidad de trabajo aumente con la dimension. en la practica, se utiliza para evaluar integrales de dimensiones mayores que tres ya que no hay otra tecnica que sea competitiva. se puede mejorar la precision de las respuestas empleando tecnicas hibridas.  hay problemas para los que no se conoce ningun algoritmo eficiente (determinista o probabilista) que de siempre una solucion correcta en todas las ocasiones. los algoritmos de monte carlo cometen ocasionalmente un error, pero encuentran la solucion correcta con una probabilidad alta sea cual sea el caso considerado. al contrario de los algoritmos de las vegas, no suele darse ningun aviso cuando el algoritmo comete un error. una caracteristica importante es que suele ser posible reducir arbitrariamente la probabilidad de error a costa de un aumento del tiempo de calculo.  definicion: sea p un numero real tal que 0.5<p<1.un algoritmo de montecarlo es p–correcto si:  un ejemplo de algoritmo de montecarlo (el mas conocido) es decidir si un numero impar es primo o compuesto.  la historia de la comprobacion probabilista de primalidad tiene sus raices en pierre fermat, quien postulo en 1640 el pequeño teorema de fermat  ejemplo: n = 7, a = 5 → 56 mod 7 = 1.  el algoritmo se basa en el enunciado del contrarreciproco del mismo teorema  fermat formulo la hipotesis: fn = 2(2n)+ 1 es primo para todo n y lo comprobo para: f0=3, f1=5, f2=17, f3=257, f4=65537. lamentablemente, no pudo comprobar f5 ya que era un numero demasiado grande. tuvo que pasar casi un siglo para que euler demostrara que no es primo.    utilizacion del pequeño teorema de fermat para comprobar la primalidad: en el caso de f5, a fermat le hubiera bastado con ver que existe un a tal que 1≤a≤f5-1 tal que a(f5 - 1) mod f5 <> 1) (a=3). con estas premisas, se puede desarrollar el siguiente algoritmo:    sabemos que n es compuesto cuando la funcion devuelve el valor falso, por el teorema de fermat. cabe destacar que cuando el algoritmo establece que el numero es compuesto, no ofrece informacion de sus divisores. en cambio, cuando el algoritmo devuelve el valor verdadero no podemos afirmar que n sea primo. necesitariamos el reciproco y el contrapositivo del teorema de fermat.  un algoritmo de las vegas nunca da una solucion falsa.  hay dos tipos de algoritmos de las vegas, segun la posibilidad de no encontrar una solucion:  tipo a: algoritmos de sherwood  existe una solucion determinista que es mucho mas rapida en media que en el peor caso.  ejemplo: quicksort.  coste peor o(n²) y coste promedio ω(n log(n)).  los algoritmos de sherwood pueden reducir o eliminar la diferencia de eficiencia para distintos datos de entrada:  tipo b: algoritmos que, a veces, no dan respuesta.  consideraciones sobre el coste:  ahora repetimos el algoritmo anterior para ganar en eficacia:  ejemplo: el problema de todos los . en el tablero de go. ",
        "snippet": "Un algoritmo probabilista (o probabilístico) es un algoritmo que basa su resultado en la toma de algunas decisiones al azar, de tal forma que, en promedio, obtiene una buena solución al problema planteado para cualquier distribución de los datos de entrada. Es decir, al contrario que un algoritmo determinista, a partir de unos mismos datos se pueden obtener distintas soluciones y, en algunos casos, soluciones erróneas.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_probabilista",
            "/wiki/Algoritmo_probabilista",
            "/wiki/Algoritmo_probabilista",
            "/wiki/Algoritmo_determinista",
            "/wiki/Bucle_infinito",
            "/wiki/Tiempo_de_ejecuci%C3%B3n",
            "/wiki/Aguja_de_Buffon",
            "/wiki/Georges-Louis_Leclerc_de_Buffon",
            "/wiki/Integraci%C3%B3n_de_Montecarlo",
            "/wiki/Integraci%C3%B3n_de_Monte_Carlo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Varianza",
            "/wiki/Funci%C3%B3n_continua",
            "/wiki/Integral_m%C3%BAltiple",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Test_de_primalidad",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/RSA",
            "/wiki/Pierre_Fermat",
            "/wiki/Peque%C3%B1o_teorema_de_Fermat",
            "/wiki/Contrarrec%C3%ADproco",
            "/wiki/Euler",
            "/wiki/Peque%C3%B1o_teorema_de_Fermat",
            "/wiki/Algoritmo_de_Las_Vegas",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_determin%C3%ADstico",
        "titulo": "Algoritmo determinista",
        "contenido": "en ciencias de la computacion, un algoritmo determinista es un algoritmo que, en terminos informales, es completamente predictivo si se conocen sus entradas. dicho de otra forma, si se conocen las entradas del algoritmo siempre producira la misma salida, y la maquina interna pasara por la misma secuencia de estados. este tipo de algoritmos ha sido el mas estudiado durante la historia y por lo tanto resulta ser el tipo mas familiar de los algoritmos, asi como el mas practico ya que puede ejecutarse en las maquinas eficientemente.  un modelo simple de algoritmo determinista es la funcion matematica, pues esta extrae siempre la misma salida para una entrada dada. no obstante un algoritmo describe explicitamente como la salida se obtiene de la entrada, mientras que las funciones definen implicitamente su salida.  formalmente los algoritmos deterministas se pueden definir en terminos de una maquina de estado; un «estado» describe que esta haciendo la maquina en un instante particular de tiempo. justo cuando se produce la entrada, la maquina comienza en su «estado inicial» y, posteriormente, si la maquina es determinista, comenzara la ejecucion de la secuencia de estados predeterminados. una maquina puede ser determinista y no tener limite temporal para la ejecucion o quedarse en un bucle de estados ciclicos eternamente.  ejemplos de maquinas abstractas deterministas son las maquinas de turing deterministas y los automatas finitos deterministas.  por diversos motivos un algoritmo determinista puede comportarse de una forma no determinista:  aunque los programas reales rara vez son puramente deterministas, es conveniente considerar que si lo son ya que es mas facil razonar sobre estos. por este motivo, la mayoria de los lenguajes de programacion y especialmente aquellos que entran dentro de la categoria de la programacion funcional son lenguajes que hacen un esfuerzo en prevenir eventos que se ejecuten sin control. este tipo de restricciones fuerzan el caracter determinista y por ello a los algoritmos deterministas se les suele denominar puramente funcionales.  la prevalencia de los procesadores de varios nucleos ha levantado el interes por el determinismo en la programacion en paralelo y se han documentado bien los problemas del no determinismo.​​ numerosas herramientas utiles en estos problemas se han propuesto para tratar con los bloqueos mutuos y las condiciones de carrera.​​​​​  para algunos problemas es muy dificil implementar un algoritmo determinista. por ejemplo, existen eficientes y simples algoritmos probabilistas que pueden determinar si un numero entero es primo o no, pero tienen una pequeña posibilidad de equivocarse. algunos de ellos son muy conocidos desde los 1970 (vease, por ejemplo, el test de primalidad de fermat); sin embargo tuvieron que pasar 30 años para que se desarrollara un algoritmo determinista similar que fuera asintoticamente igual de rapido (vease aks).​  otro ejemplo puede encontrarse en los problemas np-completos. dentro de esta categoria puede encontrarse la mayoria de los problemas practicos; este tipo de problemas puede resolverse rapidamente empleando de forma masiva y paralela una maquina de turing no determinista, pero no se ha encontrado aun un algoritmo eficiente para esta tarea, tan solo soluciones aproximadas para casos especiales.  otro problema sobre el planteamiento de algoritmos deterministas es que a veces no es «deseable» que los resultados sean completamente predecibles. por ejemplo, en un juego on-line de blackjack que utiliza un generador pseudoaleatorio de numeros para barajar las cartas, un jugador astuto podria determinar con exactitud los numeros que el generador fuera a elegir y por consiguiente averiguar el contenido del mazo antes de tiempo. problemas similares pueden encontrarse en criptografia, donde las claves privadas a menudo se crean mediante uno de estos generadores. este tipo de problemas se evita mediante el empleo de un generador de numeros pseudo-aleatorios criptograficamente seguro. ",
        "snippet": "En ciencias de la computación, un algoritmo determinista es un algoritmo que, en términos informales, es completamente predictivo si se conocen sus entradas. Dicho de otra forma, si se conocen las entradas del algoritmo siempre producirá la misma salida, y la máquina interna pasará por la misma secuencia de estados. Este tipo de algoritmos ha sido el más estudiado durante la historia y por lo tanto resulta ser el tipo más familiar de los algoritmos, así como el más práctico ya que puede ejecutarse en las máquinas eficientemente.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_determinista",
            "/wiki/Algoritmo_determinista",
            "/wiki/Algoritmo_determinista",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Algoritmo",
            "/wiki/Entrada",
            "/wiki/Salida_(inform%C3%A1tica)",
            "/wiki/Funci%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/M%C3%A1quina_de_estados",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/M%C3%A1quina_de_Turing_determinista",
            "/wiki/Aut%C3%B3mata_finito_determinista",
            "/wiki/Hardware",
            "/wiki/Software",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/Bloqueo_mutuo",
            "/wiki/Condici%C3%B3n_de_carrera",
            "/wiki/Algoritmos_probabilistas",
            "/wiki/N%C3%BAmeros_primo",
            "/wiki/A%C3%B1os_1970",
            "/wiki/Test_de_primalidad_de_Fermat",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/AKS",
            "/wiki/NP-completo",
            "/wiki/Blackjack",
            "/wiki/Generador_pseudoaleatorio_de_n%C3%BAmeros",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Clave_privada",
            "/wiki/Generador_de_n%C3%BAmeros_pseudo-aleatorios_criptogr%C3%A1ficamente_seguro",
            "/wiki/Algoritmo_no_determinista",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Algoritmo_no_determin%C3%ADstico",
        "titulo": "Algoritmo no determinista",
        "contenido": "en ciencias de la computacion, un algoritmo no determinista es un algoritmo que con la misma entrada ofrece muchos posibles resultados, y por tanto no ofrece una solucion unica. no se puede saber de antemano cual sera el resultado de la ejecucion de un algoritmo no determinista.  en la teoria estandar de la computacion la definicion de algoritmo deja en claro que de por si un algoritmo es determinista.  sin embargo, los algoritmos no deterministas emplean modelos de computacion tales como la maquina de turing probabilistica, que no son deterministas. se considera entonces que los algoritmos no deterministas son un caso especial.  una forma de simular algoritmos no deterministas n mediante el empleo de otros deterministas d puede realizarse tratando los estados de n como estados de d. esto significa que d puede trazar todas las posibilidades y trayectorias de ejecucion del algoritmo n.  otra posibilidad es emplear algoritmos de generacion de numeros aleatorios que consisten en perturbar los estados mediante el establecimiento de todas las posibilidades mediante un generador de numeros aleatorios. el resultado es un algoritmo determinista probabilistico.  el algunas ocasiones, el hecho anterior puede producirse en el sentido inverso de manera que el comportamiento de un algoritmo varie pase a encontrarse en un lugar diferente  en este caso, deben existir una serie de factores que permitan que dicho algoritmo llegue a convertirse en uno no determinista. a continuacion se expondran las causas mas importantes: ",
        "snippet": "En ciencias de la computación, un algoritmo no determinista es un algoritmo que con la misma entrada ofrece muchos posibles resultados, y por tanto no ofrece una solución única. No se puede saber de antemano cuál será el resultado de la ejecución de un algoritmo no determinista.",
        "enlaces_salientes": [
            "/wiki/Algoritmo_no_determinista",
            "/wiki/Algoritmo_no_determinista",
            "/wiki/Algoritmo_no_determinista",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Algoritmo",
            "/wiki/Algoritmo_determinista",
            "/wiki/M%C3%A1quina_de_Turing_probabil%C3%ADstica",
            "/wiki/Algoritmos_probabil%C3%ADsticos",
            "/wiki/Generador_de_n%C3%BAmeros_aleatorios",
            "/wiki/Probabilidad",
            "/wiki/Algoritmo_determinista",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Divide_y_vencer%C3%A1s",
        "titulo": "Divide y vencerás",
        "contenido": "en politica y psicologia, divide y venceras o dividir para reinar (del griego: δαρε κα βασλευε, diairei kai basileue) es ganar y mantener el poder mediante la ruptura de las concentraciones mas grandes, en fracciones que tienen menos energia en su aislada individualidad. el concepto se refiere a una estrategia que rompe las estructuras de poder existentes y evita la vinculacion de los grupos de poder mas pequeños. podria ser utilizada en todos los ambitos en los que, para obtener un mejor resultado, es en primer lugar necesario o ventajoso romper o dividir lo que se opone a la solucion o a un determinado problema inicial.  posteriormente las maximas latinas divide et impera (pronunciado: divide et impera, «divide y domina»), y sus variantes: divide et vinces, divide ut imperes y divide ut regnes,​ fueron utilizados por el gobernante romano julio cesar y el emperador de francia, napoleon.​​​  en politica y sociologia, se utiliza para definir una estrategia orientada a mantener bajo control un territorio y/o una poblacion, dividiendo y fragmentando el poder de las distintas facciones o grupos alli existentes, de tal manera que no puedan reunirse en pos de un objetivo comun. de hecho, esta estrategia ayuda a prevenir la formacion de una serie de entidades tal vez mas pequeñas y a la vez con menos contradicciones internas, cada una titular de una fraccion de poder, y con posibilidades de eventualmente unirse entre si, formando un solo centro de autoridad, o sea, una nueva y unica entidad mas relevante y peligrosa. y precisamente, para evitar uniones y entendimientos, el poder central tiende a dividir y a crear disensiones y desconfianzas entre las distintas facciones, a fin de disminuir las posibilidades de uniones y entendimiento en contra de si misma.​  en resumidas cuentas, la tecnica permite a un poder central, que puede ser un gobierno despotico, o una gobernacion colonial-imperialista, compuesta por un numero relativamente pequeño, gobernar y dominar a una poblacion mucho mas numerosa, y de una forma relativamente simple.​​  la caracteristica tipica de esta tecnica, consiste pues en crear o alimentar disputas y controversias entre las facciones originales. al proceder de esta manera, se contribuye al debilitamiento y posterior deterioro de las relaciones entre las facciones o tribus dominadas, haciendo imposible o dificultando las alianzas o coaliciones entre ellas, lo que si se llegara a concretar podria cuestionar el orden establecido.​  otra caracteristica que puede ser utilizada, es la de eventualmente promover la cooperacion financiera no reembolsable, y asimismo apoyar cualquier asunto o tendencia que sea fiel a esta regla, pues una forma de quitar autonomia es creando dependencia. esta forma de accion conviene aplicarla solo si se disponen de capacidades politicas y conocimientos relevantes en areas especificas: ciencia politica, historia politica, psicologia, etc.  que la tecnica \"divide y venceras\" es aplicable proporcionando resultados satisfactorios, esta bien documentado por la historia, particularmente en el caso de sociedades fragmentadas y con pocas tradiciones comunes, frente al poder de un gran imperio.​  en el tiempo de los romanos, era esta la manera de dirigir el territorio italiano, y de evitar disturbios y revueltas por parte de los pueblos italicos.  en el año 338 a. c. roma derroto a su mayor enemigo de la epoca, la liga latina, una confederacion de unas 30 aldeas y tribus aliadas para bloquear la expansion romana. no obstante, tras la victoria, los romanos se enfrentaban a un nuevo problema, relativo a como gobernar la region evitando que el vacio de poder dejado por la caida de la liga, allanase el camino a otro enemigo aun mayor.  la solucion que adoptaron fue la que mas tarde se denominaria divide et impera, lo que se convirtio en el fundamento estrategico sobre el cual se forjaria el imperio.  en lugar de tratar de engullir y controlar todas las ciudades, lo cual hubiera diluido el poder en una zona demasiado grande, crearon un sistema mediante el cual algunas ciudades se incorporaron a la republica y sus habitantes adquirieron los privilegios que otorgaba la ciudadania romana, mientras que otras ciudades obtuvieron la independencia total pero se las privo de gran parte de su territorio, y mientras que otras fueron divididas y colonizadas. ademas, si alguna ciudad independiente se mostraba lo bastante leal y presta a luchar en favor de roma, entonces podia ganar el derecho a convertirse en parte de la republica romana.  la idea era que roma ocupase una posicion central y las ciudades tuviesen que competir por ganarse el favor romano.  un ejemplo moderno de este tipo de politica, se puede constatar en el imperio colonial britanico, y mas precisamente en la llamada india britanica, donde los britanicos usaron marginalmente sus ejercitos, y contextual y simultaneamente alimentaban disidencias entre las tribus, consolidando asi su dominio colonial.  en concreto, los ingleses mantuvieron las fronteras regionales entre los distintos grupos etnicos de la india, para preservar la diversidad cultural y linguistica, asi como las fricciones y reclamaciones territoriales de un grupo etnico sobre otro, manteniendo los desacuerdos y las disputas de caracter religioso y social.  de hecho, esta situacion sobrevivio a la independencia de la india britanica, desembocando en una serie de luchas internas dentro del subcontinente indio, que fragmentaron lo que en un tiempo fue el gran imperio indo-britanico, en cinco estados independientes : india, pakistan, banglades, butan, y sri lanka. asi, las controversias y disputas entre grupos etnicos fueron minando la voluntad y el deseo de las personas a ser un pais unido. ",
        "snippet": "En política y psicología, divide y vencerás o dividir para reinar (del griego: διαίρει καὶ βασίλευε, diaírei kaì basíleue) es ganar y mantener el poder mediante la ruptura de las concentraciones más grandes, en fracciones que tienen menos energía en su aislada individualidad. El concepto se refiere a una estrategia que rompe las estructuras de poder existentes y evita la vinculación de los grupos de poder más pequeños. Podría ser utilizada en todos los ámbitos en los que, para obtener un mejor resultado, es en primer lugar necesario o ventajoso romper o dividir lo que se opone a la solución o a un determinado problema inicial.",
        "enlaces_salientes": [
            "/wiki/Divide_y_vencer%C3%A1s",
            "/wiki/Divide_y_vencer%C3%A1s",
            "/wiki/Divide_y_vencer%C3%A1s",
            "/wiki/Divide_y_vencer%C3%A1s_(desambiguaci%C3%B3n)",
            "/wiki/Pol%C3%ADtica",
            "/wiki/Psicolog%C3%ADa",
            "/wiki/Griego_antiguo",
            "/wiki/Locuci%C3%B3n_latina",
            "/wiki/Cayo_Julio_C%C3%A9sar",
            "/wiki/Napole%C3%B3n",
            "/wiki/Pol%C3%ADtica",
            "/wiki/Sociolog%C3%ADa",
            "/wiki/Estrategia_militar",
            "/wiki/Poder_(social_y_pol%C3%ADtico)",
            "/wiki/Ciencia_pol%C3%ADtica",
            "/wiki/Historia_pol%C3%ADtica",
            "/wiki/Psicolog%C3%ADa",
            "/wiki/Imperio",
            "/wiki/Historia_de_Roma",
            "/wiki/Liga_Latina",
            "/wiki/Imperio_Brit%C3%A1nico",
            "/wiki/India_Brit%C3%A1nica",
            "/wiki/India_Brit%C3%A1nica",
            "/wiki/India",
            "/wiki/Pakist%C3%A1n",
            "/wiki/Banglad%C3%A9s",
            "/wiki/But%C3%A1n",
            "/wiki/Sri_Lanka",
            "/wiki/Personas",
            "/wiki/Pa%C3%ADs",
            "/wiki/Agente_provocador",
            "/wiki/Argumento_ad_hominem",
            "/wiki/Astroturfing",
            "/wiki/Cultura_del_miedo",
            "/wiki/Discurso_de_odio",
            "/wiki/Estrategia_de_la_tensi%C3%B3n",
            "/wiki/Guerra_psicol%C3%B3gica",
            "/wiki/La_uni%C3%B3n_hace_la_fuerza",
            "/wiki/Operaci%C3%B3n_de_bandera_falsa",
            "/wiki/Organizaci%C3%B3n_fachada",
            "/wiki/Pol%C3%ADtica_identitaria",
            "/wiki/Pork_barrel",
            "/wiki/Promover_al_adversario",
            "/wiki/Propaganda_negra",
            "/wiki/Red_herring",
            "/wiki/T%C3%A1ctica_del_salami",
            "/wiki/Monarqu%C3%ADa_romana",
            "/wiki/Rep%C3%BAblica_romana",
            "/wiki/Imperio_romano",
            "/wiki/Raj_brit%C3%A1nico",
            "/wiki/L%C3%ADnea_Durand",
            "/wiki/Contrainsurgencia",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Metaheur%C3%ADsticas",
        "titulo": "Metaheurística",
        "contenido": "una metaheuristica es un metodo heuristico para resolver un tipo de problema computacional general, usando los parametros dados por el usuario sobre unos procedimientos genericos y abstractos de una manera que se espera eficiente. normalmente, estos procedimientos son heuristicos. el nombre combina el prefijo griego \"meta\" (\"mas alla\", aqui con el sentido de \"nivel superior\") y \"heuristico\" (de ευρσκεν, heuriskein, \"encontrar\").  las metaheuristicas generalmente se aplican a problemas que no tienen un algoritmo o heuristica especifica que de una solucion satisfactoria; o bien cuando no es posible implementar ese metodo optimo. la mayoria de las metaheuristicas tienen como objetivo los problemas de optimizacion combinatoria, pero por supuesto, se pueden aplicar a cualquier problema que se pueda reformular en terminos heuristicos, por ejemplo en resolucion de ecuaciones booleanas.  las metaheuristicas no son la panacea y suelen ser menos eficientes que las heuristicas especificas, en varios ordenes de magnitud, en problemas que aceptan este tipo de heuristicas puras.  el objetivo de la optimizacion combinatoria es encontrar un objeto matematico finito (por ejemplo, un vector de bits o permutacion) que maximice (o minimice, dependiendo del problema) una funcion especificada por el usuario de la metaheuristica. a estos objetos se les suele llamar estados, y al conjunto de todos los estados candidatos se le llama espacio de busqueda. la naturaleza de los estados y del espacio de busqueda son usualmente especificos del problema.  la funcion a optimizar se le llama funcion objetivo, y se da al usuario como un procedimiento caja-negra que evalua el estado actual o la funcion. dependiendo de la metaheuristica, el usuario puede tener que dar otras funciones caja-negra que produzcan un nuevo estado, generan variantes del estado actual, elijan un estado entre varios, aporten valores maximos o minimos para la funcion objetivo en un conjunto de estados, y en ese estilo.  algunas metaheuristicas mantienen en cada instante de ejecucion un unico estado actual, y lo cambian en cada iteracion por uno nuevo. este paso basico se conoce como transicion de estado, movimiento o actualizacion del estado. el movimiento es colina arriba o colina abajo dependiendo de si los valores que da la funcion objetivo se incrementa o se decrementa. el nuevo estado puede estar construido desde la nada por un generador de estados dado por el usuario. alternativamente, el nuevo estado puede derivar del estado actual por un mutador proporcionado por el usuario; en este caso, el nuevo estado se conoce como vecino del estado actual. generadores y mutadores son habitualmente procedimientos probabilisticos. el conjunto de todos los nuevos estados dados por el mutador es el vecindario del estado actual.  metaheuristicas mas sofisticadas mantienen, en vez de un unico estado actual, un conjunto de varios estados candidato. asi, el paso basico añade o elimina estados de este conjunto. en este caso, los procedimientos dados por el usuario seleccionan estados para ser descartados, y generan nuevos estados a añadir. el ultimo estado puede ser generado como combinacion o cruce de dos o mas estados del conjunto.  una metaheuristica puede guardar informacion del optimo actual, escogiendo el estado optimo entre todos los optimos actuales obtenidos en varias etapas del algoritmo.  dado que el numero de candidatos puede ser muy grande, normalmente, las metaheuristicas estan diseñadas de manera que puedan ser interrumpidas por un tiempo maximo especificado por el usuario. si no se interrumpen, algunas metaheuristicas exactas examinaran todos los candidatos, y usaran metodos heuristicos solo para escoger el orden de la enumeracion; de hecho, siempre devolveran un optimo real, si el tiempo maximo es lo suficientemente grande. en cambio, otras metaheuristicas dan solo una garantia probabilistica pobre de poder alcanzar el optimo, de manera que cuando el tiempo maximo se aproxima a infinito, la probabilidad de examinar cada candidato tiende a 1.  algunas metaheuristicas muy conocidas son:   hay un numero enorme de variables e hibridos propuestos, y muchas mas metaheuristicas han sido probadas en problemas especificos. este es un campo en investigacion, con un gran numero de publicaciones en revistas, un gran numero de investigadores y usuarios, ademas de un gran numero de aplicaciones.  c. blum and a. roli a. (2003). metaheuristics in combinatorial optimization: overview and conceptual comparison. acm computing surveys 35(3) 268–308. ",
        "snippet": "Una metaheurística es un método heurístico para resolver un tipo de problema computacional general, usando los parámetros dados por el usuario sobre unos procedimientos genéricos y abstractos de una manera que se espera eficiente. Normalmente, estos procedimientos son heurísticos. El nombre combina el prefijo griego \"meta\" (\"más allá\", aquí con el sentido de \"nivel superior\") y \"heurístico\" (de ευρισκειν, heuriskein, \"encontrar\").",
        "enlaces_salientes": [
            "/wiki/Metaheur%C3%ADstica",
            "/wiki/Metaheur%C3%ADstica",
            "/wiki/Metaheur%C3%ADstica",
            "/wiki/Heur%C3%ADstica",
            "/wiki/Idioma_griego",
            "/wiki/Meta_(prefijo)",
            "/wiki/Optimizaci%C3%B3n_combinatoria",
            "/wiki/Ecuaciones_booleanas",
            "/wiki/Permutaci%C3%B3n",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Conjunto",
            "/wiki/Procedimientos_probabil%C3%ADsticos",
            "/wiki/Algoritmo_mem%C3%A9tico",
            "/wiki/Algoritmos_de_enjambre",
            "/wiki/Algoritmos_gen%C3%A9ticos",
            "/wiki/Algoritmos_voraces",
            "/wiki/Ascensi%C3%B3n_de_colinas",
            "/wiki/B%C3%BAsqueda_tab%C3%BA",
            "/wiki/GRASP",
            "/wiki/Inteligencia_de_enjambre",
            "/wiki/Optimizaci%C3%B3n_de_enjambre_de_part%C3%ADculas",
            "/wiki/Optimizaci%C3%B3n_por_colonia_de_hormigas",
            "/wiki/Simulated_annealing",
            "/wiki/Espacio_de_b%C3%BAsqueda",
            "/wiki/Investigaci%C3%B3n_de_operaciones",
            "/wiki/Matheur%C3%ADstica",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Optimizaci%C3%B3n_multiobjetivo",
            "/wiki/Programaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Programaci%C3%B3n_din%C3%A1mica_(computaci%C3%B3n)",
        "titulo": "Programación dinámica",
        "contenido": "en informatica, la programacion dinamica es un metodo para reducir el tiempo de ejecucion de un algoritmo mediante la utilizacion de subproblemas superpuestos y subestructuras optimas.  el matematico richard bellman invento la programacion dinamica en 1953 que se utiliza para optimizar problemas complejos que pueden ser discretizados y secuencializados.  una «subestructura optima» significa que se pueden usar soluciones optimas de subproblemas para encontrar la solucion optima del problema en su conjunto. por ejemplo, el camino mas corto entre dos vertices de un grafo se puede encontrar calculando primero el camino mas corto al objetivo desde todos los vertices adyacentes al de partida, y despues usando estas soluciones para elegir el mejor camino de todos ellos. en general, se pueden resolver problemas con subestructuras optimas siguiendo estos tres pasos:  los subproblemas se resuelven a su vez dividiendolos en subproblemas mas pequeños hasta que se alcance el caso facil, donde la solucion al problema es trivial.  decir que un problema tiene subproblemas superpuestos es decir que se usa un mismo subproblema para resolver diferentes problemas mayores. por ejemplo, en la sucesion de fibonacci (f3 = f1 + f2 y f4 = f2 + f3) calcular cada termino supone calcular f2. como para calcular f5 hacen falta tanto f3 como f4, una mala implementacion para calcular f5 acabara calculando f2 dos o mas veces. esto sucede siempre que haya subproblemas superpuestos: una mala implementacion puede acabar desperdiciando tiempo recalculando las soluciones optimas a problemas que ya han sido resueltos anteriormente.  esto se puede evitar guardando las soluciones que ya hemos calculado. entonces, si necesitamos resolver el mismo problema mas tarde, podemos obtener la solucion de la lista de soluciones calculadas y reutilizarla. este acercamiento al problema se llama memoizacion (no confundir con memorizacion; en ingles es llamado memoization, vease en). si estamos seguros de que no volveremos a necesitar una solucion en concreto, la podemos descartar para ahorrar espacio. en algunos casos, podemos calcular las soluciones a problemas que de antemano sabemos que vamos a necesitar.  en resumen, la programacion hace uso de:  la programacion toma normalmente uno de los dos siguientes enfoques:  originalmente, el termino de programacion dinamica se referia a la resolucion de ciertos problemas y operaciones fuera del ambito de la ingenieria informatica, al igual que hacia la programacion lineal. aquel contexto no tiene relacion con la programacion en absoluto; el nombre es una coincidencia. el termino tambien lo uso en los años 40 richard bellman, un matematico estadounidense, para describir el proceso de resolucion de problemas donde hace falta calcular la mejor solucion consecutivamente.  algunos lenguajes de programacion funcionales, sobre todo haskell, pueden usar la memoizacion automaticamente sobre funciones con un conjunto concreto de argumentos, para acelerar su proceso de evaluacion. esto solo es posible en funciones que no tengan efectos secundarios, algo que ocurre en haskell, pero no tanto en otros lenguajes.  la programacion dinamica es un metodo cuantitativo desarrollado por richard bellman alrededor de la decada de los años 50, con la finalidad de optimizar procesos, ya que en ese momento esa era su funcion como trabajador de rand corporation. bellman decidio emplear la palabra dinamica a esta tecnica, ya que deseaba analizar las variables de los problemas con respecto al tiempo. siendo asi dasgupta, papadimitriou y vazirani (2006), entendieron a la programacion dinamica como “optimizacion de procesos con etapa multiples”. la idea de bellman sobre la teoria de programacion dinamica se basa en una estructura de optimizacion, la cual consiste en descomponer el problema en subproblemas (mas manejables). los calculos se realizan entonces recursivamente donde la solucion optima de un subproblema se utiliza como dato de entrada al siguiente problema. por lo cual, se entiende que el problema es solucionado en su totalidad, una vez se haya solucionado el ultimo subproblema. dentro de esta teoria, bellman desarrolla el principio de optimalidad, el cual es fundamental para la resolucion adecuada de los calculos recursivos. lo cual quiere decir que las etapas futuras desarrollan una politica optima independiente de las decisiones de las etapas predecesoras. es por ello, que se define a la programacion dinamica como una tecnica matematica que ayuda a resolver decisiones secuenciales interrelacionadas, combinandolas para obtener de la solucion optima.  el problema se puede dividir por etapas, y cada una de las etapas requiere de una politica de decision.  cada etapa tiene cierto numero de estados, los estados son las distintas condiciones posibles en las que se puede encontrar el sistema en cada etapa.  el efecto de la politica de decision en cada etapa es transformar el estado actual en un estado asociado con el inicio de la siguiente etapa, entonces podemos decir que un estado es una columna de nodos, cada nodo representa un estado y cada rama una politica de decision.  el procedimiento de resolucion de la programacion dinamica esta diseñado para encontrar una politica optima para cada etapa logrando asi la politica optima general.  dado el estado actual, una politica optima para las etapas restantes es independiente de la politica adoptada en etapas anteriores, por ende, la decision inmediata optima solo depende del estado actual y no de como se llego ahi, esto es el principio de optimalidad de la programacion dinamica.  se dispone de una relacion recursiva que identifica la politica optima para la etapa n, dada la politica optima para la etapa n+1.  cuando se hace uso de la relacion recursiva, el procedimiento de solucion comienza al final se mueve hacia atras etapa por etapa hasta encontrar la politica optima en cada etapa hasta la etapa inicial.  existen dos tipos de programacion dinamica: la programacion dinamica deterministica se utilizan datos que se conocen con certeza y la programacion dinamica probabilistica donde se usan datos que no se conocen con certeza pero que se determinan a traves de distribuciones de probabilidad.  1) programacion dinamica deterministica: el enfoque deterministico consiste en que el estado de la siguiente etapa se encuentra determinado por completo con respecto al estado y la decision que posee la etapa actual. en la etapa n el proceso se encontrara en algun estado sn. al tomar la decision xn se mueve a algun estado sn+1 en la etapa n+1. el valor de la funcion objetiva para la politica optima de ese punto en adelante se calculo previamente como f*n+1(sn+1). la politica de decision tambien hace una contribucion a la funcion objetivo. al combinar estas dos cantidades en la forma apropiada se proporciona a la funcion objetivo fn(sn,xn) la contribucion de la etapa n en adelante. la optimizacion respecto a xn proporciona entonces f*n(sn)= fn(sn,xn). una vez encontrados xn y fn*(sn) para cada valor posible de sn, el procedimiento de solucion se mueve hacia atras una etapa.  los problemas de programacion dinamica deterministica se pueden clasificar segun su funcion objetivo (minimizar la suma de las contribuciones de cada una de las etapas individuales, maximizar esa suma, minimizar el producto de los terminos, etc.) y segun la naturaleza del conjunto de estados (variables discretas o variables continuas).  2) programacion dinamica probabilistica: en este enfoque, el valor del estado de la siguiente etapa y politica de decision queda completamente determinado mediante una distribucion probabilistica. sea s el numero de estados posibles en la etapa n+1 y etiquete estos estados al lado derecho por 1,2…,s. el sistema cambia al estado i con probabilidad pi (i=1,2…,s) dados el estado sn y la decision xn en la etapa n. si el sistema cambia al estado i, ci es la contribucion de la etapa n a la funcion objetivo.   cuando se expande el diagrama para incluir todos los estados y las decisiones posibles en todas las etapas, se obtiene lo que con frecuencia se conoce como un arbol de decision. si este arbol de decision no es muy grande, proporciona una forma util de resumir estas posibilidades. la programacion dinamica probabilistica difiere de la deterministica, en que el estado de la siguiente etapa no esta completamente determinado por el estado y la politica de decision de la etapa actual. en este caso, existe una distribucion de probabilidad para determinar cual sera el estado en la siguiente etapa. debido a la estructura probabilistica, la relacion entre fn(sn,xn) y fn+1*(sn+1) dependera de la forma global de la funcion objetivo.  cuando hablamos de optimizar nos referimos a buscar la mejor solucion de entre muchas alternativas posibles. dicho proceso de optimizacion puede ser visto como una secuencia de decisiones que nos proporcionan la solucion correcta. si, dada una subsecuencia de decisiones, siempre se conoce cual es la decision que debe tomarse a continuacion para obtener la secuencia optima, el problema es elemental y se resuelve trivialmente tomando una decision detras de otra, lo que se conoce como estrategia voraz. en otros casos, aunque no sea posible aplicar la estrategia voraz, se cumple el principio de optimalidad de bellman que dicta que «dada una secuencia optima de decisiones, toda subsecuencia de ella es, a su vez, optima». en este caso sigue siendo posible el ir tomando decisiones elementales, en la confianza de que la combinacion de ellas seguira siendo optima, pero sera entonces necesario explorar muchas secuencias de decisiones para dar con la correcta, siendo aqui donde interviene la programacion dinamica.  contemplar un problema como una secuencia de decisiones equivale a dividirlo en problemas mas pequeños y por lo tanto mas faciles de resolver como hacemos en divide y venceras, tecnica similar a la de programacion dinamica. la programacion dinamica se aplica cuando la subdivision de un problema conduce a:  esta sucesion puede expresarse mediante la siguiente recurrencia:   f i b ( n ) = { 0 si n = 0 1 si n = 1 f i b ( n − 1 ) + f i b ( n − 2 ) si n > 1 0&}\\;n=0\\\\1&}\\;n=1\\\\fib(n-1)+fib(n-2)&}\\;n>1\\\\\\end{cases}}}  una implementacion de una funcion que encuentre el n-esimo termino de la sucesion de fibonacci basada directamente en la definicion matematica de la sucesion realizando llamadas recursivas hace mucho trabajo redundante, obteniendose una complejidad exponencial:  si llamamos, por ejemplo, a fib(5), produciremos un arbol de llamadas que contendra funciones con los mismos parametros varias veces:  en particular, fib(2) se ha calculado tres veces desde cero. en ejemplos mayores, se recalculan muchos otros valores de fib, o subproblemas.  para evitar este inconveniente, podemos resolver el problema mediante programacion dinamica, y en particular, utilizando el enfoque de memoizacion (guardar los valores que ya han sido calculados para utilizarlos posteriormente). asi, rellenariamos una tabla con los resultados de los distintos subproblemas, para reutilizarlos cuando haga falta en lugar de volver a calcularlos. la tabla resultante seria una tabla unidimensional con los resultados desde 0 hasta n.  un programa que calculase esto, usando bottom-up, tendria la siguiente estructura:  la funcion resultante tiene complejidad o(n), en lugar de 2 a la n (puesto que genera un arbol binario en memoria, donde el ultimo nivel de hojas es de la forma 2 a la n). en otras palabras, la programacion dinamica, en este caso, permite disminuir la complejidad computacional del algoritmo.  otro nivel de refinamiento que optimizaria la solucion seria quedarnos tan solo con los dos ultimos valores calculados en lugar de toda la tabla, que son realmente los que nos resultan utiles para calcular la solucion a los subproblemas.  el mismo problema usando top-down tendria la siguiente estructura:  suponemos que la tabla se introduce por primera vez correctamente inicializada, con todas las posiciones con un valor invalido, como por ejemplo -1, que se distingue por no ser uno de los valores que computa la funcion.  el algoritmo recursivo que calcula los coeficientes binomiales resulta ser de complejidad exponencial por la repeticion de los calculos que realiza. no obstante, es posible diseñar un algoritmo con un tiempo de ejecucion de orden o(nk) basado en la idea del triangulo de pascal, idea claramente aplicable mediante programacion dinamica. para ello es necesaria la creacion de una tabla bidimensional en la que ir almacenando los valores intermedios que se utilizan posteriormente.  la idea recursiva de los coeficientes binomiales es la siguiente:   ( n k ) } = ( n − 1 k − 1 ) } + ( n − 1 k ) } si 0 < k < n   ( n 0 ) } = ( n n ) } = 1  la idea para construir la tabla de manera eficiente y sin valores inutiles es la siguiente:  el siguiente algoritmo memorizado de estrategia bottom-up tiene complejidad polinomica y va rellenando la tabla de izquierda a derecha y de arriba abajo:  por supuesto, el problema de los coeficientes binomiales tambien puede resolverse mediante un enfoque top-down.  en un rio hay n embarcaderos, en cada uno de los cuales se puede alquilar un bote para ir a otro embarcadero que este mas abajo en el rio. suponemos que no se puede remontar el rio. una tabla de tarifas indica los costes de viajar entre los distintos embarcaderos. se supone que puede ocurrir que un viaje entre i y j salga mas barato haciendo escala en k embarcaderos que yendo directamente.  el problema consistira en determinar el coste minimo para un par de embarcaderos.  vamos a llamar a la tabla de tarifas, t. asi, t[i,j] sera el coste de ir del embarcadero i al j. la matriz sera triangular superior de orden n, donde n es el numero de embarcaderos.  la idea recursiva es que el coste se calcula de la siguiente manera:  c(i, j) = t[i, k] + c(k, j)  a partir de esta idea, podemos elaborar una expresion recurrente para la solucion:  un algoritmo que resuelve este problema es el siguiente, donde t es la matriz de tarifas, origen y destino los embarcaderos del que se parte y al que se llega respectivamente, y c la matriz en la que almacenaremos los resultados de los costes. la funcion menordeloscandidatos devuelve el menor coste entre dos puntos, utilizando como base la recurrencia anteriormente expuesta.   ",
        "snippet": "En informática, la programación dinámica es un método para reducir el tiempo de ejecución de un algoritmo mediante la utilización de subproblemas superpuestos y subestructuras óptimas.",
        "enlaces_salientes": [
            "/wiki/Programaci%C3%B3n_din%C3%A1mica",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Algoritmo",
            "/wiki/Richard_Bellman",
            "/wiki/1953",
            "/wiki/Problema_del_camino_m%C3%A1s_corto",
            "/wiki/Grafo",
            "/wiki/Sucesi%C3%B3n_de_Fibonacci",
            "/wiki/Memoizaci%C3%B3n",
            "/wiki/Memorizaci%C3%B3n",
            "/wiki/Memoizaci%C3%B3n",
            "/wiki/Top-down",
            "/wiki/Memoizaci%C3%B3n",
            "/wiki/Recursi%C3%B3n",
            "/wiki/Bottom-up",
            "/wiki/Ingenier%C3%ADa_Inform%C3%A1tica",
            "/wiki/Programaci%C3%B3n_lineal",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Richard_Bellman",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Paradigma_funcional",
            "/wiki/Haskell",
            "/wiki/Memoizaci%C3%B3n",
            "/wiki/Efecto_secundario_(computaci%C3%B3n)",
            "/wiki/Haskell",
            "/wiki/Richard_Bellman",
            "/wiki/Algoritmo_divide_y_vencer%C3%A1s",
            "/wiki/Sucesi%C3%B3n_de_Fibonacci",
            "/wiki/Big-O_notation",
            "/wiki/Problema_de_la_mochila",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Ramificaci%C3%B3n_y_acotaci%C3%B3n",
        "titulo": "Ramificación y poda",
        "contenido": "el metodo de diseño de algoritmos ramificacion y poda (tambien llamado ramificacion y acotacion) es una variante del backtracking mejorado sustancialmente. el termino (del ingles, branch and bound) se aplica mayoritariamente para resolver cuestiones o problemas de optimizacion.  la tecnica de ramificacion y poda se suele interpretar como un arbol de soluciones, donde cada rama conduce a una posible solucion posterior a la actual. la caracteristica de esta tecnica con respecto a otras anteriores (y a la que debe su nombre) es que el algoritmo se encarga de detectar en que ramificacion las soluciones dadas ya no estan siendo optimas, para «podar» esa rama del arbol y no continuar malgastando recursos y procesos en casos que se alejan de la solucion optima.  nuestra meta sera encontrar el valor minimo de una funcion f(x) (un ejemplo puede ser el coste de manufacturacion de un determinado producto) donde fijamos x rangos sobre un determinado conjunto s de posibles soluciones. un procedimiento de ramificacion y poda requiere dos herramientas.  la primera es la de un procedimiento de expansion, que dado un conjunto fijo s de candidatos, devuelve dos o mas conjuntos mas pequeños s 1 } , s 2 } , … , s n } cuya union cubre s. notese que el minimo de f(x) sobre s es min{ v 1 } , v 2 } , … } donde cada v i } es el minimo de f(x) en s i } . este paso es llamado ramificacion; como su aplicacion es recursiva, esta definira una estructura de arbol cuyos nodos seran subconjuntos de s.   la idea clave del algoritmo de ramificacion y poda es:  si la menor rama para algun arbol nodo(conjunto de candidatos) a es mayor que la rama padre para otro nodo b, entonces a debe ser descartada con seguridad de la busqueda. este paso es llamado poda, y usualmente es implementado manteniendo una variable global m que graba el minimo nodo padre visto entre todas las subregiones examinadas hasta entonces. cualquier nodo cuyo nodo hijo es mayor que m puede ser descartado. la recursion para cuando el conjunto candidato s es reducido a un solo elemento, o tambien cuando el nodo padre para el conjunto s coincide con el nodo hijo. de cualquier forma, cualquier elemento de s va a ser el minimo de una funcion dentro de s.  el pseudocodigo del algoritmo de ramificacion y poda es el siguiente:  donde:    la eficiencia de este metodo depende fundamentalmente del procedimiento de expansion de nodos, o de la estimacion de los nodos padres e hijos. es mejor elegir un metodo de expansion que provea que no se solapen los subconjuntos para ahorrarnos problemas de duplicacion de ramas.  idealmente, el procedimiento se detiene cuando todos los nodos del arbol de busqueda estan podados o resueltos. en ese punto, todas las subregiones no podadas, tendran un nodo padre e hijo iguales a una funcion global minima. en la practica el procedimiento a menudo termina cuando finaliza un tiempo dado,  hasta el punto en que el minimo de nodos hijos y el maximo de nodos padres sobre todas las secciones no podadas definen un rango de valores que contienen el minimo global. alternativamente, sin superar un tiempo restringido, el algoritmo debe terminar cuando un criterio de error, tal que (max-min)/(max+min), cae bajo un valor especifico.  la eficiencia del metodo depende especialmente de la efectividad de los algoritmos de ramificacion y poda usados. una mala eleccion puede llevarnos a una repetida ramificacion, sin poda, hasta que las subregiones se conviertan en muy pequeñas. en ese caso el metodo seria reducido a una exhaustiva enumeracion del dominio, que es a menudo impracticablemente larga. no hay un algoritmo de poda universal que trabaje para todos los problemas, pero existe una pequeña esperanza de que alguna vez se encuentre alguno. hasta entonces necesitaremos implementar cada uno por separado para cada aplicacion informatica, con el algoritmo de ramificacion y poda especialmente diseñados para el.  los metodos de ramificacion y poda deben ser clasificados de manera acorde a los metodos de poda, y a las maneras de creacion/clasificacion de los arboles de busqueda.  la estrategia  de diseño de ramificacion y poda es muy similar al de vuelta atras (backtracking), donde el estado del arbol es usado para resolver un problema. las diferencias son que el metodo de ramificacion y poda no nos limitan a ninguna forma particular de obtener un arbol transverso, y es usado solamente para problemas de optimizacion. este metodo naturalmente lleva a una forma de implementacion paralela y distribuida, como podemos ver por ejemplo en el problema del viajante de comercio.  nuestro objetivo principal sera eliminar aquellos nodos que no lleven a soluciones buenas. podemos utilizar dos estrategias basicas. supongamos un problema de maximizacion donde se han recorrido varios nodos i=1,…,n. estimando para cada uno la cota superior cs(xi) e inferior ci( x i } ).  si a partir de un nodo x i } se puede obtener una solucion valida, entonces se podra podar dicho nodo si la cota superior cs( x i } ) es menor o igual que la cota inferior ci( x j } ) para algun nodo j generado en el arbol.  por ejemplo: supongamos el problema de la mochila, el cual se va a desarrollar en la seccion de ejemplos, donde utilizamos un arbol binario. entonces:  si a partir de x i } se puede encontrar un beneficio maximo de cs( x i } ) = 4 y a partir de x j } , se tiene asegurado un beneficio minimo de ci( x j } ) = 5, esto nos llevara a la conclusion de que se puede podar el nodo x i } sin que perdamos ninguna posible solucion optima.  si se obtiene una posible solucion valida para el problema con un beneficio b j } , entonces se podran podar aquellos nodos x i } cuya cota superior cs( x i } ) sea menor o igual que el beneficio que se puede obtener b j } (este proceso seria similar para la cota inferior).  como se comenta en la introduccion de este apartado, la expansion del arbol con las distintas estrategias esta condicionada por la busqueda de la solucion optima. debido a esto todos los nodos de un nivel deben ser expandidos antes de alcanzar un nuevo nivel, cosa que es logica ya  que para poder elegir la rama del arbol que va a ser explorada, se deben conocer todas las ramas posibles.  todos estos nodos que se van generando y que no han sido explorados se almacenan en lo que se denomina lista de nodos vivos (a partir de ahora lnv), nodos pendientes de expandir por el algoritmo.  la lnv contiene todos los nodos que han sido generados pero que no han sido explorados todavia. segun como esten almacenados los nodos en la lista, el recorrido del arbol sera de uno u otro tipo, dando lugar a las tres estrategias que se detallan a continuacion.  en la estrategia fifo (first in first out), la lnv sera una cola, dando lugar a un recorrido en anchura del arbol.    en la figura 1 se puede observar que se comienza introduciendo en la  lnv el nodo a. sacamos el nodo de la cola y se expande generando los nodos b y c que son introducidos en la lnv. seguidamente se saca el primer nodo que es el b y se vuelve a expandir generando los nodos d y e que se introducen en la lnv. este proceso se repite mientras que quede algun elemento en la cola.  en la estrategia lifo (last in first out), la lnv sera una pila, produciendo un recorrido en profundidad del arbol.    en la figura 2 se muestra el orden de generacion de los nodos con una estrategia lifo. el proceso que se sigue en la lnv es similar al de la estrategia fifo, pero en lugar de utilizar una cola, se utiliza una pila.  al  utilizar las estrategias fifo y lifo se realiza lo que se denomina una busqueda “a ciegas”, ya que expanden sin tener en cuenta los beneficios que se pueden alcanzar desde cada nodo. si la expansion se realizase en funcion de los beneficios que cada nodo reporta (con una “vision de futuro”), se podria conseguir en la mayoria de los casos una mejora sustancial.  es asi como nace la estrategia de menor coste o lc (least cost), selecciona para expandir entre todos los nodos de la lnv aquel que tenga mayor beneficio (o menor coste). por lo tanto ya no estamos hablando de un avance “a ciegas”.  esto nos puede llevar a la situacion de que varios nodos puedan ser expandidos al mismo tiempo. de darse el caso, es necesario disponer de un mecanismo que solucione este conflicto:  -estrategia lc-fifo: elige de la lnv el nodo que tenga mayor beneficio y en caso de empate se escoge el primero que se introdujo.  -estrategia lc-lifo: elige de la lnv el nodo que tenga mayor beneficio y en caso de empate se escoge el ultimo que se introdujo.  un variante del metodo de ramificacion y poda mas eficiente se puede obtener “relajando” el problema, es decir, eliminando algunas de las restricciones para hacerlo mas permisivo.  cualquier solucion valida del problema original sera solucion valida para el problema “relajado”, pero no tiene por que ocurrir al contrario. si conseguimos resolver esta version del problema de forma optima, entonces si la solucion obtenida es valida para el problema original, esto querra decir que es optima tambien para dicho problema.  la verdadera utilidad de este proceso reside en la utilizacion de un metodo eficiente que nos resuelva el problema relajado. uno de los metodos mas conocidos es el de ramificacion y corte (branch and cut (version inglesa)).  ramificacion y corte es un metodo de optimizacion combinacional para resolver problemas de enteros lineales, que son problemas de programacion lineal donde algunas o todas las incognitas estan restringidas a valores enteros. se trata de un hibrido de ramificacion y poda con metodos de planos de corte.  este metodo resuelve programas lineales sin restricciones enteras usando algoritmos regulares simplificados. cuando se obtiene una solucion optima que tiene un valor no entero para una variable que ha de ser entera, el algoritmo de planos de corte se usa para encontrar una restriccion lineal mas adelante que sea satisfecha por todos los puntos factibles enteros, pero violados por la solucion fraccional actual. si se encuentra esa desigualdad, se añade al programa lineal, de tal forma que resolverla nos llevara a una solucion diferente que esperamos que sea “menos fraccional”. este proceso se repite hasta que o bien, se encuentra una solucion entera (que podemos demostrar que es optima), o bien no se encuentran mas planos de corte.  en este punto comienza la parte del algoritmo de ramificacion y poda. este problema se divide en dos versiones: una con restriccion adicional en que la variable es mas grande o igual que el siguiente entero mayor que el resultado intermedio, y uno donde la variable es menor o igual que el siguiente entero menor. de esta forma se introducen nuevas variables en las bases de acuerdo al numero de variables basicas que no son enteros en la solucion intermedia pero son enteros de acuerdo a las restricciones originales. los nuevos programas lineales se resuelven usando un metodo simplificado y despues el proceso repetido hasta que una solucion satisfaga todas las restricciones enteras.  durante el proceso de ramificacion y poda, los planos de corte se pueden separar mas adelante y pueden ser o cortes globales validos para todas las soluciones enteras factibles, o cortes locales que son satisfechos por todas las soluciones llenando todas las ramas de la restriccion del subarbol de ramificacion y poda actual.  esta tecnica es usada por un gran numero  de problemas np-hard, tales como:  tambien puede ser una base de varios razonamientos heuristicos. por ejemplo, uno puede desear parar  la ramificacion cuando el hueco entre el nodo hijo y padre llegue a ser mas pequeño que un cierto umbral. esto es usado cuando la solucion es suficientemente buena para el problema propuesto, y puede reducir gratamente la complejidad computacional. este tipo de solucion particular es aplicable cuando la funcion coste usada esta clara o  es el resultado de estimaciones estadisticas  y aunque no se conoce, se sabe que hay una probabilidad especifica de que pertenezca a un rango de valores. ",
        "snippet": "El método de diseño de algoritmos ramificación y poda (también llamado ramificación y acotación) es una variante del backtracking mejorado sustancialmente. El término (del inglés, Branch and Bound) se aplica mayoritariamente para resolver cuestiones o problemas de optimización.",
        "enlaces_salientes": [
            "/wiki/Ramificaci%C3%B3n_y_poda",
            "/wiki/Ramificaci%C3%B3n_y_poda",
            "/wiki/Ramificaci%C3%B3n_y_poda",
            "/wiki/Algoritmos",
            "/wiki/Backtracking",
            "/wiki/Conjuntos",
            "/wiki/%C3%81rbol_(estructura_de_datos)",
            "/wiki/Variable_(programaci%C3%B3n)",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Aplicaci%C3%B3n_inform%C3%A1tica",
            "/wiki/Vuelta_atr%C3%A1s",
            "/wiki/Problema_del_viajante",
            "/wiki/Problema_de_la_mochila",
            "/wiki/Lista_(estructura_de_datos)",
            "/wiki/FIFO",
            "/wiki/Cola_(estructura_de_datos)",
            "/wiki/LIFO",
            "/wiki/Pila_(estructura_de_datos)",
            "/wiki/Programaci%C3%B3n_lineal",
            "/wiki/NP-hard",
            "/wiki/Problema_de_la_mochila",
            "/wiki/Programaci%C3%B3n_lineal",
            "/wiki/Programaci%C3%B3n_no_lineal",
            "/wiki/Problema_del_viajante",
            "/wiki/Problema_de_la_asignaci%C3%B3n_cuadr%C3%A1tica",
            "/wiki/Heur%C3%ADsticos",
            "/wiki/Complejidad_computacional",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Probabilidad",
            "/wiki/Sudoku_ramificaci%C3%B3n_y_poda",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Vuelta_atr%C3%A1s",
        "titulo": "Vuelta atrás",
        "contenido": "vuelta atras (backtracking) es una estrategia para encontrar soluciones a problemas que satisfacen restricciones. el termino \"backtrack\" fue acuñado por primera vez por el matematico estadounidense d. h. lehmer en la decada de 1950.  los problemas que deben satisfacer un determinado tipo de restricciones son problemas completos, donde el orden de los elementos de la solucion no importa. estos problemas consisten en un conjunto (o lista) de variables a la que a cada una se le debe asignar un valor sujeto a las restricciones del problema. la tecnica va creando todas las posibles combinaciones de elementos para obtener una solucion. su principal virtud es que en la mayoria de las implementaciones se puede evitar combinaciones, estableciendo funciones de acotacion (o poda) reduciendo el tiempo de ejecucion.  vuelta atras esta muy relacionado con la busqueda combinatoria.  esencialmente, la idea es encontrar la mejor combinacion posible en un momento determinado, por eso, se dice que este tipo de algoritmo es una busqueda en profundidad. durante la busqueda, si se encuentra una alternativa incorrecta, la busqueda retrocede hasta el paso anterior y toma la siguiente alternativa. cuando se han terminado las posibilidades, se vuelve a la eleccion anterior y se toma la siguiente opcion (hijo [si nos referimos a un arbol]). si no hay mas alternativas la busqueda falla. de esta manera, se crea un arbol implicito, en el que cada nodo es un estado de la solucion (solucion parcial en el caso de nodos interiores o solucion total en el caso de los nodos hoja).  normalmente, se suele implementar este tipo de algoritmos como un procedimiento recursivo. asi, en cada llamada al procedimiento se toma una variable y se le asignan todos los valores posibles, llamando a su vez al procedimiento para cada uno de los nuevos estados. la diferencia con la busqueda en profundidad es que se suelen diseñar funciones de cota, de forma que no se generen algunos estados si no van a conducir a ninguna solucion, o a una solucion peor de la que ya se tiene. de esta forma se ahorra espacio en memoria y tiempo de ejecucion.  algunas heuristicas son comunmente usadas para acelerar el proceso. como las variables se pueden procesar en cualquier orden, generalmente es mas eficiente intentar ser lo mas restrictivo posible con las primeras (esto es, las primeras con menores valores posibles). este proceso poda el arbol de busqueda antes de que se tome la decision y se llame a la subrutina recursiva.  cuando se elige que valor se va a asignar, muchas implementaciones hacen un examen hacia delante (fc, forward checking), para ver que valor restringira el menor numero posible de valores, de forma que se anticipa en a) preservar una posible solucion y b) hace que la solucion encontrada no tenga restricciones destacadas.  algunas implementaciones muy sofisticadas usan una funcion de cotas, que examina si es posible encontrar una solucion a partir de una solucion parcial. ademas, se comprueba si la solucion parcial que falla puede incrementar significativamente la eficiencia del algoritmo. por el uso de estas funciones de cota, se debe ser muy minucioso en su implementacion de forma que sean poco costosas computacionalmente hablando, ya que lo mas normal es que se ejecuten en para cada nodo o paso del algoritmo. cabe destacar, que las cotas eficaces se crean de forma parecida a las funciones heuristicas, esto es, relajando las restricciones para conseguir mayor eficiencia.  con el objetivo de mantener la solucion actual con coste minimo, los algoritmos vuelta atras mantienen el coste de la mejor solucion en una variable que va variando con cada nueva mejor solucion encontrada. asi, si una solucion es peor que la que se acaba de encontrar, el algoritmo no actualizara la solucion. de esta forma, devolvera siempre la mejor solucion que haya encontrado. y recuerden, la vida es un backtracking  vuelta atras se usa en la implementacion de los lenguajes de programacion tales como lenguaje de programacion planner y prolog. ademas, se usa en los analisis sintacticos de los compiladores. su uso en inteligencia artificial ha sido muy importante, dando lugar a nuevos tipos de busquedas como el a estrella.  este metodo busca una solucion como en el metodo de backtracking, pero cada solucion tiene asociado un costo y la solucion que se busca es una de minimo costo llamada optima. ademas de ramificar una solucion padre (branch) en hijos se trata de eliminar de consideracion aquellos hijos cuyos descendientes tienen un costo que supera al optimo buscado acotando el costo de los descendientes del hijo (bound). la forma de acotar es un arte que depende de cada problema. la acotacion reduce el tiempo de busqueda de la solucion optima al \"podar\" (pruning) los subarboles de descendientes costosos. ",
        "snippet": "Vuelta atrás (Backtracking) es una estrategia para encontrar soluciones a problemas que satisfacen restricciones. El término \"backtrack\" fue acuñado por primera vez por el matemático estadounidense D. H. Lehmer en la década de 1950.",
        "enlaces_salientes": [
            "/wiki/Vuelta_atr%C3%A1s",
            "/wiki/Vuelta_atr%C3%A1s",
            "/wiki/Vuelta_atr%C3%A1s",
            "/wiki/Derrick_Henry_Lehmer",
            "/wiki/D%C3%A9cada_de_1950",
            "/wiki/B%C3%BAsqueda_en_profundidad",
            "/wiki/Recursividad",
            "/wiki/B%C3%BAsqueda_en_profundidad",
            "/wiki/%C3%81rbol_(estructura_de_datos)",
            "/wiki/Heur%C3%ADstica",
            "/wiki/Sudoku_backtracking",
            "/wiki/Problema_de_los_movimientos_de_un_caballo",
            "/wiki/Las_ocho_reinas",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/Planner",
            "/wiki/Prolog",
            "/wiki/Inteligencia_artificial",
            "/wiki/A*",
            "/wiki/Sudoku_backtracking",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Cota_inferior_asint%C3%B3tica",
        "titulo": "Cota inferior asintótica",
        "contenido": "en analisis de algoritmos una cota inferior asintotica es una funcion que sirve de cota inferior de otra funcion cuando el argumento tiende a infinito. usualmente se utiliza la notacion ω(g(x)) para referirse a las funciones acotadas inferiormente por la funcion g(x).  mas formalmente se define:  una funcion f(x) pertenece a ω(g(x)) cuando existe una constante positiva c tal que a partir de un valor x 0 } , c g ( x ) no supera f(x). quiere decir que la funcion f es superior a g a partir de un valor dado salvo por un factor constante.  la cota inferior asintotica tiene utilidad en teoria de la complejidad computacional a la hora de calcular la complejidad del mejor caso para los algoritmos.  a pesar de que ω(g(x)) esta definido como un conjunto, se acostumbra escribir f(x)=ω(g(x)) en lugar de f(x) ∈ ω(g(x)). muchas veces tambien se habla de una funcion nombrando unicamente su expresion, como en x² en lugar de h(x)=x², siempre que este claro cual es el parametro de la funcion dentro de la expresion. en la grafica se da un ejemplo esquematico de como se comporta c g ( x ) con respecto a f(x) cuando x tiende a infinito.  la cota ajustada asintotica (notacion θ) tiene relacion con las cotas superior (notacion o) e inferior asintoticas : ",
        "snippet": "En análisis de algoritmos una cota inferior asintótica es una función que sirve de cota inferior de otra función cuando el argumento tiende a infinito. Usualmente se utiliza la notación Ω(g(x)) para referirse a las funciones acotadas inferiormente por la función g(x).",
        "enlaces_salientes": [
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Notaci%C3%B3n_de_Landau",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Cota_ajustada_asint%C3%B3tica",
        "titulo": "Cota ajustada asintótica",
        "contenido": "en analisis de algoritmos una cota ajustada asintotica es una funcion que sirve de cota tanto superior como inferior de otra funcion cuando el argumento tiende a infinito. usualmente se utiliza la notacion θ(g(x)) para referirse a las funciones acotadas por la funcion g(x).  mas formalmente se define:   θ ( g ( x ) ) = { f ( x ) : existen c 1 , c 2 , x 0 constantes positivas tales que ∀ x : x 0 ≤ x : 0 ≤ c 1 g ( x ) ≤ f ( x ) ≤ c 2 g ( x ) } f(x):}c_{1},c_{2},x_{0}}\\\\\\forall x:x_{0}\\leq x:0\\leq c_{1}g(x)\\leq f(x)\\leq c_{2}g(x)\\end{matrix}}\\right\\}}  una funcion f(x) pertenece a θ(g(x)) cuando existen constantes positivas c 1 } y c 2 } tales que a partir de un valor x 0 } f(x) se encuentra atrapada entre c 1 g ( x ) g(x)} y c 2 g ( x ) g(x)} . quiere decir que las funciones f y g son iguales a partir de un valor dado salvo por una factor constante. por tanto tiene sentido tomar a g como un representante de f.  a pesar de que θ(g(x)) esta definido como un conjunto, se acostumbra escribir f(x)=θ(g(x)) en lugar de f(x)∈θ(g(x)). muchas veces tambien se habla de la funcion x² en lugar de h(x)=x² siempre que este claro cual es el parametro de la funcion dentro de la expresion. en la grafica se da un ejemplo esquematico de como se comportan c 1 g ( x ) g(x)} y c 2 g ( x ) g(x)} con respecto a f(x) cuando x tiende a infinito.  la cota ajustada asintotica tiene relacion con las cotas superior e inferior asintoticas (respectivamente las notaciones o y ω):   f ( x ) = θ ( g ( x ) ) si y solo si f ( x ) = o ( g ( x ) ) y f ( x ) = ω ( g ( x ) ) }f(x)=o(g(x))}f(x)=\\omega (g(x))\\,} ",
        "snippet": "En análisis de algoritmos una cota ajustada asintótica es una función que sirve de cota tanto superior como inferior de otra función cuando el argumento tiende a infinito. Usualmente se utiliza la notación Θ(g(x)) para referirse a las funciones acotadas por la función g(x).",
        "enlaces_salientes": [
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Bien_definido",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/As%C3%ADntota",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Complejidad_computacional",
        "titulo": "Teoría de la complejidad computacional",
        "contenido": "la teoria de la complejidad  computacional​ o teoria de la complejidad informatica es una rama de la teoria de la computacion que se centra en la clasificacion de los problemas computacionales de acuerdo con su dificultad inherente, y en la relacion entre dichas clases de complejidad.​  un problema se cataloga como \"inherentemente \" si su solucion requiere de una cantidad significativa de recursos computacionales, sin importar el algoritmo utilizado. la teoria de la complejidad computacional formaliza dicha aseveracion, introduciendo  modelos de computacion matematicos para el estudio de estos problemas y la cuantificacion de la cantidad de recursos necesarios para resolverlos, como tiempo y memoria.  una de las metas de la teoria de la complejidad computacional es determinar los limites practicos de que es lo que se puede hacer en una computadora y que no. otros campos relacionados con la teoria de la complejidad computacional son el analisis de algoritmos y la teoria de la computabilidad. una diferencia significativa entre el analisis de algoritmos y la teoria de la complejidad computacional, es que el primero se dedica a determinar la cantidad de recursos requeridos por un algoritmo en particular para resolver un problema, mientras que la segunda, analiza todos los posibles algoritmos que pudieran ser usados para resolver el mismo problema.  la teoria de la complejidad computacional trata de clasificar los problemas que pueden, o no pueden ser resueltos con una cantidad determinada de recursos. a su vez, la imposicion de restricciones sobre estos recursos, es lo que la distingue de la teoria de la computabilidad, la cual se preocupa por que tipo de problemas pueden ser resueltos de manera algoritmica.  antes de que se realizaran investigaciones en torno a la complejidad de los algoritmos, se crearon los cimientos de esta teoria por varios investigadores. uno de los aportes mas influyentes fue la definicion de las maquinas de turing en 1936,​ las cuales resultaron ser una nocion de computadora muy flexible y robusta. a medida que las computadoras se desarrollaban en los 40's y los 50's, la maquina de turing demostro ser el modelo teorico correcto de computo.  sin embargo, rapidamente se descubrio que el modelo basico de la maquina de turing fallaba al cuantificar el tiempo y la memoria requerida por una computadora, un problema critico hoy en dia, y aun mas en aquellos tiempos. la idea de medir el tiempo y espacio como una funcion de la longitud de la entrada se origino a principios de los 60s por hartmanis y stearns, y asi nacio la teoria de la complejidad computacional.  en los inicios, los investigadores trataban de entender las nuevas medidas de complejidad, y como se relacionaban unas con otras. en 1965, edmonds definio un \"buen\" algoritmo como uno con un tiempo de ejecucion acotado por un polinomio, es decir, con un tiempo de ejecucion polinomico.​ esto condujo al surgimiento de uno de los conceptos mas importantes de la teoria de la complejidad computacional: la np-completitud y su pregunta fundamental, si p=np.  el campo comenzo a florecer cuando el investigador estadounidense stephen cook y el sovietico leonid levin, trabajando de manera independiente, probaron que existen problemas relevantes que son np-completos. en 1972, richard karp llevo esta idea un paso mas adelante, demostrando que 21 problemas  combinatorios y de teoria de grafos, caracterizados por ser computacionalmente intratables, eran np-completos.​ tambien en los 70's, se produjo un crecimiento de las clases de complejidad a medida que los investigadores trataban de comprender los distintos modelos de computo existentes.  en los 80's, se produjo un auge de los modelos finitos, que analizaban el proceso de computo de una manera inherentemente distinta. surgio un nuevo acercamiento a problemas como p=np, y aun cuando estos modelos tenian sus limitaciones separando las clases de complejidad, esta aproximacion introdujo tecnicas combinatorias que permitieron un mejor entendimiento de los limites de estos modelos.  ya en los 90's, se estudiaron nuevos modelos de computo como las computadoras cuanticas, donde una misma tarea puede tener diferente complejidad en la computacion clasica y en la computacion cuantica. sin embargo, existen varias limitantes, entre ellas, la de desarrollar un hardware para este modelo, y que se requieren grandes cantidades de espacio para realizar los calculos.  para poder referirnos a problemas como \"inherentemente intratables\" y problemas de dificultad \"equivalente\", es necesario comprender algunos terminos mas basicos.​  un problema computacional constituye una pregunta a ser respondida, teniendo generalmente varios parametros, o variables libres, cuyos valores no se han especificado. un problema se describe mediante:  una instancia de un problema se obtiene cuando se especifican valores particulares para todos los parametros del problema. por ejemplo, consideremos el problema del test de primalidad. la instancia es un numero (e.g. 15) y la solucion es \"si\" si el numero es primo, y \"no\" en caso contrario. visto de otra manera, la instancia es una entrada particular del problema, y la solucion es la salida correspondiente para la entrada dada.  un problema de decision es un tipo especial de problema computacional cuya respuesta es solamente \"si\" o \"no\" (o, de manera mas formal, \"1\" o \"0\").  un problema de decision pudiera verse como un lenguaje formal, donde los elementos que pertenecen al lenguaje son las instancias del problema cuya respuesta es \"si\", los que no pertenecen al lenguaje son aquellas instancias cuya respuesta es \"no\". el objetivo es decidir, con la ayuda de un algoritmo, si una determinada entrada es un elemento del lenguaje formal considerado. si el algoritmo devuelve como respuesta \"si\", se dice que el algoritmo acepta la entrada, de lo contrario se dice que la rechaza.  los problemas de decision constituyen uno de los principales objetos de estudio de la teoria de la complejidad computacional, pues la np-completitud se aplica directamente a estos tipos de problemas en vez de a problemas de optimizacion. estos problemas tienen gran importancia porque casi todo problema puede transformarse en un problema de decision.  podemos decir informalmente, que los algoritmos son procedimientos paso-a-paso para resolver problemas. se puede pensar en ellos como simples programas de computadora, escritos en un lenguaje artificial especifico.​  se dice que un algoritmo resuelve un problema a, si dicho algoritmo se puede aplicar a cualquier instancia i de a, y se garantiza que siempre produce una solucion para dicha instancia. de manera general, nos interesa encontrar el algoritmo mas \"eficiente\" para resolver cierto problema. en su sentido mas amplio, la nocion de eficiencia involucra a todos los recursos computacionales necesarios para la ejecucion de un algoritmo.  por algoritmo \"mas eficiente\" usualmente nos referimos al mas rapido. debido a que los requerimientos de tiempo son usualmente un factor dominante cuando se trata de determinar si un algoritmo es lo suficientemente eficiente para ser util en la practica, nos concentraremos en este recurso.  los cientificos de la computacion realizan la distincion entre algoritmos de tiempo polinomico y algoritmos de tiempo exponencial cuando se trata de caracterizar a los algoritmos como \"suficientemente eficiente\" y \"muy ineficiente\" respectivamente.  un algoritmo de tiempo polinomial​ se define como aquel con funcion de complejidad temporal dentro de una cota superior asintotica (denominada a veces \"orden\") o(p(n)) para alguna funcion polinomica p, donde n denota el tamaño de la entrada. los algoritmos de tiempo exponencial, o ( e n ) , ),} son los que el numero de ciclos que tienen que realizarse con el algoritmo es proporcional a la funcion e n } de modo que el poder computacional necesario para correr el algoritmo crece de forma exponencial al tamaño n del problema.  la mayoria de los algoritmos de tiempo exponencial son simples variaciones de una busqueda exhaustiva, mientras que los algoritmos de tiempo polinomial, usualmente se obtienen mediante un analisis mas profundo de la estructura del problema. en la teoria de la complejidad computacional, existe el consenso de que un problema no esta \"bien resuelto\" hasta que se conozca un algoritmo de tiempo polinomial que lo resuelva. por tanto, nos referiremos a un problema como intratable, si es tan dificil que no existe algoritmo de tiempo polinomial capaz de resolverlo.​  una clase de complejidad es un conjunto de problemas que poseen la misma complejidad computacional.  las clases de complejidad mas sencillas se definen teniendo en cuenta factores como:  la clase p contiene a aquellos problemas resolubles en tiempo polinomico por una maquina de turing determinista.​  para la definicion anterior se ha fijado el modelo de computo: la maquina de turing determinista. existen distintas variantes de la maquina de turing y es conocido que la mas debil de ellas puede simular a la mas fuerte, adicionando a lo sumo un tiempo polinomico. en las decadas posteriores a la tesis de church-turing surgieron otros modelos de computo, y se pudo mostrar que la maquina de turing tambien podia simularlos a lo sumo adicionando tambien un tiempo polinomico. por tanto, la clase analoga a p para dichos modelos no es mayor que la clase p para el modelo de computo de la maquina de turing.  la clase p juega un papel importante en la teoria de la complejidad computacional debido a que:  muchas veces podemos evitar utilizar la fuerza bruta en los problemas para obtener soluciones en tiempo polinomico. sin embargo, para algunos problemas esto no ha podido lograrse, es decir, no se conocen algoritmos que los resuelvan en tiempo polinomico. quizas estos problemas tengan algoritmos en tiempo polinomial que se basan en principios por ahora desconocidos, o quizas estos problemas no pueden ser resueltos en tiempo polinomico, debido a que son \"inherentemente dificiles\".  la clase de complejidad np consta de los problemas \"verificables\" en tiempo polinomico. por verificable se entiende a un problema tal que dado un certificado de solucion (candidato a solucion), se puede verificar que dicho certificado es correcto en un tiempo polinomico en el tamaño de la entrada. a los problemas en la clase np usualmente se les llama problemas np.​  el termino np proviene de no determinista en tiempo polinomico y se deriva de un caracterizacion alternativa de esta clase, donde se utilizan maquinas de turing no deterministas. informalmente, se puede definir la clase np en terminos de un algoritmo no determinista (recordar la equivalencia entre algoritmo y maquina de turing).  el algoritmo mencionado esta compuesto por 2 etapas separadas. dada una instancia del problema i, la primera etapa simplemente \"adivina\" un candidato a solucion s. entonces, la etapa de verificacion recibe como entrada a i y a s, y procede a realizar el computo de una manera determinista, finalmente deteniendose con la respuesta \"si\", o con la respuesta \"no\", o sigue computando sin detenerse.  al igual que la clase p, la clase np es insensible a la eleccion del modelo de computo no determinista, debido a que dichos modelos son equivalentes polinomicamente.  muchas clases de complejidad importantes pueden ser definidas acotando el tiempo o el espacio utilizado por el algoritmo. algunas de estas clases de problemas de decision son:  la relacion entre las clases p y np es fundamental para la teoria de la np-completitud. intuitivamente, creemos que p es un subconjunto de np. y, efectivamente, cada problema de decision resuelto por un algoritmo de tiempo polinomial determinista, tambien puede ser resuelto por un algoritmo de tiempo polinomial no determinista. simplemente se necesita observar que cualquier algoritmo determinista puede ser utilizado en la etapa de verificacion de un algoritmo no determinista. si b es un problema de p, y a es un algoritmo de tiempo polinomial para b, entonces se puede construir un algoritmo de tiempo polinomial no determinista para b, simplemente utilizando a en la etapa de verificacion e ignorando la etapa de adivinacion. por tanto, si b pertenece a p, entonces b tambien pertenece a np.  la pregunta p=np es una de las mas importantes en el campo de las ciencias de la computacion, debido a las grandes repercusiones que habria, en caso de encontrarse una solucion. si p=np, cualquier problema polinomica mente verificable seria polinomica mente decidible. la mayoria de los investigadores cree que estas clases no son iguales, porque se ha realizado bastantes esfuerzos, sin exito, para encontrar algoritmos de tiempo polinomial para varios problemas en np. los investigadores tambien han tratado de probar que las clases son distintas, pero eso conllevaria a mostrar que no existe un algoritmo «eficiente» para reemplazar a la busqueda por fuerza bruta.  una reduccion es una transformacion de un problema en otro problema. intuitivamente, un problema q puede ser reducido a otro problema q', si cualquier instancia del problema q puede ser \"facilmente\" expresada como una instancia del problema q', y cuya solucion proporcione una solucion para la instancia de q.​  existen muchos tipos de reducciones: basadas en el metodo de reduccion, como las reducciones de cook, las reducciones de karp y las reducciones de levin, y las basadas en la cota de la complejidad, como la  reduccion en tiempo polinomial o la reduccion de espacio logaritmica. una de las reducciones mas utilizadas es la reduccion en tiempo polinomial, lo cual significa que el proceso de reduccion toma un tiempo polinomial.  las reducciones en tiempo polinomial nos dotan de elementos para probar, de una manera formal, que un problema es al menos tan dificil que otro, con una diferencia de un factor polinomial. estas son esenciales para definir a los  problemas np-completos, ademas de ayudar a comprender los mismos.  la clase de los problemas np-completos contiene a los problemas mas dificiles en np, en el sentido de que son los que esten mas lejos de estar en p. debido a que el problema p=np no ha sido resuelto, el hecho de reducir un problema b, a otro problema a, indicaria que no se conoce solucion en tiempo polinomial para a. esto es debido a que una solucion en tiempo polinomial para a, tendria como consecuencia la existencia de una solucion polinomial para b. de manera similar, debido a que todos los problemas np pueden ser reducidos a este conjunto, encontrar un problema np-completo que pueda ser resuelto en un tiempo polinomial significaria que p=np.  quizas la razon de mayor peso por la cual los cientificos de la computacion creen que p es distinto de np, es la existencia de la clase de problemas \"np-completos\". esta clase tiene la curiosa propiedad de que si algun problema np-completo puede ser resuelto en tiempo polinomial, entonces todo problema en np tiene una solucion en tiempo polinomial, es decir, p=np. a pesar de años de estudio, ningun algoritmo de tiempo polinomial se ha descubierto para ningun problema np-completo.  desde el punto de vista teorico, un investigador intentando mostrar que la clase p es distinta de la clase np, pudiera enfocarse en un problema np-completo. si algun problema en np requiere mas que un tiempo polinomial, entonces uno np-completo tambien. ademas, un investigador intentando demostrar que p=np, solo necesita encontrar un algoritmo de tiempo polinomial para un problema np-completo para lograrlo.  desde el punto de vista practico, el fenomeno de la np-completitud puede prevenir la perdida de tiempo cuando se busca un algoritmo de tiempo polinomial no existente para resolver un problema determinado. aun cuando no se posean los elementos matematicos para demostrar que cierto problema no se puede resolver en tiempo polinomial, creemos que p no es igual a np, asi que demostrar que el problema es np-completo, es una fuerte evidencia de su no \"polinomialdad\".  teniendo en cuenta la definicion de problema intratable, si no se cumple que p=np, entonces los problemas np-completos son intratables.  muchos problemas de la practica son np-completos, y son muy importantes como para desistir simplemente porque no sabemos como encontrar una solucion optima en tiempo polinomial. aunque un problema sea np-completo, puede haber esperanza. existen tres estrategias fundamentales para lidiar con un problema np-completo: ",
        "snippet": "La teoría de la complejidad computacional[1]​ o teoría de la complejidad informática es una rama de la teoría de la computación que se centra en la clasificación de los problemas computacionales de acuerdo con su dificultad inherente, y en la relación entre dichas clases de complejidad.[2]​",
        "enlaces_salientes": [
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Gram%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Problema_computacional",
            "/wiki/Clase_de_complejidad",
            "/wiki/Modelo_de_computaci%C3%B3n",
            "/wiki/Computadora",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Jack_Edmonds",
            "/wiki/Tiempo_de_ejecuci%C3%B3n",
            "/wiki/Polinomio",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/NP-completo",
            "/wiki/Clases_de_complejidad_P_y_NP",
            "/wiki/Stephen_Cook",
            "/wiki/Leonid_Levin",
            "/wiki/Richard_Karp",
            "/wiki/Combinatoria",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Problema_computacional",
            "/wiki/Problema_de_decisi%C3%B3n",
            "/wiki/Algoritmo",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/Tiempo_exponencial",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/O_grande",
            "/wiki/Clase_de_complejidad",
            "/wiki/P_(clase_de_complejidad)",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/NP_(clase_de_complejidad)",
            "/wiki/DTIME",
            "/wiki/P_(clase_de_complejidad)",
            "/wiki/PP_(clase_de_complejidad)",
            "/wiki/EXPTIME",
            "/wiki/NTIME",
            "/wiki/NP_(clase_de_complejidad)",
            "/wiki/NEXPTIME",
            "/wiki/DSPACE",
            "/wiki/L_(clase_de_complejidad)",
            "/wiki/PSPACE",
            "/wiki/EXPSPACE",
            "/wiki/NSPACE",
            "/wiki/NL_(clase_de_complejidad)",
            "/wiki/NPSPACE",
            "/wiki/EXPSPACE",
            "/wiki/Clases_de_complejidad_P_y_NP",
            "/wiki/Transformaci%C3%B3n_polin%C3%B3mica",
            "/wiki/Transformaci%C3%B3n_polin%C3%B3mica",
            "/wiki/NP-completo",
            "/wiki/NP-completo",
            "/wiki/Algoritmo_de_aproximaci%C3%B3n",
            "/wiki/Heur%C3%ADstica",
            "/wiki/Metaheur%C3%ADstica",
            "/wiki/Reducci%C3%B3n_(complejidad)",
            "/wiki/Teorema_de_Cook-Levin",
            "/wiki/Lista_de_21_problemas_NP-completos_de_Karp",
            "/wiki/Clases_de_complejidad_P_y_NP",
            "/wiki/Teorema_de_la_jerarqu%C3%ADa_temporal",
            "/wiki/Complejidad_de_Kolmog%C3%B3rov",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/MIT_Press",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/Stephen_Cook",
            "/wiki/ISSN",
            "/wiki/Sanjeev_Arora",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/Zentralblatt_MATH",
            "/wiki/ISBN",
            "/wiki/Michael_Garey",
            "/wiki/David_S._Johnson",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Ronald_L._Rivest",
            "/wiki/Clifford_Stein",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Diagrama_de_flujo",
        "titulo": "Diagrama de flujo",
        "contenido": "el diagrama de flujo o flujograma o diagrama de actividades es la representacion grafica de un algoritmo o proceso. se utiliza en disciplinas como programacion, economia, procesos industriales y psicologia cognitiva.  en lenguaje unificado de modelado (uml), es un diagrama de actividades que representa los flujos de trabajo paso a paso. un diagrama de actividades muestra el flujo de control general.  en sysml el diagrama ha sido extendido para indicar flujos entre pasos que mueven elementos fisicos (p. ej., gasolina) o energia (p. ej., presion). los cambios adicionales permiten al diagrama soportar mejor flujos de comportamiento y datos continuos.  estos diagramas utilizan simbolos con significados definidos que representan los pasos del algoritmo, y representan el flujo de ejecucion mediante flechas que conectan los puntos de inicio y de fin del proceso.  las siguientes son acciones previas a la realizacion del diagrama de flujo:  los pasos a seguir para construir el diagrama de flujo son:  en uml 1.x, un diagrama de actividades es una variacion del diagrama de estado unl donde los \"estados\" representan operaciones, y las transiciones representan las actividades que ocurren cuando la operacion se termina.  el diagrama de mensajes de uml 2.0, mientras que es similar en aspecto al diagrama de actividades uml 1.x, ahora tiene semanticas basadas en redes de petri. en uml 2.0, el diagrama general de interaccion esta basado en el diagrama de actividades. el diagrama de actividad es una forma especial de diagrama de estado usado para modelar una secuencia de acciones y condiciones tomadas dentro de un proceso.  la especificacion del lenguaje de notificacion unificado (unl) define un diagrama de actividad como:  el proposito del diagrama de actividad es modelar un proceso de flujo de trabajo (workflow) y/o modelar operaciones.  una operacion es un servicio proporcionado por un objeto, que esta disponible a traves de una interfaz.  una interfaz es un grupo de operaciones relacionadas con la semantica.  1.-segun gomez cejas, guillermo. año 1997:  2.-segun chiavenato, idalberto. año 1993:  3.-segun gomez rondon, francisco. año 1995:  el instituto nacional estadounidense de estandares (ansi, por su siglas en ingles) establecio estandares para los diagramas de flujo y sus simbolos en los años 1960s.​ la organizacion internacional de normalizacion (iso, por sus siglas en ingles) adopto los simbolos ansi en 1970.​ el estandar actual, iso 5807, fue revisado en 1985.​  se trata de la mas comun y practica entre todas las clases de diagramas de flujo. describe el flujo de informacion en un ente u organizacion, sus procesos, sistemas administrativos y de control. permite la impresion visual de los procedimientos y una clara y logica interpretacion.  segun la normativa, el flujo presupuesto es de izquierda a derecha y de arriba hacia abajo, siendo optativo el uso de flechas. cuando el sentido es invertido (de derecha a izquierda o de abajo hacia arriba), es obligatorio el uso de la flecha.​  la paternidad del diagrama de flujo es en principio algo difusa. el metodo estructurado para documentar graficamente un proceso como un flujo de pasos sucesivos y alternativos, el \"proceso de diagrama de flujo\", fue expuesto por frank gilbreth, en la sociedad americana de ingenieros mecanicos (asme), en 1921, bajo el enunciado de \"proceso de graficas-primeros pasos para encontrar el mejor modo\". estas herramientas de gilbreth rapidamente encontraron sitio en los programas de ingenieria industrial.  al principio de los 30, un ingeniero industrial, allan h. mogensen comenzo la formacion de personas de negocios en lake placid, nueva york, incluyendo el uso del diagrama de flujo. art spinanger, asistente a las clases de mogesen, utilizo las herramientas en su trabajo en procter & gamble, donde desarrollo su “programa metodico de cambios por etapas”. otro asistente al grupo de graduados en 1944, ben s. graham, director de ingenieria de formcraft standard register corporation, adapto la grafica de flujo de procesos al tratamiento de la informacion en su empresa. y desarrollo la grafica del proceso de multiples flujos en multiples pantallas, documentos, y sus relaciones. en 1947, asme adopto un conjunto de simbolos derivados de la obra original de gilbreth como norma asme para los graficos de procesos (preparada mishad, ramsan y raiaan).  sin embargo, segun explica douglas hartree fueron originalmente herman goldstine y john von neumann quienes desarrollaron el diagrama de flujo (inicialmente llamado \"diagrama\") para planificar los programas de ordenador. las tablas de programacion original de flujo de goldstine y von neumann, aparecen en un informe no publicado, \"planificacion y codificacion de los problemas de un instrumento de computacion electronica, la parte ii, volumen 1 \"(1947), reproducido en las obras completas de von neumann.  inicialmente los diagramas de flujo resultaron un medio popular para describir algoritmos de computadora, y aun se utilizan con este fin. herramientas como los diagramas de actividad uml, pueden ser considerados como evoluciones del diagrama de flujo.  en la decada de 1970 la popularidad de los diagramas de flujo como metodo propio de la informatica disminuyo, con el nuevo hardware y los nuevos lenguajes de programacion de tercera generacion. y por otra parte se convirtieron en instrumentos comunes en el mundo empresarial. son una expresion concisa, legible y practica de algoritmos. actualmente se aplican en muchos campos del conocimiento, especialmente como simplificacion y expresion logica de procesos, etc.  actualmente existe una gran cantidad de software para la elaboracion de diagramas de flujo. a continuacion se listan los programas mas comunes para elaborar diagramas de flujo.  tambien existen aplicaciones que permiten que, una vez que un creador haya diseñado el diagrama de flujo, un usuario final lo utilice y, sobre la base de las opciones que vaya escogiendo, se le vayan mostrando las siguientes etapas hasta llegar a un resultado final. un ejemplo de este tipo de aplicaciones es iboske. ",
        "snippet": "El diagrama de flujo o flujograma o diagrama de actividades es la representación gráfica de un algoritmo o proceso. Se utiliza en disciplinas como programación, economía, procesos industriales y psicología cognitiva.",
        "enlaces_salientes": [
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Diagrama_de_flujo",
            "/wiki/L%C3%A1mpara",
            "/wiki/Bucle_for",
            "/wiki/Gr%C3%A1fica",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Econom%C3%ADa",
            "/wiki/Proceso_de_fabricaci%C3%B3n",
            "/wiki/Psicolog%C3%ADa_cognitiva",
            "/wiki/Lenguaje_Unificado_de_Modelado",
            "/wiki/Flujo_de_trabajo",
            "/wiki/SysML",
            "/wiki/Red_de_Petri",
            "/wiki/Instituto_Nacional_Estadounidense_de_Est%C3%A1ndares",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/Estadio_(geometr%C3%ADa)",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/Paralelogramo",
            "/wiki/Campo_de_b%C3%A9isbol#Home_plate",
            "/wiki/Pent%C3%A1gono",
            "/wiki/%C3%93valo",
            "/wiki/Elipse",
            "/wiki/Rect%C3%A1ngulo",
            "/wiki/Rombo",
            "/wiki/C%C3%ADrculo",
            "/wiki/Tri%C3%A1ngulo",
            "/wiki/Lake_Placid",
            "/wiki/Nueva_York",
            "/wiki/Herman_Goldstine",
            "/wiki/John_von_Neumann",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Ordenador",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/Microsoft_Office",
            "/wiki/Microsoft_Word",
            "/wiki/Microsoft_Excel",
            "/wiki/Microsoft_PowerPoint",
            "/wiki/Microsoft_Visio",
            "/wiki/LibreOffice_Draw",
            "/wiki/GitMind",
            "/wiki/XMind",
            "/wiki/DRAKON",
            "/wiki/UML",
            "/wiki/Flujo_de_trabajo",
            "/wiki/Red_de_Petri",
            "/wiki/Diagrama_de_secuencia",
            "/wiki/Algoritmo",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Resoluci%C3%B3n_de_problemas_de_programaci%C3%B3n",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Estructuras_de_control",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/Bucle_for",
            "/wiki/Bucle_while",
            "/wiki/Bucle_repetir",
            "/wiki/Bucle_infinito",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/National_Archives_and_Records_Administration",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Diagrama_Nassi-Shneiderman",
        "titulo": "Diagrama Nassi-Shneiderman",
        "contenido": "en programacion de computadores un diagrama nassi-shneiderman (o nsd por sus siglas en ingles), tambien conocido como diagrama de chapin​​ es una representacion grafica que muestra el diseño de un programa estructurado.​  fue desarrollado en 1972 por isaac nassi y ben shneiderman. este diagrama tambien es conocido como estructograma, ya que sirve para representar la estructura de los programas. combina la descripcion textual del pseudocodigo con la representacion grafica del diagrama de flujo.  basado en un diseño top-down (de lo mas complejo a lo mas simple), el problema que se debe resolver se divide en subproblemas cada vez mas pequeños —y simples— hasta que solo queden instrucciones simples y construcciones para el control de flujo. el diagrama nassi-shneiderman refleja la descomposicion del problema en una forma simple usando cajas anidadas para representar cada uno de los subproblemas. para mantener una consistencia con los fundamentos de la programacion estructurada, los diagramas nassi-shneiderman no tienen representacion para las instrucciones goto.  los diagramas nassi-shneiderman se utilizan muy raramente en las tareas de programacion analitica. su nivel de abstraccion es muy cercano al codigo de la programacion estructurada y ciertas modificaciones requieren que se redibuje todo el diagrama.​  los diagramas nassi-shneiderman son (la mayoria de las veces) isomorficos con los diagramas de flujo. todo lo que se puede representar con un diagrama nassi-shneiderman se puede representar con un diagrama de flujo. las unicas excepciones se dan en las instrucciones goto, break y continue.  bloques de procesos el bloque de proceso representa el paso mas simple y no requiere ningun analisis especifico. cuando un bloque de proceso es encontrado, la accion dentro del bloque se realiza, y pasamos directamente al siguiente bloque.  bloques ramificados hay dos tipos de estos bloques. el primero y mas sencillo de ellos es el bloque verdadero-falso el cual ofrece al programa dos caminos para tomar, dependiendo de si una determinada condicion ha sido especificada. estos bloques pueden ser usados como bucles que detienen el programa hasta que una determinada condicion se cumpla.  el segundo tipo es un bloque ramificado multiple. este tipo de bloque es utilizado cuando se necesita la seleccion de un caso en un programa . el bloque suele contener una pregunta. ademas, el bloque le da al programa una cadena de oportunidades y es generalmente usado en las conjunciones con bloques de subprocesos para ahorrar espacio.  bucles testeadores: este bloque permite al programa repetir un bloque o un conjunto de bloques  hasta que una determinada condicion se haya cumplido.  hay dos tipos de estos bloques: de testeo inicial y testeo final. la unica diferencia entre los dos es el orden  en el cual se completan los pasos involucrados en el proceso. en los de la primera situacion, cuando el programa encuentra el bloque, testea si la condicion necesaria se cumple, si no, se repite el bucle. el test se repite hasta que se cumpla dicha condicion. en el nivel que se cumpla la condicion, el programa detiene la ejecucion del bucle y pasa a analizar los bloques del siguiente nivel.  los de testeo final operan al reves.  una expresion concurrente puede ser dibujada asi:​   ",
        "snippet": "En programación de computadores un diagrama Nassi-Shneiderman (o NSD por sus siglas en inglés), también conocido como diagrama de Chapin[1]​[2]​ es una representación gráfica que muestra el diseño de un programa estructurado.[3]​",
        "enlaces_salientes": [
            "/wiki/Diagrama_Nassi-Shneiderman",
            "/wiki/Diagrama_Nassi-Shneiderman",
            "/wiki/Diagrama_Nassi-Shneiderman",
            "/wiki/Ben_Shneiderman",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/Diagrama",
            "/wiki/Isom%C3%B3rfico",
            "/wiki/Diagramas_de_flujo",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Linux",
            "/wiki/Mac_OS_X",
            "/wiki/Microsoft_Windows",
            "/wiki/GNU_General_Public_License",
            "/wiki/GNU_General_Public_License",
            "/wiki/GNU_General_Public_License",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/M%C3%A1quina_de_Turing",
        "titulo": "Máquina de Turing",
        "contenido": " una maquina de turing es un dispositivo que manipula simbolos sobre una tira de cinta de acuerdo con una tabla de reglas. a pesar de su simplicidad, una maquina de turing puede ser adaptada para simular la logica de cualquier algoritmo de computador y es particularmente util en la explicacion de las funciones de una cpu dentro de un computador.  originalmente fue definida por el matematico ingles alan turing como una «maquina automatica» en 1936 en la revista proceedings of the london mathematical society[nota 1]​. la maquina de turing no esta diseñada como una tecnologia de computacion practica, sino como un dispositivo hipotetico que representa una maquina de computacion. las maquinas de turing ayudan a los cientificos a entender los limites del calculo mecanico.​​  turing dio una definicion sucinta del experimento en su ensayo de 1948, «maquinas inteligentes». refiriendose a su publicacion de 1936, turing escribio que la maquina de turing, aqui llamada una maquina de computacion logica, consistia en:  una maquina de turing que es capaz de simular cualquier otra maquina de turing es llamada una maquina universal de turing (utm, o simplemente una maquina universal). una definicion mas matematicamente orientada, con una similar naturaleza \"universal\", fue presentada por alonzo church, cuyo trabajo sobre el calculo lambda se entrelaza con el de turing en una teoria formal de la computacion conocida como la tesis de church-turing. la tesis señala que las maquinas de turing capturan, de hecho, la nocion informal de un metodo eficaz en la logica y las matematicas y proporcionan una definicion precisa de un algoritmo o 'procedimiento mecanico'.  la importancia de la maquina de turing en la historia de la computacion es doble: primero, la maquina de turing fue uno de los primeros (si no el primero) modelos teoricos para las computadoras, viendo la luz en 1936. segundo, estudiando sus propiedades abstractas, la maquina de turing ha servido de base para mucho desarrollo teorico en las ciencias de la computacion y en la teoria de la complejidad. una razon para esto es que las maquinas de turing son simples, y por tanto amenas al analisis. dicho esto, cabe aclarar que las maquinas de turing no son un modelo practico para la computacion en maquinas reales, las cuales precisan modelos mas rapidos como los basados en ram.  alan turing introdujo el concepto de maquina de turing en el trabajo on computable numbers, with an application to the entscheidungsproblem, publicado por la sociedad matematica de londres en 1936, en el que se estudiaba la cuestion planteada por david hilbert sobre si las matematicas son decidibles, es decir, si hay un metodo definido que pueda aplicarse a cualquier sentencia matematica y que nos diga si esa sentencia es cierta o no. turing ideo un modelo formal de computador, la maquina de turing, y demostro que existian problemas que una maquina no podia resolver.​  con este aparato extremadamente sencillo es posible realizar cualquier computo que un computador digital sea capaz de realizar.​  mediante este modelo teorico y el analisis de la complejidad de los algoritmos, fue posible la categorizacion de problemas computacionales de acuerdo a su comportamiento, apareciendo asi, el conjunto de problemas denominados p y np, cuyas soluciones pueden encontrarse en tiempo polinomico por maquinas de turing deterministas y no deterministas, respectivamente.  precisamente, la tesis de church-turing formulada por alan turing y alonzo church, de forma independiente a mediados del siglo xx caracteriza la nocion informal de computabilidad con la computacion mediante una maquina de turing.​  la idea subyacente es el concepto de que una maquina de turing puede verse como un automata ejecutando un procedimiento efectivo definido formalmente, donde el espacio de memoria de trabajo es ilimitado, pero en un momento determinado solo una parte finita es accesible.  la maquina de turing modela matematicamente a una maquina que opera mecanicamente sobre una cinta. en esta cinta hay simbolos que la maquina puede leer y escribir, uno a la vez, usando un cabezal lector/escritor de cinta. la operacion esta completamente determinada por un conjunto finito de instrucciones elementales como \"en el estado 42, si el simbolo visto es 0, escribe un 1; si el simbolo visto es 1, cambia al estado 17; en el estado 17, si el simbolo visto es 0, escribe un 1 y cambia al estado 6; etc\". en el articulo original (\"sobre numeros computables con una aplicacion al entscheidungsproblem\"), turing no imagina un mecanismo, sino una persona a la que el llama la \"computadora\", quien ejecuta servilmente estas reglas mecanicas deterministas (o como turing pone, \"de una manera desganada\").  mas precisamente, una maquina de turing consta de:  note que cada parte de la maquina — su estado y colecciones de simbolos — y sus acciones — imprimir, borrar, movimiento de la cinta — es finito, discreto y distinguible; es la cantidad potencialmente ilimitada de cinta lo que le da una cantidad ilimitada de espacio de almacenamiento.  una maquina de turing​ es un modelo computacional que realiza una lectura/escritura de manera automatica sobre una entrada llamada cinta, generando una salida en esta misma.  este modelo esta formado por un alfabeto de entrada y uno de salida, un simbolo especial llamado blanco (normalmente b, δ o 0), un conjunto de estados finitos y un conjunto de transiciones entre dichos estados. su funcionamiento se basa en una funcion de transicion, que recibe un estado inicial y una cadena de caracteres (la cinta, la cual puede ser infinita) pertenecientes al alfabeto de entrada. la maquina va leyendo una celda de la cinta en cada paso, borrando el simbolo en el que se encuentra posicionado su cabezal y escribiendo un nuevo simbolo perteneciente al alfabeto de salida, para luego desplazar el cabezal a la izquierda o a la derecha (solo una celda a la vez). esto se repite segun se indique en la funcion de transicion, para finalmente detenerse en un estado final o de aceptacion, representando asi la salida.  una maquina de turing con una sola cinta puede definirse como una 7-tupla  donde:​  existe en la literatura un abundante numero de definiciones alternativas, pero todas ellas tienen el mismo poder computacional, por ejemplo se puede añadir el simbolo s como simbolo de \"no movimiento\" en un paso de computo.  la maquina de turing consta de un cabezal lector/escritor y una cinta infinita en la que el cabezal lee el contenido, borra el contenido anterior y escribe un nuevo valor. las operaciones que se pueden realizar en esta maquina se limitan a:  el computo se determina a partir de una tabla de estados de la forma:  esta tabla toma como parametros el estado actual de la maquina y el caracter leido de la cinta, dando la direccion para mover el cabezal, el nuevo estado de la maquina y el valor a escribir en la cinta.  la memoria es la cinta de la maquina que se divide en espacios de trabajo denominados celdas, donde se pueden escribir y leer simbolos. inicialmente todas las celdas contienen un simbolo especial denominado \"blanco\". las instrucciones que determinan el funcionamiento de la maquina tienen la forma, \"si estamos en el estado x leyendo la posicion y, donde hay escrito el simbolo z, entonces este simbolo debe ser reemplazado por este otro simbolo, y pasar a leer la celda siguiente, bien a la izquierda o bien a la derecha\".  la maquina de turing puede considerarse como un automata capaz de reconocer lenguajes formales. en ese sentido, es capaz de reconocer los lenguajes recursivamente enumerables, de acuerdo a la jerarquia de chomsky. su potencia es, por tanto, superior a otros tipos de automatas, como el automata finito, o el automata con pila, o igual a otros modelos con la misma potencia computacional.   las maquinas de turing pueden representarse mediante grafos particulares, tambien llamados diagramas de estados finitos, de la siguiente manera: es una secuencia de la forma α 1 q α 2 q\\alpha _{2}\\!} donde α 1 , α 2 ∈ γ ∗ ,\\alpha _{2}\\in \\gamma ^{*}} y q ∈ q que escribe el estado de una maquina de turing. la cinta contiene la cadena α 1 α 2 \\alpha _{2}\\!} seguida de infinitos blancos. el cabezal señala el primer simbolo de α 2 \\!} .  por ejemplo, para la maquina de turing  con las transiciones  la descripcion instantanea para la cinta 1011 es:  definimos una maquina de turing sobre el alfabeto { 0 , 1 } } , donde 0 representa el simbolo blanco. la maquina comenzara su proceso situada sobre un simbolo \"1\" de una serie. la maquina de turing copiara el numero de simbolos \"1\" que encuentre hasta el primer blanco detras de dicho simbolo blanco. es decir, posiciona el cabezal sobre el 1 situado en el extremo izquierdo, doblara el numero de simbolos 1, con un 0 en medio. asi, si tenemos la entrada \"111\" devolvera \"1110111\", con \"1111\" devolvera \"111101111\", y sucesivamente.  el conjunto de estados es { s 1 , s 2 , s 3 , s 4 , s 5 } ,s_{2},s_{3},s_{4},s_{5}\\}\\!} y el estado inicial es s 1 \\!} . la tabla que describe la funcion de transicion es la siguiente:  el funcionamiento de una computacion de esta maquina puede mostrarse con el siguiente ejemplo (en negrita se resalta la posicion de la cabeza lectora/escritora):  la maquina realiza su proceso por medio de un bucle, en el estado inicial s 1 \\!} , reemplaza el primer 1 con un 0, y pasa al estado s 2 \\!} , con el que avanza hacia la derecha, saltando los simbolos 1 hasta un 0 (que debe existir), cuando lo encuentra pasa al estado s 3 \\!} , con este estado avanza saltando los 1 hasta encontrar otro 0 (la primera vez no habra ningun 1). una vez en el extremo derecho, añade un 1. despues comienza el proceso de retorno; con s 4 \\!} vuelve a la izquierda saltando los 1, cuando encuentra un 0 (en el medio de la secuencia), pasa a s 5 \\!} que continua a la izquierda saltando los 1 hasta el 0 que se escribio al principio. se reemplaza de nuevo este 0 por 1, y pasa al simbolo siguiente, si es un 1, se pasa a otra iteracion del bucle, pasando al estado s1 de nuevo. si es un simbolo 0, sera el simbolo central, con lo que la maquina se detiene al haber finalizado el computo.  una razon para aceptar la maquina de turing como un modelo general de computo es que el modelo que hemos definido anteriormente es equivalente a muchas versiones modificadas que en principio pareciera incrementar el poder computacional.  la funcion de transicion de la mt sencilla esta definida por  la cual puede ser modificada como  donde s significa «permanecer» o «esperar», es decir no mover el cabezal de lectura/escritura. por lo tanto, δ ( q , σ ) = ( p , σ ′ , s ) significa que se pasa del estado q al p, se escribe σ ′ en la celda actual y la cabeza se queda sobre la celda actual.  esta modificacion se denota al igual que una mt sencilla, lo que la hace diferente es que la cinta es infinita tanto por la derecha como por la izquierda, lo cual permite realizar transiciones iniciales como δ ( q 0 , x ) = ( q 1 , y , l ) ,x)=(q_{1},y,l)\\!} .  es aquella que mediante la cual cada celda de la cinta de una maquina sencilla se divide en subceldas. cada celda es asi capaz de contener varios simbolos de la cinta. por ejemplo, la cinta de la figura tiene cada celda subdividida en tres subceldas.  se dice que esta cinta tiene multiples pistas puesto que cada celda de esta maquina de turing contiene multiples caracteres, el contenido de las celdas de la cinta puede ser representado mediante n-tuplas ordenadas. los movimientos que realice esta maquina dependeran de su estado actual y de la n-tupla que represente el contenido de la celda actual. cabe mencionar que posee un solo cabezal al igual que una mt sencilla.  una mt con mas de una cinta consiste de un control finito con k cabezales lectores/escritores y k cintas. cada cinta es infinita en ambos sentidos. la mt define su movimiento dependiendo del simbolo que esta leyendo cada uno de sus cabezales, da reglas de sustitucion para cada uno de los simbolos y direccion de movimiento para cada uno de los cabezales. inicialmente la mt empieza con la entrada en la primera cinta y el resto de las cintas en blanco.  una mt multidimensional es aquella cuya cinta puede verse como extendiendose infinitamente en mas de una direccion, el ejemplo mas basico seria el de una maquina bidimensional cuya cinta se extenderia infinitamente hacia arriba, abajo, derecha e izquierda.  en la modificacion bidimensional de mt que se muestra en la figura tambien se agregan dos nuevos movimientos del cabezal {u,d} (es decir arriba y abajo). de esta forma la definicion de los movimientos que realiza el cabezal sera {l,r,u,d}.  la entrada de una maquina de turing viene determinada por el estado actual y el simbolo leido, un par (estado, simbolo), siendo el cambio de estado, la escritura de un nuevo simbolo y el movimiento del cabezal, las acciones a tomar en funcion de una entrada. en el caso de que para cada par (estado, simbolo) posible exista a lo sumo una posibilidad de ejecucion, se dira que es una maquina de turing determinista, mientras que en el caso de que exista al menos un par (estado, simbolo) con mas de una posible combinacion de actuaciones se dira que se trata de una maquina de turing no determinista.  la funcion de transicion δ en el caso no determinista, queda definida como sigue:  ¿como sabe una maquina no determinista que accion tomar de las varias posibles? hay dos formas de verlo: una es decir que la maquina es \"el mejor adivino posible\", esto es, que siempre elige la transicion que finalmente la llevara a un estado final de aceptacion. la otra es imaginarse que la maquina se \"clona\", bifurcandose en varias copias, cada una de las cuales sigue una de las posibles transiciones. mientras que una maquina determinista sigue un unico \"camino computacional\", una maquina no determinista tiene un \"arbol computacional\". si cualquiera de las ramas del arbol finaliza en un estado de aceptacion, se dice que la maquina acepta la entrada.  la capacidad de computo de ambas versiones es equivalente; se puede demostrar que dada una maquina de turing no determinista existe otra maquina de turing determinista equivalente, en el sentido de que reconoce el mismo lenguaje, y viceversa. no obstante, la velocidad de ejecucion de ambos formalismos no es la misma, pues si una maquina no determinista m reconoce una cierta palabra de tamaño n en un tiempo o ( t ( n ) ) , la maquina determinista equivalente reconocera la palabra en un tiempo o ( 2 t ( n ) ) )\\!} . es decir, el no determinismo permitira reducir la complejidad de la solucion de los problemas, permitiendo resolver, por ejemplo, problemas de complejidad exponencial en un tiempo polinomico.  el problema de la parada o problema de la detencion (halting problem en ingles) para maquinas de turing consiste en: dada una mt m y una palabra w, determinar si m terminara en un numero finito de pasos cuando se ejecuta usando w como entrada.  alan turing, en su famoso articulo «on computable numbers, with an application to the entscheidungsproblem» (1936), demostro que el problema de la parada de la maquina de turing es indecidible, en el sentido de que ninguna maquina de turing lo puede resolver.  toda maquina de turing puede codificarse como una secuencia binaria finita, es decir una secuencia finita de ceros y unos. para simplificar la codificacion, suponemos que toda mt tiene un unico estado inicial denotado por q 1 \\!} , y un unico estado final denotado q 2 \\!} . tendremos que para una mt m de la forma  todos estos simbolos se codifican como secuencias de unos:  los estados de una mt q 1 , q 2 , q 3 , … , q n ,q_{2},q_{3},\\ldots ,q_{n}\\!} se codifican tambien con secuencias de unos:  las directrices de desplazamiento r , l y s se codifican con 1, 11, 111, respectivamente. una transicion δ ( q , a ) = ( p , c , r ) se codifica usando ceros como separadores entre los estados, los simbolos del alfabeto de cinta y la directriz de desplazamiento r . asi, la transicion δ ( q 3 , s 2 ) = ( q 5 , s 3 , r ) ,s_{2})=(q_{5},s_{3},r)\\!} se codifica como  en general, la codificacion de una transicion cualquiera δ ( q i , s k ) = ( q j , s l , r ) ,s_{k})=(q_{j},s_{l},r)\\!} es  donde t ∈ { 1 , 2 , 3 } \\!} , segun la direccion sea d e r e c h a ( r ) , i z q u i e r d a ( l ) , e s p e r a r ( s ) (r),\\ \\mathrm {izquierda} (l),\\ \\mathrm {esperar} (s)} .  una mt se codifica escribiendo consecutivamente las secuencias de las modificaciones de todas sus transiciones. mas precisamente, la codificacion de una mt m es de la forma c 1 c 2 … c i c_{2}\\ldots c_{i}\\!} , donde c i \\!} es la codificacion de la i -esima transicion de m. puesto que el orden en que se representen las transiciones de una mt no es relevante, una misma mt tiene varias codificaciones diferentes. esto no representa ninguna desventaja practica o conceptual ya que no se pretende que las codificaciones sean unicas.  una maquina de turing computa una determinada funcion parcial de caracter definido e univoca, definida sobre las secuencias de posibles cadenas de simbolos de su alfabeto. en este sentido se puede considerar como equivalente a un programa de ordenador, o a un algoritmo. sin embargo es posible realizar una codificacion de la tabla que representa a una maquina de turing, a su vez, como una secuencia de simbolos en un determinado alfabeto; por ello, podemos construir una maquina de turing que acepte como entrada la tabla que representa a otra maquina de turing, y, de esta manera, simule su comportamiento.  en 1947, turing indico:  con esta codificacion de tablas como cadenas, se abre la posibilidad de que unas maquinas de turing se comporten como otras maquinas de turing. sin embargo, muchas de sus posibilidades son indecidibles, pues no admiten una solucion algoritmica. por ejemplo, un problema interesante es determinar si una maquina de turing cualquiera se parara en un tiempo finito sobre una determinada entrada; problema conocido como problema de la parada, y que turing demostro que era indecidible. en general, se puede demostrar que cualquier cuestion no trivial sobre el comportamiento o la salida de una maquina de turing es un problema indecidible.  el concepto de maquina de turing universal esta relacionado con el de un sistema operativo basico, pues puede ejecutar cualquier instruccion computable sobre el.​  en 1985, deutsch presento el diseño de la primera maquina cuantica basada en una maquina de turing. con este fin enuncio una nueva variante la tesis de church-turing dando lugar al denominado \"principio de church-turing-deutsch\".  la estructura de una maquina de turing cuantica es muy similar a la de una maquina de turing clasica. esta compuesta por los tres elementos clasicos:  el procesador contiene el conjunto de instrucciones que se aplica sobre el elemento de la cinta señalado por el cabezal. el resultado dependera del qubit de la cinta y del estado del procesador. el procesador ejecuta una instruccion por unidad de tiempo.  la cinta de memoria es similar a la de una maquina de turing tradicional. la unica diferencia es que cada elemento de la cinta de la maquina cuantica es un qubit. el alfabeto de esta nueva maquina esta formado por el espacio de valores del qubit. la posicion del cabezal se representa con una variable entera.  dos modelos matematicos equivalentes a los de las maquinas de turing son las maquinas de post, creadas en forma paralela por emil leon post,​ y el calculo lambda, introducido por alonzo church y stephen kleene en los años 1930, y tambien usado por church para demostrar en 1936 el entscheidungsproblem.   ",
        "snippet": "Una máquina de Turing es un dispositivo que manipula símbolos sobre una tira de cinta de acuerdo con una tabla de reglas. A pesar de su simplicidad, una máquina de Turing puede ser adaptada para simular la lógica de cualquier algoritmo de computador y es particularmente útil en la explicación de las funciones de una CPU dentro de un computador.",
        "enlaces_salientes": [
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Turing_(desambiguaci%C3%B3n)",
            "/wiki/Algoritmo",
            "/wiki/Computador",
            "/wiki/Unidad_central_de_procesamiento",
            "/wiki/Alan_Turing",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Computador",
            "/wiki/M%C3%A1quina_universal_de_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/L%C3%B3gica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Memoria_de_acceso_aleatorio",
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/David_Hilbert",
            "/wiki/Complejidad_computacional",
            "/wiki/Algoritmo",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/NP_(Complejidad_computacional)",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Alan_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/Siglo_XX",
            "/wiki/Memoria_de_trabajo",
            "/wiki/Conjunto_finito",
            "/wiki/Entscheidungsproblem",
            "/wiki/Registro_de_estado",
            "/wiki/Almacenamiento_de_computadora",
            "/wiki/Modelo_computacional",
            "/wiki/Lectura",
            "/wiki/Escritura",
            "/wiki/Entrada",
            "/wiki/Salida_(inform%C3%A1tica)",
            "/wiki/Alfabeto",
            "/wiki/Estado_(inform%C3%A1tica)",
            "/wiki/Funci%C3%B3n_de_transici%C3%B3n",
            "/wiki/Cadena_de_caracteres",
            "/wiki/Alfabeto",
            "/wiki/Funci%C3%B3n_de_transici%C3%B3n",
            "/wiki/Tupla",
            "/wiki/Estado_f%C3%ADsico",
            "/wiki/Funci%C3%B3n_parcial",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Lenguaje_formal",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/Aut%C3%B3mata_con_pila",
            "/wiki/Grafo",
            "/wiki/Alfabeto",
            "/wiki/Estados",
            "/wiki/Arista_(teor%C3%ADa_de_grafos)",
            "/wiki/Grafo_dirigido",
            "/wiki/Complejidad_computacional",
            "/wiki/Cambio_de_estado",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/Problema_de_la_parada",
            "/wiki/Alan_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/Problema_indecidible",
            "/wiki/Binario",
            "/wiki/M%C3%A1quina_de_Turing_universal",
            "/wiki/Un%C3%ADvoca",
            "/wiki/Programa_(computaci%C3%B3n)",
            "/wiki/Algoritmo",
            "/wiki/Problema_indecidible",
            "/wiki/Problema_de_la_parada",
            "/wiki/Problema_indecidible",
            "/wiki/Sistema_operativo",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Qubit",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/Qubit",
            "/wiki/Qubit",
            "/wiki/Qubit",
            "/wiki/M%C3%A1quina_de_Post",
            "/wiki/Emil_Leon_Post",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Alonzo_Church",
            "/wiki/Stephen_Kleene",
            "/wiki/Entscheidungsproblem",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Sistema_combinacional",
            "/wiki/Aut%C3%B3mata_finito",
            "/wiki/Aut%C3%B3mata_con_pila",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/M%C3%A1quina_de_Turing_universal",
            "/wiki/M%C3%A1quina_de_Turing_alternante",
            "/wiki/Problema_de_la_parada",
            "/wiki/Jerarqu%C3%ADa_de_Chomsky",
            "/wiki/Juego_de_la_vida",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/London_Mathematical_Society",
            "/wiki/Wiktionary",
            "/wiki/ISBN",
            "/wiki/Andrew_Hodges",
            "/wiki/ISBN",
            "/wiki/Marvin_Minsky",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Ciencias_de_la_Computaci%C3%B3n",
        "titulo": "Ciencias de la computación",
        "contenido": "las ciencias de la computacion o ciencias de la informatica son las ciencias formales que abarcan las bases teoricas de la informacion y la computacion, asi como su aplicacion en los sistemas informaticos.​​​ el cuerpo de conocimiento de las ciencias de la computacion es frecuentemente descrito como el estudio sistematico de los procesos algoritmicos que describen y transforman informacion: su teoria, analisis, diseño, eficiencia, implementacion, algoritmos sistematizados y aplicacion.​ en terminos mas especificos se trata del estudio sistematico de la factibilidad, estructura, expresion y mecanizacion de procedimientos metodicos (o algoritmos) que subyacen en la adquisicion, representacion, procesamiento, almacenamiento, comunicacion y acceso a la informacion. la informacion puede estar codificada en forma de bits en una memoria de computadora, o en algun otro objeto, como los genes y proteinas en una celula biologica.​  existen diversas ramas o disciplinas dentro de las ciencias de la computacion; algunos resaltan los resultados especificos del computo (como los graficos por computadora), mientras que otros (como la teoria de la complejidad computacional) se relacionan con propiedades de los algoritmos usados al realizar computo; y otros se enfocan en los problemas que requieren la implementacion de sistemas informaticos. por ejemplo, los estudios de la teoria de lenguajes de programacion describen un computo, mientras que la programacion de computadoras aplica lenguajes de programacion especificos para desarrollar una solucion a un problema computacional especifico. un computologo se especializa en teoria de la computacion y en el diseño e implementacion de sistemas computacionales.​  segun peter j. denning, la cuestion fundamental en que se basa la ciencia de la computacion es: «¿que puede ser (eficientemente) automatizado?».​  la historia de la ciencia de la computacion antecede a la invencion del computador digital moderno. antes de la decada de 1920, el termino computador se referia a un ser humano que realizaba calculos.​ los primeros cimientos de lo que se convertiria en ciencias de la computacion son anteriores a la invencion de la computadora digital moderna. se trataba de maquinas para el calculo de las tareas numericas fijas, como el abaco han existido desde la antiguedad, ayudando en calculos tales como la multiplicacion y la division. ademas, los algoritmos para realizar calculos han existido desde la antiguedad, incluso antes de que se crearan equipos de computacion sofisticados. los antiguos sanscritos tratadistas shulba sutras, o \"reglas de la cuerda\", es un libro de algoritmos escritos en 800 a. c. para la construccion de objetos geometricos como altares utilizando una clavija y cuerda, un precursor temprano del campo moderno de la geometria computacional.  blaise pascal diseño y construyo la primera calculadora mecanica de trabajo, la pascalina, en 1642.​ en 1673 gottfried leibniz creo una calculadora mecanica digital, llamada stepped reckoner.​ el puede ser considerado el primer computologo y teorico de la informacion, entre otras razones, porque fue el primero en documentar el sistema numerico binario. en 1820, charles xavier thomas de colmar lanzo la calculadora mecanica industrial​ cuando lanzo su simplificado aritmometro, que fue la primera maquina de calcular lo suficientemente fuerte y lo suficientemente fiable para ser usada a diario en un entorno industrial. charles babbage inicio el diseño de la primera calculadora automatica mecanica, su maquina diferencial, en 1822, que finalmente le dio la idea de la primera calculadora mecanica programable, su maquina analitica.​ el comenzo a desarrollar esta maquina en 1834 y en menos de dos años habia esbozado muchas de las caracteristicas mas destacadas del moderno equipo. un paso fundamental fue la adopcion de un sistema de tarjetas perforadas derivado del telar de jacquard​ haciendolo infinitamente programable.​ en 1843, durante la traduccion de un articulo frances sobre la maquina analitica, ada lovelace escribio, en una de las muchas notas que incluye el articulo, un algoritmo para calcular los numeros de bernoulli, que es considerado como el primer programa de ordenador.​ alrededor de 1885, herman hollerith invento la maquina tabuladora, que usaba tarjetas perforadas para procesar informacion estadistica; finalmente, su compañia se convirtio en parte de ibm. en 1937, cien años despues del sueño imposible de babbage, howard aiken fue convencido por ibm (que estaban manufacturando todo tipo de equipos de tarjetas perforadas y asi como la calculadora de negocio​) para desarrollar su calculadora programable gigante, el ascc/harvard mark i. se baso en la maquina analitica de babbage, que a su vez utiliza las tarjetas perforadas y una unidad central de calculo. cuando se termino de construir la maquina, algunas personas lo aclamaron como «el sueño de babbage hecho realidad».​  durante la decada de 1940, conforme se desarrollaban las nuevas y mas poderosas maquinas para computar, el termino computador se comenzo a utilizar para referirse a las maquinas y ya no a sus antecesores humanos.​ cuando se hizo evidente que las computadoras no solamente podrian utilizarse para realizar calculos matematicos, el campo de las ciencias de la computacion se amplio para estudiar computo en general. las ciencias de la computacion empezaron a establecerse como una disciplina academica distinta de las demas en la decada de 1950 y principios de 1960.​​ entonces surgio el primer programa de grado universitario del mundo, el cambridge diploma in computer science, del cambridge computer lab (departamento de ciencias de la computacion) de la universidad de cambridge, en 1953. el primer programa de grado universitario en ciencias de la informatica en estados unidos se formo en la universidad de purdue en 1962.​ desde que se dispone ordenadores practicos, muchas aplicaciones la de las ciencias de la computacion se convirtieron en diferentes areas de estudio en sus propios terminos.  aunque inicialmente muchos creyeron que era imposible que las computadoras en si mismas podrian constituir en realidad un campo cientifico de estudio, a finales de los años cincuenta se fue volviendo gradualmente aceptada entre la poblacion mayor academica.​​  la disciplina cientifica de las ciencias de la computacion nace a principios de 1940 con la confluencia de la teoria de algoritmos, logica matematica y la invencion del programa almacenado en una computadora electronica.​ ejemplos de esto son los trabajos de alan turing, alonzo church y kurt godel en 1930 acerca de los algoritmos y su trabajo en sistemas de reglas (vease calculo lambda, maquina de turing y problemas indecidibles), los algoritmos creados por augusta ada sesenta años antes, la computadora analogica construida por vannevar bush en 1920 y las computadoras electricas construidas por howard aiken y konrad zuse en 1930. los escritos de john von neumann dieron una profundidad intelectual considerable a esta disciplina emergente a mediados de la decada de 1940.  en 1960, habia suficientemente cuerpo de conocimiento que ameritaba la creacion de departamentos academicos y programas de grado universitario para esta disciplina.​ ibm es reconocida como la marca que formo parte de la revolucion de las ciencias de la computacion durante ese tiempo. ibm (abreviacion de international business machines) lanzo la ibm 704​ y mas tarde la ibm 709​ computadoras, que fueron ampliamente utilizadas durante el periodo de exploracion de este tipo de dispositivos. \"sin embargo, el trabajo con la ibm [equipo] era frustrante ... si te equivocas en una letra de alguna instruccion, el programa se arruinaria, y se tendria que empezar todo el proceso otra vez\".​ durante la decada de 1950, la disciplina de las ciencias de la computacion estaba en su etapa de desarrollo, y estos problemas eran algo comun.  el tiempo ha dado mejoras significativas en la capacidad de uso y la eficacia de la tecnologia de la computacion. la sociedad moderna ha presenciado un cambio significativo en los usuarios de la tecnologia en computo, de ser utilizada unicamente por expertos, profesionales y cientificos, a una base de usuarios que es casi omnipresente a la teoria con la cual se desarrollo y funciona este tipo de tecnologia. inicialmente, las computadoras eran bastante costosas, y era necesario un cierto grado de ayuda humana para el uso eficiente - en parte de operadores de computadoras profesionales. como la adopcion equipo se hizo mas generalizado y asequible, se necesitaba menos asistencia humana en el uso comun.  a pesar de su corto tiempo de ser una disciplina cientifica formal, las ciencias de la computacion han hecho un gran numero de contribuciones importantes a la ciencia y la sociedad –de hecho, junto con la electronica, es una ciencia fundacional de la epoca actual de la historia humana llamada era de la informacion y la revolucion de la informacion, visto como el tercer gran salto en el progreso tecnologico humano despues de la revolucion industrial (1750-1850) y la revolucion neolitica (8000-5000 a. c.).  estas contribuciones a la humanidad incluyen:  algunos cientificos de la computacion han argumentado a favor de la distincion de tres paradigmas diferentes en ciencias de la computacion. peter wegner ha argumentado que esos paradigmas son la ciencia, la tecnologia y las matematicas.​ el grupo de investigacion de peter denning argumento que son la abstraccion (modelado), y diseño. amnon h. eden lo describe como el «paradigma racionalista» (el cual trata a las ciencias de la computacion como una rama de las matematicas, la cual prevalece en ciencias de la computacion teorica y principalmente emplea el razonamiento deductivo), el paradigma tecnocratico (que podria ser encontrado en enfoques ingenieriles, mas prominente en la ingenieria de software) y el paradigma cientifico (que se enfoca a objetos relacionados con la computacion desde la perspectiva empirica de las ciencias naturales identificable en algunas ramas de la inteligencia artificial).  a pesar de su primera proposicion en 1956,​ la locucion «ciencias de la computacion» aparece en 1959 en un articulo de la revista communications of the acm (prestigiada publicacion cientifica destinada a lectores con experiencia en todos los ambitos de la computacion y los sistemas de informacion),​ en el cual louis fein discute sobre la creacion de una escuela de estudios de posgrado en ciencias computacionales analoga a la creacion de harvard business school en 1921,​ justificando el nombre con el argumento de que: como la ciencia administrativa, el tema o area de conocimiento puede ser aplicado, es de caracter interdisciplinario y que cuenta con las caracteristicas tipicas de una disciplina academica.​ sus esfuerzos y los de otros, como el analista numerico george forsythe, fueron recompensados: universidades pasaron a crear este tipo de programas de estudio, a partir de 1962 en purdue.​ a pesar del nombre de esta disciplina academica, una cantidad significativa de topicos en ciencias de la computacion no involucran el estudio de las computadoras, por esta razon muchos nombres alternativos han sido propuestos.​  algunos departamentos de universidades prefieren la locucion «ciencias de la computacion» para hacer enfasis en esta diferencia. el cientifico danes peter naur sugirio el termino datologia,​ para reflejar el hecho de que esta disciplina cientifica gira en torno a los datos y a al tratamiento de estos, mientras que no necesariamente involucra a las computadoras. la primera institucion cientifica en usar el termino fue el departamento de datologia de la universidad de copenhague, fundado en 1969, con peter naur como profesor de datologia. el termino es usado en paises escandinavos. en los primeros años de la computacion, un numero de terminus para los practicantes del campo de la computacion fueron propuestos en la revista communications of the acm – turingeniero, turologo, hombre de los diagramas de flujo, matematico meta-aplicado, y epistemologo aplicado.​ tres meses despues en esa misma publicacion cientifica, el termino computologo fue sugerido. el siguiente año en la misma publicacion surgio el termino hypologo.​ el termino computica tambien ha sido sugerido.​ en europa, terminos derivados de traducciones de la expresion \"automatic information\" (e.g. \"informazione automatica\" en italiano) or \"informacion y matematicas\" son frecuentemente usados, e.g. informatique (frances), informatik (aleman), informatica (italia, paises bajos), informatica (españa y portugal), informatika (lenguas eslavas) o pliroforiki (πληροφορκη, que significa informatica) en griego. palabras similares han sido adoptadas en algunos lugares del reino unido, por ejemplo en la universidad de edimburgo.​ pero estas no reflejan el aspecto de la computabilidad, por esta razon en un contexto de investigacion cientifica tanto academica como industrial el termino ciencias de la computacion es mayormente usado en publicaciones y conferencias cientificas.  como disciplina cientifica, las ciencias de la computacion abarca una gama de temas, desde los estudios teoricos de los algoritmos y los limites de la computacion a los problemas practicos de la implementacion de sistemas computacionales en hardware y software.​​ computing sciences acreditation board o la junta de acreditacion en ciencias de la computacion. –compuesta por representantes de la association for computing machinery (acm), y la sociedad de computacion ieee (ieee-cs)​– identifica cuatro areas que considera cruciales para la disciplina de ciencias de la computacion: teoria de la computacion, algoritmos y estructuras de datos, metodologia y lenguajes de programacion, y arquitectura de computadoras. ademas de estas cuatro areas, c.s.a.b. tambien identifica ambitos como la ingenieria de software, inteligencia artificial, redes de computadoras, sistemas de bases de datos, computacion paralela, computacion distribuida, la interaccion persona-computador, graficos por ordenador, sistemas operativos, calculo numerico y simbolico siendo importantes areas de las ciencias de la computacion.​  el campo mas amplio de la ciencia de la computacion teorica abarca tanto la teoria clasica de la computacion y una amplia gama de otros temas que se centran en los aspectos mas abstractos, logicos y matematicos de la computacion.  de acuerdo a peter j. denning, la pregunta fundamental en ciencias de la computacion es, «¿que puede ser eficientemente automatizado?»​ el estudio de la teoria de la computacion esta enfocado en responder preguntas fundamentales acerca de que puede ser computado y que cantidad de recursos son requeridos para ejecutar tales computos. en un esfuerzo por resolver esta pregunta, la teoria de la computabilidad examina que problemas computacionales se pueden resolver en varios modelos teoricos de computo. la segunda pregunta esta dirigida por la teoria de la complejidad computacional, que estudia los costos de tiempo y espacio asociados a diferentes enfoques para resolver una multitud de problemas computacionales.  el famoso problema \"¿p=np?\" es uno de los problemas del milenio,​ es un problema abierto en ciencias de la computacion.  la teoria de la informacion esta relacionada con la cuantificacion de la informacion. fue desarrollada por claude e. shannon para desarrollar los limites fundamentales del procesamiento de señales asi como sus operaciones, tales como compresion y almacenamiento de datos asi como la comunicacion de los datos de manera fiable.​ la teoria de codigos es un area de las matematicas que busca resolver el problema de detectar y corregir errores al momento de transmitir informacion.​ los codigos son usados para comprimir datos, criptografia y mas recientemente para la codificacion de redes. los codigos son estudiados para el proposito de diseñar metodos eficientes y seguros para la transmision de datos.  los algoritmos y las estructuras de datos son el estudio de metodos computacionales comunmente usados asi como su eficiencia computacional.  la teoria del lenguaje de programacion es una rama de las ciencias de la computacion que se ocupa del diseño, activacion, analisis, caracterizacion y clasificacion de los lenguaje de programacion y sus caracteristicas individuales, cae dentro de la disciplina de las ciencias de la computacion, tanto en dependencia de las matematicas y la linguistica. es un area de investigacion activa, con numerosas revistas academicas y conferencias especializadas en el tema.  los metodos formales son un tipo particular de la tecnica basada en las matematicas para la especificacion formal, desarrollo y verificacion formal de los sistemas de software y hardware. el uso de metodos formales para el diseño de soportes logico y fisico esta motivado por la expectativa de que, la realizacion de un analisis matematico adecuado puede contribuir a la fiabilidad y robustez de un diseño. estos forman una importante base teorica para la ingenieria de software, especialmente cuando esta involucrado la seguridad o robustez. los metodos formales son un complemento util para las pruebas de software, ya que ayudan a evitar errores y tambien pueden dar un marco para hacer pruebas. para su uso industrial, se requiere el apoyo de herramientas. sin embargo, el alto costo de la utilizacion de metodos formales significa que por lo general solo se utilizan en el desarrollo de sistemas criticos de alta integridad donde la vida o la seguridad es de muy alta importancia.  los metodos formales se describen mejor como la aplicacion de una amplia variedad de fundamentos teoricos de las ciencias de la computacion, en particular la logica computacional, lenguajes formales, teoria de automatas y semantica de lenguajes de programacion pero tambien areas como sistemas de tipos y tipos de datos algebraicos a problemas en la especificacion y verificacion de software y hardware.  las ciencias de la computacion aplicadas tratan de identificar ciertos aspectos conceptuales y teoricos de las ciencias de la informatica que pueden ser aplicados directamente para resolver problemas del mundo real.  esta rama de las ciencias de la computacion pretende o es requerida para la sintesis de procesos metaorientados tales como la resolucion de problemas, toma de decisiones, la adaptacion del medio ambiente, el aprendizaje y la comunicacion que se encuentran en los seres humanos y los animales. desde sus origenes en la cibernetica y en la conferencia de dartmouth (1956), la investigacion en inteligencia artificial (ia) ha sido necesariamente multidisciplinaria, aprovechando areas de especializacion, tales como las matematicas, la logica simbolica, la semiotica, la ingenieria electrica, la filosofia de la mente, la neurofisiologia, y la inteligencia social. la ia erroneamente es asociada en la mente popular con el desarrollo robotico, pero el principal campo de aplicacion practica ha sido como un componente integrado en las areas de desarrollo de programas informaticos que requieren la comprension y la modelacion computacional, tales como las finanzas y la economia, la mineria de datos y las ciencias fisicas. el termino fue acuñado por el cientifico de la computacion y matematico john mccarthy en 1955.  la arquitectura de computadores u organizacion de computadoras digitales es el diseño conceptual y la estructura operacional fundamental de un sistema computo. se centra en gran medida de la manera en que la unidad central de procesamiento realiza internamente y accede a las direcciones en la memoria.​ el campo involucra disciplinas de la ingenieria en computacion y la ingenieria electrica, la seleccion y la interconexion de los componentes fisicos para crear los equipos que cumplen funciones, de rendimiento, y costes.  analisis de rendimiento del equipo es el estudio del trabajo que fluye a traves de los equipos con el objetivo general de mejora de rendimiento y control de tiempo de respuesta, utilizando los recursos de manera eficiente, la eliminacion de los cuellos de botella, y la prediccion de rendimiento bajo cargas maximas previstas.​  la ciencia computacional (o computacion cientifica) es el campo de estudio que trata con la construccion de modelos matematicos y tecnicas de analisis cuantitativos, asi como el uso de computadoras para analizar y resolver problemas cientificos. en el uso practico, es tipicamente la aplicacion de simulacion por ordenador y otras formas de calculo a los problemas en diversas disciplinas cientificas.  esta rama de las ciencias de la computacion tiene como objetivo gestionar la conectividad entre redes (lan / wan) de computadoras a nivel mundial.  concurrencia es una propiedad de los sistemas en los que varios calculos estan ejecutando de forma simultanea, y, potencialmente, que interactuan entre si. un numero de modelos matematicos han sido desarrollados para el calculo concurrente general, incluyendo las redes de petri, calculos de proceso y del modelo de maquina de acceso aleatorio en paralelo. un sistema distribuido se extiende la idea de la simultaneidad en varios ordenadores conectados a traves de una red. las computadoras dentro del mismo sistema distribuido tienen su propia memoria privada, y la informacion es a menudo intercambiada entre si para lograr un objetivo comun.  una base de datos tiene la intencion de organizar, almacenar y recuperar grandes cantidades de datos de forma sencilla. bases de datos digitales se gestionan mediante sistemas de gestion de base de datos para almacenar, crear, mantener y consultar los datos, a traves de modelos de bases de datos y lenguajes de consulta. una base de datos es un conjunto de datos interrelacionados entre ellos mismos.  el campo estudia la estructura, algoritmos, comportamiento e interacciones de los sistemas naturales y artificiales que guardan, procesan, acceden a y comunican informacion. tambien desarrolla sus propios fundamentos conceptuales y teoricos y emplea fundamentos desarrollados en otros campos. una aplicacion moderna es el big data, que consiste en el procesamiento de un conjunto de datos (provenientes de fuentes como por ejemplo: transacciones comerciales, formularios web, imagenes, videos, correos electronicos, redes sociales, entre otros), los cuales son sometidos a herramientas informaticas de analisis que permiten extraer informacion valiosa para predecir comportamientos futuros y formular estrategias de toma decisiones.​  ingenieria de software consiste en el estudio del diseño, activacion y modificacion del software con la finalidad de asegurarse de que es de alta calidad, asequible, facil de mantener, y rapido de construir. es un enfoque sistematico para el diseño de software, que implica la aplicacion de practicas de ingenieria de software. los ingenieros de software comercian con la organizacion y analisis de software — no solo lidian con la creacion o fabricacion de un nuevo soporte logico, sino tambien con su mantenimiento y disposicion interna. se preve que esten entre las ocupaciones de mas rapido crecimiento entre 2008 y 2018. debido a la novedad de este subcampo, la educacion formal en ingenieria de software generalmente es parte de los planes de estudio de ciencias de la computacion, la gran mayoria de ingenieros de software tienen un grado academico en ciencias de la computacion sin tener relacion con la ingenieria.​  por ser una disciplina reciente, existen varias definiciones alternativas para la ciencia de la computacion. esta puede ser vista como una forma de ciencia, matematicas o una nueva disciplina que no puede ser categorizada siguiendo los modelos actuales.  las ciencias de la computacion frecuentemente se cruzan con otras areas de investigacion, tales como la fisica y la linguistica. pero es con las matematicas con las que se considera que tiene un grado mayor de relacion. eso es evidenciado por el hecho de que los primeros trabajos en el area fueran fuertemente influenciados por matematicos como kurt godel y alan turing. en la actualidad sigue habiendo un intercambio de ideas util entre ambos campos en areas como la logica matematica, la teoria de categorias, la teoria de dominios, el algebra y la geometria.  otro punto a destacar es que, a pesar de su nombre, las ciencias de la computacion raramente involucran el estudio mismo de las maquinas conocidas como computadoras. de hecho, el renombrado cientifico edsger dijkstra es muy citado por la frase «las ciencias de la computacion estan tan poco relacionadas con los ordenadores como la astronomia con los telescopios». la investigacion en ciencias de la computacion tambien suele relacionarse con otras disciplinas, como la ciencia cognitiva, la fisica (vease computacion cuantica), la linguistica, etc.  la relacion entre las ciencias de la computacion y la ingenieria de software es un tema muy discutido, por disputas sobre lo que realmente significa la lucion «ingenieria de software» y sobre como se define a las ciencias de la computacion. algunas personas creen que la ingenieria de software seria un subconjunto de las ciencias de la informatica. otras, tomando en cuenta la relacion entre otras disciplinas cientificas y de la ingenieria, creen que el principal objetivo de las ciencias de la computacion seria estudiar las propiedades del computo en general, mientras que el objetivo de la ingenieria de software seria diseñar computos especificos para lograr objetivos practicos, con lo que se convertiria en disciplinas diferentes. este punto de vista es el que sostiene, por ejemplo, parnas (1998). incluso hay otros que sostienen que no podria existir una ingenieria de software.  los aspectos academicos, politicos y de financiamiento en las areas de ciencias de la computacion tienden a verse influidos drasticamente por el criterio del departamento encargado de la investigacion y la educacion en cada universidad, que puede estar orientado a las matematica o a la ingenieria. los departamentos de ciencias de la computacion orientados a las matematicas teoricas suelen alinearse del lado de la computacion cientifica y las aplicaciones de calculo numerico.  la locucion «computacion cientifica», que no debe confundirse con ciencia de la computacion, designa a todas aquellas practicas destinadas a modelar, plantear experimentos y validar teorias cientificas sirviendose de medios informaticos. en estos casos la computacion es una mera herramienta y el esfuerzo se dirige a avanzar en los campos objetivo (fisica, biologia, mecanica de fluidos, radiotransmision...), mas que en la propia ciencia de la computacion.  finalmente, el publico en general algunas veces confunde la ciencia de la computacion con areas vocacionales que trabajan con computadoras o piensan que trata acerca de su propia experiencia con las computadoras, lo cual suele incluir actividades como los juegos, la navegacion web y el procesamiento de texto. sin embargo, el punto central de la ciencia de la computacion va mas alla de entender las propiedades de los programas que se emplean para ejecutar aplicaciones de software como juegos y navegadores web, y utiliza ese entendimiento para crear nuevos programas o mejorar los existentes.​     ",
        "snippet": "Las ciencias de la computación o ciencias de la informática son las ciencias formales que abarcan las bases teóricas de la información y la computación, así como su aplicación en los sistemas informáticos.[1]​[2]​[3]​ El cuerpo de conocimiento de las ciencias de la computación es frecuentemente descrito como el estudio sistemático de los procesos algorítmicos que describen y transforman información: su teoría, análisis, diseño, eficiencia, implementación, algoritmos sistematizados y aplicación.[4]​ En términos más específicos se trata del estudio sistemático de la factibilidad, estructura, expresión y mecanización de procedimientos metódicos (o algoritmos) que subyacen en la adquisición, representación, procesamiento, almacenamiento, comunicación y acceso a la información. La información puede estar codificada en forma de bits en una memoria de computadora, o en algún otro objeto, como los genes y proteínas en una célula biológica.[5]​",
        "enlaces_salientes": [
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Computaci%C3%B3n_gr%C3%A1fica",
            "/wiki/Interacci%C3%B3n_persona-computador",
            "/wiki/Ciencias_formales",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Sistemas_de_informaci%C3%B3n",
            "/wiki/Factibilidad",
            "/wiki/Estructura_de_datos",
            "/wiki/Expresi%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Algoritmos",
            "/wiki/Grafo",
            "/wiki/Proceso_(inform%C3%A1tica)",
            "/wiki/Dispositivo_de_almacenamiento_de_datos",
            "/wiki/Comunicaci%C3%B3n",
            "/wiki/Acceso",
            "/wiki/Informaci%C3%B3n",
            "/wiki/Bit",
            "/wiki/Gr%C3%A1ficos_por_computadora",
            "/wiki/Complejidad_computacional",
            "/wiki/Algoritmos",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Peter_J._Denning",
            "/wiki/Charles_Babbage",
            "/wiki/Turing_completo",
            "/wiki/Alan_Turing",
            "/wiki/Ada_Lovelace",
            "/wiki/Algoritmo",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Computadora_electr%C3%B3nica",
            "/wiki/A%C3%B1os_1920",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Blaise_Pascal",
            "/wiki/Pascalina",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Stepped_Reckoner",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Charles_Xavier_Thomas_de_Colmar",
            "/wiki/Calculadora_mec%C3%A1nica",
            "/wiki/Aritm%C3%B3metro",
            "/wiki/Charles_Babbage",
            "/wiki/M%C3%A1quina_diferencial",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Ada_Lovelace",
            "/wiki/Bernoulli",
            "/wiki/Herman_Hollerith",
            "/wiki/Tabuladora",
            "/wiki/IBM",
            "/wiki/Howard_Aiken",
            "/wiki/Harvard_Mark_I",
            "/wiki/A%C3%B1os_1940",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Universidad_de_Purdue",
            "/wiki/Disciplina_acad%C3%A9mica",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Alan_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/1930",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Problema_indecidible",
            "/wiki/Ada_Lovelace",
            "/wiki/Vannevar_Bush",
            "/wiki/Howard_Aiken",
            "/wiki/Konrad_Zuse",
            "/wiki/A%C3%B1os_1930",
            "/wiki/John_Von_Neumann",
            "/wiki/1960",
            "/wiki/IBM",
            "/wiki/Wehrmacht",
            "/wiki/M%C3%A1quina_Enigma",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Alan_Turing",
            "/wiki/Bletchley_Park",
            "/wiki/Disciplina_acad%C3%A9mica",
            "/wiki/Ciencia",
            "/wiki/Sociedad",
            "/wiki/Electr%C3%B3nica",
            "/wiki/Era_de_la_informaci%C3%B3n",
            "/wiki/Revoluci%C3%B3n_Industrial",
            "/wiki/Revoluci%C3%B3n_neol%C3%ADtica",
            "/wiki/Revoluci%C3%B3n_digital",
            "/wiki/Era_de_la_informaci%C3%B3n",
            "/wiki/Internet",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Problema_indecidible",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Criptolog%C3%ADa",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Computaci%C3%B3n_cient%C3%ADfica",
            "/wiki/Clase_de_complejidad",
            "/wiki/Proyecto_Genoma_Humano",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Folding@home",
            "/wiki/Plegamiento_de_prote%C3%ADnas",
            "/wiki/Computaci%C3%B3n_gr%C3%A1fica",
            "/wiki/Imagen_generada_por_computadora",
            "/wiki/Entretenimiento",
            "/wiki/Televisi%C3%B3n",
            "/wiki/Cine",
            "/wiki/Publicidad",
            "/wiki/Animaci%C3%B3n",
            "/wiki/Videojuegos",
            "/wiki/Simulaci%C3%B3n",
            "/wiki/Din%C3%A1mica_de_fluidos",
            "/wiki/SPICE",
            "/wiki/Circuito_integrado",
            "/wiki/Inteligencia_artificial",
            "/wiki/Peter_Wegner",
            "/wiki/Peter_J._Denning",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Ciencias_naturales",
            "/wiki/Inteligencia_artificial",
            "/wiki/Harvard_Business_School",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Peter_Naur",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/Lenguas_eslavas",
            "/wiki/Idioma_griego",
            "/wiki/Universidad_de_Edimburgo",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Disciplina_acad%C3%A9mica",
            "/wiki/Algoritmos",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/IEEE",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Algoritmos",
            "/wiki/Estructuras_de_datos",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Arquitectura_de_computadoras",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Inteligencia_artificial",
            "/wiki/Redes_de_computadoras",
            "/wiki/Bases_de_datos",
            "/wiki/Computaci%C3%B3n_paralela",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Interacci%C3%B3n_persona-computador",
            "/wiki/Gr%C3%A1ficos_por_ordenador",
            "/wiki/Sistemas_operativos",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/C%C3%A1lculo_simb%C3%B3lico",
            "/wiki/Ciencia_computacional_te%C3%B3rica",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Peter_J._Denning",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Clases_de_complejidad_P_y_NP",
            "/wiki/Problemas_del_milenio",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Claude_Shannon",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Transmisi%C3%B3n_de_datos",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Teor%C3%ADa_de_c%C3%B3digos",
            "/wiki/Algoritmo",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Algoritmos",
            "/wiki/Estructuras_de_datos",
            "/wiki/Optimizaci%C3%B3n_combinatoria",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Teor%C3%ADa_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Teor%C3%ADa_de_tipos",
            "/wiki/Compiladores",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/M%C3%A9todos_formales",
            "/wiki/Especificaci%C3%B3n_formal",
            "/wiki/Verificaci%C3%B3n_formal",
            "/wiki/Lenguajes_formales",
            "/wiki/Teor%C3%ADa_de_aut%C3%B3matas",
            "/wiki/Sem%C3%A1ntica_de_lenguajes_de_programaci%C3%B3n",
            "/wiki/Sistema_de_tipos",
            "/wiki/Inteligencia_artificial",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Visi%C3%B3n_artificial",
            "/wiki/Procesamiento_de_im%C3%A1genes",
            "/wiki/Reconocimiento_de_patrones",
            "/wiki/Ciencia_cognitiva",
            "/wiki/Miner%C3%ADa_de_datos",
            "/wiki/Computaci%C3%B3n_evolutiva",
            "/wiki/B%C3%BAsqueda_y_recuperaci%C3%B3n_de_informaci%C3%B3n",
            "/wiki/Representaci%C3%B3n_del_conocimiento",
            "/wiki/Procesamiento_de_lenguaje_natural",
            "/wiki/Rob%C3%B3tica",
            "/wiki/Arquitectura_de_computadoras",
            "/wiki/L%C3%B3gica_digital",
            "/wiki/Microarquitectura",
            "/wiki/Multiprocesamiento",
            "/wiki/Sistemas_operativos",
            "/wiki/Redes_de_computadoras",
            "/wiki/Sistema_de_gesti%C3%B3n_de_bases_de_datos",
            "/wiki/Seguridad_inform%C3%A1tica",
            "/wiki/Computaci%C3%B3n_ubicua",
            "/wiki/Arquitectura_de_software",
            "/wiki/Compiladores",
            "/wiki/Lenguajes_de_programaci%C3%B3n",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/F%C3%ADsica_computacional",
            "/wiki/Qu%C3%ADmica_computacional",
            "/wiki/Bioinform%C3%A1tica",
            "/wiki/Redes_de_computadoras",
            "/wiki/Red_de_%C3%A1rea_local",
            "/wiki/Red_de_%C3%A1rea_amplia",
            "/wiki/Computaci%C3%B3n_concurrente",
            "/wiki/Computaci%C3%B3n_distribuida",
            "/wiki/Bases_de_datos",
            "/wiki/Sistema_de_gesti%C3%B3n_de_bases_de_datos",
            "/wiki/Inform%C3%A1tica_en_salud",
            "/wiki/Inform%C3%A1tica_en_salud",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Software_m%C3%A9dico",
            "/wiki/Tecnolog%C3%ADas_sanitarias",
            "/wiki/Big_Data",
            "/wiki/Toma_de_decisiones",
            "/wiki/Ciencias_de_la_informaci%C3%B3n_(tecnolog%C3%ADa)",
            "/wiki/B%C3%BAsqueda_y_recuperaci%C3%B3n_de_informaci%C3%B3n",
            "/wiki/Representaci%C3%B3n_del_conocimiento",
            "/wiki/Procesamiento_de_lenguaje_natural",
            "/wiki/Interacci%C3%B3n_persona-computador",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Software",
            "/wiki/Categor%C3%ADa",
            "/wiki/F%C3%ADsica",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Alan_Turing",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_categor%C3%ADas",
            "/wiki/Teor%C3%ADa_de_dominios",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Edsger_Dijkstra",
            "/wiki/Ciencia_cognitiva",
            "/wiki/F%C3%ADsica",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Software",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Ciencias_de_la_informaci%C3%B3n_(tecnolog%C3%ADa)",
            "/wiki/Ingenier%C3%ADa_en_computaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Problema_de_la_cena_de_los_fil%C3%B3sofos",
            "/wiki/Problemas_no_resueltos_de_las_Ciencias_de_la_Computaci%C3%B3n",
            "/wiki/Mujeres_en_inform%C3%A1tica",
            "/wiki/Premio_Turing",
            "/wiki/Ciencia_web",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Peter_J._Denning",
            "/wiki/Princeton_University_Press",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Steven_Levy",
            "/wiki/ISBN",
            "/wiki/Hal_Abelson",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Donald_Knuth",
            "/wiki/Wayback_Machine",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/University_of_Cambridge",
            "/wiki/Bertrand_Meyer",
            "/wiki/CiteSeerX",
            "/wiki/Digital_Bibliography_%26_Library_Project",
            "/wiki/Universit%C3%A4t_Trier",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Historical_Dictionary_of_Switzerland",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/An%C3%A1lisis_de_algoritmos",
        "titulo": "Análisis de algoritmos",
        "contenido": "el termino analisis de algoritmos fue acuñado por donald knuth​ y se refiere al proceso de encontrar la complejidad computacional de un algoritmo que resuelva un problema computacional dado, con el objetivo de proveer estimaciones teoricas de los recursos que necesita. usualmente, los recursos a los cuales se hace referencia son el tiempo (complejidad temporal) y el almacenamiento (complejidad espacial). mientras que la complejidad temporal involucra determinar una funcion que relaciona la longitud o el tamaño de la entrada del algoritmo con el numero de pasos que realiza, la complejidad espacial busca la cantidad de ubicaciones de almacenamiento que utiliza.  distintos algoritmos pueden utilizarse para resolver un mismo problema y a su vez los algoritmos pueden estudiarse de forma independiente del lenguaje de programacion a utilizar y de la maquina donde se ejecutara.​ esto significa que se necesitan tecnicas que permitan comparar la eficiencia de los algoritmos antes de su implementacion.  este analisis es conocido tambien con el nombre de analisis del tiempo de ejecucion. a continuacion, se presenta una explicacion intuitiva utilizando el ejemplo del algoritmo de busqueda para luego profundizar en forma mas teorica.  si se piensa en el problema de encontrar una clave en un conjunto de registros ubicados dentro de un vector devolviendo la posicion donde se encuentra, se tienen distintos algoritmos de busquedas que se pueden aplicar. el mas sencillo es la busqueda secuencial pero si el conjunto de elementos se encuentran ordenados (segun su clave) dentro del vector se podria aplicar la busqueda binaria. de este ejemplo se pueden sacar varias conclusiones.  por un lado, dependiendo el algoritmo utilizado el proceso de busqueda sera mas o menos eficiente en el sentido de cantidad de comparaciones realizadas. por ejemplo, segun la figura 1 para buscar \"morin, arthur\" la busqueda secuencial debe realizar 28 comparaciones mientras que la busqueda binaria realiza solo 5 comparaciones. esto confirma que para la resolucion de un determinado problema existe mas de un algoritmo y que estos suelen tener distintos niveles de eficiencia, necesitandose una forma de elegirlos antes de programarlos como se menciono en la introduccion.  si se continua analizando la busqueda secuencial y  si la intencion es encontrar a  \"zeeman, pieter\" se deben realizar 33 comparaciones pero si se intenta encontrar a \"abt, antal\" solo dos comparaciones son necesarias. es decir, si se busca el ultimo elemento la cantidad de comparaciones es equivalente a n, donde n es la cantidad de elementos presentes en el vector; pero por otro, tambien depende de la clave a buscar. en consecuencia, la cantidad de comparaciones necesarias depende de la cantidad de elementos que posea el vector y su orden; y del elemento a buscar, esto es, depende de las entradas del algoritmo. de aqui se puede concluir que para analizar el tiempo de ejecucion se podria contar la cantidad de comparaciones realizadas y se la multiplica por el tiempo requerido por cada comparacion.  pero aqui se presenta otro inconveniente ¿el tiempo que toma una comparacion depende de la computadora en donde se este ejecutando? seria conveniente encontrar una funcion que dado el tamaño de entrada acote los pasos realizados por el algoritmo para encontrar la solucion en un tiempo que dependa de una constante c que representa el tiempo en diferentes computadoras.  diferentes entradas de la misma longitud pueden causar que el algoritmo se comporte distinto, por lo que se podria analizar el algoritmo desde tres perspectivas: el mejor caso, el caso promedio y el peor caso.​ en la figura 2 se muestra dichos casos de manera grafica.  cuando no se especifica lo contrario, la funcion que describe el rendimiento de un algoritmo suele este caso, dado que este caso garantiza que el algoritmo no tardara mayor cantidad de tiempo, es decir acota superiormente la cantidad de pasos.  a la hora de realizar un analisis teorico de algoritmos es comun calcular su complejidad en un sentido asintotico, es decir, para un tamaño de entrada suficientemente grande. la cota superior asintotica, y las notaciones omega (cota inferior) y theta (caso promedio) se usan con esa finalidad. por ejemplo, la busqueda binaria decimos que se ejecuta en una cantidad de pasos proporcional a un logaritmo, en o ( l o g ( n ) ) , coloquialmente \"en tiempo logaritmico\". normalmente, las estimaciones asintoticas se utilizan porque diferentes implementaciones del mismo algoritmo no tienen por que tener la misma eficiencia. no obstante, la eficiencia de dos implementaciones \"razonables\" cualesquiera de un algoritmo dado estan relacionadas por una constante multiplicativa llamada constante oculta.  de manera informal, se puede decir que un algoritmo exhibe una tasa de crecimiento del orden de una funcion matematica si mas alla de un cierto tamaño de entrada n , la funcion f ( n ) multiplicada por una constante positiva proporciona un limite superior o limite para el tiempo de ejecucion de ese algoritmo. en otras palabras, para un tamaño de entrada dado n mayor que algun n 0 } y una constante c , el tiempo de ejecucion de ese algoritmo nunca sera mayor que f ( n ) . este concepto se expresa con frecuencia utilizando la notacion o grande, que brinda una forma conveniente de expresar el peor de los casos para un algoritmo dado.  por ejemplo, el ordenamiento por insercion crece cuadraticamente a medida que aumenta su tamaño de entrada, entonces se puede decir que este tipo de ordenamiento es del orden de n cuadrado, en notacion o grande seria: o ( n 2 ) )} . otro tipo de funciones que pueden ser utilizadas para acotar un algoritmo son las mostradas en la figura 3.  la medida exacta (no asintotica) de la eficiencia a veces puede ser computada, pero para ello suele hacer falta aceptar supuestos acerca de la implementacion concreta del algoritmo, llamada modelo de computacion. un modelo de computacion puede definirse en terminos de un ordenador abstracto, como la maquina de turing, y/o postulando que ciertas operaciones se ejecutan en una unidad de tiempo. por ejemplo, si al conjunto ordenado al que aplicamos una busqueda binaria tiene n elementos, y podemos garantizar que una unica busqueda binaria puede realizarse en un tiempo unitario, entonces se requieren, como mucho, l o g 2 n + 1 n+1} unidades de tiempo para devolver una respuesta.  las medidas exactas de eficiencia son utiles para quienes verdaderamente implementan y usan algoritmos porque tienen mas precision y, asi, les permite saber cuanto tiempo pueden suponer que tomara la ejecucion. para algunas personas, como los desarrolladores de videojuegos, una constante oculta puede significar la diferencia entre exito y fracaso.  las estimaciones de tiempo dependen de como definamos un paso. para que el analisis tenga sentido, debemos garantizar que el tiempo requerido para realizar un paso se encuentra acotado superiormente por una constante. hay que mantenerse precavido en este terreno; por ejemplo, algunos analisis cuentan con que la suma de dos numeros se hace en un paso. este supuesto puede no estar garantizado en ciertos contextos. si, por ejemplo, los numeros involucrados en la computacion pueden ser arbitrariamente grandes, dejamos de poder asumir que la adicion requiere un tiempo constante (usando papel y lapiz, compara el tiempo que necesitas para sumar dos enteros de 2 digitos cada uno y el necesario para hacerlo con dos enteros pero de 1000 digitos cada uno).  en la practica el analisis de algoritmos es importante porque el uso accidental o no intencional de un algoritmo ineficiente puede afectar significativamente el rendimiento de un sistema. en aplicaciones de tiempo real, un algoritmo que tarda demasiado en ejecutarse puede hacer que sus resultados sean obsoletos o inutiles. un algoritmo ineficiente tambien puede terminar requiriendo una cantidad antieconomica de potencia de calculo o almacenamiento para funcionar, volviendolo practicamente inutil. ",
        "snippet": "El término análisis de algoritmos fue acuñado por Donald Knuth[1]​ y se refiere al proceso de encontrar la complejidad computacional de un algoritmo que resuelva un problema computacional dado, con el objetivo de proveer estimaciones teóricas de los recursos que necesita. Usualmente, los recursos a los cuales se hace referencia son el tiempo (complejidad temporal) y el almacenamiento (complejidad espacial). Mientras que la complejidad temporal involucra determinar una función que relaciona la longitud o el tamaño de la entrada del algoritmo con el número de pasos que realiza, la complejidad espacial busca la cantidad de ubicaciones de almacenamiento que utiliza. Distintos algoritmos pueden utilizarse para resolver un mismo problema y a su vez los algoritmos pueden estudiarse de forma independiente del lenguaje de programación a utilizar y de la máquina donde se ejecutará.[2]​ Esto significa que se necesitan técnicas que permitan comparar la eficiencia de los algoritmos antes de su implementación.",
        "enlaces_salientes": [
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/B%C3%BAsqueda_lineal",
            "/wiki/B%C3%BAsqueda_binaria",
            "/wiki/Donald_Knuth",
            "/wiki/Algoritmo",
            "/wiki/Problema_computacional",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Registro_(estructura_de_datos)",
            "/wiki/Vector_(inform%C3%A1tica)",
            "/wiki/B%C3%BAsqueda_lineal",
            "/wiki/B%C3%BAsqueda_binaria",
            "/wiki/Algoritmo_de_b%C3%BAsqueda",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Cota_inferior_asint%C3%B3tica",
            "/wiki/Cota_ajustada_asint%C3%B3tica",
            "/wiki/B%C3%BAsqueda_binaria",
            "/wiki/Logaritmo",
            "/wiki/Implementaci%C3%B3n",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Ordenamiento_por_inserci%C3%B3n",
            "/wiki/As%C3%ADntota",
            "/wiki/Modelo_de_computaci%C3%B3n",
            "/wiki/M%C3%A1quina_abstracta",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/B%C3%BAsqueda_binaria",
            "/wiki/Videojuego",
            "/wiki/Donald_Knuth",
            "/wiki/Algoritmos",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Teorema_maestro",
            "/wiki/Optimizaci%C3%B3n_de_software",
            "/wiki/Complejidad_temporal",
            "/wiki/ISBN",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Ronald_L._Rivest",
            "/wiki/Clifford_Stein",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/MIT_Press",
            "/wiki/Gilles_Brassard",
            "/wiki/Control_de_autoridades",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Complejidad_computacional",
        "titulo": "Teoría de la complejidad computacional",
        "contenido": "la teoria de la complejidad  computacional​ o teoria de la complejidad informatica es una rama de la teoria de la computacion que se centra en la clasificacion de los problemas computacionales de acuerdo con su dificultad inherente, y en la relacion entre dichas clases de complejidad.​  un problema se cataloga como \"inherentemente \" si su solucion requiere de una cantidad significativa de recursos computacionales, sin importar el algoritmo utilizado. la teoria de la complejidad computacional formaliza dicha aseveracion, introduciendo  modelos de computacion matematicos para el estudio de estos problemas y la cuantificacion de la cantidad de recursos necesarios para resolverlos, como tiempo y memoria.  una de las metas de la teoria de la complejidad computacional es determinar los limites practicos de que es lo que se puede hacer en una computadora y que no. otros campos relacionados con la teoria de la complejidad computacional son el analisis de algoritmos y la teoria de la computabilidad. una diferencia significativa entre el analisis de algoritmos y la teoria de la complejidad computacional, es que el primero se dedica a determinar la cantidad de recursos requeridos por un algoritmo en particular para resolver un problema, mientras que la segunda, analiza todos los posibles algoritmos que pudieran ser usados para resolver el mismo problema.  la teoria de la complejidad computacional trata de clasificar los problemas que pueden, o no pueden ser resueltos con una cantidad determinada de recursos. a su vez, la imposicion de restricciones sobre estos recursos, es lo que la distingue de la teoria de la computabilidad, la cual se preocupa por que tipo de problemas pueden ser resueltos de manera algoritmica.  antes de que se realizaran investigaciones en torno a la complejidad de los algoritmos, se crearon los cimientos de esta teoria por varios investigadores. uno de los aportes mas influyentes fue la definicion de las maquinas de turing en 1936,​ las cuales resultaron ser una nocion de computadora muy flexible y robusta. a medida que las computadoras se desarrollaban en los 40's y los 50's, la maquina de turing demostro ser el modelo teorico correcto de computo.  sin embargo, rapidamente se descubrio que el modelo basico de la maquina de turing fallaba al cuantificar el tiempo y la memoria requerida por una computadora, un problema critico hoy en dia, y aun mas en aquellos tiempos. la idea de medir el tiempo y espacio como una funcion de la longitud de la entrada se origino a principios de los 60s por hartmanis y stearns, y asi nacio la teoria de la complejidad computacional.  en los inicios, los investigadores trataban de entender las nuevas medidas de complejidad, y como se relacionaban unas con otras. en 1965, edmonds definio un \"buen\" algoritmo como uno con un tiempo de ejecucion acotado por un polinomio, es decir, con un tiempo de ejecucion polinomico.​ esto condujo al surgimiento de uno de los conceptos mas importantes de la teoria de la complejidad computacional: la np-completitud y su pregunta fundamental, si p=np.  el campo comenzo a florecer cuando el investigador estadounidense stephen cook y el sovietico leonid levin, trabajando de manera independiente, probaron que existen problemas relevantes que son np-completos. en 1972, richard karp llevo esta idea un paso mas adelante, demostrando que 21 problemas  combinatorios y de teoria de grafos, caracterizados por ser computacionalmente intratables, eran np-completos.​ tambien en los 70's, se produjo un crecimiento de las clases de complejidad a medida que los investigadores trataban de comprender los distintos modelos de computo existentes.  en los 80's, se produjo un auge de los modelos finitos, que analizaban el proceso de computo de una manera inherentemente distinta. surgio un nuevo acercamiento a problemas como p=np, y aun cuando estos modelos tenian sus limitaciones separando las clases de complejidad, esta aproximacion introdujo tecnicas combinatorias que permitieron un mejor entendimiento de los limites de estos modelos.  ya en los 90's, se estudiaron nuevos modelos de computo como las computadoras cuanticas, donde una misma tarea puede tener diferente complejidad en la computacion clasica y en la computacion cuantica. sin embargo, existen varias limitantes, entre ellas, la de desarrollar un hardware para este modelo, y que se requieren grandes cantidades de espacio para realizar los calculos.  para poder referirnos a problemas como \"inherentemente intratables\" y problemas de dificultad \"equivalente\", es necesario comprender algunos terminos mas basicos.​  un problema computacional constituye una pregunta a ser respondida, teniendo generalmente varios parametros, o variables libres, cuyos valores no se han especificado. un problema se describe mediante:  una instancia de un problema se obtiene cuando se especifican valores particulares para todos los parametros del problema. por ejemplo, consideremos el problema del test de primalidad. la instancia es un numero (e.g. 15) y la solucion es \"si\" si el numero es primo, y \"no\" en caso contrario. visto de otra manera, la instancia es una entrada particular del problema, y la solucion es la salida correspondiente para la entrada dada.  un problema de decision es un tipo especial de problema computacional cuya respuesta es solamente \"si\" o \"no\" (o, de manera mas formal, \"1\" o \"0\").  un problema de decision pudiera verse como un lenguaje formal, donde los elementos que pertenecen al lenguaje son las instancias del problema cuya respuesta es \"si\", los que no pertenecen al lenguaje son aquellas instancias cuya respuesta es \"no\". el objetivo es decidir, con la ayuda de un algoritmo, si una determinada entrada es un elemento del lenguaje formal considerado. si el algoritmo devuelve como respuesta \"si\", se dice que el algoritmo acepta la entrada, de lo contrario se dice que la rechaza.  los problemas de decision constituyen uno de los principales objetos de estudio de la teoria de la complejidad computacional, pues la np-completitud se aplica directamente a estos tipos de problemas en vez de a problemas de optimizacion. estos problemas tienen gran importancia porque casi todo problema puede transformarse en un problema de decision.  podemos decir informalmente, que los algoritmos son procedimientos paso-a-paso para resolver problemas. se puede pensar en ellos como simples programas de computadora, escritos en un lenguaje artificial especifico.​  se dice que un algoritmo resuelve un problema a, si dicho algoritmo se puede aplicar a cualquier instancia i de a, y se garantiza que siempre produce una solucion para dicha instancia. de manera general, nos interesa encontrar el algoritmo mas \"eficiente\" para resolver cierto problema. en su sentido mas amplio, la nocion de eficiencia involucra a todos los recursos computacionales necesarios para la ejecucion de un algoritmo.  por algoritmo \"mas eficiente\" usualmente nos referimos al mas rapido. debido a que los requerimientos de tiempo son usualmente un factor dominante cuando se trata de determinar si un algoritmo es lo suficientemente eficiente para ser util en la practica, nos concentraremos en este recurso.  los cientificos de la computacion realizan la distincion entre algoritmos de tiempo polinomico y algoritmos de tiempo exponencial cuando se trata de caracterizar a los algoritmos como \"suficientemente eficiente\" y \"muy ineficiente\" respectivamente.  un algoritmo de tiempo polinomial​ se define como aquel con funcion de complejidad temporal dentro de una cota superior asintotica (denominada a veces \"orden\") o(p(n)) para alguna funcion polinomica p, donde n denota el tamaño de la entrada. los algoritmos de tiempo exponencial, o ( e n ) , ),} son los que el numero de ciclos que tienen que realizarse con el algoritmo es proporcional a la funcion e n } de modo que el poder computacional necesario para correr el algoritmo crece de forma exponencial al tamaño n del problema.  la mayoria de los algoritmos de tiempo exponencial son simples variaciones de una busqueda exhaustiva, mientras que los algoritmos de tiempo polinomial, usualmente se obtienen mediante un analisis mas profundo de la estructura del problema. en la teoria de la complejidad computacional, existe el consenso de que un problema no esta \"bien resuelto\" hasta que se conozca un algoritmo de tiempo polinomial que lo resuelva. por tanto, nos referiremos a un problema como intratable, si es tan dificil que no existe algoritmo de tiempo polinomial capaz de resolverlo.​  una clase de complejidad es un conjunto de problemas que poseen la misma complejidad computacional.  las clases de complejidad mas sencillas se definen teniendo en cuenta factores como:  la clase p contiene a aquellos problemas resolubles en tiempo polinomico por una maquina de turing determinista.​  para la definicion anterior se ha fijado el modelo de computo: la maquina de turing determinista. existen distintas variantes de la maquina de turing y es conocido que la mas debil de ellas puede simular a la mas fuerte, adicionando a lo sumo un tiempo polinomico. en las decadas posteriores a la tesis de church-turing surgieron otros modelos de computo, y se pudo mostrar que la maquina de turing tambien podia simularlos a lo sumo adicionando tambien un tiempo polinomico. por tanto, la clase analoga a p para dichos modelos no es mayor que la clase p para el modelo de computo de la maquina de turing.  la clase p juega un papel importante en la teoria de la complejidad computacional debido a que:  muchas veces podemos evitar utilizar la fuerza bruta en los problemas para obtener soluciones en tiempo polinomico. sin embargo, para algunos problemas esto no ha podido lograrse, es decir, no se conocen algoritmos que los resuelvan en tiempo polinomico. quizas estos problemas tengan algoritmos en tiempo polinomial que se basan en principios por ahora desconocidos, o quizas estos problemas no pueden ser resueltos en tiempo polinomico, debido a que son \"inherentemente dificiles\".  la clase de complejidad np consta de los problemas \"verificables\" en tiempo polinomico. por verificable se entiende a un problema tal que dado un certificado de solucion (candidato a solucion), se puede verificar que dicho certificado es correcto en un tiempo polinomico en el tamaño de la entrada. a los problemas en la clase np usualmente se les llama problemas np.​  el termino np proviene de no determinista en tiempo polinomico y se deriva de un caracterizacion alternativa de esta clase, donde se utilizan maquinas de turing no deterministas. informalmente, se puede definir la clase np en terminos de un algoritmo no determinista (recordar la equivalencia entre algoritmo y maquina de turing).  el algoritmo mencionado esta compuesto por 2 etapas separadas. dada una instancia del problema i, la primera etapa simplemente \"adivina\" un candidato a solucion s. entonces, la etapa de verificacion recibe como entrada a i y a s, y procede a realizar el computo de una manera determinista, finalmente deteniendose con la respuesta \"si\", o con la respuesta \"no\", o sigue computando sin detenerse.  al igual que la clase p, la clase np es insensible a la eleccion del modelo de computo no determinista, debido a que dichos modelos son equivalentes polinomicamente.  muchas clases de complejidad importantes pueden ser definidas acotando el tiempo o el espacio utilizado por el algoritmo. algunas de estas clases de problemas de decision son:  la relacion entre las clases p y np es fundamental para la teoria de la np-completitud. intuitivamente, creemos que p es un subconjunto de np. y, efectivamente, cada problema de decision resuelto por un algoritmo de tiempo polinomial determinista, tambien puede ser resuelto por un algoritmo de tiempo polinomial no determinista. simplemente se necesita observar que cualquier algoritmo determinista puede ser utilizado en la etapa de verificacion de un algoritmo no determinista. si b es un problema de p, y a es un algoritmo de tiempo polinomial para b, entonces se puede construir un algoritmo de tiempo polinomial no determinista para b, simplemente utilizando a en la etapa de verificacion e ignorando la etapa de adivinacion. por tanto, si b pertenece a p, entonces b tambien pertenece a np.  la pregunta p=np es una de las mas importantes en el campo de las ciencias de la computacion, debido a las grandes repercusiones que habria, en caso de encontrarse una solucion. si p=np, cualquier problema polinomica mente verificable seria polinomica mente decidible. la mayoria de los investigadores cree que estas clases no son iguales, porque se ha realizado bastantes esfuerzos, sin exito, para encontrar algoritmos de tiempo polinomial para varios problemas en np. los investigadores tambien han tratado de probar que las clases son distintas, pero eso conllevaria a mostrar que no existe un algoritmo «eficiente» para reemplazar a la busqueda por fuerza bruta.  una reduccion es una transformacion de un problema en otro problema. intuitivamente, un problema q puede ser reducido a otro problema q', si cualquier instancia del problema q puede ser \"facilmente\" expresada como una instancia del problema q', y cuya solucion proporcione una solucion para la instancia de q.​  existen muchos tipos de reducciones: basadas en el metodo de reduccion, como las reducciones de cook, las reducciones de karp y las reducciones de levin, y las basadas en la cota de la complejidad, como la  reduccion en tiempo polinomial o la reduccion de espacio logaritmica. una de las reducciones mas utilizadas es la reduccion en tiempo polinomial, lo cual significa que el proceso de reduccion toma un tiempo polinomial.  las reducciones en tiempo polinomial nos dotan de elementos para probar, de una manera formal, que un problema es al menos tan dificil que otro, con una diferencia de un factor polinomial. estas son esenciales para definir a los  problemas np-completos, ademas de ayudar a comprender los mismos.  la clase de los problemas np-completos contiene a los problemas mas dificiles en np, en el sentido de que son los que esten mas lejos de estar en p. debido a que el problema p=np no ha sido resuelto, el hecho de reducir un problema b, a otro problema a, indicaria que no se conoce solucion en tiempo polinomial para a. esto es debido a que una solucion en tiempo polinomial para a, tendria como consecuencia la existencia de una solucion polinomial para b. de manera similar, debido a que todos los problemas np pueden ser reducidos a este conjunto, encontrar un problema np-completo que pueda ser resuelto en un tiempo polinomial significaria que p=np.  quizas la razon de mayor peso por la cual los cientificos de la computacion creen que p es distinto de np, es la existencia de la clase de problemas \"np-completos\". esta clase tiene la curiosa propiedad de que si algun problema np-completo puede ser resuelto en tiempo polinomial, entonces todo problema en np tiene una solucion en tiempo polinomial, es decir, p=np. a pesar de años de estudio, ningun algoritmo de tiempo polinomial se ha descubierto para ningun problema np-completo.  desde el punto de vista teorico, un investigador intentando mostrar que la clase p es distinta de la clase np, pudiera enfocarse en un problema np-completo. si algun problema en np requiere mas que un tiempo polinomial, entonces uno np-completo tambien. ademas, un investigador intentando demostrar que p=np, solo necesita encontrar un algoritmo de tiempo polinomial para un problema np-completo para lograrlo.  desde el punto de vista practico, el fenomeno de la np-completitud puede prevenir la perdida de tiempo cuando se busca un algoritmo de tiempo polinomial no existente para resolver un problema determinado. aun cuando no se posean los elementos matematicos para demostrar que cierto problema no se puede resolver en tiempo polinomial, creemos que p no es igual a np, asi que demostrar que el problema es np-completo, es una fuerte evidencia de su no \"polinomialdad\".  teniendo en cuenta la definicion de problema intratable, si no se cumple que p=np, entonces los problemas np-completos son intratables.  muchos problemas de la practica son np-completos, y son muy importantes como para desistir simplemente porque no sabemos como encontrar una solucion optima en tiempo polinomial. aunque un problema sea np-completo, puede haber esperanza. existen tres estrategias fundamentales para lidiar con un problema np-completo: ",
        "snippet": "La teoría de la complejidad computacional[1]​ o teoría de la complejidad informática es una rama de la teoría de la computación que se centra en la clasificación de los problemas computacionales de acuerdo con su dificultad inherente, y en la relación entre dichas clases de complejidad.[2]​",
        "enlaces_salientes": [
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Teor%C3%ADa_de_la_complejidad_computacional",
            "/wiki/Gram%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Problema_computacional",
            "/wiki/Clase_de_complejidad",
            "/wiki/Modelo_de_computaci%C3%B3n",
            "/wiki/Computadora",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Jack_Edmonds",
            "/wiki/Tiempo_de_ejecuci%C3%B3n",
            "/wiki/Polinomio",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/NP-completo",
            "/wiki/Clases_de_complejidad_P_y_NP",
            "/wiki/Stephen_Cook",
            "/wiki/Leonid_Levin",
            "/wiki/Richard_Karp",
            "/wiki/Combinatoria",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Computaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Problema_computacional",
            "/wiki/Problema_de_decisi%C3%B3n",
            "/wiki/Algoritmo",
            "/wiki/Tiempo_polin%C3%B3mico",
            "/wiki/Tiempo_exponencial",
            "/wiki/Cota_superior_asint%C3%B3tica",
            "/wiki/O_grande",
            "/wiki/Clase_de_complejidad",
            "/wiki/P_(clase_de_complejidad)",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/NP_(clase_de_complejidad)",
            "/wiki/DTIME",
            "/wiki/P_(clase_de_complejidad)",
            "/wiki/PP_(clase_de_complejidad)",
            "/wiki/EXPTIME",
            "/wiki/NTIME",
            "/wiki/NP_(clase_de_complejidad)",
            "/wiki/NEXPTIME",
            "/wiki/DSPACE",
            "/wiki/L_(clase_de_complejidad)",
            "/wiki/PSPACE",
            "/wiki/EXPSPACE",
            "/wiki/NSPACE",
            "/wiki/NL_(clase_de_complejidad)",
            "/wiki/NPSPACE",
            "/wiki/EXPSPACE",
            "/wiki/Clases_de_complejidad_P_y_NP",
            "/wiki/Transformaci%C3%B3n_polin%C3%B3mica",
            "/wiki/Transformaci%C3%B3n_polin%C3%B3mica",
            "/wiki/NP-completo",
            "/wiki/NP-completo",
            "/wiki/Algoritmo_de_aproximaci%C3%B3n",
            "/wiki/Heur%C3%ADstica",
            "/wiki/Metaheur%C3%ADstica",
            "/wiki/Reducci%C3%B3n_(complejidad)",
            "/wiki/Teorema_de_Cook-Levin",
            "/wiki/Lista_de_21_problemas_NP-completos_de_Karp",
            "/wiki/Clases_de_complejidad_P_y_NP",
            "/wiki/Teorema_de_la_jerarqu%C3%ADa_temporal",
            "/wiki/Complejidad_de_Kolmog%C3%B3rov",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/MIT_Press",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/Stephen_Cook",
            "/wiki/ISSN",
            "/wiki/Sanjeev_Arora",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/Zentralblatt_MATH",
            "/wiki/ISBN",
            "/wiki/Michael_Garey",
            "/wiki/David_S._Johnson",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Ronald_L._Rivest",
            "/wiki/Clifford_Stein",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Gobierno_por_algoritmos",
        "titulo": "Gobierno por algoritmos",
        "contenido": "el gobierno por algoritmo (tambien conocido como regulacion algoritmica, regulacion por algoritmos, gobierno algoritmico, gobierno algocratico, orden legal algoritmico o algocracia) es una forma alternativa de gobierno u orden social en la que el uso de algoritmos informaticos, especialmente de inteligencia artificial y blockchain, se aplica a las regulaciones, a la aplicacion de la ley y, en general, a cualquier aspecto de la vida cotidiana, como el transporte o el registro de la propiedad.​​​​​​​​ el termino gobierno por algoritmos aparecio en la literatura academica como una alternativa para «gobernanza algoritmica» en 2013.​ la regulacion algoritmica, termino relacionado, se define como el establecimiento de la norma, la supervision y la modificacion del comportamiento por medio de algoritmos computacionales; la automatizacion del poder judicial esta en su ambito.​  el gobierno por algoritmo presenta nuevos retos que no estan recogidos en la literatura sobre el gobierno electronico ni en la practica de la administracion publica.​ algunas fuentes equiparan la cibercracia, que es una forma de gobierno hipotetica que se rige por el uso eficaz de informacion, con el gobierno por algoritmos, a pesar de que los algoritmos no son el unico medio de procesar la informacion.​​​​​ nello cristianini y teresa scantamburlo sostienen que la combinacion de una sociedad humana y ciertos algoritmos de regulacion (como la puntuacion basada en la reputacion) forma una maquina social.​  en 1962, el director del instituto para problemas de transmision de la informacion de la academia rusa de ciencias en moscu (mas tarde conocido como instituto kharkevich),​ alexander kharkevich, publico un articulo en el diario \"comunista\" sobre una red informatica para el procesamiento de la informacion y el control de la economia.​​ de hecho, propuso hacer una red como la moderna internet para las necesidades del gobierno algoritmico. esto creo una gran preocupacion entre los analistas de la cia.​ en particular, arthur m. schlesinger jr. advirtio que ''para 1970 la urss puede tener una tecnologia de produccion radicalmente nueva, que implique empresas totales o complejos de industrias, gestionadas por un control de bucle cerrado y retroalimentado que emplee ordenadores autodidactas.''​  entre los años 1971 y 1973, el gobierno chileno llevo a cabo el proyecto cybersyn durante la presidencia de salvador allende. este proyecto tenia como objetivo construir un sistema distribuido de apoyo a la toma de decisiones para mejorar la gestion de la economia nacional.​​   tambien en la decada de 1960 y 1970, herbert a. simon defendio los sistemas expertos como herramientas para la racionalizacion y evaluacion de los comportamientos administrativos.​ la automatizacion de los procesos basados en reglas fue una ambicion de las agencias tributarias a lo largo de muchas decadas que tuvo un exito variable.​ entre los primeros trabajos de este periodo se encuentran el influyente proyecto taxman de thorne mccarty​  en los ee.uu. y el proyecto legol de ronald stamper en reino unido.​ en 1993, el informatico paul cockshott de la universidad de glasgow y el economista allin cottrell de la universidad de wake forest publicaron el libro hacia un socialismo nuevo, en el que pretendian demostrar la posibilidad de una economia planificada democraticamente y basada en la tecnologia informatica moderna.​ el honorable juez  michael kirby publico un articulo en 1998, donde  expresa su optimismo de que las tecnologias informaticas disponibles en ese momento, como el sistema de expertos legales, podrian evolucionar hacia sistemas informaticos, lo que afectaria fuertemente a la practica de los tribunales.​ en 2006, el abogado lawrence lessig, conocido por el lema \"el codigo es la ley\", escribio \"la mano invisible del ciberespacio esta construyendo una arquitectura que es bastante contraria a la arquitectura en su nacimiento. esta mano invisible, empujada por el gobierno y por el comercio, esta construyendo una arquitectura que perfeccionara el control y hara posible una regulacion altamente eficaz.\"​  desde la decada de los 2000, los algoritmos han sido diseñados y utilizados para analizar automaticamente videos de vigilancia.​  el sociologo a. aneesh utilizo la idea de gobierno algoritmico en 2002 en su teoria de la algocracia.​​​ aneesh diferencio los sistemas algocraticos de los sistemas burocraticos (regulacion legal-racional) asi como de los sistemas basados en el mercado (regulacion basada en el precio).​   en 2013, el control algoritmico fue acuñado por tim o'reilly, fundador y ceo de o'reilly media inc: a veces las \"reglas\" no son ni siquiera reglas. gordon bruce, el anterior cio de la ciudad de honolulu, me explico  que cuando  entro al gobierno desde el sector privado e intento hacer cambios, le dijeron, \"eso va contra la ley.\" su respuesta fue \"vale. muestrame la ley.\" \"bueno, en realidad no es una ley. es un reglamento.\" \"vale. muestrame el reglamento\" \"bueno, no es realmente un reglamento. es una politica que fue puesta en marcha por el sr. alguien hace veinte años\" \"estupendo. podemos cambiarlo\".  [...] las leyes tendrian que especificar objetivos, derechos, resultados, autoridades, y limites. hablando en terminos generales, esas leyes sobreviven al paso del tiempo. si se especifican con amplitud, esas leyes pueden resistir el paso del tiempo. los reglamentos, que especifican como ejecutar esas leyes con mucho mas detalle, deberian considerarse de forma muy parecida a como los programadores consideran su codigo y sus algoritmos, es decir, como un conjunto de herramientas constantemente actualizadas para lograr los resultados especificados en las leyes. [...]  es hora de que el gobierno entre en la era de los grandes datos. la regulacion algoritmica es una idea a la que le ha llegado la hora.​  en 2017, el ministerio de justicia de ucrania llevo a cabo subastas gubernamentales experimentales utilizando la tecnologia blockchain para garantizar la transparencia y dificultar la corrupcion en las transacciones gubernamentales.​ \"¿gobierno por algoritmos?\" fue el tema central presentado en la conferencia data for policy 2017, celebrada los dias 6 y 7 de septiembre de 2017 en londres (reino unido).​  una ciudad inteligente es una zona urbana, en la que los datos de vigilancia recogidos se utilizan para mejorar diversas operaciones en esta zona. el aumento de la potencia de calculo permite una toma de decisiones mas automatizada y la sustitucion de los organismos publicos por una gobernanza algoritmica.​ en particular, el uso combinado de la inteligencia artificial y las cadenas de bloques para el internet de las cosas podria conducir a la creacion de ecosistemas de ciudades inteligentes sostenibles. el alumbrado publico inteligente de glasgow es un ejemplo de los beneficios que aporta la aplicacion gubernamental de algoritmos de ia.​  el  millonario de las criptomonedas, jeffrey berns, propuso gestionar los gobiernos locales mediante empresas de tecnologia en nevada en 2021.​ el señor berns compro 67,000 acres (271 km²) en el condado rural de storey, en nevada, por 170,000,000 dolares (121,000,000 libras) en 2018 para desarrollar una ciudad inteligente con mas de 36,000 residentes que generasen una produccion anual de 4,600,000 dolares.​ se permitiria el uso de criptomonedas como forma de pago.  tim o'reilly sugirio que las fuentes de datos y los sistemas de reputacion combinados en la regulacion algoritmica pueden superar las regulaciones tradicionales..​ por ejemplo, una vez que los pasajeros califiquen a los taxistas, la calidad de sus servicios mejorara automaticamente y \"los conductores que presten un mal servicio seran eliminados\".​ la sugerencia de o'reilly se basa en el concepto de control teorico de bucle de retroalimentacion: las mejoras y desmejoras de la reputacion imponen el comportamiento deseado.​ el uso de bucles de retroalimentacion para la gestion de sistemas sociales ya fue sugerido anteriormente por stafford beer en la cibernetica de la gestion.​  estas conexiones son exploradas por nello cristianini y teresa scantamburlo​ donde el sistema de puntuacion de reputacion y credito se modela como un incentivo dado a los ciudadanos y computado por una maquina social,  de modo que los agentes racionales serian motivados para aumentar su puntuacion adaptando su comportamiento. varios aspectos eticos de esta tecnologia siguen siendo objeto de debate.  el sistema de credito social de china esta estrechamente relacionado con los sistemas de vigilancia masiva de china como el skynet,​​​ el cual incorpora un sistema de reconocimiento facial, una tecnologia de analisis de big data e ia.​​​​  este sistema proporciona evaluaciones de la fiabilidad de las personas y las empresas.​​​ entre los comportamientos que el sistema considera como mala conducta, se citan el hecho de cruzar la calle imprudentemente y no clasificar correctamente los residuos personales.​​​​​ entre los comportamientos considerados como factores positivos de la calificacion crediticia se encuentran la donacion de sangre, las donaciones a organizaciones beneficas, el voluntariado para servicios comunitarios, etc..​​ el sistema de credito social chino  permite castigar a los ciudadanos \"poco fiables\", como negarles la compra de billetes, y premiar a los \"fiables\", como reducir el tiempo de espera en hospitales y organismos publicos.​​​  los contratos inteligentes, criptodivisas, y la organizacion autonoma descentralizada se mencionan como un medios parasustituir las formas tradicionales de gobierno.​​​ las criptodivisas son monedas que se activan mediante algoritmos sin un banco central gubernamental.​ la moneda digital del banco central a menudo emplea una tecnologia similar, pero se diferencia por el hecho de que utiliza un banco central. pronto sera empleada por los principales sindicatos y gobiernos, como la union europea y china. los contratos inteligentes son contratos auto-ejecutables, cuyos objetivos son la reduccion de la necesidad de intermediarios gubernamentales de confianza, los arbitrajes y los costes de ejecucion.​​ una organizacion autonoma descentralizada es una organizacion  representada por contratos inteligentes que es transparente, controlada por los accionistas y no influenciada por un gobierno central.​​​ se ha hablado de los contratos inteligentes para su uso en aplicaciones tales como el uso en contratos de trabajo​​ (temporales) y en la transferencia automatica de fondos y propiedades (es decir, la herencia, tras el registro de un certificado de defuncion).​​​​ algunos paises como georgia y suecia ya han puesto en marcha programas de blockchain centrados en la propiedad (titulos de propiedad y propiedad inmobiliaria).​​​​ ucrania tambien esta estudiando otros ambitos, como los registros estatales.​   de acuerdo a un estudio de la universidad de stanford, el 45% de las agencias federales de los estados unidos han experimentado con la ia y herramientas relacionadas con el aprendizaje automatico hasta 2020.​ las agencias federales de estados unidos han contado con los siguientes numeros de las aplicaciones de inteligencia artificial.​  el 53% de estas aplicaciones estuvieron producidas por expertos internos.​ entre los proveedores comerciales de aplicaciones residuales se encuentra palantir technologies.​  desde 2012, la nopd empezo a colaborar con palantir technologies en el campo de la vigilancia predictiva.​ ademas del software gotham de palantir, otros programas similares (de analisis numerico) utilizados por los organismos policiales (como el ncric) son sas.​  en la lucha contra el blanqueo de capitales, el fincen emplea el sistema de inteligencia artificial fincen (fais).​  las entidades y organizaciones nacionales de administracion sanitaria, como ahima (american health information management association)  son titulares de las historias clinicas. las historias clinicas sirven de repositorio central para planificar la atencion al paciente y documentar la comunicacion entre este y los profesionales que contribuyen a su cuidado.  en la ue, se esta trabajando en un espacio europeo de datos sanitarios que de soporte al uso de los datos sanitarios.​  el departamento de seguridad nacional de los estados unidos  ha empleado el software atlas, que se ejecuta en amazon cloud. este software escanea mas de 16.5 millones de registros de americanos nacionalizados y se marcaron aproximadamente 124.000 de ellos para realizar analisis y revisiones por parte de agentes de la uscis con respecto a la desnaturalizacion.​​ estas personas fueron etiquetadas por posibles fraudes y por cuestiones de seguridad publica y nacional. algunos de los datos escaneados procedieron de la terrorist screening database y del national crime information center.  en estonia, la inteligencia artificial es utilizada en su gobierno electronico para hacerlo mas automatizado y constante. un asistente virtual guiara a los ciudadanos en cualquier interaccion que tengan con el gobierno. los servicios automatizados y proactivos ofreceran servicios a los ciudadanos en momentos clave de sus vidas (incluyendo nacimientos, perdidas de familiares, paro, etc.). un ejemplo de estos servicios es el registro automatizado de bebes cuando estos nacen.​ el sistema x-road de estonia tambien se reconstruira para incluir aun mas control de la privacidad y responsabilidad en la forma en que el gobierno utiliza los datos de los ciudadanos.​  en costa rica, se ha investigado sobre la posibilidad de digitalizar las actividades de aprovisionamiento publico (por ejemplo, licitaciones para el empleo publico, etc.). el documento que discute esta posibilidad menciona que el uso de las tic en el aprovisionamiento tiene varios beneficios tales como la mejora en la transparencia, facilidad para acceder digitalmente a concursos publicos, reduccion de la interaccion directa entre los funcionarios encargados de la contratacion y las empresas en momentos de alto riesgo para la integridad, el aumento del alcance y la competencia, y la deteccion mas facil de las irregularidades.​  aparte de utilizar los concursos electronicos publicos para trabajos publicos regulares (construccion de edificios, etc.), tambien pueden usarse para proyectos de reforestacion y otros proyectos de restauracion de sumideros de carbono.​ estos proyectos de restauracion de sumideros de carbono pueden formar parte de los planes de contribuciones determinadas a nivel nacional para alcanzar los objetivos nacionales del acuerdo de paris.  tambien se puede utilizar un software de auditoria para la contratacion publica.​​ las auditorias se realizan en algunos paises despues de que hayan recibido los subsidios.  algunas agencias gubernamentales proporcionan sistemas de seguimiento y localizacion en los servicios que ofrecen. un ejemplo de ello es el seguimiento de las solicitudes realizadas por los ciudadanos en sus aplicaciones (por ejemplo, para la obtencion del permiso de conduccion).​  algunos servicios del gobierno usan sistemas de seguimiento de incidentes para mantener un registro de todas las proximas tareas que se van a realizar.​​​​ estos sistemas pueden mostrar todas las tareas pendientes de la administracion (en una cola de espera), tareas finalizadas, tareas en progreso, orden de las tareas, etc.. las tareas terminadas tambien pueden ser previstas con el informe, mostrando exactamente que se ha hecho con el incidente.  el software compas se utiliza en ee.uu. para evaluar el riesgo de reincidencia en tribunales.​  segun la declaracion del tribunal de internet de beijing, china es el primer pais  en crear un tribunal de internet o ciber tribunal.​​​ la jueza chinese ai es una recreacion virtual  de una jueza real. \"ayudara a los jueces del tribunal a completar trabajo basico y repetitivo, incluyendo la recepcion de pleitos, habilitando asi a los practicantes profesionales a centrarse mejor en su trabajo en el juzgado\".​  tambien estonia planea emplear inteligencia artificial para decidir casos de reclamacion pequeña de menos de 7,000 euros.​  los robots juridicos pueden llevar a cabo tareas que son tipicamente realizadas por asistentes legales o socios jovenes en empresas de ley. una tecnologia asi utilizada por empresas juridicas de los ee.uu. para la ayuda en la busqueda legal es de ross intelligence,​ y otros varian en la sofisticacion y dependencia sobre los algoritmos.​ otra aplicacion de chatbot de tecnologia legal es donotpay.  debido a la pandemia del covid-19 en 2020, los examenes finales presenciales eran imposibles para miles de estudiantes.​ el instituto publico westminster high school empleo algoritmos para asignar calificaciones. el departamento de educacion de reino unido tambien empleo un calculo estadistico para asignar calificaciones finales a los niveles avanzados, debido a la pandemia.​  ademas de su uso en las calificaciones, los sistemas de software y la ia tambien estan optimizando el trabajo del curso y se esta utilizado en la preparacion de examenes de acceso a la universidad.​  asistentes de enseñanza ia estan siendo desarrollados y utilizados para la educacion (i.e. georgia tech, de jill watson)​​ y  tambien hay un debate actual sobre si quizas los profesores pueden ser enteramente reemplazados por sistemas ia (i.e. en la educacion en el hogar).​  en 2018, un activista llamado michihito matsuda se presento a candidato a la alcaldia en la ciudad de tama, en tokio, como representante humano de un programa de inteligencia artificial.​ mientras que los carteles electorales y el material de la campaña utilizaban el termino robot de plazo, y mostrar imagenes de stock de un androide femenino, el \"alcalde de la ia\" era en realidad un algoritmo de aprendizaje automatico que fue entrenado utilizando conjuntos de datos  de la ciudad de tama.​ el proyecto estuvo respaldado por los ejecutivos de alto nivel tetsuzo matsumoto de softbank y norio murakami de google.​ michihito matsuda quedo tercero en las elecciones, siendo derrotado por hiroyuki abe.​ los organizadores afirmaron que el 'alcalde de la ia' fue programado para analizar las peticiones online que los ciudadanos presentan al ayuntamiento de una forma mas 'justa y equilibrada' que los politicos humanos.​  en 2019, el chatbot de mensajeria impulsado por la ia, sam, participo en los debates en las redes sociales relacionados con una carrera electoral en nueva zelanda.​ el creador de sam, nick gerritsen, cree que sam sera lo suficientemente avanzado como para presentarse como candidato a finales de 2020, cuando nueva zelanda tenga sus proximas elecciones generales.​  en febrero de 2020, china lanzo una aplicacion movil llamada \"detector de contacto cercano\"​ para hacer frente a la pandemia del coronavirus.​ se solicita a los usuarios que ingresen su nombre y numero de identificacion. la aplicacion puede detectar \"contacto cercano\" utilizando datos de vigilancia (es decir, utilizando registros de transporte publico, incluidos trenes y vuelos)​ y, por lo tanto, un riesgo potencial de infeccion. cada usuario tambien puede comprobar el estado de otros tres usuarios. para realizar esta consulta, los usuarios escanean un codigo de respuesta rapida (qr) en sus telefonos inteligentes utilizando aplicaciones como alipay o wechat.​ se puede acceder al detector de contacto cercano a traves de aplicaciones moviles populares, incluida alipay. si se detecta un riesgo potencial, la aplicacion no solo recomienda la auto cuarentena, sino que tambien alerta a los funcionarios de salud locales.​  alipay tambien tiene el codigo de salud de alipay, que se utiliza para proteger a los ciudadanos. este sistema genera un codigo qr en uno de los tres colores (verde, amarillo o rojo) despues de que los usuarios completen un formulario en alipay con sus datos personales. un codigo verde permite al titular moverse sin restricciones. un codigo amarillo requiere que el usuario permanezca en casa durante siete dias y el rojo significa una cuarentena de dos semanas. en algunas ciudades como hangzhou, se ha vuelto casi imposible moverse sin mostrar el codigo alipay.​  en cannes, francia, se ha utilizado software de monitoreo en metraje filmado por camaras cctv, lo que permite monitorear su cumplimiento con el distanciamiento social local y el uso de mascaras durante la pandemia de covid-19. el sistema no almacena datos de identificacion, sino que permite alertar a las autoridades de la ciudad y a la policia cuando se detectan infracciones de la mascara y las reglas de uso de la mascara (lo que permite que se apliquen multas donde sea necesario). los algoritmos utilizados por el software de monitorizacion se pueden incorporar a los sistemas de vigilancia existentes en espacios publicos (hospitales, estaciones, aeropuertos, centros comerciales, …)​  los datos de telefonos moviles se utilizan para localizar pacientes infectados en corea del sur, taiwan, singapur y otros paises.​​ en marzo de 2020, el gobierno israeli permitio a las agencias de seguridad rastrear los datos de telefonos moviles de personas que se suponia que tenian coronavirus. la medida se tomo para hacer cumplir la cuarentena y proteger a quienes puedan entrar en contacto con ciudadanos infectados.​ tambien en marzo de 2020, deutsche telekom compartio datos de telefonos moviles privados con la agencia del gobierno federal, el instituto robert koch, con el fin de investigar y prevenir la propagacion del virus.​  rusia implemento tecnologia de reconocimiento facial para detectar quebrantadores de la cuarentena.​ el comisionado regional de salud italiano, giulio gallera, dijo que \"el 40% de las personas continuan moviendose de todos modos\", segun le han informado los operadores de telefonia movil.​ en ee. uu., europa y el reino unido, palantir technologies se encarga de proporcionar los servicios de seguimiento de covid-19.​ los tsunamis pueden ser detectados por sistemas de alerta de tsunamis, que pueden hacer uso de la ia.​​ las inundaciones tambien pueden ser detectados por sistemas de la ia.​ se pueden aproximar las areas de reproduccion de las langostas mediante el aprendizaje automatico, lo que podria ayudar a detener los enjambres de langostas en una fase temprana.​ ademas, se pueden detectar posibles incendios forestales utilizando sistemas de la ia​​ (es decir, a traves de datos provenientes de satelites, imagenes aereas y posicion del personal en tiempo real),​​​ y pueden ayudar a evacuar a personas durante los incendios.​  se supone que la regulacion algoritmica es un sistema de gobierno donde los datos mas exactos, recopilados de los ciudadanos a traves de sus dispositivos inteligentes y computadoras, se utilizan para organizar de manera mas eficiente la vida humana como un colectivo.​​ como deloitte estimo en 2017, la automatizacion del trabajo del gobierno de ee. uu. podria ahorrar 96.7 millones de horas federales al año, con un ahorro potencial de $ 3.3 mil millones; en el extremo superior, esto se eleva a 1,2 mil millones de horas y ahorros anuales potenciales de $ 41,1 mil millones.​  existen riesgos potenciales asociados con el uso de algoritmos en el gobierno. entre ellos se incluyen los algoritmos que se vuelven susceptibles al sesgo, la falta de transparencia en la forma en que un algoritmo puede tomar decisiones y la responsabilidad de tales decisiones.​​​  tambien existe una seria preocupacion de que puedan ocurrir manipulaciones por parte de las partes reguladas, una vez que la gobernanza algoritmica aporta mas transparencia a la toma de decisiones, las partes reguladas podrian intentar manipular su resultado a su favor e incluso utilizar el aprendizaje automatico contradictorio.​​ segun yuval noah harari, el conflicto entre la democracia y la dictadura se ve como un conflicto entre dos sistemas diferentes de procesamiento de datos: la inteligencia artificial y los algoritmos pueden inclinar la ventaja hacia la segunda al procesar enormes cantidades de informacion de forma centralizada.​  en 2018, los paises bajos emplearon un sistema algoritmico syri (systeem risico indicatie) para detectar ciudadanos percibidos como de alto riesgo de cometer fraude social, que silenciosamente señalo a miles de personas a los investigadores.​ esto provoco una protesta publica. el tribunal de distrito de la haya cerro syri haciendo referencia al articulo 8 del convenio europeo de derechos humanos (cedh).​  los colaboradores del documental ihuman de 2019 expresaron su aprension por las \"dictaduras infinitamente estables\" creadas por el gobierno ai.​  en 2020, los algoritmos que asignaban calificaciones en los examenes a los alumnos en el reino unido provoco una protesta abierta bajo el lema \"fuck the algorithm\".​ la protesta fue exitosa y las calificaciones fueron retiradas.​  en 2020, el software del gobierno de ee.uu., atlas, que se ejecuta en la amazon cloud, provoco la indignacion de los activistas y de los propios empleados de amazon.​  en 2021, la fundacion eticas ha lanzado una base de datos de algoritmos gubernamentales denominada observatorio de algoritmos con impacto social (oasi).​  un enfoque inicial hacia la transparencia incluyo el codigo abierto de algoritmos.​ se puede examinar el codigo de software y se pueden proponer mejoras a traves de instalaciones de alojamiento de codigo fuente.  una encuesta de 2019 realizada por el centro para la gobernanza del cambio de la ie universidad en españa encontro que el 25% de los ciudadanos de paises europeos seleccionados estaban algo o totalmente a favor de permitir que una inteligencia artificial tomara decisiones importantes sobre como se administra su pais.​ la siguiente tabla enumera los resultados por pais:  los investigadores encontraron pruebas de que cuando los ciudadanos perciben que sus dirigentes politicos o proveedores de seguridad no son de fiar, son decepcionantes o inmorales,  prefieren reemplazarles por agentes artificiales, a los que consideran mas fiables.​ la evidencia se establece mediante experimentos con encuestas a estudiantes universitarios de todos los generos.  las novelas daemon y libertad™ por daniel suarez describen un escenario ficticio de regulacion algoritmica global.​ ",
        "snippet": "El gobierno por algoritmo (también conocido como regulación algorítmica, regulación por algoritmos, gobierno algorítmico, gobierno algocrático, orden legal algorítmico o algocracia) es una forma alternativa de gobierno u orden social en la que el uso de algoritmos informáticos, especialmente de inteligencia artificial y blockchain, se aplica a las regulaciones, a la aplicación de la ley y, en general, a cualquier aspecto de la vida cotidiana, como el transporte o el registro de la propiedad.[1]​[2]​[3]​[4]​[5]​[6]​[7]​[8]​ El término gobierno por algoritmos apareció en la literatura académica como una alternativa para «gobernanza algorítmica» en 2013.[9]​ La regulación algorítmica, término relacionado, se define como el establecimiento de la norma, la supervisión y la modificación del comportamiento por medio de algoritmos computacionales; la automatización del poder judicial está en su ámbito.[10]​",
        "enlaces_salientes": [
            "/wiki/Gobierno_por_algoritmos",
            "/wiki/Gobierno_por_algoritmos",
            "/wiki/Gobierno_por_algoritmos",
            "/wiki/Macrodatos",
            "/wiki/Gobierno",
            "/wiki/Orden_social",
            "/wiki/Algoritmo",
            "/wiki/Inteligencia_artificial",
            "/wiki/Cadena_de_bloques",
            "/wiki/Normativa",
            "/wiki/Fuerza_de_seguridad",
            "/wiki/Transporte",
            "/wiki/Registro_de_la_propiedad",
            "/wiki/Gobernanza",
            "/wiki/Gobierno_electr%C3%B3nico",
            "/wiki/Administraci%C3%B3n_p%C3%BAblica",
            "/wiki/Gobierno",
            "/wiki/Academia_de_Ciencias_de_Rusia",
            "/wiki/Arthur_M._Schlesinger_Jr.",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Chile",
            "/wiki/Cybersyn",
            "/wiki/Gobierno_de_Salvador_Allende",
            "/wiki/Sistemas_de_soporte_a_decisiones",
            "/wiki/Herbert_A._Simon",
            "/wiki/Sistema_experto",
            "/wiki/Paul_Cockshott",
            "/wiki/Universidad_de_Glasgow",
            "/wiki/Universidad_de_Wake_Forest",
            "/wiki/Michael_Kirby",
            "/wiki/Lawrence_Lessig",
            "/wiki/El_c%C3%B3digo_y_otras_leyes_del_ciberespacio",
            "/wiki/Circuito_cerrado_de_televisi%C3%B3n",
            "/wiki/Tim_O%27Reilly",
            "/wiki/Ciudad_inteligente",
            "/wiki/Internet_de_las_cosas",
            "/wiki/Criptomonedas",
            "/wiki/Gobierno_local",
            "/wiki/Nevada",
            "/wiki/Condado_de_Storey",
            "/wiki/Nevada",
            "/wiki/Teor%C3%ADa_del_control",
            "/wiki/Realimentaci%C3%B3n",
            "/wiki/Realimentaci%C3%B3n_positiva",
            "/wiki/Realimentaci%C3%B3n_negativa",
            "/wiki/Stafford_Beer",
            "/wiki/Sistema_de_cr%C3%A9dito_social_chino",
            "/wiki/Sistema_de_reconocimiento_facial",
            "/wiki/Tecnolog%C3%ADa",
            "/wiki/Macrodatos",
            "/wiki/Recogida_selectiva_de_basura",
            "/wiki/Donaci%C3%B3n_de_sangre",
            "/wiki/Voluntariado",
            "/wiki/Contratos_inteligentes",
            "/wiki/Criptomoneda",
            "/wiki/Organizaci%C3%B3n_aut%C3%B3noma_descentralizada",
            "/wiki/Banco_central",
            "/wiki/Contrato_inteligente",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Contrato_laboral",
            "/wiki/Herencia_(Derecho)",
            "/wiki/Inmueble",
            "/wiki/Universidad_Stanford",
            "/wiki/Inteligencia_artificial",
            "/wiki/Comisi%C3%B3n_de_Bolsa_y_Valores",
            "/wiki/NASA",
            "/wiki/Administraci%C3%B3n_de_Medicamentos_y_Alimentos",
            "/wiki/Servicio_Geol%C3%B3gico_de_Estados_Unidos",
            "/wiki/Servicio_Postal_de_los_Estados_Unidos",
            "/wiki/Administraci%C3%B3n_del_Seguro_Social",
            "/wiki/Oficina_de_Patentes_y_Marcas_Registradas_de_Estados_Unidos",
            "/wiki/Oficina_de_Estad%C3%ADsticas_Laborales",
            "/wiki/Oficina_de_Aduanas_y_Protecci%C3%B3n_Fronteriza_de_los_Estados_Unidos",
            "/wiki/Palantir_Technologies",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/SAS_(software)",
            "/wiki/FinCEN",
            "/wiki/Historia_cl%C3%ADnica",
            "/wiki/Departamento_de_Seguridad_Nacional_de_los_Estados_Unidos",
            "/wiki/Amazon_Web_Services",
            "/wiki/Servicio_de_Ciudadan%C3%ADa_e_Inmigraci%C3%B3n_de_los_Estados_Unidos",
            "/wiki/Gobierno_electr%C3%B3nico",
            "/wiki/Obra_p%C3%BAblica",
            "/wiki/Reforestaci%C3%B3n",
            "/wiki/Sumidero_de_carbono",
            "/wiki/Sumidero_de_carbono",
            "/wiki/Acuerdo_de_Par%C3%ADs",
            "/wiki/Sistema_de_seguimiento_de_incidentes",
            "/wiki/Reincidencia",
            "/wiki/Estonia",
            "/wiki/Algoritmo",
            "/wiki/Chatbot",
            "/wiki/Departamento_de_Educaci%C3%B3n_(Reino_Unido)",
            "/wiki/Advanced_Level",
            "/wiki/Educaci%C3%B3n_en_el_hogar",
            "/wiki/Tama_(Tokio)",
            "/wiki/Inteligencia_artificial",
            "/wiki/Fotograf%C3%ADa_de_stock",
            "/wiki/Androide",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/SoftBank",
            "/wiki/Google",
            "/wiki/Concejo_municipal",
            "/wiki/Bot_conversacional",
            "/wiki/Aplicaci%C3%B3n_m%C3%B3vil",
            "/wiki/COVID-19",
            "/wiki/Alipay",
            "/wiki/WeChat",
            "/wiki/Deutsche_Telekom",
            "/wiki/Instituto_Robert_Koch",
            "/wiki/Sistema_de_reconocimiento_facial",
            "/wiki/Giulio_Gallera",
            "/wiki/Palantir_Technologies",
            "/wiki/Tsunami",
            "/wiki/Alerta_de_tsunami",
            "/wiki/Inundaci%C3%B3n",
            "/wiki/Langosta_(insecto)",
            "/wiki/Incendio_forestal",
            "/wiki/Deloitte",
            "/wiki/Sesgo_algor%C3%ADtmico",
            "/wiki/Yuval_Noah_Harari",
            "/wiki/Convenci%C3%B3n_Europea_de_Derechos_Humanos",
            "/wiki/Amazon_Web_Services",
            "/wiki/C%C3%B3digo_abierto",
            "/wiki/IE_Universidad",
            "/wiki/Gobierno_electr%C3%B3nico",
            "/wiki/Tecnolog%C3%ADa_c%C3%ADvica",
            "/wiki/Ciberpunk",
            "/wiki/Brecha_digital",
            "/wiki/Multivac",
            "/wiki/An%C3%A1lisis_predictivo",
            "/wiki/Econom%C3%ADa_colaborativa",
            "/wiki/Contrato_inteligente",
            "/wiki/Utopismo_tecnol%C3%B3gico",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Bibcode",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Bibcode",
            "/wiki/ISSN",
            "/wiki/ArXiv",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Lawrence_Lessig",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Tim_O%27Reilly",
            "/wiki/Stafford_Beer",
            "/wiki/ISBN",
            "/wiki/South_China_Morning_Post#SCMP_Group",
            "/wiki/ISSN",
            "/wiki/Xinhua_News_Agency",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/The_Washington_Post",
            "/wiki/Bibcode",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Universidad_Stanford",
            "/wiki/Parlamento_Europeo",
            "/wiki/University_College_de_Londres",
            "/wiki/University_College_de_Londres",
            "/wiki/Universidad_de_Harvard",
            "/wiki/Wayback_Machine",
            "/wiki/El_c%C3%B3digo_2.0",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Inform%C3%A1tica",
        "titulo": "Informática",
        "contenido": "la informatica,​ tambien llamada computacion,​ es el area de la ciencia que se encarga de estudiar la administracion de metodos, tecnicas y procesos con el fin de almacenar, procesar y transmitir informacion y datos en formato digital. la informatica abarca desde disciplinas teoricas (como algoritmos, teoria de la computacion y teoria de la informacion) hasta disciplinas practicas (incluido el diseño y la implementacion de hardware y software).​ la informatica generalmente se considera un area de investigacion academica y distinta de la programacion informatica.​  de esa manera, la informatica se refiere al procesamiento automatico de informacion, dispositivos electronicos, sistemas computacionales.  los sistemas informaticos deben contar con la capacidad de cumplir tres tareas basicas: entrada (input, captacion de la informacion), procesamiento y salida (transmision de los resultados).  no existe una definicion consensuada sobre el termino. sin embargo, la asociacion de docentes de informatica y computacion de la republica argentina ha tomado una posicion, definiendola de la siguiente manera: «la informatica es la disciplina o campo de estudio que abarca el conjunto de conocimientos, metodos y tecnicas referentes al tratamiento automatico de la informacion, junto con sus teorias y aplicaciones practicas, con el fin de almacenar, procesar y transmitir datos e informacion en formato digital utilizando sistemas computacionales. los datos son la materia prima para que, mediante su proceso, se obtenga como resultado informacion. para ello, la informatica crea y/o emplea sistemas de procesamiento de datos, que incluyen medios fisicos (hardware) en interaccion con medios logicos (software) y las personas que los programan y/o los usan (humanware)».​  es por lo que se hace distincion entre este termino y las ciencias de la computacion, puesto que el segundo engloba la parte mas teorica mientras que informatica se refiere a la aplicabilidad de esta anterior en datos usando dispositivos electronicos. de hecho, se definen cinco subdisciplinas del campo de la informatica: ciencias de la computacion, ingenieria informatica, sistemas de informacion, tecnologia de la informacion e ingenieria de software.​  la informatica es la forma cientifica de procesar la informacion. este procesamiento consiste en ordenar, seleccionar, ejecutar calculos de forma que nos permita extraer conclusiones de la informacion manipulada. procesar informacion es transformar datos primarios en informacion organizada, significativa y util, que a su vez esta compuesta de datos. la informatica, que se ha desarrollado rapidamente a partir de la segunda mitad del siglo xx con la aparicion de tecnologias como el circuito integrado, el internet y el telefono movil,​ es la rama de la tecnologia que estudia el tratamiento automatico de la informacion.​​  en 1957, karl steinbuch añadio la palabra alemana informatik en la publicacion de un documento denominado informatik: automatische informationsverarbeitung (informatica: procesamiento automatico de informacion).​ el sovietico alexander ivanovich mikhailov fue el primero en utilizar informatik con el significado de «estudio, organizacion y diseminacion de la informacion cientifica», que sigue siendo su significado en dicha lengua.​ en ingles, la palabra informatics fue acuñada independiente y casi simultaneamente por walter f. bauer, en 1962, cuando bauer cofundo la empresa informatics general, inc.​  la disciplina de la informatica es anterior a la creacion de las computadoras. ya en la antiguedad se conocian metodos para realizar calculos matematicos, por ejemplo el algoritmo de euclides. en el siglo xvii comenzaron a inventarse maquinas calculadoras. la herramienta mas antigua conocida para su uso en computacion es el abaco, y se cree que fue inventado en babilonia alrededor del 2400 a. c. su diseño original de uso fue por lineas dibujadas en arena con guijarros. abaci, de un diseño mas moderno, todavia se utilizan como herramientas de calculo en la actualidad. esta fue la primera ayuda de calculo conocida, precediendo a los metodos griegos por 2000 años.​  en el siglo xix se desarrollaron las primeras maquinas programables, es decir, que el usuario podria modificar la secuencia de acciones a realizar a traves de algoritmos especificos. la primera propuesta registrada para el uso de la electronica digital en la informatica fue el articulo de 1931 \"el uso de tiratrones para el conteo automatico de fenomenos fisicos a alta velocidad\" de c. e. wynn-williams.​ el articulo de 1938 de claude shannon \"un analisis simbolico de los circuitos de conmutacion y reles\" introdujo la idea de utilizar la electronica para las operaciones de algebra booleana.  el concepto de un transistor de efecto de campo fue propuesto por julius edgar lilienfeld en 1925. john bardeen y walter brattain, mientras trabajaban con william shockley en bell labs, construyo el primer transistor en funcionamiento, el transistor de contacto puntual, en 1947.​​ en 1953, la universidad de manchester construyo la primera ordenador transistorizado, llamada ordenador de transistores.​ sin embargo, los primeros transistores de union eran dispositivos relativamente voluminosos que eran dificiles de producir en masa, lo que los limitaba a una serie de aplicaciones especializadas.​ el transistor de efecto de campo de oxido de metal-silicio (mosfet, o transistor mos) fue inventado por mohamed atalla y dawon kahng en bell labs en 1959.​​ fue el primer transistor verdaderamente compacto que podia ser miniaturizado y producido en masa para una amplia gama de usos.​ el mosfet hizo posible construir chiis de circuitos integrados de alta densidad,​​ dando lugar a lo que se conoce como la revolucion informatica​ o revolucion de la microcomputadora.​  en los inicios del procesamiento automatico de la informacion, con la informatica solo se facilitaban los trabajos repetitivos y monotonos del area administrativa. la automatizacion de esos procesos trajo como consecuencia directa una disminucion de los costes y un incremento en la productividad. en la informatica convergen los fundamentos de las ciencias de la computacion, la programacion y tambien las metodologias para el desarrollo de software, la arquitectura de las computadoras, las redes de computadores, la inteligencia artificial y ciertas cuestiones relacionadas con la electronica. se puede entender por informatica a la union sinergica de todo este conjunto de disciplinas. esta disciplina se aplica a numerosas y variadas areas del conocimiento o la actividad humana, por ejemplo: gestion de negocios, almacenamiento y consulta de informacion; monitorizacion y control de procesos, industria, robotica, comunicaciones, control de transportes, investigacion, desarrollo de juegos, diseño computarizado, aplicaciones/herramientas multimedia, medicina, biologia, fisica, quimica, meteorologia, ingenieria, arte, etc. puede tanto facilitar la toma de decisiones a nivel gerencial (en una empresa) como permitir el control de procesos criticos. actualmente, es dificil concebir un area que no este vinculada o requiera del apoyo de la informatica. esta puede cubrir un enorme abanico de funciones, que van desde las mas simples cuestiones domesticas hasta los calculos cientificos mas complejos. entre las funciones principales de la informatica se enumeran las siguientes:  los sistemas computacionales, generalmente implementados como dispositivos electronicos, permiten el procesamiento automatico de la informacion. conforme a ello, los sistemas informaticos deben realizar las siguientes tres tareas basicas:  en un editor de texto presionando las teclas alt + el numero del codigo ascii, aparecera el caracter correspondiente, solamente funciona en un teclado que tenga las teclas numericas.   ",
        "snippet": "La informática,[1]​ también llamada computación,[2]​ es el área de la ciencia que se encarga de estudiar la administración de métodos, técnicas y procesos con el fin de almacenar, procesar y transmitir información y datos en formato digital. La informática abarca desde disciplinas teóricas (como algoritmos, teoría de la computación y teoría de la información) hasta disciplinas prácticas (incluido el diseño y la implementación de hardware y software).[3]​ La informática generalmente se considera un área de investigación académica y distinta de la programación informática.[4]​",
        "enlaces_salientes": [
            "/wiki/Inform%C3%A1tica",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Placa_base",
            "/wiki/Z%C3%B3calo_de_CPU",
            "/wiki/Intel",
            "/wiki/Hardware",
            "/wiki/Computadora",
            "/wiki/C%C3%B3digo_fuente",
            "/wiki/Programa_Hola_Mundo",
            "/wiki/Lenguaje_de_programaci%C3%B3n_C%2B%2B",
            "/wiki/Ciencia",
            "/wiki/Informaci%C3%B3n",
            "/wiki/Dato",
            "/wiki/Electr%C3%B3nica_digital",
            "/wiki/Algoritmo",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Aparato_electr%C3%B3nico",
            "/wiki/Input",
            "/wiki/Procesamiento_de_datos",
            "/wiki/Output",
            "/wiki/Asociaci%C3%B3n_de_Docentes_de_Inform%C3%A1tica_y_Computaci%C3%B3n_de_la_Rep%C3%BAblica_Argentina",
            "/wiki/Hardware",
            "/wiki/Software",
            "/wiki/Humanware",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Ingenier%C3%ADa_inform%C3%A1tica",
            "/wiki/Sistema_de_informaci%C3%B3n",
            "/wiki/Tecnolog%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Circuito_integrado",
            "/wiki/Internet",
            "/wiki/Tel%C3%A9fono_m%C3%B3vil",
            "/wiki/Karl_Steinbuch",
            "/wiki/Alexander_Mikhailov",
            "/wiki/Disciplina",
            "/wiki/Computadora",
            "/wiki/Algoritmo_de_Euclides",
            "/wiki/Calculadora",
            "/wiki/Claude_Shannon",
            "/wiki/%C3%81lgebra_booleana",
            "/wiki/Transistor_de_efecto_de_campo",
            "/wiki/Julius_Edgar_Lilienfeld",
            "/wiki/John_Bardeen",
            "/wiki/Walter_Brattain",
            "/wiki/William_Shockley",
            "/wiki/Bell_Labs",
            "/wiki/Transistor",
            "/wiki/Transistor_de_contacto_puntual",
            "/wiki/Universidad_de_M%C3%A1nchester",
            "/wiki/Ordenadores_de_Manchester",
            "/wiki/MOSFET",
            "/wiki/Mohamed_Atalla",
            "/wiki/Dawon_Kahng",
            "/wiki/Escala_MOSFET",
            "/wiki/Ley_de_Moore",
            "/wiki/Circuitos_integrados",
            "/wiki/Integraci%C3%B3n_a_muy_gran_escala",
            "/wiki/Revoluci%C3%B3n_inform%C3%A1tica",
            "/wiki/Revoluci%C3%B3n_de_la_microcomputadora",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Software",
            "/wiki/Arquitectura_de_computadoras",
            "/wiki/Red_de_computadoras",
            "/wiki/Inteligencia_artificial",
            "/wiki/Electr%C3%B3nica",
            "/wiki/Administraci%C3%B3n",
            "/wiki/Dispositivo_de_almacenamiento_de_datos",
            "/wiki/Proceso_(inform%C3%A1tica)",
            "/wiki/Industria",
            "/wiki/Rob%C3%B3tica",
            "/wiki/Transporte",
            "/wiki/Investigaci%C3%B3n",
            "/wiki/Videojuego",
            "/wiki/Dise%C3%B1o",
            "/wiki/Multimedia",
            "/wiki/Medicina",
            "/wiki/Biolog%C3%ADa",
            "/wiki/F%C3%ADsica",
            "/wiki/Qu%C3%ADmica",
            "/wiki/Meteorolog%C3%ADa",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Arte",
            "/wiki/Toma_de_decisiones",
            "/wiki/Director_ejecutivo",
            "/wiki/Empresa",
            "/wiki/Proceso_de_fabricaci%C3%B3n",
            "/wiki/Sistema_inform%C3%A1tico",
            "/wiki/Aparato_electr%C3%B3nico",
            "/wiki/Razonamiento_autom%C3%A1tico",
            "/wiki/Dato",
            "/wiki/Sistema_inform%C3%A1tico",
            "/wiki/Entrada/salida",
            "/wiki/Proceso_(inform%C3%A1tica)",
            "/wiki/Entrada/salida",
            "/wiki/Perif%C3%A9rico_de_entrada",
            "/wiki/Biblioteca",
            "/wiki/ASCII",
            "/wiki/Historia_de_las_ciencias_de_la_computaci%C3%B3n",
            "/wiki/Computadora",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Generaciones_de_computadoras",
            "/wiki/Primera_generaci%C3%B3n_de_computadoras",
            "/wiki/Historia_de_las_computadoras_personales",
            "/wiki/Software",
            "/wiki/Mujeres_en_inform%C3%A1tica",
            "/wiki/Tecnolog%C3%ADa",
            "/wiki/Internet",
            "/wiki/Computadoras_en_la_ciencia_ficci%C3%B3n",
            "/wiki/Internet_en_la_ciencia_ficci%C3%B3n",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Bibcode",
            "/wiki/Digital_object_identifier",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/John_Wiley_%26_Sons",
            "/wiki/ISBN",
            "/wiki/John_Wiley_%26_Sons",
            "/wiki/ISBN",
            "/wiki/Computer_History_Museum",
            "/wiki/Springer_Science_%26_Business_Media",
            "/wiki/ISBN",
            "/wiki/Computer_History_Museum",
            "/wiki/Bibcode",
            "/wiki/ISSN",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/Cambridge_University_Press",
            "/wiki/ISBN",
            "/wiki/American_Chemical_Society",
            "/wiki/ISBN",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Inteligencia_artificial",
        "titulo": "Inteligencia artificial",
        "contenido": "la inteligencia artificial  (ia), en el contexto de las ciencias de la computacion, es una disciplina y un conjunto de capacidades cognoscitivas e intelectuales expresadas por sistemas informaticos o combinaciones de algoritmos cuyo proposito es la creacion de maquinas que imiten la inteligencia humana para realizar tareas, y que pueden mejorar conforme recopilen informacion.​​ se hizo presente poco despues de la segunda guerra mundial con el desarrollo de la «prueba de turing», mientras que la locucion fue acuñada en 1956 por el informatico john mccarthy en la conferencia de dartmouth.  en la actualidad, la inteligencia artificial abarca una gran variedad de subcampos. estos van desde areas de proposito general, aprendizaje y percepcion, a otras mas especificas como el reconocimiento de voz, el juego de ajedrez, la demostracion de teoremas matematicos, la escritura de poesia y el diagnostico de enfermedades. la inteligencia artificial sintetiza y automatiza tareas que en principio son intelectuales y, por lo tanto, es potencialmente relevante para cualquier ambito de diversas actividades intelectuales humanas. en este sentido, es un campo genuinamente universal.​  la arquitectura de las inteligencias artificiales y los procesos por los cuales aprenden, se mejoran y se implementan en algun area de interes varian segun el enfoque de utilidad que se les quiera dar, pero de manera general, estos van desde la ejecucion de sencillos algoritmos hasta la interconexion de complejas redes neuronales artificiales que intentan replicar los circuitos neuronales del cerebro humano y que aprenden mediante diferentes modelos de aprendizaje tales como el aprendizaje automatico, el aprendizaje por refuerzo, el aprendizaje profundo o el aprendizaje supervisado.​  por otro lado, el desarrollo y aplicacion de la inteligencia artificial en muchos aspectos de la vida cotidiana tambien ha propiciado la creacion de nuevos campos de estudio como la roboetica y la etica de las maquinas que abordan aspectos relacionados con la etica en la inteligencia artificial y que se encargan de analizar como los avances en este tipo de tecnologias impactarian en diversos ambitos de la vida, asi como el manejo responsable y etico que se les deberia dar a los mismos, ademas de establecer cual deberia ser la manera correcta de proceder de las maquinas y las reglas que deberian cumplir.​  en cuanto a su clasificacion, tradicionalmente se divide a la inteligencia artificial en inteligencia artificial debil, la cual es la unica que existe en la actualidad y que se ocupa de realizar tareas especificas, e inteligencia artificial general, que seria una ia que excediese las capacidades humanas. algunos expertos creen que si alguna vez se alcanza este nivel, se podria dar lugar a la aparicion de una singularidad tecnologica, es decir, una entidad tecnologica superior que se mejoraria a si misma constantemente, volviendose incontrolable para los humanos, dando pie a teorias como el basilisco de roko.​  algunas de las inteligencias artificiales mas conocidas y utilizadas en la actualidad alrededor del mundo incluyen inteligencia artificial en el campo de la salud, asistentes virtuales como alexa, el asistente de google o siri, traductores automaticos como el traductor de google y deepl, sistemas de recomendacion como el de la plataforma digital de youtube, motores de ajedrez y otros juegos como stockfish y alphazero, chatbots como chatgpt, creadores de arte de inteligencia artificial como midjourney, dall-e, leonardo y stable diffusion, e incluso la conduccion de vehiculos autonomos como tesla autopilot.​  asimismo la inteligencia artificial, se esta desarrollando en la plataforma digital cada vez mas, evolucionando y creando nuevas herramientas, como la plataforma laboral que existe desde el año 2023 llamada sivium , una herramienta por el cual, una persona postula en forma automatizada a todas las ofertas laborales de todos los portales de trabajo, sin necesidad de estar revisando cada oferta laboral que se presente y enviar su cv uno por uno.  en 2019 la comision mundial de etica del conocimiento cientifico y la tecnologia (comest) de la unesco definio la inteligencia artificial como un campo que implica maquinas capaces de imitar determinadas funcionalidades de la inteligencia humana, incluidas caracteristicas como la percepcion, el aprendizaje, el razonamiento, la resolucion de problemas, la interaccion linguistica e incluso la produccion de trabajos creativos.  coloquialmente, la locucion «inteligencia artificial» se aplica cuando una maquina imita las funciones «cognitivas» que los humanos asocian como competencias humanas, por ejemplo: «percibir», «razonar», «aprender» y «resolver problemas».​ andreas kaplan y michael haenlein definen la inteligencia artificial como «la capacidad de un sistema para interpretar correctamente datos externos, y asi aprender y emplear esos conocimientos para lograr tareas y metas concretas a traves de la adaptacion flexible».​ a medida que las maquinas se vuelven cada vez mas capaces, se elimina de la definicion la tecnologia que alguna vez se penso que requeria de inteligencia. marvin minsky, uno de los ideadores de la ia, hablaba del termino inteligencia artificial como una palabra maleta (\"suitcase word\") porque en el se pueden meter una diversidad de elementos.​​  por ejemplo, el reconocimiento optico de caracteres ya no se percibe como un ejemplo de la «inteligencia artificial» habiendose convertido en una tecnologia comun.​ avances tecnologicos todavia clasificados como inteligencia artificial son los sistemas de conduccion autonomos o los capaces de jugar ajedrez o go.​  la inteligencia artificial es una nueva forma de resolver problemas dentro de los cuales se incluyen los sistemas expertos, el manejo y control de robots y los procesadores, que intenta integrar el conocimiento en tales sistemas, en otras palabras, un sistema inteligente capaz de escribir su propio programa. un sistema experto definido como una estructura de programacion capaz de almacenar y utilizar un conocimiento sobre un area determinada que se traduce en su capacidad de aprendizaje.​ de igual manera se puede considerar a la ia como la capacidad de las maquinas para usar algoritmos, aprender de los datos y utilizar lo aprendido en la toma de decisiones tal y como lo haria un ser humano,​.  segun takeyas (2007) la ia es una rama de las ciencias computacionales encargada de estudiar modelos de computo capaces de realizar actividades propias de los seres humanos con base en dos de sus caracteristicas primordiales: el razonamiento y la conducta.​  en 1956, john mccarthy acuño la expresion «inteligencia artificial», y la definio como «la ciencia e ingenio de hacer maquinas inteligentes, especialmente programas de computo inteligentes».​  tambien existen distintos tipos de percepciones y acciones, que pueden ser obtenidas y producidas, respectivamente, por sensores fisicos y sensores mecanicos en maquinas, pulsos electricos u opticos en computadoras, tanto como por entradas y salidas de bits de un software y su entorno software.  varios ejemplos se encuentran en el area de control de sistemas, planificacion automatica, la capacidad de responder a diagnosticos y a consultas de los consumidores, reconocimiento de escritura, reconocimiento del habla y reconocimiento de patrones. los sistemas de ia actualmente son parte de la rutina en campos como economia, medicina, ingenieria, el transporte, las comunicaciones y la milicia, y se ha usado en gran variedad de programas informaticos, juegos de estrategia, como ajedrez de computador, y otros videojuegos.  stuart j. russell y peter norvig diferencian varios tipos de inteligencia artificial:​  la ia se divide en dos escuelas de pensamiento:  se conoce tambien como ia simbolica-deductiva. esta basada en el analisis formal y estadistico del comportamiento humano ante diferentes problemas:  la inteligencia computacional (tambien conocida como ia subsimbolica-inductiva) implica desarrollo o aprendizaje interactivo (por ejemplo, modificaciones interactivas de los parametros en sistemas de conexiones). el aprendizaje se realiza basandose en datos empiricos.  la inteligencia computacional tiene una doble finalidad. por un lado, su objetivo cientifico es comprender los principios que posibilitan el comportamiento inteligente (ya sea en sistemas naturales o artificiales) y, por otro, su objetivo tecnologico consiste en especificar los metodos para diseñar sistemas inteligentes.​  ante la posibilidad de crear maquinas dotadas de inteligencia, se volvio importante preocuparse por la cuestion etica de las maquinas para tratar de garantizar que no se produzca ningun daño a los seres humanos, a otros seres vivos e incluso a las mismas maquinas segun algunas corrientes de pensamiento​. es asi como surgio un amplio campo de estudios conocido como etica de la inteligencia artificial de relativamente reciente aparicion y que generalmente se divide en dos ramas, la roboetica, encargada de estudiar las acciones de los seres humanos hacia los robots, y la etica de las maquinas encargada del estudio del comportamiento de los robots para con los seres humanos.  el acelerado desarrollo tecnologico y cientifico de la inteligencia artificial que se ha producido en el siglo xxi supone tambien un importante impacto en otros campos. en la economia mundial durante la segunda revolucion industrial se vivio un fenomeno conocido como desempleo tecnologico, que se refiere a cuando la automatizacion industrial de los procesos de produccion a gran escala reemplaza la mano de obra humana. con la inteligencia artificial podria darse un fenomeno parecido, especialmente en los procesos en los que interviene la inteligencia humana, tal como se ilustraba en el cuento ¡como se divertian! de isaac asimov, en el que su autor vislumbra algunos de los efectos que tendria la interaccion de maquinas inteligentes especializadas en pedagogia infantil, en lugar de profesores humanos, con los niños en etapa escolar. este mismo escritor diseño lo que hoy se conocen como las tres leyes de la robotica, aparecidas por primera vez en el relato circulo vicioso (runaround) de 1942, donde establecia lo siguiente:  otras obras de ciencia ficcion mas recientes tambien exploran algunas cuestiones eticas y filosoficas con respecto a la inteligencia artificial fuerte, como las peliculas yo, robot o a.i. inteligencia artificial, en los que se tratan temas tales como la autoconsciencia o el origen de una conciencia emergente de los robots inteligentes o sistemas computacionales, o si estos podrian considerarse sujetos de derecho debido a sus caracteristicas casi humanas relacionadas con la sintiencia, como el poder ser capaces de sentir dolor y emociones o hasta que punto obedecerian al objetivo de su programacion, y en caso de no ser asi, si podrian ejercer libre albedrio. esto ultimo es el tema central de la famosa saga de terminator, en la que las maquinas superan a la humanidad y deciden aniquilarla, historia que, segun varios especialistas, podria no limitarse a la ciencia ficcion y ser una posibilidad real en una sociedad posthumana que dependiese de la tecnologia y las maquinas completamente.​​  el derecho​ desempeña un papel fundamental en el uso y desarrollo de la ia. las leyes establecen reglas y normas de comportamiento para asegurar el bienestar social y proteger los derechos individuales, y pueden ayudarnos a obtener los beneficios de esta tecnologia mientras minimizamos sus riesgos, que son significativos. de momento no hay normas juridicas que regulen directamente a la ia. pero con fecha 21 de abril de 2021, la comision europea ha presentado una propuesta de reglamento europeo para la regulacion armonizada de la inteligencia artificial (ia) en la ue. su titulo exacto es propuesta de reglamento del parlamento europeo y del consejo por el que se establecen normas armonizadas en materia de inteligencia artificial –ley de inteligencia artificial– y se modifican otros actos legislativos de la union.  en marzo de 2023, cientos de empresarios como elon musk, steve wozniak (cofundador de apple) o los presidentes de numerosas compañias tecnologicas; intelectuales como yuval noah harari y cientos de academicos e investigadores especializados en inteligencia artificial firmaron una carta abierta avisando del peligro de la falta de regulacion de la ia, poniendo el foco sobre openai, la empresa que ha desarrollado chatgpt. pidieron una pausa de al menos 6 meses para sus experimentos mas potentes, hasta que el mundo logre un consenso internacional para que estos sistemas «sean mas precisos, seguros, interpretables, transparentes, robustos, neutrales, confiables y leales».​  dos meses mas tarde, en mayo, 350 ejecutivos de las principales empresas desarrolladoras de ia, academicos e investigadores expertos firmaron un nuevo manifiesto alertando de que la ia avanzada sin regular representa un peligro de extincion para la humanidad: «mitigar el riesgo de extincion de la ia deberia ser una prioridad mundial junto a otros riesgos a escala social como las pandemias y la guerra nuclear»​ entre los impulsores de esta peticion esta toda la plana mayor de openai, el jefe de tecnologia de microsoft, el lider de google deepmind con 38 ejecutivos, investigadores o profesores de universidad relacionados con la empresa, y representantes de desarrolladoras mas pequeñas como anthropic, stability ai o inflection ai.​  los primeros investigadores desarrollaron algoritmos que imitaban el razonamiento paso a paso que los humanos usan cuando resuelven acertijos o hacen deducciones logicas.​ a finales de la decada de 1981-1990, la investigacion de la inteligencia artificial habia desarrollado metodos para tratar con informacion incierta o incompleta, empleando conceptos de probabilidad y economia.​  estos algoritmos demostraron ser insuficientes para resolver grandes problemas de razonamiento porque experimentaron una «explosion combinatoria»: se volvieron exponencialmente mas lentos a medida que los problemas crecian.​ de esta manera, se concluyo que los seres humanos rara vez usan la deduccion paso a paso que la investigacion temprana de la inteligencia artificial seguia; en cambio, resuelven la mayoria de sus problemas utilizando juicios rapidos e intuitivos.​  la representacion del conocimiento​ y la ingenieria del conocimiento​ son fundamentales para la investigacion clasica de la inteligencia artificial. algunos «sistemas expertos» intentan recopilar el conocimiento que poseen los expertos en algun ambito concreto. ademas, otros proyectos tratan de reunir el «conocimiento de sentido comun» conocido por una persona promedio en una base de datos que contiene un amplio conocimiento sobre el mundo.  entre los temas que contendria una base de conocimiento de sentido comun estan: objetos, propiedades, categorias y relaciones entre objetos,​ situaciones, eventos, estados y tiempo​ causas y efectos;poole, mackworth y goebel, 1998, pp. 335–337 y el conocimiento sobre el conocimiento (lo que sabemos sobre lo que saben otras personas)​ entre otros.  otro objetivo de la inteligencia artificial consiste en poder establecer metas y finalmente alcanzarlas.​ para ello necesitan una forma de visualizar el futuro, una representacion del estado del mundo y poder hacer predicciones sobre como sus acciones lo cambiaran, con tal de poder tomar decisiones que maximicen la utilidad (o el «valor») de las opciones disponibles.​  en los problemas clasicos de planificacion, el agente puede asumir que es el unico sistema que actua en el mundo, lo que le permite estar seguro de las consecuencias de sus acciones.​ sin embargo, si el agente no es el unico actor, entonces se requiere que este pueda razonar bajo incertidumbre. esto requiere un agente que no solo pueda evaluar su entorno y hacer predicciones, sino tambien evaluar sus predicciones y adaptarse en funcion de su evaluacion.​ la planificacion de multiples agentes utiliza la cooperacion y la competencia de muchos sistemas para lograr un objetivo determinado. el comportamiento emergente como este es utilizado por algoritmos evolutivos e inteligencia de enjambre.​  el aprendizaje automatico es un concepto fundamental de la investigacion de la inteligencia artificial desde el inicio de los estudios de este campo; consiste en la investigacion de algoritmos informaticos que mejoran automaticamente a traves de la experiencia.​  el aprendizaje no supervisado es la capacidad de encontrar patrones en un flujo de entrada, sin que sea necesario que un humano etiquete las entradas primero. el aprendizaje supervisado incluye clasificacion y regresion numerica, lo que requiere que un humano etiquete primero los datos de entrada. la clasificacion se usa para determinar a que categoria pertenece algo y ocurre despues de que un programa observe varios ejemplos de entradas de varias categorias. la regresion es el intento de producir una funcion que describa la relacion entre entradas y salidas y predice como deben cambiar las salidas a medida que cambian las entradas.​ tanto los clasificadores como los aprendices de regresion intentan aprender una funcion desconocida; por ejemplo, un clasificador de spam puede verse como el aprendizaje de una funcion que asigna el texto de un correo electronico a una de dos categorias, «spam» o «no spam». la teoria del aprendizaje computacional puede evaluar a los estudiantes por complejidad computacional, complejidad de la muestra (cuantos datos se requieren) o por otras nociones de optimizacion.​  el procesamiento del lenguaje natural​ permite a las maquinas leer y comprender el lenguaje humano. un sistema de procesamiento de lenguaje natural suficientemente eficaz permitiria interfaces de usuario de lenguaje natural y la adquisicion de conocimiento directamente de fuentes escritas por humanos, como los textos de noticias. algunas aplicaciones sencillas del procesamiento del lenguaje natural incluyen la recuperacion de informacion, la mineria de textos, la respuesta a preguntas y la traduccion automatica.​ muchos enfoques utilizan las frecuencias de palabras para construir representaciones sintacticas de texto. las estrategias de busqueda de «deteccion de palabras clave» son populares y escalables, pero poco optimas; una consulta de busqueda para «perro» solo puede coincidir con documentos que contengan la palabra literal «perro» y perder un documento con el vocablo «caniche». los enfoques estadisticos de procesamiento de lenguaje pueden combinar todas estas estrategias, asi como otras, y a menudo logran una precision aceptable a nivel de pagina o parrafo. mas alla del procesamiento de la semantica, el objetivo final de este es incorporar una comprension completa del razonamiento de sentido comun.​ en 2019, las arquitecturas de aprendizaje profundo basadas en transformadores podian generar texto coherente.​  la percepcion de la maquina​ es la capacidad de utilizar la entrada de sensores (como camaras de espectro visible o infrarrojo, microfonos, señales inalambricas y lidar, sonar, radar y sensores tactiles) para entender aspectos del mundo. las aplicaciones incluyen reconocimiento de voz,​ reconocimiento facial y reconocimiento de objetos.russell y norvig, 2003, pp. 885–892 la vision artificial es la capacidad de analizar la informacion visual, que suele ser ambigua; un peaton gigante de cincuenta metros de altura muy lejos puede producir los mismos pixeles que un peaton de tamaño normal cercano, lo que requiere que la inteligencia artificial juzgue la probabilidad relativa y la razonabilidad de las diferentes interpretaciones, por ejemplo, utilizando su «modelo de objeto» para evaluar que los peatones de cincuenta metros no existen.​  la gran importancia de la ia radica en el hecho de que tiene una amplia gama de aplicaciones, desde la automatizacion de tareas tediosas hasta la creacion de sistemas avanzados de asistencia medica y diagnostico de enfermedades, la deteccion de fraudes y la optimizacion de procesos empresariales. en muchos casos, la ia puede hacer cosas que los humanos no pueden hacer, como el procesamiento de datos en grandes cantidades y la localizacion de patrones e interrelaciones entre estos que serian dificiles o imposibles de detectar de otra manera.  esta herramienta ayuda a automatizar el aprendizaje y descubrimiento repetitivo a traves de datos, realiza tareas computarizadas frecuentes de manera confiable, sin embargo, necesita intervencion humana para la configuracion del sistema. analiza datos mas profundos y agrega inteligencia ya que no se puede vender como una aplicacion individual, por lo que es un valor agregado a los productos. tiene una gran precision a traves de redes neuronales profundas; por ejemplo, en medicina se puede utilizar la ia para detectar cancer con mris (imagenes ppr resonancia magnetica). se adapta a traves de algoritmos de aprendizaje progresivo, encuentra estructura y regularidades en los datos de modo que el algoritmo se convierte en un clasificador o predictor. y, por ultimo, la inteligencia artificial, saca el mayor provecho de datos.  ademas, una de las principales razones por las que la ia es importante es porque puede automatizar tareas repetitivas y monotonas, liberando tiempo y recursos para que las personas se centren en tareas mas creativas y valiosas. por ejemplo, la ia puede ayudar a las empresas a automatizar tareas de back office, como la contabilidad y el procesamiento de facturas, lo que puede reducir los costos y mejorar la eficiencia. de manera similar, la ia puede ayudar a los trabajadores a realizar tareas mas complejas y creativas, como el diseño y la planificacion estrategica.  otra razon por la que la ia es importante es porque puede ayudar a las empresas a tomar decisiones informadas y precisas. asi mismo, la ia puede procesar grandes cantidades de datos y proporcionar informacion valiosa para la toma de decisiones empresariales, lo que puede ayudar a las empresas a identificar oportunidades comerciales, predecir tendencias de mercado y mejorar la eficiencia del mercado financiero. ademas, la ia puede ayudar a los trabajadores a tomar decisiones informadas en tiempo real, como en el caso de la atencion medica, donde la ia puede ayudar a los medicos a identificar enfermedades y personalizar el tratamiento.  la ia tambien es importante en el campo de la ciberseguridad. la ia puede ayudar a detectar y prevenir amenazas, desde ciberataques hasta la deteccion de comportamientos sospechosos. la ia puede analizar grandes cantidades de datos en tiempo real y detectar patrones y anomalias que podrian indicar una amenaza de seguridad. ademas, la ia puede aprender de los patrones de comportamiento y mejorar su capacidad para detectar amenazas en el futuro. en el campo de la seguridad cibernetica, la ia puede ayudar a proteger los sistemas y las redes de los ataques de virus informaticos y la infiltracion de malware.  otra area donde la ia es importante es en el descubrimiento de conocimientos. la ia puede descubrir patrones y relaciones en los datos que los humanos no podrian detectar, lo que puede llevar a nuevas ideas y avances en diversos campos. por ejemplo, la ia puede ayudar a los investigadores a identificar nuevos tratamientos para enfermedades, o ayudar a los cientificos a analizar datos de sensores y satelites para entender mejor el calentamiento global.  en marzo de 2016, se hizo popular el comentario que la robot humanoide llamada sophia de la empresa hanson robotics hizo durante su presentacion cuando su creador, david hanson, le preguntara si estaba dispuesta a destruir a la humanidad, a lo que la robot contesto: «esta bien, voy a destruir a la humanidad». posteriormente, sophia se gano el reconocimiento y la atencion mediatica mundial debido a sus conductas casi humanas, siendo entrevistada en muchas ocasiones por distintos medios y sosteniendo conversaciones con personalidades famosas y reconocidas. en 2017, sophia obtuvo la ciudadania saudi, convirtiendose asi en la primera robot en ser reconocida como ciudadana por un pais, lo cual levanto la controversia sobre si se les deberia otorgar los mismos derechos y obligaciones a los robots como si se trataran de sujetos de derecho​  a finales de julio de 2017, varios medios internacionales dieron a conocer que el laboratorio de investigacion de inteligencia artificial del instituto tecnologico de georgia, en conjunto con el grupo de investigacion de inteligencia artificial (fair) de facebook, ahora meta, tuvieron que apagar dos inteligencias artificiales de tipo chatbot denominadas bob y alice ya que habian desarrollado un lenguaje propio mas eficiente que el ingles, idioma en el que habian sido entrenados para aprender a negociar, desarrollando finalmente un tipo de comunicacion incomprensible que se alejaba de las reglas gramaticales del lenguaje natural y que favorecia el uso de abreviaturas. el lenguaje creado por estas ias mostraba caracteristicas de un ingles corrupto y patrones repetitivos, en especial de pronombres y determinantes.​  este inesperado suceso fue visto con panico en los medios de comunicacion ya que se aseguraba que los chatbots supuestamente habian salido del control humano y habian desarrollado la capacidad de comunicarse entre si. sin embargo, posteriormente esto tambien fue desmentido, pues se argumento que en realidad facebook no apago las inteligencias artificiales, sino que simplemente las puso en pausa y cambio la parametros de los chatbots, desechando el experimento al final por no tener ningun interes practico o util dentro de la investigacion sobre ia.​  la utilizacion de aplicaciones gratuitas de ia para transformar fotografias de personas en falsos desnudos esta generando problemas que afectan a menores. el caso salto a los medios de comunicacion en septiembre de 2023 cuando en almendralejo (badajoz, españa) aparecieron varias fotografias de niñas y jovenes (entre 11 y 17 años) que habian sido modificadas mediante inteligencia artificial para aparecer desnudas. las imagenes fueron obtenidas de los perfiles de instagram y de la aplicacion whatsapp de al menos 20 niñas de la localidad. las fotografias de niñas desnudas habian circulado despues  mediante whatsapp y a partir de ellas se habia creado un video que tambien habia circulado entre menores. los autores de dicha transformacion tambien eran menores y compañeros de colegio o instituto. la agencia española de proteccion de datos abrio una investigacion y se comunico con el ayuntamiento de almendralejo y con la junta de extremadura informandoles de que se podia solicitar la retirada de cualquier imagen circulando en internet en el canal prioritario de la agencia.​  las principales criticas a la inteligencia artificial tienen que ver con su capacidad de imitar por completo a un ser humano​. sin embargo, hay expertos[cita requerida] en el tema que indican que ningun humano individual tiene capacidad para resolver todo tipo de problemas, y autores como howard gardner han teorizado sobre la solucion.  en los humanos, la capacidad de resolver problemas tiene dos aspectos: los aspectos innatos y los aspectos aprendidos. los aspectos innatos permiten, por ejemplo, almacenar y recuperar informacion en la memoria, mientras que en los aspectos aprendidos reside el saber resolver un problema matematico mediante el algoritmo adecuado. del mismo modo que un humano debe disponer de herramientas que le permitan solucionar ciertos problemas, los sistemas artificiales deben ser programados para que puedan llegar a resolverlos.  muchas personas consideran que la prueba de turing ha sido superada, citando conversaciones en que al dialogar con un programa de inteligencia artificial para chat no saben que hablan con un programa. sin embargo, esta situacion no es equivalente a una prueba de turing, que requiere que el participante se encuentre sobre aviso de la posibilidad de hablar con una maquina.  otros experimentos mentales como la habitacion china, de john searle, han mostrado como una maquina podria simular pensamiento sin realmente poseerlo, pasando la prueba de turing sin siquiera entender lo que hace, tan solo reaccionando de una forma concreta a determinados estimulos (en el sentido mas amplio de la palabra). esto demostraria que la maquina en realidad no esta pensando, ya que actuar de acuerdo con un programa preestablecido seria suficiente. si para turing el hecho de engañar a un ser humano que intenta evitar que le engañen es muestra de una mente inteligente, searle considera posible lograr dicho efecto mediante reglas definidas a priori.  uno de los mayores problemas en sistemas de inteligencia artificial es la comunicacion con el usuario. este obstaculo es debido a la ambiguedad del lenguaje, y se remonta a los inicios de los primeros sistemas operativos informaticos. la capacidad de los humanos para comunicarse entre si implica el conocimiento del lenguaje que utiliza el interlocutor. para que un humano pueda comunicarse con un sistema inteligente hay dos opciones: o bien que el humano aprenda el lenguaje del sistema como si aprendiese a hablar cualquier otro idioma distinto al nativo, o bien que el sistema tenga la capacidad de interpretar el mensaje del usuario en la lengua que el usuario utiliza. tambien puede haber desperfectos en las instalaciones de los mismos.  un humano, durante toda su vida, aprende el vocabulario de su lengua nativa o materna, siendo capaz de interpretar los mensajes (a pesar de la polisemia de las palabras) y utilizando el contexto para resolver ambiguedades. sin embargo, debe conocer los distintos significados para poder interpretar, y es por esto que lenguajes especializados y tecnicos son conocidos solamente por expertos en las respectivas disciplinas. un sistema de inteligencia artificial se enfrenta con el mismo problema, la polisemia del lenguaje humano, su sintaxis poco estructurada y los dialectos entre grupos.  los desarrollos en inteligencia artificial son mayores en los campos disciplinares en los que existe mayor consenso entre especialistas. un sistema experto es mas probable que sea programado en fisica o en medicina que en sociologia o en psicologia. esto se debe al problema del consenso entre especialistas en la definicion de los conceptos involucrados y en los procedimientos y tecnicas a utilizar. por ejemplo, en fisica hay acuerdo sobre el concepto de velocidad y como calcularla. sin embargo, en psicologia se discuten los conceptos, la etiologia, la psicopatologia, y como proceder ante cierto diagnostico. esto dificulta la creacion de sistemas inteligentes porque siempre habra desacuerdo sobre la forma en que deberia actuar el sistema para diferentes situaciones. a pesar de esto, hay grandes avances en el diseño de sistemas expertos para el diagnostico y toma de decisiones en el ambito medico y psiquiatrico (adaraga morales, zaccagnini sancho, 1994).  al desarrollar un robot con inteligencia artificial se debe tener cuidado con la autonomia,​ hay que tener en cuenta el no vincular el hecho de que el robot tenga interacciones con seres humanos a su grado de autonomia. si la relacion de los humanos con el robot es de tipo maestro esclavo, y el papel de los humanos es dar ordenes y el del robot obedecerlas, entonces si cabe hablar de una limitacion de la autonomia del robot. pero si la interaccion de los humanos con el robot es de igual a igual, entonces su presencia no tiene por que estar asociada a restricciones para que el robot pueda tomar sus propias decisiones.​ con el desarrollo de la tecnologia de inteligencia artificial, muchas compañias de software como el aprendizaje profundo y el procesamiento del lenguaje natural han comenzado a producirse y la cantidad de peliculas sobre inteligencia artificial ha aumentado. stephen hawking advirtio sobre los peligros de la inteligencia artificial y lo considero una amenaza para la supervivencia de la humanidad.​  los algoritmos de aprendizaje automatico requieren grandes cantidades de datos. las tecnicas utilizadas para adquirir estos datos generan preocupaciones sobre temas de privacidad y vigilancia.  las empresas tecnologicas recopilan un gran numero de datos de sus usuarios, incluida la actividad en internet, los datos de geolocalizacion, video y audio. ​ por ejemplo, para construir algoritmos de reconocimiento de voz, amazon entre otros ha grabado millones de conversaciones privadas y han permitido que [trabajo temporal|trabajadores temporales] las escuchen para transcribirlas algunas de ellas.​ las opiniones sobre esta vigilancia generalizada van desde aquellos que la ven como un mal necesario hasta aquellos para quienes no es etica y contituye una violacion del derecho a la intimidad.​  los desarrolladores de ia argumentan que esta es la unica forma de ofrecer aplicaciones valiosas y han desarrollado varias tecnicas que intentan preservar la privacidad mientras se obtienen los datos, como la agregacion de datos, la desidentificacion y la privacidad diferencial.​ desde 2016, algunos expertos en privacidad, como cynthia dwork, comenzaron a ver la privacidad desde la perspectiva de la equidad: brian christian escribio que los expertos han cambiado \"de la pregunta de 'que saben' a la pregunta de 'que estan haciendo con ello'.\".​  la ia generativa a menudo se entrena con obras protegidas por derechos de autor no autorizadas, incluidos dominios como imagenes o codigo informatico; la salida se utiliza luego bajo una justificacion de \"uso justo\". los expertos no estan de acuerdo sobre la validez de esta justificacion durante un proceso legal; podria depender de \"el proposito y el caracter del uso de la obra protegida por derechos de autor\" y \"el efecto sobre el mercado potencial de la obra protegida por derechos de autor\".​ en 2023, los principales autores (incluidos john grisham y jonathan franzen) demandaron a las empresas de ia por usar sus obras para entrenar ia generativa.​​  las tecnicas desarrolladas en el campo de la inteligencia artificial son numerosas y ubicuas. comunmente cuando un problema es resuelto mediante inteligencia artificial la solucion es incorporada en ambitos de la industria y de la vida​ diaria de los usuarios de programas informaticos, pero la percepcion popular se olvida de los origenes de estas tecnologias que dejan de ser percibidas como inteligencia artificial. a este fenomeno se le conoce como el efecto ia.​  el aprendizaje automatico y el aprendizaje profundo son dos subcampos de la inteligencia artificial que comparten algunas similitudes pero tambien presentan importantes diferencias.  el aprendizaje automatico se enfoca en desarrollar algoritmos de regresion, arboles de decision y modelos que puedan aprender de datos existentes y realizar predicciones o decisiones basadas en esos datos. en el aprendizaje automatico, se utilizan tecnicas de estadistica matematica para encontrar patrones y relaciones en los datos y, a partir de ellos, desarrollar modelos que puedan hacer predicciones sobre nuevos datos.  por otro lado, el aprendizaje profundo es una rama mas especializada del aprendizaje automatico que se centra en la creacion de redes neuronales artificiales capaces de aprender y realizar tareas de manera similar a como lo hacen los seres humanos. en el aprendizaje profundo, se utilizan capas de neuronas artificiales para procesar los datos de entrada y aprender a traves de un proceso iterativo de ajuste de los pesos de las conexiones entre neuronas.  una de las principales diferencias entre el aprendizaje automatico y el aprendizaje profundo es que el ultimo es capaz de procesar y analizar grandes cantidades de datos de manera mas eficiente y precisa que el primero, especialmente cuando se trata de datos no estructurados, como imagenes, texto y audio. ademas, el aprendizaje profundo tiene la capacidad de identificar patrones y caracteristicas mas complejas en los datos, lo que puede llevar a mejores resultados en aplicaciones como el reconocimiento de voz, la vision por computadora y el procesamiento del lenguaje natural.  como se menciono anteriormente, en resumen, la inteligencia artificial es la ciencia que entrena maquinas para que realicen tareas humanas, por lo que todo nuestro alrededor esta rodeado de ella y mientras existan recursos con ese tipo de lenguaje la ia estara presente. el «aprendizaje automatizado» es una rama de la inteligencia artificial que le entrena a una maquina a como aprender, esta se encarga de ver patrones y datos para llegar a una conclusion por si sola; como funciona es: haces una pregunta, recolecta informacion, entrena al algoritmo, lo pone a prueba, recolecta la retroalimentacion y usa esa retroalimentacion, mientras que el aprendizaje profundo se centra en la creacion de redes neuronales artificiales que puedan procesar y analizar grandes cantidades de datos de manera mas eficiente y precisa, especialmente cuando se trata de datos no estructurados.   los desarrolladores de ia argumentan que esta es la unica forma de ofrecer aplicaciones valiosas y han desarrollado varias tecnicas que intentan preservar la privacidad mientras se obtienen los datos, como la agregacion de datos, la desidentificacion y la privacidad diferencial.​ desde 2016, algunos expertos en privacidad, como cynthia dwork, comenzaron a ver la privacidad desde la perspectiva de la equidad: brian christian escribio que los expertos han cambiado \"de la pregunta de 'que saben' a la pregunta de 'que estan haciendo con ello'.\".​  al hablar acerca de la propiedad intelectual atribuida a creaciones de la inteligencia artificial se forma un debate fuerte alrededor de si una maquina puede tener derechos de autor. segun la organizacion mundial de la propiedad intelectual (ompi), cualquier creacion de la mente puede ser parte de la propiedad intelectual, pero no especifica si la mente debe ser humana o puede ser una maquina, dejando la creatividad artificial en la incertidumbre.  alrededor del mundo han comenzado a surgir distintas legislaciones con el fin de manejar la inteligencia artificial, tanto su uso como creacion. los legisladores y miembros del gobierno han comenzado a pensar acerca de esta tecnologia, enfatizando el riesgo y los desafios complejos de esta. observando el trabajo creado por una maquina, las leyes cuestionan la posibilidad de otorgarle propiedad intelectual a una maquina, abriendo una discusion respecto a la legislacion relacionada con ia.  el 5 de febrero de 2020, la oficina del derecho de autor de los estados unidos y la ompi asistieron a un simposio donde observaron de manera profunda como la comunidad creativa utiliza la inteligencia artificial (ia) para crear trabajo original. se discutieron las relaciones entre la inteligencia artificial y el derecho de autor, que nivel de involucramiento es suficiente para que el trabajo resultante sea valido para proteccion de derechos de autor; los desafios y consideraciones de usar inputs con derechos de autor para entrenar una maquina; y el futuro de la inteligencia artificial y sus politicas de derecho de autor.​​  el director general de la ompi, francis gurry, presento su preocupacion ante la falta de atencion que hay frente a los derechos de propiedad intelectual, pues la gente suele dirigir su interes hacia temas de ciberseguridad, privacidad e integridad de datos al hablar de la inteligencia artificial. asi mismo, gurry cuestiono si el crecimiento y la sostenibilidad de la tecnologia ia nos guiaria a desarrollar dos sistemas para manejar derechos de autor- uno para creaciones humanas y otro para creaciones de maquinas.​  aun hay una falta de claridad en el entendimiento alrededor de la inteligencia artificial. los desarrollos tecnologicos avanzan a paso rapido, aumentando su complejidad en politicas, legalidades y problemas eticos que se merecen la atencion global. antes de encontrar una manera de trabajar con los derechos de autor, es necesario entenderlo correctamente, pues aun no se sabe como juzgar la originalidad de un trabajo que nace de una composicion de una serie de fragmentos de otros trabajos.  la asignacion de derechos de autor alrededor de la inteligencia artificial aun no ha sido regulada por la falta de conocimientos y definiciones. aun hay incertidumbre sobre si, y hasta que punto, la inteligencia artificial es capaz de producir contenido de manera autonoma y sin ningun humano involucrado, algo que podria influenciar si sus resultados pueden ser protegidos por derechos de autor.  el sistema general de derechos de autor aun debe adaptarse al contexto digital de inteligencia artificial, pues estan centrados en la creatividad humana. los derechos de autor no estan diseñados para manejar cualquier problema en las politicas relacionado con la creacion y el uso de propiedad intelectual, y puede llegar a ser dañino estirar excesivamente los derechos de autor para resolver problemas perifericos dado que:  «usar los derechos de autor para gobernar la inteligencia artificial es poco inteligente y contradictorio con la funcion primordial de los derechos de autor de ofrecer un espacio habilitado para que la creatividad florezca»​  la conversacion acerca de la propiedad intelectual tendra que continuar hasta asegurarse de que la innovacion sea protegida pero tambien tenga espacio para florecer.  a continuacion se incluye alguna obra que tiene como motivo central la inteligencia artificial.  la ia esta cada vez mas presente en la sociedad, la evolucion de la tecnologia es una realidad y con ello, la produccion de peliculas sobre esta tematica. cabe destacar, que lleva habiendo piezas audiovisuales sobre inteligencia artificial desde hace mucho tiempo, ya sea incluyendo personajes o mostrando un trasfondo moral y etico. a continuacion, se muestra una lista de algunas de las principales peliculas que tratan este tema: ",
        "snippet": "La inteligencia artificial (IA), en el contexto de las ciencias de la computación, es una disciplina y un conjunto de capacidades cognoscitivas e intelectuales expresadas por sistemas informáticos o combinaciones de algoritmos cuyo propósito es la creación de máquinas que imiten la inteligencia humana para realizar tareas, y que pueden mejorar conforme recopilen información.[1]​[2]​ Se hizo presente poco después de la Segunda Guerra Mundial con el desarrollo de la «prueba de Turing», mientras que la locución fue acuñada en 1956 por el informático John McCarthy en la Conferencia de Dartmouth.",
        "enlaces_salientes": [
            "/wiki/Inteligencia_artificial",
            "/wiki/Inteligencia_artificial",
            "/wiki/Inteligencia_artificial",
            "/wiki/Acuarela",
            "/wiki/Alan_Turing",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Campo_de_estudio",
            "/wiki/Cognitivo",
            "/wiki/Intelecto",
            "/wiki/Sistemas_inform%C3%A1ticos",
            "/wiki/Algoritmo",
            "/wiki/M%C3%A1quina",
            "/wiki/Inteligencia_humana",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Prueba_de_Turing",
            "/wiki/John_McCarthy_(cient%C3%ADfico)",
            "/wiki/Conferencia_de_Dartmouth",
            "/wiki/Aprendizaje",
            "/wiki/Percepci%C3%B3n",
            "/wiki/Reconocimiento_de_voz",
            "/wiki/Ajedrez_por_computadora",
            "/wiki/Teorema",
            "/wiki/Poes%C3%ADa",
            "/wiki/Diagn%C3%B3stico_m%C3%A9dico",
            "/wiki/Redes_neuronales_artificiales",
            "/wiki/Circuitos_neuronales",
            "/wiki/Cerebro_humano",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Aprendizaje_por_refuerzo",
            "/wiki/Aprendizaje_profundo",
            "/wiki/Aprendizaje_supervisado",
            "/wiki/Campos_de_estudio",
            "/wiki/Robo%C3%A9tica",
            "/wiki/%C3%89tica_de_las_m%C3%A1quinas",
            "/wiki/%C3%89tica_en_la_inteligencia_artificial",
            "/wiki/Tecnolog%C3%ADa",
            "/wiki/%C3%89tico",
            "/wiki/Inteligencia_artificial_d%C3%A9bil",
            "/wiki/Inteligencia_artificial_fuerte",
            "/wiki/Singularidad_tecnol%C3%B3gica",
            "/wiki/Basilisco_de_Roko",
            "/wiki/Inteligencia_artificial_en_el_campo_de_la_salud",
            "/wiki/Asistente_virtual",
            "/wiki/Amazon_Alexa",
            "/wiki/Asistente_de_Google",
            "/wiki/Siri",
            "/wiki/Traducci%C3%B3n_autom%C3%A1tica",
            "/wiki/Traductor_de_Google",
            "/wiki/DeepL",
            "/wiki/Sistema_de_recomendaci%C3%B3n",
            "/wiki/Plataforma_digital",
            "/wiki/YouTube",
            "/wiki/Motor_de_ajedrez",
            "/wiki/Stockfish",
            "/wiki/AlphaZero",
            "/wiki/Chatbot",
            "/wiki/ChatGPT",
            "/wiki/Arte_de_inteligencia_artificial",
            "/wiki/Midjourney",
            "/wiki/Dall-e",
            "/wiki/Stable_Diffusion",
            "/wiki/Veh%C3%ADculos_aut%C3%B3nomos",
            "/wiki/Tesla_Autopilot",
            "/wiki/Plataforma_digital",
            "/wiki/2019",
            "/wiki/UNESCO",
            "/wiki/M%C3%A1quina",
            "/wiki/Inteligencia_humana",
            "/wiki/Percepci%C3%B3n",
            "/wiki/Aprendizaje",
            "/wiki/Razonamiento",
            "/wiki/Resoluci%C3%B3n_de_problemas",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Creativo",
            "/wiki/Percibir",
            "/wiki/Razonar",
            "/wiki/Aprender",
            "/wiki/Resolver_problemas",
            "/wiki/Andreas_M._Kaplan",
            "/wiki/Marvin_Minsky",
            "/wiki/Reconocimiento_%C3%B3ptico_de_caracteres",
            "/wiki/Ajedrez",
            "/wiki/Go",
            "/wiki/John_McCarthy_(cient%C3%ADfico)",
            "/wiki/Sistema_inteligente",
            "/wiki/Teor%C3%ADa_de_control",
            "/wiki/Planificaci%C3%B3n_autom%C3%A1tica",
            "/wiki/Reconocimiento_de_escritura",
            "/wiki/Reconocimiento_del_habla",
            "/wiki/Reconocimiento_de_patrones",
            "/wiki/Econom%C3%ADa",
            "/wiki/Medicina",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Transporte",
            "/wiki/Comunicaciones",
            "/wiki/Milicia",
            "/wiki/Programas_inform%C3%A1ticos",
            "/wiki/Ajedrez",
            "/wiki/Videojuegos",
            "/wiki/Stuart_J._Russell",
            "/wiki/Peter_Norvig",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Toma_de_decisiones",
            "/wiki/Resoluci%C3%B3n_de_problemas",
            "/wiki/Aprendizaje",
            "/wiki/Comportamiento_humano",
            "/wiki/Rob%C3%B3tica",
            "/wiki/Sistema_experto",
            "/wiki/C%C3%A1lculo",
            "/wiki/Percepci%C3%B3n",
            "/wiki/Raz%C3%B3n",
            "/wiki/Agente_inteligente_(inteligencia_artificial)",
            "/wiki/Artefacto",
            "/wiki/Inteligencia_computacional",
            "/wiki/Razonamiento_basado_en_casos",
            "/wiki/Sistema_experto",
            "/wiki/Red_bayesiana",
            "/wiki/Inteligencia_computacional",
            "/wiki/Historia_de_la_inteligencia_artificial",
            "/wiki/Conferencia_de_Dartmouth",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Ctesibio",
            "/wiki/Ramon_Llull",
            "/wiki/Ada_Lovelace",
            "/wiki/Leonardo_Torres_Quevedo",
            "/wiki/Autom%C3%A1tica",
            "/wiki/Alan_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Warren_McCulloch",
            "/wiki/Walter_Pitts",
            "/wiki/Modelo_cient%C3%ADfico",
            "/wiki/A%C3%B1os_1950",
            "/wiki/Alan_Turing",
            "/wiki/Herbert_Alexander_Simon",
            "/wiki/Allen_Newell",
            "/wiki/LogicTheorist",
            "/wiki/John_McCarthy_(cient%C3%ADfico)",
            "/wiki/Marvin_Minsky",
            "/wiki/Claude_Elwood_Shannon",
            "/wiki/Conferencia_de_Dartmouth",
            "/wiki/General_Problem_Solver",
            "/wiki/LISP",
            "/wiki/Perceptr%C3%B3n",
            "/wiki/Red_sem%C3%A1ntica",
            "/wiki/Sistema_experto",
            "/wiki/Terry_Winograd",
            "/wiki/SHRDLU",
            "/wiki/Marvin_Minsky",
            "/wiki/Marvin_Minsky",
            "/wiki/Seymour_Papert",
            "/wiki/Logo_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Alan_Kay",
            "/wiki/Smalltalk",
            "/wiki/Xerox_PARC",
            "/wiki/PROLOG",
            "/wiki/Script",
            "/wiki/Shell_(inform%C3%A1tica)",
            "/wiki/Quinta_generaci%C3%B3n_de_computadoras",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Gari_Kasp%C3%A1rov",
            "/wiki/Ajedrez",
            "/wiki/Deep_Blue_(computadora)",
            "/wiki/Campus_Multidisciplinar_en_Percepci%C3%B3n_e_Inteligencia_2006",
            "/wiki/IBM",
            "/wiki/Watson_(inteligencia_artificial)",
            "/wiki/Jeopardy!",
            "/wiki/Go",
            "/wiki/Bot_conversacional",
            "/wiki/Prueba_de_Turing",
            "/wiki/AlphaGo",
            "/wiki/DeepMind",
            "/wiki/Go",
            "/wiki/Lee_Sedol",
            "/wiki/Stockfish",
            "/wiki/Motor_de_ajedrez",
            "/wiki/ELO",
            "/wiki/AlphaZero",
            "/wiki/LG_Electronics",
            "/wiki/Google",
            "/wiki/Doodle_de_Google",
            "/wiki/Johann_Sebastian_Bach",
            "/wiki/Comp%C3%A1s_(m%C3%BAsica)",
            "/wiki/OECD",
            "/wiki/ChatGPT",
            "/wiki/Inteligencia_artificial_generativa",
            "/wiki/Alucinaci%C3%B3n_(inteligencia_artificial)",
            "/wiki/Midjourney",
            "/wiki/Francisco_(papa)",
            "/wiki/%C3%89tica_en_la_inteligencia_artificial",
            "/wiki/%C3%89tica",
            "/wiki/%C3%89tica_de_la_inteligencia_artificial",
            "/wiki/Robo%C3%A9tica",
            "/wiki/%C3%89tica_de_las_m%C3%A1quinas",
            "/wiki/Tecnol%C3%B3gico",
            "/wiki/Cient%C3%ADfico",
            "/wiki/Econom%C3%ADa_mundial",
            "/wiki/Segunda_revoluci%C3%B3n_industrial",
            "/wiki/Desempleo_tecnol%C3%B3gico",
            "/wiki/Automatizaci%C3%B3n_industrial",
            "/wiki/Procesos_de_producci%C3%B3n",
            "/wiki/Mano_de_obra",
            "/wiki/%C2%A1C%C3%B3mo_se_divert%C3%ADan!",
            "/wiki/Isaac_Asimov",
            "/wiki/Pedagog%C3%ADa_infantil",
            "/wiki/Profesor",
            "/wiki/Tres_leyes_de_la_rob%C3%B3tica",
            "/wiki/C%C3%ADrculo_vicioso_(cuento)",
            "/wiki/1942",
            "/wiki/Da%C3%B1o",
            "/wiki/Ciencia_ficci%C3%B3n",
            "/wiki/%C3%89tica",
            "/wiki/Filos%C3%B3fica",
            "/wiki/Inteligencia_artificial_fuerte",
            "/wiki/Yo,_robot",
            "/wiki/A.I._Inteligencia_Artificial",
            "/wiki/Autoconsciencia",
            "/wiki/Robot",
            "/wiki/Sujeto_de_derecho",
            "/wiki/Sintiencia",
            "/wiki/Dolor",
            "/wiki/Emocion",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Libre_albedr%C3%ADo",
            "/wiki/Saga",
            "/wiki/Terminator_(franquicia)",
            "/wiki/Posthumanismo",
            "/wiki/Regulaci%C3%B3n_de_la_inteligencia_artificial",
            "/wiki/Elon_Musk",
            "/wiki/Steve_Wozniak",
            "/wiki/Apple",
            "/wiki/Yuval_Noah_Harari",
            "/wiki/OpenAI",
            "/wiki/ChatGPT",
            "/wiki/DeepMind",
            "/wiki/Explosi%C3%B3n_combinatoria",
            "/wiki/Representaci%C3%B3n_del_conocimiento",
            "/wiki/Ingenier%C3%ADa_del_conocimiento",
            "/wiki/Base_de_datos",
            "/wiki/Planificaci%C3%B3n_autom%C3%A1tica",
            "/wiki/Cooperaci%C3%B3n",
            "/wiki/Emergencia_(filosof%C3%ADa)",
            "/wiki/Algoritmo_evolutivo",
            "/wiki/Inteligencia_de_enjambre",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Aprendizaje_no_supervisado",
            "/wiki/Aprendizaje_supervisado",
            "/wiki/Clasificaci%C3%B3n_estad%C3%ADstica",
            "/wiki/An%C3%A1lisis_de_la_regresi%C3%B3n",
            "/wiki/Correo_Basura",
            "/wiki/Complejidad_computacional",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Procesamiento_de_lenguajes_naturales",
            "/wiki/Comprensi%C3%B3n_del_lenguaje_natural",
            "/wiki/Interfaz_de_usuario_de_lenguaje_natural",
            "/wiki/B%C3%BAsqueda_y_recuperaci%C3%B3n_de_informaci%C3%B3n",
            "/wiki/Miner%C3%ADa_de_textos",
            "/wiki/B%C3%BAsqueda_de_respuestas",
            "/wiki/Traducci%C3%B3n_autom%C3%A1tica",
            "/wiki/Sintaxis",
            "/wiki/Transformador_(modelo_de_aprendizaje_autom%C3%A1tico)",
            "/wiki/Detector_de_bordes",
            "/wiki/LIDAR",
            "/wiki/Reconocimiento_de_voz",
            "/wiki/Sistema_de_reconocimiento_facial",
            "/wiki/Visi%C3%B3n_artificial",
            "/wiki/Automatizaci%C3%B3n",
            "/wiki/Asistencia_m%C3%A9dica",
            "/wiki/Fraude",
            "/wiki/Procesamiento_de_datos",
            "/wiki/Aprendizaje",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Medicina",
            "/wiki/C%C3%A1ncer",
            "/wiki/Imagen_por_resonancia_magn%C3%A9tica",
            "/wiki/Creatividad",
            "/wiki/Back_office",
            "/wiki/Contabilidad",
            "/wiki/Factura",
            "/wiki/Empresas",
            "/wiki/Tendencias_de_mercado",
            "/wiki/Eficiencia_del_mercado_financiero",
            "/wiki/Ciberseguridad",
            "/wiki/Ciberataque",
            "/wiki/Virus_inform%C3%A1ticos",
            "/wiki/Malware",
            "/wiki/Descubrimiento",
            "/wiki/Conocimiento",
            "/wiki/Investigador",
            "/wiki/Cient%C3%ADfico",
            "/wiki/Sat%C3%A9lite_artificial",
            "/wiki/Calentamiento_global",
            "/wiki/Marzo",
            "/wiki/2016",
            "/wiki/Robot_humanoide",
            "/wiki/Sophia_(robot)",
            "/wiki/David_Hanson",
            "/wiki/2017",
            "/wiki/Saud%C3%AD",
            "/wiki/Ciudadana",
            "/wiki/Sujetos_de_derecho",
            "/wiki/Julio",
            "/wiki/2017",
            "/wiki/Instituto_Tecnol%C3%B3gico_de_Georgia",
            "/wiki/Facebook",
            "/wiki/Meta_Platforms",
            "/wiki/Chatbot",
            "/wiki/Idioma",
            "/wiki/Medios_de_comunicaci%C3%B3n",
            "/wiki/Experimento",
            "/wiki/Almendralejo",
            "/wiki/Badajoz",
            "/wiki/WhatsApp",
            "/wiki/Agencia_Espa%C3%B1ola_de_Protecci%C3%B3n_de_Datos",
            "/wiki/Revoluci%C3%B3n_digital",
            "/wiki/Bill_Gates",
            "/wiki/Microsoft",
            "/wiki/Elon_Musk",
            "/wiki/Tesla,_Inc.",
            "/wiki/Howard_Gardner",
            "/wiki/Memoria_(proceso)",
            "/wiki/Prueba_de_Turing",
            "/wiki/Chat",
            "/wiki/Experimento_mental",
            "/wiki/Habitaci%C3%B3n_china",
            "/wiki/John_Searle",
            "/wiki/Pensamiento",
            "/wiki/Alan_Turing",
            "/wiki/A_priori_y_a_posteriori",
            "/wiki/Sistema_operativo",
            "/wiki/Comunicaci%C3%B3n",
            "/wiki/Polisemia",
            "/wiki/Sintaxis",
            "/wiki/Dialecto",
            "/wiki/Sistema_experto",
            "/wiki/Velocidad",
            "/wiki/Stephen_Hawking",
            "/wiki/Privacidad",
            "/wiki/Vigilancia",
            "/wiki/Reconocimiento_del_habla",
            "/wiki/Amazon",
            "/wiki/Vigilancia",
            "/wiki/%C3%89tica",
            "/wiki/Derecho_a_la_intimidad",
            "/wiki/Privacidad",
            "/wiki/Agregaci%C3%B3n_de_datos",
            "/wiki/Desidentificaci%C3%B3n_(privacidad)",
            "/wiki/Cynthia_Dwork",
            "/wiki/Equidad_(aprendizaje_autom%C3%A1tico)",
            "/wiki/Uso_justo",
            "/wiki/John_Grisham",
            "/wiki/Jonathan_Franzen",
            "/wiki/Aplicaciones_de_la_inteligencia_artificial",
            "/wiki/Efecto_IA",
            "/wiki/Ling%C3%BC%C3%ADstica_computacional",
            "/wiki/Miner%C3%ADa_de_datos",
            "/wiki/Industria",
            "/wiki/Medicina",
            "/wiki/Mundo_virtual",
            "/wiki/Procesamiento_de_lenguajes_naturales",
            "/wiki/Rob%C3%B3tica",
            "/wiki/Sistema_de_control",
            "/wiki/Sistemas_de_apoyo_a_la_decisi%C3%B3n",
            "/wiki/Videojuego",
            "/wiki/Sistema_din%C3%A1mico",
            "/wiki/Simulaci%C3%B3n_de_multitudes",
            "/wiki/Sistemas_Operativos",
            "/wiki/Automoci%C3%B3n",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Aprendizaje_profundo",
            "/wiki/An%C3%A1lisis_de_regresi%C3%B3n",
            "/wiki/%C3%81rboles_de_decisi%C3%B3n",
            "/wiki/Prediccion",
            "/wiki/Estad%C3%ADstica_matem%C3%A1tica",
            "/wiki/Redes_neuronales_artificiales",
            "/wiki/Aprender",
            "/wiki/Neurona_artificial",
            "/wiki/Im%C3%A1genes",
            "/wiki/Texto",
            "/wiki/Audio",
            "/wiki/Reconocimiento_de_voz",
            "/wiki/Visi%C3%B3n_por_computadora",
            "/wiki/Procesamiento_del_lenguaje",
            "/wiki/Patr%C3%B3n_(estructura)",
            "/wiki/Privacidad",
            "/wiki/Agregaci%C3%B3n_de_datos",
            "/wiki/Desidentificaci%C3%B3n_(privacidad)",
            "/wiki/Cynthia_Dwork",
            "/wiki/Equidad_(aprendizaje_autom%C3%A1tico)",
            "/wiki/Midjourney",
            "/wiki/Dominio_p%C3%BAblico",
            "/wiki/Organizaci%C3%B3n_Mundial_de_la_Propiedad_Intelectual",
            "/wiki/Oficina_del_Derecho_de_Autor_de_los_Estados_Unidos",
            "/wiki/Francis_Gurry",
            "/wiki/Antonio_Palacios_Rojo",
            "/wiki/Computadoras_en_la_ciencia_ficci%C3%B3n",
            "/wiki/The_Terminator",
            "/wiki/Matrix",
            "/wiki/Inteligencia_artificial_(pel%C3%ADcula)",
            "/wiki/Premio_Oscar",
            "/wiki/Minority_Report",
            "/wiki/Yo,_robot_(pel%C3%ADcula)",
            "/wiki/Her",
            "/wiki/Ex_Machina_(pel%C3%ADcula)",
            "/wiki/Robot",
            "/wiki/AI_box",
            "/wiki/Alucinaci%C3%B3n_(inteligencia_artificial)",
            "/wiki/Aprendizaje",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Automatizaci%C3%B3n_de_los_procesos_de_negocio",
            "/wiki/Bot_conversacional",
            "/wiki/Cerebro_artificial",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Computaci%C3%B3n_basada_en_humanos",
            "/wiki/Din%C3%A1mica_de_sistemas",
            "/wiki/ELIZA",
            "/wiki/Filosof%C3%ADa_de_la_inteligencia_artificial",
            "/wiki/Industria_de_la_inteligencia_artificial_en_China",
            "/wiki/Inteligencia_artificial_fuerte",
            "/wiki/Inteligencia_computacional",
            "/wiki/Inteligencia_sint%C3%A9tica",
            "/wiki/Internet",
            "/wiki/Internet_en_la_ciencia_ficci%C3%B3n",
            "/wiki/Interfaces_de_usuario",
            "/wiki/LLM_(modelo_grande_de_lenguaje)",
            "/wiki/Razonamiento_automatizado",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Regulaci%C3%B3n_de_la_inteligencia_artificial",
            "/wiki/Riesgo_existencial_de_la_inteligencia_artificial",
            "/wiki/William_Ross_Ashby",
            "/wiki/Seguridad_de_la_inteligencia_artificial",
            "/wiki/Singularidad_tecnol%C3%B3gica",
            "/wiki/Sistema_complejo",
            "/wiki/Sistema_din%C3%A1mico",
            "/wiki/Sistema_inteligente",
            "/wiki/Visi%C3%B3n_artificial",
            "/wiki/Red_neuronal_residual",
            "/wiki/Confabulaci%C3%B3n_(redes_neuronales)",
            "/wiki/Microsoft_Azure",
            "/wiki/ISBN",
            "/wiki/El_Pa%C3%ADs",
            "/wiki/ISBN",
            "/wiki/John_McCarthy_(cient%C3%ADfico)",
            "/wiki/La_Vanguardia",
            "/wiki/ISSN",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/El_Robot_Completo",
            "/wiki/Domingo_Santos",
            "/wiki/Mart%C3%ADnez_Roca",
            "/wiki/ISBN",
            "/wiki/El_Mundo_(Espa%C3%B1a)",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Explosi%C3%B3n_combinatoria",
            "/wiki/Bibcode",
            "/wiki/PubMed_Identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/El_Mundo",
            "/wiki/La_Raz%C3%B3n_(Espa%C3%B1a)",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/PubMed_Identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/ISBN",
            "/wiki/Stuart_J._Russell",
            "/wiki/Peter_Norvig",
            "/wiki/ISBN",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Medical_Subject_Headings"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Investigaci%C3%B3n_operativa",
        "titulo": "Investigación de operaciones",
        "contenido": "la investigacion de operaciones, tambien llamada investigacion operativa o ciencia administrativa, es una disciplina que se ocupa de la aplicacion de metodos analiticos avanzados para ayudar a tomar mejores decisiones.​ forma parte de la disciplina administrativa y la ingenieria industrial.​ el origen de la io moderna se situa en la 2.ª guerra mundial y en el bando aliado. posiblemente contribuyo en gran medida a que ganaran la guerra. de hecho, alguno de los descubrimientos de esos años (el control de calidad secuencial de wald) continuo siendo secreto militar hasta varios años despues de terminada la guerra. los ejercitos son organizaciones complejas con problemas complejos de coordinacion y logistica, de produccion y distribucion de armas, de intendencia, de estrategias de avance y despliegue de tropas. el mando aliado reunio a cientificos de diversas areas (matematicos, fisicos, ingenieros, estadisticos, economistas, entre otros) para abordar esos problemas complejos. el nombre de io viene de ese objetivo belico: investigar las operaciones (militares).​  a menudo se considera que es un subcampo de las matematicas aplicadas.​ los terminos ciencia de la gestion y teoria de la decision a veces se usan como sinonimos.​  empleando tecnicas de otras ciencias matematicas, como modelado matematico, analisis estadistico y optimizacion, la investigacion de operaciones llega a soluciones optimas o casi optimas para problemas complejos de toma de decisiones. debido a su enfasis en la interaccion humano-tecnologia y debido a su enfoque en aplicaciones practicas, la investigacion de operaciones se superpone con otras disciplinas, en particular la ingenieria industrial y la administracion de la produccion, y se basa en la psicologia y en la ciencia de la organizacion. la investigacion de operaciones a menudo se ocupa de determinar los valores extremos de algun objetivo del mundo real: los maximos (de ganancia, rendimiento o rentabilidad) o minimos (de perdida, riesgo o costo). originada en los esfuerzos militares previos a la segunda guerra mundial, sus tecnicas han crecido para tratar problemas en distintas industrias.​  la investigacion operativa (io) abarca una amplia gama de tecnicas y metodos de resolucion de problemas aplicados para mejorar la toma de decisiones y la eficiencia, como la simulacion, la optimizacion, la teoria de colas y otros modelos de procesos estocasticos, proceso de decision de markov, metodos econometricos, analisis envolvente de datos, redes neurales, sistemas expertos, analisis de decisiones y procesos analiticos jerarquicos.​ casi todas estas tecnicas implican la construccion de modelos matematicos que intentan describir el sistema. debido a la naturaleza computacional y estadistica de la mayoria de estos campos, tambien tiene fuertes vinculos con las ciencias de la computacion y la analitica. los investigadores operacionales que se enfrentan a un nuevo problema deben determinar cual de estas tecnicas es la mas adecuada, dada la naturaleza del sistema, los objetivos de mejora y las limitaciones de tiempo y capacidad de calculo.[cita requerida]  las principales subdisciplinas en la investigacion operativa moderna, identificadas por la revista operations research (investigacion de operaciones),​ son:  en las decadas posteriores a las dos guerras mundiales, las herramientas de la investigacion de operaciones se aplicaron mas ampliamente a los problemas en los negocios, la industria y la sociedad. desde entonces, la investigacion operativa se ha expandido a un campo ampliamente utilizado en industrias que van desde productos petroquimicos a lineas aereas, finanzas, logistica y gobierno, enfocandose en el desarrollo de modelos matematicos que pueden usarse para analizar y optimizar sistemas complejos, y se ha convertido en un area de investigacion academica e industrial activa.​  en el siglo xvii, matematicos como christiaan huygens y blaise pascal (abordando el problema de la partida interrumpida) intentaron resolver cuestiones relacionadas con decisiones complejas mediante el uso del calculo de probabilidad. otros matematicos de los siglos xviii y xix resolvieron este tipo de problemas mediante combinatoria. la investigacion de charles babbage sobre el costo del transporte y la clasificacion del correo condujo a la universal \"penny post\" de inglaterra en 1840, y en los estudios sobre el comportamiento dinamico de los vehiculos ferroviarios en defensa del ancho de via del gwr.​ a partir del siglo xx, el estudio de la gestion de inventarios podria considerarse el origen de la investigacion de operaciones modernas con el concepto de cantidad economica de pedido desarrollado por ford w. harris en 1913. la investigacion operativa puede haberse originado en los esfuerzos de los planificadores militares durante la primera guerra mundial (teoria de convoy y leyes de lanchester). percy williams bridgman llevo la investigacion operativa a los problemas de la fisica en la decada de 1920 y luego intentaria extenderlos a las ciencias sociales.​  la investigacion operativa moderna se origino en el establecimiento de investigacion de bawdsey en el reino unido en 1937 y fue el resultado de una iniciativa del superintendente del establecimiento, a. p. rowe, que concibio la idea como un medio para analizar y mejorar el funcionamiento del sistema planteado de alerta de radar temprana del reino unido, y de su red de instalaciones (chain home (ch)). inicialmente, analizo el funcionamiento del equipo de radar y sus redes de comunicacion, expandiendose mas tarde para incluir el comportamiento del personal operativo. esto revelo limitaciones no apreciadas de la red ch y permitio que se tomaran medidas correctivas.​  cientificos en el reino unido, incluyendo a patrick blackett, cecil gordon, solly zuckerman, c. h. waddington, owen wansbrough-jones, frank yates, jacob bronowski y freeman dyson, y en los estados unidos con george dantzig buscaron maneras para tomar mejores decisiones en areas como la logistica y los horarios de adiestramiento.  el campo moderno de la investigacion operativa surgio durante la segunda guerra mundial. en este periodo, la investigacion operativa se definio como \"un metodo cientifico para proporcionar a los departamentos ejecutivos una base cuantitativa para la toma de decisiones sobre las operaciones bajo su control\".​ la actividad tambien era conocida como analisis operacional (ministerio de defensa del reino unido desde 1962)​ y gestion cuantitativa.​  durante la segunda guerra mundial, cerca de 1000 hombres y mujeres participaron en investigacion operativa en gran bretaña, y alrededor de 200 cientificos trabajaron en este campo para el ejercito britanico.​  patrick maynard stuart blackett trabajo para varias organizaciones diferentes durante la guerra. al comienzo del conflicto, mientras trabajaba para el royal aircraft establishment (rae), creo un equipo conocido como el \"circo\", que ayudo a reducir el numero de disparos de la defensa antiaerea necesarios para derribar un avion enemigo desde un promedio de mas de 20 000 al comienzo del batalla de inglaterra a 4000 en 1941.​  en 1941, blackett se mudo de la rae a la armada, tras trabajar primero con el comando de costas de la raf en 1941 y luego a principios de 1942 al almirantazgo britanico.​ el equipo de blackett en la seccion de investigacion operacional del comando costero (cc-ors) incluyo a dos futuros ganadores del premio nobel y a muchas otras personas que pasaron a ser figuras destacadas en sus campos.​ llevaron a cabo una serie de analisis cruciales que contribuyeron al esfuerzo belico. gran bretaña introdujo el sistema de convoyes para reducir las perdidas de cargueros, pero si bien se acepto el principio de usar buques de guerra para acompañar a los buques mercantes, no estaba claro si era mejor que los convoyes fueran pequeños o grandes. los convoyes viajan a la velocidad del miembro mas lento, por lo que los convoyes pequeños pueden viajar mas rapido. tambien se argumento que los u-boot alemanes serian mas dificiles de detectar para los pequeños convoyes. por otro lado, los convoyes grandes podrian desplegar mas buques de guerra contra un atacante. el personal de blackett demostro que las perdidas sufridas por los convoyes dependian en gran medida de la cantidad de buques de escolta presentes, en lugar del tamaño del convoy. su conclusion fue que algunos convoyes grandes son mas defendibles que muchos pequeños.​   al realizar un analisis de los metodos utilizados por el comando de costas de la raf para cazar y destruir submarinos, uno de los analistas pregunto de que color eran los aviones. como la mayoria de ellos eran del comando de bombarderos, estaban pintados de negro para operaciones nocturnas. a sugerencia de cc-ors se realizo una prueba para ver si ese era el mejor color para camuflar el avion para operaciones diurnas en los cielos grises del atlantico norte. las pruebas mostraron que, en promedio, los aviones pintados de blanco no se vieron hasta que estuvieron un 20 % mas cerca que los pintados de negro. este cambio indico que un 30 % mas de submarinos serian atacados y hundidos con el mismo numero de avistamientos.​ como resultado de estos hallazgos, el comando costero cambio sus aeronaves para usar superficies inferiores blancas.  otros trabajos realizados por el cc-ors indicaron que, en promedio, si la profundidad de disparo de las cargas de profundidad se cambiara de 100 pies a 25 pies, las tasas de efectividad subirian. la razon era que si un u-boat viera un avion poco antes de que llegara al objetivo, las cargas no harian daño explotando a 100 pies (porque el u-boat no habria tenido tiempo de descender hasta esa profundidad) y si vio la aeronave desde muy lejos del objetivo, tuvo tiempo de alterar su rumbo bajo el agua, por lo que las posibilidades de que estuviera dentro de la zona de impacto de 20 pies de los cargas eran pequeñas. era mas eficiente atacar a los submarinos cerca de la superficie cuando se conocia mejor la ubicacion de los objetivos que intentar destruirlos a mayor profundidad cuando sus posiciones solo podian ser adivinadas. antes del cambio de configuracion de 100 pies a 25 pies, el 1 % de los submarinos sumergidos se hundieron y el 14 % se dañaron. despues del cambio, el 7 % fue hundido y el 11 % dañado (si se cuentan los submarinos capturados en la superficie, incluso si fueron atacados poco despues de sumergirse, los numeros aumentaron a 11 % hundidos y a 15 % dañados). blackett observo que \"puede haber pocos casos en los que se haya obtenido una ganancia operativa tan grande con un cambio de tactica tan pequeño y simple\".​   la seccion de investigacion operativa del comando de bombardeo (bc-ors) analizo un informe de una encuesta realizada por el comando de bombardeo de la raf. para la encuesta, inspecciono todos los bombarderos que regresaban de misiones sobre alemania durante un periodo en particular. se tomo nota de todos los daños causados por la defensa antiaerea alemana y se recomendo que se agregara armadura en las zonas mas dañadas. esta recomendacion no se adopto porque el hecho de que la aeronave regresara con estas areas dañadas indicaba que estas areas no eran vitales, y agregar armadura a las areas no vitales donde el daño es aceptable afecta negativamente el rendimiento de la aeronave. tambien se rechazo su sugerencia de suprimir a algunos miembros de la tripulacion para que la perdida de una aeronave produjera menores perdidas de personal. el equipo de blackett hizo la recomendacion logica de colocar la armadura en las areas que estaban completamente intactas por el daño en los bombarderos que regresaron. razonaron que la toma de datos estaba sesgada, ya que solo incluia a los aviones que regresaron a gran bretaña. las zonas intactas de las aeronaves que retornaron fueron probablemente los puntos vitales que, de ser dañadas, se traducirian en la perdida de la aeronave.​ ​ se cita una historia similar acerca de un estudio de evaluacion de daños similar completado en los estados unidos por el grupo de investigacion estadistica de la universidad de columbia.​ y fue el resultado del trabajo realizado por abraham wald.​  cuando alemania organizo sus defensas aereas en la linea kammhuber, los britanicos se dieron cuenta de que si los bombarderos de la raf volaban en una formacion lineal cerrada podrian abrumar a los cazas nocturnos alemanes que volaban individualmente, dirigidos a sus objetivos por los controladores de tierra. fue entonces una cuestion de calcular estadisticamente las perdida causadas por las colisiones entre los bombarderos frente a las perdidas causadas por los cazas nocturnos para determinar la separacion a la que deberian volar los bombarderos para minimizar las perdidas de la raf.​  la relacion de la tasa de cambio de la salida respecto a la entrada fue un rasgo caracteristico de la investigacion operativa. al comparar el numero de horas de vuelo de los aviones aliados con el numero de avistamientos de submarinos en un area determinada, fue posible redistribuir los aviones a areas de patrulla mas productivas. la comparacion de estas tasas permitieron establecer \"ratios de efectividad\" utiles en la planificacion. la proporcion de 60 minas marinas colocadas por barco hundido era comun a varias campañas: minas alemanas en puertos britanicos, minas britanicas en rutas alemanas y minas de estados unidos en rutas japonesas.​  la investigacion operacional duplico la tasa de acierto de los bombardeos sobre los objetivos previstos de los boeing b-29 superfortress que atacaban japon desde las islas marianas, al aumentar la proporcion de entrenamiento del 4 al 10 por cien de las horas de vuelo; revelo que las manadas de lobos de tres submarinos de los estados unidos eran el numero mas efectivo; mostro que la pintura de esmalte brillante era un camuflaje mas efectivo para los cazas nocturnos que el acabado de pintura de camuflaje opaco tradicional, y que el acabado liso de la pintura aumentaba la velocidad de los aviones al reducir la friccion de los fuselajes con el aire.​  en tierra, las secciones de investigacion operativa del grupo de investigacion operativa del ejercito (aorg) del ministerio de suministros (mos) fueron desplegadas en la batalla de normandia en 1944, y siguieron a las fuerzas britanicas en el avance hacia el centro de europa. analizaron, entre otros temas, la efectividad de la artilleria, los bombardeos aereos y los disparos antitanque.  con las tecnicas ampliadas y la creciente concienciacion sobre el terreno al final de la guerra, la investigacion operativa ya no se limito solo a la tactica, sino que se extendio para abarcar la adquisicion de equipos, la capacitacion, la logistica y la infraestructura. la investigacion de operaciones tambien crecio en muchas otras areas ademas del ambito militar una vez que los cientificos aprendieron a aplicar sus principios al sector civil. con el desarrollo del algoritmo simplex para programacion lineal en 1947​ y el desarrollo de computadoras en las tres decadas siguientes\".​  la investigacion operativa tambien se usa ampliamente en el gobierno, donde se usa politica basada en la evidencia.  en 1967, stafford beer caracterizo el campo de la ciencia de la administracion como \"el uso comercial de la investigacion de operaciones\".​ sin embargo, en los tiempos modernos el termino ciencia de la administracion tambien se puede usar para referirse a los campos separados de los estudios organizacionales o estrategia de negocios. la ciencia de la gestion es una rama interdisciplinaria de las matematicas aplicadas dedicada a la planificacion optima de decisiones, con fuertes vinculos con la economia, los negocios, la ingenieria y otras ciencias. utiliza varios principios basados en investigacion cientifica, estrategias y tecnicas analiticas, incluyendo modelado matematico, estadisticas y analisis numerico con el fin de mejorar la capacidad de una organizacion para adoptar decisiones de gestion racionales y significativas al llegar a soluciones optimas o casi optimas para problemas complejos de decision. los cientificos de gestion ayudan a las empresas a lograr sus objetivos utilizando los metodos cientificos de la investigacion operativa.  el mandato del cientifico de la administracion es utilizar tecnicas racionales, sistematicas y basadas en la ciencia para informar y mejorar las decisiones de todo tipo. por supuesto, las tecnicas de la ciencia de la administracion no se limitan a aplicaciones comerciales, sino que pueden aplicarse a militares, medicos, administracion publica, grupos caritativos, grupos politicos o a comunidades.  la ciencia de la administracion tiene que ver con el desarrollo y la aplicacion de modelos y conceptos que pueden resultar utiles para ayudar a iluminar los problemas de la administracion y resolver problemas de gestion, asi como para diseñar y desarrollar nuevos y mejores modelos de excelencia organizacional.​  la aplicacion de estos modelos dentro del sector corporativo se conocio como ciencia de la gestion.​  algunos de los campos que tienen una considerable superposicion con la investigacion operativa y con la ciencia de la gestion incluyen:​  las aplicaciones son abundantes, como en aerolineas, compañias de fabricacion, club de servicio, sucursales militares y gobierno. la gama de problemas y problemas a los que ha aportado ideas y soluciones es muy amplia. incluye:​  la administracion tambien esta preocupada por el llamado 'analisis operacional suave' que se refiere a los metodos para la planificacion estrategica, los sistemas de soporte a decisiones, y los metodos de estructuracion de problemas.  al tratar con este tipo de desafios, el modelado y simulacion matematicos pueden no ser apropiados o pueden no ser suficientes. por lo tanto, desde los años 1990 se han desarrollado varios metodos de modelado no cuantificados. estos incluyen:  la international federation of operational research societies (ifors)​ es una organizacion paraguas para las sociedades de investigacion operativa en todo el mundo, que representa aproximadamente a 50 sociedades nacionales, incluidas las de los estados unidos​ reino unido (operational research society),​ francia,​ alemania, italia (italian operations research society),​ canada,​ australia,​ nueva zelanda,​ filipinas,​ india,​ japon y sudafrica​ los miembros constituyentes del ifors forman grupos regionales, como el de europa, association of european operational research societies (euro).​ otras organizaciones de investigacion operativa importantes son la simulation interoperability standards organization (siso)​ y la interservice/industry training, simulation and education conference (i/itsec).​  en 2004, la organizacion informs con sede en los estados unidos comenzo una iniciativa para comercializar mejor la actividad de los profesionales de la investigacion operativa, incluido un sitio web titulado \"the science of better\"​ que proporciona una introduccion a la investigacion operativa y ejemplos de su aplicacion exitosa a problemas industriales. esta iniciativa ha sido adoptada por la operational research society en el reino unido, incluido un sitio web titulado \"learn about or (aprender acerca de la io)\".​  el institute for operations research and the management sciences (informs) publica trece revistas academicas sobre investigacion de operaciones, incluidas las dos revistas mas importantes de su clase, de acuerdo con el journal citation reports.​ de 2005:  enumeradas segun el orden alfabetico de sus titulos:   ",
        "snippet": "La investigación de operaciones, también llamada investigación operativa o ciencia administrativa, es una disciplina que se ocupa de la aplicación de métodos analíticos avanzados para ayudar a tomar mejores decisiones.[1]​ Forma parte de la disciplina administrativa y la ingeniería industrial.[2]​ El origen de la IO moderna se sitúa en la 2.ª Guerra Mundial y en el bando aliado. Posiblemente contribuyó en gran medida a que ganaran la guerra. De hecho, alguno de los descubrimientos de esos años (el control de calidad secuencial de Wald) continuó siendo secreto militar hasta varios años después de terminada la guerra. Los ejércitos son organizaciones complejas con problemas complejos de coordinación y logística, de producción y distribución de armas, de intendencia, de estrategias de avance y despliegue de tropas. El mando aliado reunió a científicos de diversas áreas (matemáticos, físicos, ingenieros, estadísticos, economistas, entre otros) para abordar esos problemas complejos. El nombre de IO viene de ese objetivo bélico: investigar las operaciones (militares).[3]​",
        "enlaces_salientes": [
            "/wiki/Investigaci%C3%B3n_de_operaciones",
            "/wiki/Investigaci%C3%B3n_de_operaciones",
            "/wiki/Investigaci%C3%B3n_de_operaciones",
            "/wiki/Administraci%C3%B3n",
            "/wiki/Ingenier%C3%ADa_industrial",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Administraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_decisi%C3%B3n",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Ingenier%C3%ADa_industrial",
            "/wiki/Administraci%C3%B3n_de_la_producci%C3%B3n",
            "/wiki/Psicolog%C3%ADa",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Extremos_de_una_funci%C3%B3n",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Simulaci%C3%B3n",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Teor%C3%ADa_de_colas",
            "/wiki/Proceso_estoc%C3%A1stico",
            "/wiki/Proceso_de_decisi%C3%B3n_de_M%C3%A1rkov",
            "/wiki/Econometr%C3%ADa",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Sistema_experto",
            "/wiki/An%C3%A1lisis_de_decisi%C3%B3n",
            "/wiki/Proceso_anal%C3%ADtico_jer%C3%A1rquico",
            "/wiki/Modelos_matem%C3%A1ticos",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Ingenier%C3%ADa_financiera",
            "/wiki/Manufactura",
            "/wiki/Administraci%C3%B3n_de_la_cadena_de_suministro",
            "/wiki/Gesti%C3%B3n_de_ingresos",
            "/wiki/Simulaci%C3%B3n",
            "/wiki/Estoc%C3%A1stico",
            "/wiki/Christiaan_Huygens",
            "/wiki/Blaise_Pascal",
            "/wiki/Problema_de_la_partida_interrumpida",
            "/wiki/Probabilidad",
            "/wiki/Combinatoria",
            "/wiki/Charles_Babbage",
            "/wiki/Great_Western_Railway",
            "/wiki/Cantidad_econ%C3%B3mica_de_pedido",
            "/wiki/Leyes_de_Lanchester",
            "/wiki/Percy_Williams_Bridgman",
            "/wiki/Patrick_Maynard_Stuart_Blackett",
            "/wiki/Conrad_Hal_Waddington",
            "/wiki/Frank_Yates",
            "/wiki/Jacob_Bronowski",
            "/wiki/Freeman_Dyson",
            "/wiki/George_Dantzig",
            "/wiki/Log%C3%ADstica",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Ej%C3%A9rcito_Brit%C3%A1nico",
            "/wiki/Patrick_Maynard_Stuart_Blackett",
            "/wiki/Royal_Aircraft_Establishment",
            "/wiki/Defensa_antia%C3%A9rea",
            "/wiki/Batalla_de_Inglaterra",
            "/wiki/Consolidated_B-24_Liberator",
            "/wiki/Comando_de_Costas_de_la_RAF",
            "/wiki/Almirantazgo_brit%C3%A1nico",
            "/wiki/Premio_Nobel",
            "/wiki/Convoy",
            "/wiki/U-Boot",
            "/wiki/Comando_de_Costas_de_la_RAF",
            "/wiki/Carga_de_profundidad",
            "/wiki/L%C3%ADnea_Kammhuber",
            "/wiki/Defensa_antia%C3%A9rea",
            "/wiki/Abraham_Wald",
            "/wiki/L%C3%ADnea_Kammhuber",
            "/wiki/Corriente_de_bombarderos",
            "/wiki/Mina_marina",
            "/wiki/Boeing_B-29_Superfortress",
            "/wiki/Islas_Marianas",
            "/wiki/Batalla_de_Normand%C3%ADa",
            "/wiki/Algoritmo_s%C3%ADmplex",
            "/wiki/Programaci%C3%B3n_lineal",
            "/wiki/M%C3%A9todo_de_la_ruta_cr%C3%ADtica",
            "/wiki/Planeamiento_de_proyectos",
            "/wiki/Circuito_integrado",
            "/wiki/Manufactura",
            "/wiki/Red_de_telecomunicaci%C3%B3n",
            "/wiki/Problema_de_la_asignaci%C3%B3n",
            "/wiki/Problema_de_la_asignaci%C3%B3n_cuadr%C3%A1tica",
            "/wiki/Encaminamiento",
            "/wiki/Administraci%C3%B3n_de_la_cadena_de_suministro",
            "/wiki/Automatizaci%C3%B3n_industrial",
            "/wiki/Globalizaci%C3%B3n",
            "/wiki/Transporte_intermodal",
            "/wiki/Problema_del_viajante",
            "/wiki/Planificador",
            "/wiki/Gesti%C3%B3n_de_proyectos",
            "/wiki/Teor%C3%ADa_de_colas",
            "/wiki/Problema_de_corte_de_valores",
            "/wiki/Stafford_Beer",
            "/wiki/Estudios_organizacionales",
            "/wiki/Estrategia_de_negocios",
            "/wiki/Ciencia",
            "/wiki/Investigaci%C3%B3n",
            "/wiki/Ciencia",
            "/wiki/Estrategia_(juegos)",
            "/wiki/T%C3%A9cnica_anal%C3%ADtica",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Concepto",
            "/wiki/Miner%C3%ADa_de_datos",
            "/wiki/Ciencia_de_datos",
            "/wiki/Macrodatos",
            "/wiki/An%C3%A1lisis_de_decisi%C3%B3n",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Ingenier%C3%ADa_financiera",
            "/wiki/Pron%C3%B3stico_(estad%C3%ADstica)",
            "/wiki/Teor%C3%ADa_de_juegos",
            "/wiki/Geograf%C3%ADa",
            "/wiki/Ciencia_de_la_informaci%C3%B3n_geogr%C3%A1fica",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Ingenier%C3%ADa_industrial",
            "/wiki/Log%C3%ADstica",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Gesti%C3%B3n_de_proyectos",
            "/wiki/Simulaci%C3%B3n",
            "/wiki/Red_social",
            "/wiki/Modelizaci%C3%B3n_de_transporte",
            "/wiki/Proceso_estoc%C3%A1stico",
            "/wiki/Administraci%C3%B3n_de_la_cadena_de_suministro",
            "/wiki/Club_de_servicio",
            "/wiki/Planificaci%C3%B3n_estrat%C3%A9gica",
            "/wiki/Sistemas_de_soporte_a_decisiones",
            "/wiki/Modelado_y_simulaci%C3%B3n",
            "/wiki/Organizaci%C3%B3n_paraguas",
            "/wiki/Association_of_European_Operational_Research_Societies",
            "/wiki/Journal_Citation_Reports",
            "/wiki/Wiley-Blackwell",
            "/wiki/European_Journal_of_Operational_Research",
            "/wiki/Taylor_and_Francis",
            "/wiki/Caja_negra_(sistemas)",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica",
            "/wiki/George_Dantzig",
            "/wiki/Leonid_Kantor%C3%B3vich",
            "/wiki/Tjalling_Koopmans",
            "/wiki/Russell_L._Ackoff",
            "/wiki/Stafford_Beer",
            "/wiki/Robert_Dorfman",
            "/wiki/Richard_Karp",
            "/wiki/Frederick_Lanchester",
            "/wiki/Alvin_E._Roth",
            "/wiki/Macrodatos",
            "/wiki/Ingenier%C3%ADa_de_Negocios",
            "/wiki/Gesti%C3%B3n_de_procesos_de_negocio",
            "/wiki/Normalizaci%C3%B3n_de_bases_de_datos",
            "/wiki/Sistema_de_informaci%C3%B3n_geogr%C3%A1fica",
            "/wiki/Ingenier%C3%ADa_industrial",
            "/wiki/Organizaci%C3%B3n_industrial",
            "/wiki/Econom%C3%ADa_gerencial",
            "/wiki/Simulaci%C3%B3n_militar",
            "/wiki/Fiabilidad_de_sistemas",
            "/wiki/Taylorismo",
            "/wiki/Ingenier%C3%ADa_del_software_basada_en_b%C3%BAsqueda",
            "/wiki/Juego_de_guerra",
            "/wiki/Proceso_de_decisi%C3%B3n_de_M%C3%A1rkov",
            "/wiki/ISBN",
            "/wiki/Wayback_Machine",
            "/wiki/Internet_Archive",
            "/wiki/Internet_Archive",
            "/wiki/Internet_Archive",
            "/wiki/Internet_Archive",
            "/wiki/Digital_object_identifier",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/Stafford_Beer",
            "/wiki/Internet_Archive",
            "/wiki/Wayback_Machine",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Internet_Archive",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/National_Archives_and_Records_Administration",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Medical_Subject_Headings"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Matem%C3%A1ticas",
        "titulo": "Matemáticas",
        "contenido": "las matematicas ​​​ (del latin mathematica, y este del griego μαθηματκα, transliterado como mathematika, derivado de μαθημα, tr. mathema (conocimiento) son una ciencia formal que surgio del estudio de las figuras geometricas y la aritmetica con numeros. hoy en dia se suele aceptar que la matematica es una ciencia que investiga patrones.​​​​​  las ciencias naturales han hecho un uso extensivo de la matematica para explicar diversos fenomenos observables, tal como lo expreso eugene paul wigner (premio nobel de fisica en 1963):  galileo galilei, en la misma linea, lo habia expresado asi:  mediante la abstraccion y el uso de la logica en el razonamiento, la matematica ha evolucionado basandose en el calculo y las mediciones, junto con el estudio sistematico de la forma y el movimiento de los objetos fisicos.​ las matematicas, desde sus comienzos, han tenido un fin practico.  las explicaciones que se apoyaban en la logica aparecieron por primera vez con la matematica helenica, especialmente con los elementos de euclides.​ la matematica siguio desarrollandose, con continuas interrupciones, hasta que en el renacimiento las innovaciones matematicas interactuaron con los nuevos descubrimientos cientificos. como consecuencia, hubo una aceleracion en la investigacion que continua hasta la actualidad.  hoy dia, la matematica se usa en todo el mundo como una herramienta esencial en muchos campos, entre los que se encuentran las ciencias naturales,​ las ciencias aplicadas, las humanidades,​​​ la medicina​ y las ciencias sociales,​​​ e incluso disciplinas que, aparentemente, no estan vinculadas con ella, como la musica​ (por ejemplo, en cuestiones de resonancia armonica, cuerda vibrante,​​ etc.) y la literatura.​ las matematicas aplicadas, rama de la matematica destinada a la aplicacion del conocimiento matematico a otros ambitos, inspiran y hacen uso de los nuevos descubrimientos matematicos y, en ocasiones, conducen al desarrollo de nuevas disciplinas. los matematicos​ tambien participan en la matematica pura, sin tener en cuenta la aplicacion de esta ciencia, aunque las aplicaciones practicas de la matematica pura suelen ser descubiertas con el paso del tiempo.  las matematicas son una de las ciencias mas antiguas. florecio primero antes de la antiguedad en mesopotamia,​ en cuanto a la geometria​, india y china, y mas tarde en la antiguedad en grecia y el helenismo. de ahi data la orientacion hacia la tarea de \"demostracion puramente logica\" y la primera axiomatizacion, a saber, la geometria euclidiana​. en la edad media sobrevivio de forma independiente en el primer humanismo de las universidades y en el mundo arabe.  a principios de la era moderna, francois viete introdujo variables y rene descartes inauguro un enfoque computacional de la geometria​​​  mediante el uso de coordenadas. la consideracion de las tasas de cambio (fluxion)​ asi como la descripcion de las tangentes y la determinacion de los contenidos de las superficies (cuadratura)​ condujeron al calculo infinitesimal​ de gottfried wilhelm leibniz e isaac newton​. la mecanica de newton y su ley de la gravitacion fueron tambien una fuente de orientacion de problemas matematicos como el problema de los tres cuerpos​​​ en los siglos siguientes.  otro de los principales problemas de la primera epoca moderna fue la solucion de ecuaciones algebraicas cada vez mas complicadas. para hacer frente a esto, niels henrik abel y evariste galois desarrollaron el concepto de grupo, que describe las relaciones entre las simetrias de un objeto.​​ el algebra mas reciente y, en particular, la geometria algebraica pueden considerarse como una profundizacion de estas investigaciones.  una idea entonces nueva en el intercambio de cartas entre blaise pascal y pierre de fermat en 1654 acerca del problema de los juegos de azar,​​​ aunque  existian otras soluciones discutibles como las de cardano, quien intento matematizarlas. pierre-simon laplace hace un recuento de los diferentes logros hasta 1812 cuando publica su ensayo filosofico sobre las posibilidades.​ las nuevas ideas y metodos conquistaron muchos campos. pero durante siglos, la teoria clasica de la probabilidad se dividio en escuelas separadas. los intentos de definir explicitamente el termino «probabilidad» solo tuvieron exito para casos especiales. solo la publicacion del libro de texto de andrei kolmogorov en 1933 los fundamentos de la teoria de la  probabilidad ​ completo el desarrollo de los fundamentos de la teoria moderna de la probabilidad.  en el transcurso del siglo xix, el calculo infinitesimal​ encontro su forma actual de rigor gracias a los trabajos de augustin-louis cauchy y karl weierstrass. la teoria de conjuntos​ desarrollada por georg cantor hacia finales del siglo xix es tambien indispensable en la matematica actual, aunque las paradojas del concepto ingenuo de conjuntos dejaron claro, en un primer momento, la incierta base sobre la que se asentaban las matematicas.​  el desarrollo de la primera mitad del siglo xx estuvo influenciado por la lista de 23 problemas matematicos​ de david hilbert. uno de los problemas fue el intento de axiomatizar completamente las matematicas; al mismo tiempo, se hicieron grandes esfuerzos de abstraccion, es decir, el intento de reducir los objetos a sus propiedades esenciales. asi, emmy noether desarrollo los fundamentos del algebra moderna,​ felix hausdorff desarrollo la topologia general como el estudio de los espacios topologicos, stefan banach desarrollo probablemente el concepto mas importante del analisis funcional, el espacio de banach que lleva su nombre. un nivel de abstraccion aun mayor, un marco comun para la consideracion de construcciones similares de diferentes areas de las matematicas, fue finalmente creado por la introduccion de la teoria de categorias por samuel eilenberg y saunders mac lane.  la palabra «matematica» (del griego μαθηματκα mathematika, «cosas que se aprenden») viene del griego antiguo μαθημα (mathema), que quiere decir «campo de estudio o instruccion». las matematicas requieren un esfuerzo de instruccion o aprendizaje, refiriendose a areas del conocimiento que solo pueden entenderse tras haber sido instruido en las mismas, como la astronomia. «el arte matematica» (μαθηματκη τεχνη, mathematike tekhne) se contrapondria en esto a la musica, «el arte de las musas» (μουσκη τεχνη, mousike techne), que seria un arte, como la poesia, retorica​​ y similares, que se puede apreciar directamente, «que se puede entender sin haber sido instruido».​ aunque el termino ya era usado por los pitagoricos (matematikoi) en el siglo vi a. c., alcanzo su significado mas tecnico y reducido de «estudio matematico» en los tiempos de aristoteles (siglo iv a. c.). su adjetivo es μαθηματκος (mathematikos), «relacionado con el aprendizaje», lo cual, de manera similar, vino a significar «matematico». en particular, μαθηματκη τεχνη (mathematike tekhne; en latin ars mathematica), significa «el arte matematica».  la forma mas usada es el plural matematicas (cuyo acortamiento, en algunos paises,  es «mates»​​), que tiene el mismo significado que el singular​ y viene de la forma latina mathematica (ciceron), basada en el plural en griego τα μαθηματκα (ta mathematika), usada por aristoteles y que significa, a grandes rasgos, «todas las cosas matematicas». algunos autores, sin embargo, hacen uso de la forma singular del termino; tal es el caso de bourbaki, en el tratado elementos de matematica (elements de mathematique, 1940), destaca la uniformidad de este campo aportada por la vision axiomatica moderna, aunque tambien hace uso de la forma plural como en elements d'histoire des mathematiques (1969),​ posiblemente sugiriendo que es bourbaki quien finalmente realiza la unificacion de las matematicas.​ asi mismo, en el escrito l'architecture des mathematiques (1948)  plantea el tema en la seccion «¿matematicas, singular o plural?» donde defiende la unicidad conceptual de la matematica aunque hace uso de la forma plural en dicho escrito.​​​​  establecer definiciones claras y precisas es el fundamento de la matematica, aunque encontrar  una definicion unica para ella es improbable.​ se muestran algunas reflexiones de reconocidos autores:  el caracter epistemologico y cientifico de la matematica ha sido ampliamente discutido. en la practica, la matematica se emplea para estudiar relaciones cuantitativas, estructuras, relaciones geometricas y las magnitudes variables. los matematicos buscan patrones,​​​​ formulan nuevas conjeturas e intentan alcanzar la verdad matematica mediante deducciones rigurosas. estas les permiten establecer los axiomas y las definiciones apropiados para dicho fin.​​ algunas definiciones clasicas restringen las matematicas al razonamiento sobre cantidades,​ aunque solo una parte de la matematica actual usa numeros,​ predominando el analisis logico de construcciones abstractas no cuantitativas.  existe cierta discusion acerca de si los objetos matematicos, como los numeros​ y puntos, realmente existen o simplemente provienen de la imaginacion humana. el matematico benjamin peirce definio las matematicas como «la ciencia que señala las conclusiones necesarias».​ por otro lado:  se ha discutido el caracter cientifico de las matematicas debido a que sus procedimientos y resultados poseen una firmeza e inevitabilidad inexistentes en otras disciplinas como pueden ser la fisica, la quimica o la biologia. asi, la matematica seria tautologica, infalible y a priori, mientras que otras, como la geologia o la fisiologia, serian falibles y a posteriori. son estas caracteristicas lo que hace dudar de colocarse en el mismo rango que las disciplinas antes citadas. john stuart mill afirmaba:  asi, los matematicos pueden descubrir nuevos procedimientos para resolver integrales o teoremas, pero se muestran incapaces de descubrir un suceso que ponga en duda el teorema de pitagoras​​  o cualquier otro, como si sucede constantemente con las ciencias de la naturaleza.​  la matematica puede ser entendida como ciencia; si es asi debiera señalarse su objeto y su metodo. sin embargo, algunos plantean que la matematica es un lenguaje formal, seguro, eficiente, aplicable al entendimiento de la naturaleza, tal como indico galileo; ademas muchos fenomenos de caracter social, otros de caracter biologico​ o geologico, pueden ser estudiados mediante la aplicacion de ecuaciones diferenciales,​​ calculo de probabilidades o teoria de conjunto.​ precisamente, el avance de la fisica y de la quimica ha exigido la invencion de nuevos conceptos, instrumentos y metodos en la matematica, sobre todo en el analisis real, analisis complejo y el analisis matricial.​  es muy posible que el arte de calcular​​​ haya sido desarrollado antes incluso que la escritura,​​ relacionado fundamentalmente con la contabilidad y la administracion de bienes, el comercio, en la agrimensura y, posteriormente, en la astronomia.  actualmente, todas las ciencias aportan problemas que son estudiados por matematicos, al mismo tiempo que aparecen nuevos problemas dentro de las propias matematicas. por ejemplo, el fisico richard feynman propuso la integral de caminos como fundamento de la mecanica cuantica, combinando el razonamiento matematico y el enfoque de la fisica, pero todavia, no se ha logrado una definicion plenamente satisfactoria en terminos matematicos. igualmente, la teoria de cuerdas, una teoria cientifica en desarrollo que trata de unificar las cuatro fuerzas fundamentales de la fisica, sigue inspirando a las mas modernas matematicas.​  algunas matematicas solo son relevantes en el area en la que estaban inspiradas y son aplicadas para otros problemas en ese campo. sin embargo, a menudo las matematicas inspiradas en un area concreta resultan utiles en muchos ambitos, y se incluyen dentro de los conceptos matematicos generales aceptados. el notable hecho de que incluso la matematica mas pura habitualmente tiene aplicaciones practicas es lo que eugene paul wigner ha definido como «la irrazonable eficacia de las matematicas en las ciencias naturales».​​  como en la mayoria de las areas de estudio, la explosion de los conocimientos en la era cientifica ha llevado a la especializacion de las matematicas. hay una importante distincion entre las matematicas puras y las matematicas aplicadas. la mayoria de los matematicos que se dedican a la investigacion se centran unicamente en una de estas areas y, a veces, la eleccion se realiza cuando comienzan su licenciatura. varias areas de las matematicas aplicadas se han fusionado con otras areas tradicionalmente fuera de las matematicas y se han convertido en disciplinas independientes, como pueden ser la estadistica, la investigacion de operaciones o la informatica.  aquellos que sienten predileccion por las matematicas, consideran que prevalece un aspecto estetico que define a la mayoria de las matematicas. muchos matematicos hablan de la elegancia de la matematica, su intrinseca estetica y su belleza interna. en general, uno de sus aspectos mas valorados es la simplicidad. hay belleza en una simple y contundente demostracion, como la demostracion de euclides​ de la existencia de infinitos numeros primos, y en un elegante analisis numerico que acelera el calculo, asi como en la transformada rapida de fourier. godfrey harold hardy en a mathematician's apology ​ (apologia de un matematico) expreso la conviccion de que estas consideraciones esteticas son, en si mismas, suficientes para justificar el estudio de las matematicas puras. los matematicos con frecuencia se esfuerzan por encontrar demostraciones de los teoremas que son especialmente elegantes, el excentrico matematico paul erdos se refiere a este hecho como la busqueda de pruebas de el libro en el que dios ha escrito sus demostraciones favoritas.​​ la popularidad de la matematica recreativa​​​​ es otra señal que nos indica el placer que produce resolver las preguntas matematicas.  la mayor parte de la notacion​ matematica que se utiliza hoy en dia no se invento hasta el siglo xviii.​​ antes de eso, las matematicas eran escritas con palabras, un minucioso proceso que limitaba el avance matematico. en el siglo xviii, euler, fue responsable de muchas de las notaciones empleadas en la actualidad. la notacion​ moderna hace que las matematicas sean mucho mas facil para los profesionales, pero para los principiantes resulta complicada. la notacion reduce las matematicas al maximo, hace que algunos simbolos​ contengan una gran cantidad de informacion. al igual que la notacion musical, la notacion matematica moderna tiene una sintaxis estricta y codifica la informacion que seria dificil de escribir de otra manera.  el lenguaje matematico tambien puede ser dificil para los principiantes. palabras tales como o y solo tienen significados mas precisos que en lenguaje cotidiano. ademas, palabras como abierto y cuerpo tienen significados matematicos muy concretos. la jerga matematica, o lenguaje matematico, incluye terminos tecnicos como homeomorfismo o integrabilidad. la razon que explica la necesidad de utilizar la notacion y la jerga es que el lenguaje matematico requiere mas precision que el lenguaje cotidiano. los matematicos se refieren a esta precision en el lenguaje y en la logica como el «rigor».  el rigor es una condicion indispensable que debe tener una demostracion matematica. los matematicos quieren que sus teoremas a partir de los axiomas sigan un razonamiento sistematico. esto sirve para evitar teoremas erroneos, basados en intuiciones falibles, que se han dado varias veces en la historia de esta ciencia.​ el nivel de rigor previsto en las matematicas ha variado con el tiempo: los griegos buscaban argumentos detallados, pero en tiempos de isaac newton los metodos empleados eran menos rigurosos. los problemas inherentes de las definiciones que newton utilizaba dieron lugar a un resurgimiento de un analisis cuidadoso y a las demostraciones oficiales del siglo xix. ahora, los matematicos continuan apoyandose entre ellos mediante demostraciones asistidas por ordenador.​  un axioma se interpreta tradicionalmente como una «verdad evidente», pero esta concepcion es problematica. en el ambito formal, un axioma no es mas que una cadena de simbolos, que tiene un significado intrinseco solo en el contexto de todas las formulas derivadas de un sistema axiomatico.  carl friedrich gauss se referia a la matematica como «la reina de las ciencias».​ tanto en el latin original scientiarum regina, asi como en aleman konigin der wissenschaften, la palabra ciencia debe ser interpretada como (campo de) conocimiento. si se considera que la ciencia es el estudio del mundo fisico, entonces las matematicas, o por lo menos las matematicas puras, no son una ciencia.  muchos filosofos creen que las matematicas no son experimentalmente falsables y, por ende, no son una ciencia segun la definicion de karl popper.​ no obstante, en la decada de 1930 una importante labor en la logica matematica demuestra que las matematicas no pueden reducirse a la logica​ y karl popper llego a la conclusion de que «la mayoria de las teorias matematicas son, como las de fisica y biologia, hipotetico-deductivas. por lo tanto, las matematicas puras se han vuelto mas cercanas a las ciencias naturales​ cuyas hipotesis son conjeturas, asi ha sido hasta ahora».​ otros pensadores, en particular imre lakatos, han solicitado una version de falsacionismo​​ para las propias matematicas.​  una vision alternativa es que determinados campos cientificos (como la fisica teorica) son matematicas con axiomas que pretenden corresponder a la realidad. de hecho, el fisico teorico, john michael ziman, propone que la ciencia es «conocimiento publico» y, por tanto, incluye a las matematicas.​ en cualquier caso, las matematicas tienen mucho en comun con distintos campos de las ciencias fisicas, especialmente la exploracion de las consecuencias logicas de las hipotesis. la intuicion​ y la experimentacion tambien desempeñan un papel importante en la formulacion de conjeturas tanto en las matematicas como en las otras ciencias. las matematicas experimentales siguen ganando representacion dentro de las matematicas. el calculo​ y simulacion​ estan jugando un papel cada vez mayor tanto en las ciencias como en las matematicas, atenuando la objecion de que las matematicas no se sirven del metodo cientifico. en 2002 stephen wolfram propuso, en su libro​ un nuevo tipo de ciencia, que la matematica computacional merece ser explorada empiricamente como un campo cientifico.  las opiniones de los matematicos sobre este asunto son muy variadas. muchos matematicos consideran que llamar a su campo ciencia es minimizar la importancia de su perfil estetico, ademas supone negar su historia dentro de las siete artes liberales. otros consideran que hacer caso omiso de su conexion con las ciencias supone ignorar la evidente conexion entre las matematicas y sus aplicaciones en la ciencia y la ingenieria, que ha impulsado considerablemente el desarrollo de las matematicas. otro asunto de debate, que guarda cierta relacion con el anterior, es si la matematica fue creada (como el arte) o descubierta (como la ciencia). este es uno de los muchos temas de incumbencia de la filosofia de las matematicas.  los premios matematicos se mantienen generalmente separados de sus equivalentes en la ciencia. el mas prestigioso premio dentro de las matematicas es la medalla fields,​ fue instaurado en 1936 y se concede cada cuatro años. a menudo se le considera el equivalente del premio nobel para la ciencia. otros premios son el premio wolf en matematica, creado en 1978, que reconoce los logros en vida de los matematicos, y el premio abel, otro gran premio internacional, que se introdujo en 2003. estos dos ultimos se conceden por un excelente trabajo, que puede ser una investigacion innovadora o la solucion de un problema pendiente en un campo determinado. una famosa lista de esos 23 problemas sin resolver​, denominada los «problemas de hilbert», fue recopilada en 1900 por el matematico aleman david hilbert. esta lista ha alcanzado gran popularidad entre los matematicos y, al menos, nueve de los problemas ya han sido resueltos. una nueva lista de siete problemas fundamentales, titulada «problemas del milenio», se publico en 2000. la solucion de cada uno de los problemas sera recompensada con 1 millon de dolares. curiosamente, tan solo uno (la hipotesis de riemann) aparece en ambas listas.  la sociedad matematica americana distingue unas 5.000 ramas distintas de matematica.​ en una subdivision escolarizada de la matematica se distinguen cinco areas de estudio basicas: la cantidad, la estructura, el espacio, el cambio y la variabilidad que se corresponden con la aritmetica, el algebra, la geometria, el calculo, la probabilidad y estadistica. como señalaba richard courant​ «es posible seguir una ruta directa a partir de los elementos fundamentales hasta puntos avanzados» para que puedan divisarse las directrices de la matematica como ciencia. ademas, hay ramas de las matematicas conectadas a otros campos, por ejemplo la logica, teoria de conjuntos y las matematicas aplicadas entre muchas otras tal como indica la sociedad matematica americana.​  2ei4π⁄3  el concepto «matematica aplicada» se refiere a aquellos metodos y herramientas matematicas que pueden ser utilizados en el analisis o resolucion de problemas pertenecientes al area de las ciencias basicas o aplicadas.  muchos metodos matematicos han resultado efectivos en el estudio de problemas en fisica, quimica, biologia,​ medicina,​ ciencias sociales,​ ingenieria, economia,​ finanzas, ecologia entre otras.  sin embargo, una posible diferencia es que en matematica aplicada se procura el desarrollo de la matematica «hacia afuera», es decir su aplicacion o transferencia hacia el resto de las areas. y en menor grado «hacia dentro» o sea, hacia el desarrollo de la matematica misma. este ultimo seria el caso de la matematica pura o matematica elemental.  la matematica aplicada se usa con frecuencia en distintas areas tecnologicas para modelado,​​ simulacion​ y optimizacion de procesos o fenomenos,​ como el tunel de viento o el diseño de experimentos.  la estadistica es la rama de la matematica que estudia la variabilidad, asi como el proceso aleatorio que la genera siguiendo leyes de probabilidad.​ es un conocimiento fundamental para la investigacion cientifica en algunos campos de la tecnologia, como informatica e ingenieria, y de las ciencias facticas,​ como economia,​ genetica, sociologia,​ psicologia,​ medicina,​ contabilidad, etc. en ocasiones, estas areas de conocimiento necesitan aplicar tecnicas estadisticas durante su proceso de investigacion factual, con el fin de obtener nuevos conocimientos basados en la experimentacion y en la observacion, precisando para ello recolectar, organizar, presentar y analizar un conjunto de datos numericos y, a partir de ellos y de un marco teorico, hacer las inferencias apropiadas.​​​​​  se consagra en forma directa al gran problema universal de como tomar decisiones inteligentes y acertadas en condiciones de incertidumbre. la estadistica descriptiva sirve como fuente de instruccion en los niveles basicos de estadistica aplicada a las ciencias facticas​ y, por tanto, los conceptos manejados y las tecnicas empleadas suelen ser presentadas de la forma mas simple y clara posibles. ",
        "snippet": "Las matemáticas [2]​[3]​[4]​ (del latín mathematĭca, y este del griego μαθηματικά, transliterado como mathēmatiká, derivado de μάθημα, tr. máthēma (conocimiento) son una ciencia formal que surgió del estudio de las figuras geométricas y la aritmética con números. Hoy en día se suele aceptar que la matemática es una ciencia que investiga patrones.[5]​[6]​[7]​[8]​[9]​",
        "enlaces_salientes": [
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Papiro_de_Ahmes",
            "/wiki/Ahmes_(escriba)",
            "/wiki/Gregor_Reisch",
            "/wiki/Algorista",
            "/wiki/Euclides",
            "/wiki/Comp%C3%A1s_(instrumento)",
            "/wiki/Rafael_Sanzio",
            "/wiki/La_escuela_de_Atenas",
            "/wiki/Lat%C3%ADn",
            "/wiki/Griego_antiguo",
            "/wiki/Romanizaci%C3%B3n_del_griego",
            "/wiki/Conocimiento",
            "/wiki/Ciencias_formales",
            "/wiki/Figura_geom%C3%A9trica",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Ciencias_naturales",
            "/wiki/Eugene_Paul_Wigner",
            "/wiki/Galileo_Galilei",
            "/wiki/L%C3%B3gica",
            "/wiki/Razonamiento",
            "/wiki/C%C3%A1lculo",
            "/wiki/Medici%C3%B3n",
            "/wiki/Forma_(figura)",
            "/wiki/Movimiento_(f%C3%ADsica)",
            "/wiki/Matem%C3%A1tica_hel%C3%A9nica",
            "/wiki/Elementos_de_Euclides",
            "/wiki/Euclides",
            "/wiki/Renacimiento",
            "/wiki/Ciencias_naturales",
            "/wiki/Ciencias_aplicadas",
            "/wiki/Humanidades",
            "/wiki/Medicina",
            "/wiki/Ciencias_sociales",
            "/wiki/M%C3%BAsica",
            "/wiki/Cuerda_vibrante",
            "/wiki/Matem%C3%A1tica_aplicada",
            "/wiki/Historia_de_las_matem%C3%A1ticas",
            "/wiki/Antig%C3%BCedad",
            "/wiki/Mesopotamia",
            "/wiki/India",
            "/wiki/Historia_de_China",
            "/wiki/Helenismo",
            "/wiki/Axiomatizaci%C3%B3n",
            "/wiki/Geometr%C3%ADa_euclidiana",
            "/wiki/Edad_Media",
            "/wiki/Era_moderna",
            "/wiki/Fran%C3%A7ois_Vi%C3%A8te",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Coordenadas",
            "/wiki/C%C3%A1lculo_infinitesimal#Modernidad",
            "/wiki/Cuadratura_(geometr%C3%ADa)",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Isaac_Newton",
            "/wiki/Mec%C3%A1nica_cl%C3%A1sica",
            "/wiki/Ley_de_gravitaci%C3%B3n_universal",
            "/wiki/Problema_de_los_tres_cuerpos",
            "/wiki/Niels_Henrik_Abel",
            "/wiki/%C3%89variste_Galois",
            "/wiki/Grupo_(matem%C3%A1tica)",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa_algebraica",
            "/wiki/Blaise_Pascal",
            "/wiki/Pierre_de_Fermat",
            "/wiki/Pierre-Simon_Laplace",
            "/wiki/Andr%C3%A9i_Kolmog%C3%B3rov",
            "/wiki/Rigor_matem%C3%A1tico",
            "/wiki/Augustin_Louis_Cauchy",
            "/wiki/Karl_Weierstra%C3%9F",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Georg_Cantor",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/David_Hilbert",
            "/wiki/Emmy_Noether",
            "/wiki/Felix_Hausdorff",
            "/wiki/Topolog%C3%ADa",
            "/wiki/Espacios_topol%C3%B3gicos",
            "/wiki/Stefan_Banach",
            "/wiki/An%C3%A1lisis_funcional",
            "/wiki/Espacio_de_Banach",
            "/wiki/Teor%C3%ADa_de_categor%C3%ADas",
            "/wiki/Samuel_Eilenberg",
            "/wiki/Saunders_Mac_Lane",
            "/wiki/Astronom%C3%ADa",
            "/wiki/Musa",
            "/wiki/Ret%C3%B3rica",
            "/wiki/Pitag%C3%B3ricos",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Marco_Tulio_Cicer%C3%B3n",
            "/wiki/Nicolas_Bourbaki",
            "/wiki/Elementos_de_matem%C3%A1tica",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Mathesis_Universalis",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/David_Hilbert",
            "/wiki/Finitismo",
            "/wiki/Benjamin_Peirce",
            "/wiki/Bertrand_Russell",
            "/wiki/John_David_Barrow",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/Espacio_m%C3%A9trico",
            "/wiki/C%C3%A1lculo",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Conjetura",
            "/wiki/Verdad",
            "/wiki/Razonamiento_deductivo",
            "/wiki/Rigor",
            "/wiki/Axioma",
            "/wiki/Definici%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Definici%C3%B3n",
            "/wiki/Punto_(geometr%C3%ADa)",
            "/wiki/Benjamin_Peirce",
            "/wiki/Albert_Einstein",
            "/wiki/F%C3%ADsica",
            "/wiki/Qu%C3%ADmica",
            "/wiki/Biolog%C3%ADa",
            "/wiki/Tautolog%C3%ADa",
            "/wiki/A_priori_y_a_posteriori",
            "/wiki/Geolog%C3%ADa",
            "/wiki/Fisiolog%C3%ADa",
            "/wiki/John_Stuart_Mill",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Teorema",
            "/wiki/Teorema_de_Pit%C3%A1goras",
            "/wiki/Ciencias",
            "/wiki/Naturaleza",
            "/wiki/Teorema_de_Pit%C3%A1goras",
            "/wiki/%C3%81baco",
            "/wiki/Calculadora",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Suma",
            "/wiki/Resta",
            "/wiki/Multiplicaci%C3%B3n",
            "/wiki/Galileo_Galilei",
            "/wiki/Isaac_Newton",
            "/wiki/Gottfried_Leibniz",
            "/wiki/C%C3%A1lculo",
            "/wiki/Contabilidad",
            "/wiki/Comercio",
            "/wiki/Agrimensura",
            "/wiki/Astronom%C3%ADa",
            "/wiki/F%C3%ADsico",
            "/wiki/Richard_Feynman",
            "/wiki/Integral_de_caminos_(mec%C3%A1nica_cu%C3%A1ntica)",
            "/wiki/Mec%C3%A1nica_cu%C3%A1ntica",
            "/wiki/Teor%C3%ADa_de_cuerdas",
            "/wiki/Interacciones_fundamentales",
            "/wiki/Eugene_Paul_Wigner",
            "/wiki/Ciencias_Naturales",
            "/wiki/Matem%C3%A1ticas_puras",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Licenciatura",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Investigaci%C3%B3n_de_operaciones",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Est%C3%A9tica",
            "/wiki/Belleza",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/N%C3%BAmero_primo",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Transformada_r%C3%A1pida_de_Fourier",
            "/wiki/Godfrey_Harold_Hardy",
            "/wiki/Apolog%C3%ADa_de_un_matem%C3%A1tico",
            "/wiki/Paul_Erd%C5%91s",
            "/wiki/Matem%C3%A1tica_recreativa",
            "/wiki/Notaci%C3%B3n_matem%C3%A1tica",
            "/wiki/Leonhard_Euler",
            "/wiki/Siglo_XVIII",
            "/wiki/Leonhard_Euler",
            "/wiki/Notaci%C3%B3n_musical",
            "/wiki/Infinito",
            "/wiki/Lenguaje",
            "/wiki/Conjunto_abierto",
            "/wiki/Cuerpo_(matem%C3%A1ticas)",
            "/wiki/Jerga",
            "/wiki/Homeomorfismo",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Rigor",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Teorema",
            "/wiki/Isaac_Newton",
            "/wiki/Siglo_XIX",
            "/wiki/Axioma",
            "/wiki/Sistema_axiom%C3%A1tico",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/Carl_Friedrich_Gauss",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/Ciencia",
            "/wiki/F%C3%ADsico",
            "/wiki/Matem%C3%A1ticas_puras",
            "/wiki/Falsacionismo",
            "/wiki/Karl_Popper",
            "/wiki/A%C3%B1os_1930",
            "/wiki/F%C3%ADsica",
            "/wiki/Biolog%C3%ADa",
            "/wiki/M%C3%A9todo_hipot%C3%A9tico-deductivo",
            "/wiki/Hip%C3%B3tesis_(l%C3%B3gica)",
            "/wiki/Imre_Lakatos",
            "/wiki/Falsacionismo",
            "/wiki/F%C3%ADsica_te%C3%B3rica",
            "/wiki/Axiomas",
            "/wiki/John_Michael_Ziman",
            "/wiki/Ciencias_f%C3%ADsicas",
            "/wiki/Intuici%C3%B3n",
            "/wiki/Experimentaci%C3%B3n",
            "/wiki/Conjeturas",
            "/wiki/C%C3%A1lculo",
            "/wiki/M%C3%A9todo_cient%C3%ADfico",
            "/wiki/Stephen_Wolfram",
            "/wiki/Un_nuevo_tipo_de_ciencia",
            "/wiki/Matem%C3%A1tica_computacional",
            "/wiki/Est%C3%A9tico",
            "/wiki/Artes_liberales",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Debate",
            "/wiki/Filosof%C3%ADa_de_la_matem%C3%A1tica",
            "/wiki/Medalla_Fields",
            "/wiki/Premio_Nobel",
            "/wiki/Premio_Abel",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/David_Hilbert",
            "/wiki/Problemas_del_milenio",
            "/wiki/Hip%C3%B3tesis_de_Riemann",
            "/wiki/%C3%81reas_de_las_matem%C3%A1ticas",
            "/wiki/Sociedad_Matem%C3%A1tica_Americana",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/C%C3%A1lculo",
            "/wiki/Probabilidad",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Richard_Courant",
            "/wiki/L%C3%B3gica",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Matem%C3%A1ticas_puras",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/N%C3%BAmero_entero",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/N%C3%BAmero_real",
            "/wiki/N%C3%BAmero_complejo",
            "/wiki/Combinatoria",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Teor%C3%ADa_de_grupos",
            "/wiki/Teor%C3%ADa_de_grafos",
            "/wiki/Teor%C3%ADa_del_orden",
            "/wiki/%C3%81lgebra",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Trigonometr%C3%ADa",
            "/wiki/Geometr%C3%ADa_diferencial",
            "/wiki/Topolog%C3%ADa",
            "/wiki/Fractal",
            "/wiki/Teor%C3%ADa_de_la_medida",
            "/wiki/C%C3%A1lculo",
            "/wiki/C%C3%A1lculo_vectorial",
            "/wiki/Ecuaci%C3%B3n_diferencial",
            "/wiki/Sistema_din%C3%A1mico",
            "/wiki/Teor%C3%ADa_del_caos",
            "/wiki/An%C3%A1lisis_complejo",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Ciencias_f%C3%A1cticas",
            "/wiki/F%C3%ADsica_matem%C3%A1tica",
            "/wiki/Mec%C3%A1nica_de_fluidos",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Optimizaci%C3%B3n_(matem%C3%A1tica)",
            "/wiki/Teor%C3%ADa_de_la_probabilidad",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Matem%C3%A1tica_financiera",
            "/wiki/Teor%C3%ADa_de_juegos",
            "/wiki/Biolog%C3%ADa_matem%C3%A1tica",
            "/wiki/Qu%C3%ADmica_matem%C3%A1tica",
            "/wiki/Econom%C3%ADa_matem%C3%A1tica",
            "/wiki/Teor%C3%ADa_de_control",
            "/wiki/Belleza_matem%C3%A1tica",
            "/wiki/Filosof%C3%ADa_de_las_matem%C3%A1ticas",
            "/wiki/Fundamentos_de_las_matem%C3%A1ticas",
            "/wiki/Matem%C3%A1ticas_y_arquitectura",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Olimpiada_Internacional_de_Matem%C3%A1tica",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Euclides",
            "/wiki/Keith_Devlin",
            "/wiki/ISBN",
            "/wiki/Mate_(infusi%C3%B3n)",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Demostraci%C3%B3n_inv%C3%A1lida",
            "/wiki/Teorema_de_los_cuatro_colores",
            "/wiki/ISBN",
            "/wiki/Constante_macabra",
            "/wiki/Funci%C3%B3n_gaussiana",
            "/wiki/Eric_Temple_Bell",
            "/wiki/Albert_Einstein",
            "/wiki/Benjamin_Peirce",
            "/wiki/Karl_Popper",
            "/wiki/Wolfgang_Sartorius_von_Waltershausen",
            "/wiki/Wolfgang_Sartorius_von_Waltershausen",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Historical_Dictionary_of_Switzerland",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Medical_Subject_Headings"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Programaci%C3%B3n",
        "titulo": "Programación",
        "contenido": "la programacion es el proceso de crear un conjunto de instrucciones que le dicen a una computadora como realizar algun tipo de tarea. pero no solo la accion de escribir un codigo para que la computadora o el software lo ejecute. incluye, ademas, todas las tareas necesarias para que el codigo funcione correctamente y cumpla el objetivo para el cual se escribio.​  en la actualidad, la nocion de programacion se encuentra muy asociada a la creacion de aplicaciones de informatica y videojuegos. en este sentido, es el proceso por el cual una persona desarrolla un programa, valiendose de una herramienta que le permita escribir el codigo (el cual puede estar en uno o varios lenguajes, como c++, java y python, entre muchos otros) y de otra que sea capaz de “traducirlo” a lo que se conoce como lenguaje de maquina, que puede \"comprender\" el microprocesador.​  para crear un programa y que la computadora lo interprete y ejecute, las instrucciones deben escribirse en un lenguaje de programacion.  el lenguaje entendido por una computadora se conoce como codigo maquina. consiste en secuencias de instrucciones basicas que el procesador reconoce, codificadas como cadenas de numeros 1 y 0 (sistema binario). en los primeros tiempos de la computacion se programaba directamente en codigo maquina. escribir programas asi resultaba demasiado complicado, tambien era dificil entenderlos y mantenerlos una vez escritos. con el tiempo, se fueron desarrollando herramientas para facilitar el trabajo.  los primeros cientificos que trabajaron en el area decidieron reemplazar las secuencias de unos y ceros por mnemonicos, que son abreviaturas en ingles de la funcion que cumple una instruccion de procesador. por ejemplo, para sumar se podria usar la letra a de la palabra inglesa add (añadir). crearon asi una familia de lenguajes de mayor nivel, que se conocen como lenguaje ensamblador o simplemente ensamblador (en ingles, assembly). con el tiempo los ensambladores incorporaron facilidades adicionales, pero siempre manteniendo una correspondencia directa con las instrucciones de procesador. a nivel conceptual, entonces, programar en ensamblador es muy similar a hacerlo en lenguaje maquina, solo que de una forma mas amigable.  a medida que la complejidad de las tareas que realizaban las computadoras aumentaba, el lenguaje ensamblador fue mostrando limitaciones. para hacer un programa habia que conocer en detalle el funcionamiento de la computadora donde se iba a ejecutar, que instrucciones proveia y como emplearlas. a veces las instrucciones eran demasiado basicas, por ejemplo podia haber una para sumar dos numeros pero no para multiplicar, y entonces era necesario programar un algoritmo que realizara la multiplicacion con base en instrucciones mas basicas. otras veces, la forma de emplear las instrucciones era engorrosa. ademas, si se usaba otro modelo de computadora, en muchos casos habia que reescribir el programa con otras instrucciones. el siguiente paso fue crear los lenguajes de alto nivel.  una vez que se termina de escribir un programa, es necesario de alguna forma traducirlo a lenguaje maquina, que es lo unico que entiende el procesador. esta tarea es automatica, por medio de un programa adicional que toma el codigo escrito y lo procesa. hay distintos enfoques para este procesamiento. el enfoque clasico se llama compilacion: el programa toma el codigo en un lenguaje y genera codigo en el otro; al programa traductor se lo llama compilador. en general se habla de compilacion y compiladores cuando el lenguaje de origen es de alto nivel; si la traduccion es desde lenguaje ensamblador, se llama ensamblado y el programa se llama ensamblador (hay que distinguir el lenguaje ensamblador del programa ensamblador; en ingles es mas claro, son assembly language y assembler respectivamente).​ generalmente existe una fase posterior a la compilacion denominada enlace o enlazado (linking en ingles). los programas pueden escribirse en partes separadas y ademas pueden usar recursos provistos por bibliotecas. el enlazado, realizado por un programa llamado enlazador, combina todos los componentes y asi genera un programa ejecutable completo.  en algunos lenguajes de programacion, puede usarse un enfoque diferente que no requiera compilacion y enlace: un programa llamado interprete va leyendo el codigo y realizando en el momento las acciones que haria el programa. se evita generar codigo separado y la experiencia es que se esta ejecutando el codigo en el lenguaje de alto nivel, a pesar de que el procesador no lo entienda de forma nativa.  la programacion se rige por reglas y un conjunto mas o menos reducido de ordenes, expresiones, instrucciones y comandos que tienden a asemejarse a una lengua natural acotada (en ingles); y que ademas tienen la particularidad de una reducida ambiguedad.  en los lenguajes de programacion se distinguen diversos elementos entre los que se incluyen el lexico propio del lenguaje y las reglas semanticas y sintacticas. dentro del lexico, generalmente se utilizan simbolos y palabras con funciones especificas dentro del lenguaje. estas palabras suelen tomarse del ingles y no se las puede utilizar de manera diferente: son las denominadas palabras reservadas. otra particularidad de los lenguajes es el permitir a los programadores el uso de comentarios: frases o parrafos sin funcionalidad en el programa, que los compiladores o interpretes descartan y solo estan destinados a ser leidos por personas; asi se pueden dejar explicaciones que ayuden a entender el codigo a quien lo lea.​  un algoritmo es una secuencia no ambigua, finita y ordenada de instrucciones que han de seguirse para resolver un determinado problema.​ un programa normalmente implementa y contiene uno o mas algoritmos. un algoritmo puede expresarse de distintas maneras: en forma grafica, como un diagrama de flujo, en forma de codigo como en pseudocodigo o un lenguaje de programacion, en forma explicativa.  los programas suelen subdividirse en partes menores, llamadas modulos, de modo que la complejidad algoritmica de cada una de las partes sea menor que la del programa completo, lo cual ayuda a simplificar el desarrollo del programa. esta es una practica muy utilizada y se conoce como \"refino progresivo\".  segun niklaus wirth, un programa esta formado por los algoritmos y estructuras de datos.  la programacion puede seguir muchos enfoques, o paradigmas, es decir, diversas maneras de formular la resolucion de un problema dado. algunos de los principales paradigmas de programacion son:  el programa escrito en un lenguaje de programacion de alto nivel (facilmente comprensible por el programador) es llamado programa fuente y no se puede ejecutar directamente en una computadora. la opcion mas comun es compilar el programa obteniendo un modulo objeto, aunque tambien, si el lenguaje lo soporta, puede ejecutarse en forma directa pero solo a traves de un interprete. algunos lenguajes, tal como basic, disponen de ambas formas de ejecucion, lo cual facilita la tarea de depuracion y prueba del programa.  el codigo fuente del programa se debe someter a un proceso de traduccion para convertirlo a lenguaje maquina o bien a un codigo intermedio, generando asi un modulo denominado \"objeto\". a este proceso se le llama compilacion.  habitualmente la creacion de un programa ejecutable (un tipico .exe para microsoft windows o dos) conlleva dos pasos: el primer paso se llama compilacion (propiamente dicho) y traduce el codigo fuente, escrito en un lenguaje de programacion y almacenado en un archivo de texto, a codigo en bajo nivel (normalmente a codigo objeto, no directamente a lenguaje maquina). el segundo paso se llama enlazado en el cual se enlaza el codigo de bajo nivel generado de todos los ficheros y subprogramas que se han mandado a compilar y se añade el codigo de las funciones necesarias que residen en bibliotecas externas, para que el ejecutable pueda comunicarse directamente con el sistema operativo, traduciendo asi finalmente el codigo objeto a codigo maquina, y generando un modulo ejecutable.  estos dos pasos se pueden hacer por separado, almacenando el resultado de la fase de compilacion en archivos objetos (un tipico .o para unix, .obj para ms-windows y dos); para enlazarlos en fases posteriores, o crear directamente el ejecutable; con lo que la fase de compilacion puede almacenarse de forma temporal. un programa podria tener partes escritas en varios lenguajes, por ejemplo, java, c, c++ y ensamblador, que se podrian compilar de forma independiente y luego combinarse para formar un unico modulo ejecutable.  existe una tendencia a identificar el proceso de creacion de un programa informatico con la programacion, que es cierta cuando se trata de programas pequeños para uso personal, y que dista de la realidad cuando se trata de grandes proyectos.  el proceso de creacion de software, desde el punto de vista de la ingenieria, incluye minimamente los siguientes pasos:  la ingenieria del software se centra en los pasos de planificacion y diseño del programa, mientras que antiguamente (programacion artesanal) la realizacion de un programa consistia casi unicamente en escribir el codigo, bajo solo el conocimiento de los requisitos y con una modesta fase de analisis y diseño.  el trabajo de ada lovelace, hija de anabella milbanke byron y lord byron, que realizo para la maquina de babbage le hizo ganarse el titulo de primera programadora de computadoras del mundo, aunque babbage nunca completo la construccion de la maquina. el nombre del lenguaje de programacion ada fue escogido como homenaje a esta programadora.  la programacion debe perseguir la obtencion de programas de calidad. para ello se establece una serie de factores que determinan la calidad de un programa. algunos de los factores de calidad mas importantes son los siguientes:  el termino ciclo de vida del software describe el desarrollo de software, desde la fase inicial hasta la fase final, incluyendo su estado funcional. el proposito es definir las distintas fases intermedias que se requieren para validar el desarrollo de la aplicacion, es decir, para garantizar que el software cumpla los requisitos para la aplicacion y verificacion de los procedimientos de desarrollo: se asegura que los metodos utilizados son apropiados. estos metodos se originan en el hecho de que es muy costoso corregir los errores que se detectan tarde dentro de la fase de implementacion (programacion propiamente dicha), o peor aun, durante la fase funcional. en el modelo de ciclo de vida se intenta que los errores se detecten lo antes posible y por lo tanto, permite a los desarrolladores concentrarse en la calidad del software, en los plazos de implementacion y en los costos asociados. el ciclo de vida basico de un software consta de, al menos, los siguientes procedimientos:  el orden y la presencia de cada uno de estos procedimientos dependen del tipo de modelo de ciclo de vida acordado entre el cliente y el equipo de desarrolladores. en el caso del software libre se tiene un ciclo de vida mucho mas dinamico, puesto que muchos programadores trabajan en simultaneo desarrollando sus eliminaciones. ",
        "snippet": "La programación es el proceso de crear un conjunto de instrucciones que le dicen a una computadora como realizar algún tipo de tarea. Pero no solo la acción de escribir un código para que la computadora o el software lo ejecute. Incluye, además, todas las tareas necesarias para que el código funcione correctamente y cumpla el objetivo para el cual se escribió.[1]​",
        "enlaces_salientes": [
            "/wiki/Programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n_(desambiguaci%C3%B3n)",
            "/wiki/Conjunto_de_instrucciones",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Software",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Videojuegos",
            "/wiki/C%2B%2B",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Python",
            "/wiki/Lenguaje_de_m%C3%A1quina",
            "/wiki/Microprocesador",
            "/wiki/Programa_inform%C3%A1tico",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/C%C3%B3digo_m%C3%A1quina",
            "/wiki/Sistema_binario",
            "/wiki/Mnem%C3%B3nico",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Lenguaje_de_alto_nivel",
            "/wiki/Compilador",
            "/wiki/Enlazador",
            "/wiki/Biblioteca_(inform%C3%A1tica)",
            "/wiki/Int%C3%A9rprete_(inform%C3%A1tica)",
            "/wiki/Lengua_natural",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Palabra_reservada",
            "/wiki/Algoritmo",
            "/wiki/Ambig%C3%BCedad",
            "/wiki/Diagrama_de_flujo",
            "/wiki/Pseudoc%C3%B3digo",
            "/wiki/Niklaus_Wirth",
            "/wiki/Algoritmo",
            "/wiki/Estructuras_de_datos",
            "/wiki/Paradigma_de_programaci%C3%B3n",
            "/wiki/Programacion_declarativa",
            "/wiki/Programaci%C3%B3n_imperativa",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/Programaci%C3%B3n_modular",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Programaci%C3%B3n_dirigida_por_eventos",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Programador",
            "/wiki/Compilador",
            "/wiki/Int%C3%A9rprete_inform%C3%A1tico",
            "/wiki/BASIC",
            "/wiki/Programa_(computaci%C3%B3n)",
            "/wiki/Proceso_de_traducci%C3%B3n_de_programas",
            "/wiki/Compilaci%C3%B3n",
            "/wiki/Ejecutable",
            "/wiki/Microsoft_Windows",
            "/wiki/DOS",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Enlazador",
            "/wiki/C%C3%B3digo_objeto",
            "/wiki/C%C3%B3digo_m%C3%A1quina",
            "/wiki/Unix",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%2B%2B",
            "/wiki/Lenguaje_ensamblador",
            "/wiki/Ejecutable",
            "/wiki/Ingenier%C3%ADa_del_software",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Requisito_(sistemas)",
            "/wiki/Ada_Lovelace",
            "/wiki/Lord_Byron",
            "/wiki/Charles_Babbage",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Ada",
            "/wiki/Correctitud",
            "/wiki/Programador",
            "/wiki/Arte_ASCII",
            "/wiki/C%C3%B3digo_ofuscado",
            "/wiki/Eficiencia",
            "/wiki/Portabilidad",
            "/wiki/Hardware",
            "/wiki/Software",
            "/wiki/GNU/Linux",
            "/wiki/Windows",
            "/wiki/Proceso_para_el_desarrollo_de_software",
            "/wiki/Proceso_para_el_desarrollo_de_software",
            "/wiki/Software_libre",
            "/wiki/Error_de_software",
            "/wiki/Filosof%C3%ADas_del_desarrollo_de_software",
            "/wiki/Historia_de_la_ingenier%C3%ADa_del_software",
            "/wiki/Ingenier%C3%ADa_en_computaci%C3%B3n",
            "/wiki/Ingenier%C3%ADa_inform%C3%A1tica",
            "/wiki/L%C3%ADnea_de_c%C3%B3digo_fuente",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n_autom%C3%A1tica",
            "/wiki/Programaci%C3%B3n_dirigida_por_eventos",
            "/wiki/Programaci%C3%B3n_estructurada",
            "/wiki/Programaci%C3%B3n_extrema",
            "/wiki/Programaci%C3%B3n_en_pareja",
            "/wiki/Programaci%C3%B3n_din%C3%A1mica",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Pruebas_de_software",
            "/wiki/Software",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Wikcionario",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Thomas_H._Cormen",
        "titulo": "Thomas H. Cormen",
        "contenido": "thomas h. cormen es catedratico de informatica en la universidad dartmouth. nacio en estados unidos. su mayor contribucion hasta la fecha ha sido la copublicacion junto con charles leiserson, ron rivest y clifford stein del libro introduccion a los algoritmos.  en 1978 se graduo summa cum laude en la universidad de princeton. en 1986 se licencio en el mit, y en 1992 se doctoro en el mismo lugar. sus investigaciones se centran en algoritmia, computacion paralela y computacion fuera de nucleo (ingles: out-of-core).  su mayor aficion son las barbacoas. ",
        "snippet": "Thomas H. Cormen es catedrático de informática en la universidad Dartmouth. Nació en Estados Unidos. Su mayor contribución hasta la fecha ha sido la copublicación junto con Charles Leiserson, Ron Rivest y Clifford Stein del libro Introducción a los algoritmos.",
        "enlaces_salientes": [
            "/wiki/Thomas_H._Cormen",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Catedr%C3%A1tico_de_Universidad",
            "/wiki/Estados_Unidos",
            "/wiki/Ron_Rivest",
            "/wiki/Clifford_Stein",
            "/wiki/Introducci%C3%B3n_a_los_algoritmos",
            "/wiki/Summa_cum_laude",
            "/wiki/Universidad_de_Princeton",
            "/wiki/MIT",
            "/wiki/Algoritmia",
            "/wiki/Computaci%C3%B3n_paralela",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Ronald_L._Rivest",
            "/wiki/Introducci%C3%B3n_a_los_algoritmos",
            "/wiki/MIT_Press",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Ronald_L._Rivest",
            "/wiki/Clifford_Stein",
            "/wiki/Introducci%C3%B3n_a_los_algoritmos",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Open_Library"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/MIT_Press",
        "titulo": "MIT Press",
        "contenido": "mit press es una editorial universitaria afiliada a instituto tecnologico de massachusetts (mit). la editorial se centra en libros y revistas de ciencia y tecnologia.  mit press se creo en 1932 como technology press. se convirtio en una editorial independiente y tomo el nombre actual en 1962. ha publicado mas de 7000 libros a lo largo de su historia, y publica cerca de 200 libros y 40 revistas cada año. a traves de su pagina web venden libros a todo el mundo.​  en 1926 max born visito el mit para realizar una serie de lecturas de problemas de la dinamica atomica. el instituto publico las lecturas imprimiendolo el mismo. ese libro es el numero 1 en los archivos de mit press.  en 1932, james r. killian jr. ayudo a crear technology press que publicaria ocho titulos en los siguientes cinco años.  en 1937, john wiley & sons se hicieron cargo de la editorial y el marketing de la imprenta, durante los 25 siguientes años publico 125 titulos.  en 1962, mit se separo amigablemente de wiley y mejoro su imprenta creando la editorial independiente mit press. en la actualidad (2004) wiley es la encargada de distribuir los libros de mit press en europa.  en 1968 se añadio una division de revistas periodicas.  en 1969 se abrio una oficina de marketing en europa.  en julio del año 2003 mit press alcanzo los 7000 libros publicados. ",
        "snippet": "MIT Press es una editorial universitaria afiliada a Instituto Tecnológico de Massachusetts (MIT). La editorial se centra en libros y revistas de ciencia y tecnología.",
        "enlaces_salientes": [
            "/wiki/MIT_Press",
            "/wiki/MIT_Press",
            "/wiki/MIT_Press",
            "/wiki/Coordenadas_geogr%C3%A1ficas",
            "/wiki/Tipos_de_entidad_empresarial",
            "/wiki/Editorial_(empresa)",
            "/wiki/Industria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/James_Rhyne_Killian",
            "/wiki/Sede_central",
            "/wiki/Estados_Unidos",
            "/wiki/Cambridge_(Massachusetts)",
            "/wiki/Afiliado",
            "/wiki/Asociaci%C3%B3n_de_Imprentas_Universitarias_Americanas",
            "/wiki/Coordenadas_geogr%C3%A1ficas",
            "/wiki/Sitio_web",
            "/wiki/Lema",
            "/wiki/Editorial_(empresa)",
            "/wiki/Instituto_Tecnol%C3%B3gico_de_Massachusetts",
            "/wiki/1932",
            "/wiki/1962",
            "/wiki/1926",
            "/wiki/Max_Born",
            "/wiki/1932",
            "/wiki/1937",
            "/wiki/John_Wiley_%26_Sons",
            "/wiki/1962",
            "/wiki/1968",
            "/wiki/1969",
            "/wiki/2003",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/BIBSYS"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISSN",
        "titulo": "International Standard Serial Number",
        "contenido": "el  issn (international standard serial number, numero internacional normalizado de publicaciones seriadas)​ es un codigo de 8 digitos internacional que sirve para identificar publicaciones periodicas y recursos continuos de toda clase y editada en cualquier soporte, ya sean impresos en papel o en formato digital, evitando el trabajo y posibles errores de transcribir el titulo o la informacion bibliografica pertinente. se reserva a las publicaciones en serie como los diarios y las publicaciones periodicas.​ el issn es especialmente util para distinguir entre publicaciones seriadas con el mismo titulo. los issn se utilizan para ordenar, catalogar, prestamos interbibliotecarios y otras practicas relacionadas con la literatura seriada.​ el sistema issn se redacto por primera vez como norma internacional de la organizacion internacional de normalizacion (iso) en 1971 y se publico como iso 3297 en 1975.​ el subcomite iso tc 46/sc 9 es responsable de mantener el estandar. el issn permite normalizar las clasificaciones, en las bibliotecas por ejemplo. en libros se usa el numero estandar internacional de libro (isbn, international standard book number).  el issn esta constituido por los caracteres \"issn\" seguidos de dos grupos de cuatro cifras separados por guiones. la ultima cifra, situada en octava posicion, sirve de clave de control; puede a veces tomar el valor \"x\", que representa el numero 10.  contrariamente al isbn, las cifras del issn no significan nada en si mismas. son asignadas secuencialmente, independientemente del pais de origen, de la lengua, etc. a cada issn corresponde un titulo-clave asi como una fecha de principio de publicacion. la fecha de final se fija normalmente en \"9999\". el titulo-clave esta formado por el nombre de la publicacion y, eventualmente, por un calificativo, frecuentemente el lugar de publicacion.  el issn identifica de manera inequivoca una publicacion seriada, y puede cumplir entre otras, las siguientes funciones:  se asigna una ponderacion a cada posicion (de 8 a 2 en sentido decreciente) y se hace la suma de los productos asi obtenidos. se conserva el resto de la division euclidea de este numero por 11. se resta este numero a 11: es la clave.  ejemplo: ¿para el numero issn (de 7 cifras) issn 0395-203, cual es la clave de control?  lo que hace un total de 0+21+54+25+8+0+6=114, cuyo resto de la division euclidea por 11 es 4 (114/11=10x11+4). la clave de control es pues 11-4=7. el issn completo es: issn 0395-2037.  el issn-l (del ingles linking issn) es un numero especifico unico de issn que agrupa las diferentes ediciones de una misma publicacion seriada, publicadas en varios medios o soportes, como en papel, en linea, cd, etc., cada una de las cuales tiene asignado su propio issn. el numero de issn-l es uno de los numeros ya existentes de issn asignado a la publicacion, coincidente con el de la version en papel si la hubiera.​ ",
        "snippet": "El ISSN (International Standard Serial Number, Número Internacional Normalizado de Publicaciones Seriadas)[1]​ es un código de 8 dígitos internacional que sirve para identificar publicaciones periódicas y recursos continuos de toda clase y editada en cualquier soporte, ya sean impresos en papel o en formato digital, evitando el trabajo y posibles errores de transcribir el título o la información bibliográfica pertinente. Se reserva a las publicaciones en serie como los diarios y las publicaciones periódicas.[2]​ El ISSN es especialmente útil para distinguir entre publicaciones seriadas con el mismo título. Los ISSN se utilizan para ordenar, catalogar, préstamos interbibliotecarios y otras prácticas relacionadas con la literatura seriada.[3]​ El sistema ISSN se redactó por primera vez como norma internacional de la Organización Internacional de Normalización (ISO) en 1971 y se publicó como ISO 3297 en 1975.[4]​ El subcomité ISO TC 46/SC 9 es responsable de mantener el estándar. El ISSN permite normalizar las clasificaciones, en las bibliotecas por ejemplo. En libros se usa el Número Estándar Internacional de Libro (ISBN, International Standard Book Number).",
        "enlaces_salientes": [
            "/wiki/International_Standard_Serial_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Prensa_escrita",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/ISBN",
            "/wiki/Discapacitado",
            "/wiki/Fonograma",
            "/wiki/Revista",
            "/wiki/Anuario",
            "/wiki/Pdf",
            "/wiki/Divisi%C3%B3n_eucl%C3%ADdea",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/ASIN",
            "/wiki/Amazon.com",
            "/wiki/Amazon.com",
            "/wiki/ISBN",
            "/wiki/International_Standard_Music_Number",
            "/wiki/ISAN",
            "/wiki/IBSN",
            "/wiki/Blog",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISSN",
        "titulo": "International Standard Serial Number",
        "contenido": "el  issn (international standard serial number, numero internacional normalizado de publicaciones seriadas)​ es un codigo de 8 digitos internacional que sirve para identificar publicaciones periodicas y recursos continuos de toda clase y editada en cualquier soporte, ya sean impresos en papel o en formato digital, evitando el trabajo y posibles errores de transcribir el titulo o la informacion bibliografica pertinente. se reserva a las publicaciones en serie como los diarios y las publicaciones periodicas.​ el issn es especialmente util para distinguir entre publicaciones seriadas con el mismo titulo. los issn se utilizan para ordenar, catalogar, prestamos interbibliotecarios y otras practicas relacionadas con la literatura seriada.​ el sistema issn se redacto por primera vez como norma internacional de la organizacion internacional de normalizacion (iso) en 1971 y se publico como iso 3297 en 1975.​ el subcomite iso tc 46/sc 9 es responsable de mantener el estandar. el issn permite normalizar las clasificaciones, en las bibliotecas por ejemplo. en libros se usa el numero estandar internacional de libro (isbn, international standard book number).  el issn esta constituido por los caracteres \"issn\" seguidos de dos grupos de cuatro cifras separados por guiones. la ultima cifra, situada en octava posicion, sirve de clave de control; puede a veces tomar el valor \"x\", que representa el numero 10.  contrariamente al isbn, las cifras del issn no significan nada en si mismas. son asignadas secuencialmente, independientemente del pais de origen, de la lengua, etc. a cada issn corresponde un titulo-clave asi como una fecha de principio de publicacion. la fecha de final se fija normalmente en \"9999\". el titulo-clave esta formado por el nombre de la publicacion y, eventualmente, por un calificativo, frecuentemente el lugar de publicacion.  el issn identifica de manera inequivoca una publicacion seriada, y puede cumplir entre otras, las siguientes funciones:  se asigna una ponderacion a cada posicion (de 8 a 2 en sentido decreciente) y se hace la suma de los productos asi obtenidos. se conserva el resto de la division euclidea de este numero por 11. se resta este numero a 11: es la clave.  ejemplo: ¿para el numero issn (de 7 cifras) issn 0395-203, cual es la clave de control?  lo que hace un total de 0+21+54+25+8+0+6=114, cuyo resto de la division euclidea por 11 es 4 (114/11=10x11+4). la clave de control es pues 11-4=7. el issn completo es: issn 0395-2037.  el issn-l (del ingles linking issn) es un numero especifico unico de issn que agrupa las diferentes ediciones de una misma publicacion seriada, publicadas en varios medios o soportes, como en papel, en linea, cd, etc., cada una de las cuales tiene asignado su propio issn. el numero de issn-l es uno de los numeros ya existentes de issn asignado a la publicacion, coincidente con el de la version en papel si la hubiera.​ ",
        "snippet": "El ISSN (International Standard Serial Number, Número Internacional Normalizado de Publicaciones Seriadas)[1]​ es un código de 8 dígitos internacional que sirve para identificar publicaciones periódicas y recursos continuos de toda clase y editada en cualquier soporte, ya sean impresos en papel o en formato digital, evitando el trabajo y posibles errores de transcribir el título o la información bibliográfica pertinente. Se reserva a las publicaciones en serie como los diarios y las publicaciones periódicas.[2]​ El ISSN es especialmente útil para distinguir entre publicaciones seriadas con el mismo título. Los ISSN se utilizan para ordenar, catalogar, préstamos interbibliotecarios y otras prácticas relacionadas con la literatura seriada.[3]​ El sistema ISSN se redactó por primera vez como norma internacional de la Organización Internacional de Normalización (ISO) en 1971 y se publicó como ISO 3297 en 1975.[4]​ El subcomité ISO TC 46/SC 9 es responsable de mantener el estándar. El ISSN permite normalizar las clasificaciones, en las bibliotecas por ejemplo. En libros se usa el Número Estándar Internacional de Libro (ISBN, International Standard Book Number).",
        "enlaces_salientes": [
            "/wiki/International_Standard_Serial_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Prensa_escrita",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/ISBN",
            "/wiki/Discapacitado",
            "/wiki/Fonograma",
            "/wiki/Revista",
            "/wiki/Anuario",
            "/wiki/Pdf",
            "/wiki/Divisi%C3%B3n_eucl%C3%ADdea",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/ASIN",
            "/wiki/Amazon.com",
            "/wiki/Amazon.com",
            "/wiki/ISBN",
            "/wiki/International_Standard_Music_Number",
            "/wiki/ISAN",
            "/wiki/IBSN",
            "/wiki/Blog",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Rivest,_R._L.",
        "titulo": "Ronald Rivest",
        "contenido": "ronald linn rivest (6 de mayo de 1947) es un criptografo y profesor en el mit.​ en dicha institucion es miembro del departamento de ingenieria electrica y ciencias de la computacion, y del laboratorio de ciencias de la computacion e inteligencia artificial.  rivest es uno de los inventores del algoritmo rsa junto con adi shamir y len adleman.​ es el inventor de los algoritmos de criptografia simetrica rc2, rc4, rc5, y co-inventor de rc6. tambien fue autor de las funciones hash criptograficas md2, md4, md5 y md6. en 2006, publico su invento threeballot, un sistema de voto que incorpora la habilidad para el votante de discernir que su voto fue contabilizado a la vez que se protege su privacidad.  rivest recibio su licenciatura en matematicas por la universidad de yale en 1969, y un doctorado en ciencias de la computacion por la universidad de stanford en 1974.​ rivest es el coautor de introduccion a los algoritmos, un libro de texto sobre algoritmos, junto a thomas h. cormen, charles e. leiserson y clifford stein. tambien fue fundador de rsa security, verisign y peppercoin. rivest ha investigado en los campos de la criptografia, seguridad en redes de la computacion y algoritmos.  rivest es miembro de academia nacional de ingenieria, la academia nacional de ciencias, y es un miembro de la association for computing machinery, la international association for cryptologic research, y la academia estadounidense de las artes y las ciencias. junto a adi shamir y len adleman, ha sido galardonado con el premio turing. rivest es doctor honoris causa por la universidad de roma la sapienza.​ en 2017, recibio el premio fundacion bbva fronteras del conocimiento, en la categoria de tecnologias de la informacion y la comunicacion.   ",
        "snippet": "Ronald Linn Rivest (6 de mayo de 1947) es un criptógrafo y profesor en el MIT.[1]​ En dicha institución es miembro del Departamento de Ingeniería Eléctrica y Ciencias de la Computación, y del Laboratorio de Ciencias de la Computación e Inteligencia Artificial.",
        "enlaces_salientes": [
            "/wiki/Ronald_Rivest",
            "/wiki/Ronald_Rivest",
            "/wiki/Ronald_Rivest",
            "/wiki/6_de_mayo",
            "/wiki/1947",
            "/wiki/Schenectady",
            "/wiki/Nueva_York",
            "/wiki/Estados_Unidos",
            "/wiki/Estados_Unidos",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Universidad_de_Yale",
            "/wiki/Robert_W._Floyd",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Criptograf%C3%ADa_asim%C3%A9trica",
            "/wiki/RSA",
            "/wiki/RC2",
            "/wiki/RC4",
            "/wiki/RC5",
            "/wiki/RC6",
            "/wiki/MD2",
            "/wiki/MD4",
            "/wiki/MD5",
            "/wiki/Firma_de_anillo",
            "/wiki/Instituto_Tecnol%C3%B3gico_de_Massachusetts",
            "/wiki/RSA",
            "/wiki/Introducci%C3%B3n_a_los_algoritmos",
            "/wiki/MD5",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Academia_Nacional_de_Ingenier%C3%ADa_(Estados_Unidos)",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Asociaci%C3%B3n_Estadounidense_para_el_Avance_de_la_Ciencia",
            "/wiki/Premio_Turing",
            "/wiki/Premio_Marconi",
            "/wiki/Premios_Fundaci%C3%B3n_BBVA_Fronteras_del_Conocimiento",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Massachusetts_Institute_of_Technology",
            "/wiki/MIT_Computer_Science_and_Artificial_Intelligence_Laboratory",
            "/wiki/RSA",
            "/wiki/Adi_Shamir",
            "/wiki/Len_Adleman",
            "/wiki/Criptograf%C3%ADa_sim%C3%A9trica",
            "/wiki/RC2",
            "/wiki/RC4",
            "/wiki/RC5",
            "/wiki/RC6",
            "/wiki/Funci%C3%B3n_hash_criptogr%C3%A1fica",
            "/wiki/MD2",
            "/wiki/MD4",
            "/wiki/MD5",
            "/wiki/Licenciatura",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Universidad_de_Yale",
            "/wiki/Philosophi%C3%A6_doctor",
            "/wiki/Ciencias_de_la_Computaci%C3%B3n",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/Algoritmos",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Clifford_Stein",
            "/wiki/RSA_Security",
            "/wiki/Verisign",
            "/wiki/Academia_Nacional_de_Ciencias_de_Estados_Unidos",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/American_Academy_of_Arts_and_Sciences",
            "/wiki/Adi_Shamir",
            "/wiki/Len_Adleman",
            "/wiki/Turing_Award",
            "/wiki/Universidad_de_Roma_La_Sapienza",
            "/wiki/Premios_Fundaci%C3%B3n_BBVA_Fronteras_del_Conocimiento",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Clifford_Stein",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/ISBN",
            "/wiki/Thomas_H._Cormen",
            "/wiki/Charles_E._Leiserson",
            "/wiki/Clifford_Stein",
            "/wiki/Introduction_to_Algorithms",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Ole-Johan_Dahl",
            "/wiki/Kristen_Nygaard",
            "/wiki/Premio_Turing",
            "/wiki/2002",
            "/wiki/Alan_Kay",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Open_Library",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Gilles_Brassard",
        "titulo": "Gilles Brassard",
        "contenido": "gilles brassard (montreal, 1955) es un ingeniero canadiense, catedratico de informatica cuantica.  estudio en la universidad de montreal (1975), y obtuvo su titulo en ciencias de la computacion por la universidad de cornell en 1979, trabajando en una agencia de cartografia junto a john hopcroft como su supervisor. ha sido un miembro de importantes facultades en la universidad de montreal hasta convertirse en profesor en 1988.  brassard es conocido por su trabajo fundamental en criptografia cuantica, teleportacion cuantica, entrelazamiento cuantico y la clasica simulacion del entrelazamiento cuantico. muchos de esos conceptos son todavia teoricos, pero otros han sido implementados en laboratorios.  en 1984, junto con charles h. bennett, invento el protocolo bb84 para criptografia cuantica. mas tarde el extendio su trabajo para corregir el dado en llamar error cascada, un error en dicho protocolo, que consiste en la eficiente deteccion y correccion de los ruidos causados por las deficiencias del mismo y sus signos.   ",
        "snippet": "Gilles Brassard (Montreal, 1955) es un ingeniero canadiense, catedrático de informática cuántica.",
        "enlaces_salientes": [
            "/wiki/Gilles_Brassard",
            "/wiki/Gilles_Brassard",
            "/wiki/Gilles_Brassard",
            "/wiki/Montreal",
            "/wiki/Canad%C3%A1",
            "/wiki/Universidad_de_Montreal",
            "/wiki/Universidad_Cornell",
            "/wiki/Escuela_de_Ingenier%C3%ADa_de_la_Universidad_Cornell",
            "/wiki/John_Hopcroft",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Ingeniero",
            "/wiki/Informaci%C3%B3n_y_comunicaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Criptograf%C3%ADa_cu%C3%A1ntica",
            "/wiki/Academia_Europ%C3%A6a",
            "/wiki/Royal_Society",
            "/wiki/Montreal",
            "/wiki/1955",
            "/wiki/Inform%C3%A1tica_cu%C3%A1ntica",
            "/wiki/Universidad_de_Montreal",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Universidad_de_Cornell",
            "/wiki/Cartograf%C3%ADa",
            "/wiki/John_Hopcroft",
            "/wiki/Criptograf%C3%ADa_cu%C3%A1ntica",
            "/wiki/Teleportaci%C3%B3n_cu%C3%A1ntica",
            "/wiki/Entrelazamiento_cu%C3%A1ntico",
            "/wiki/Charles_H._Bennett",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Scopus",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Royal_Society",
            "/wiki/Google_Acad%C3%A9mico"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Knuth,_D._E",
        "titulo": "Donald Knuth",
        "contenido": "donald ervin knuth (milwaukee, wisconsin; 10 de enero 1938) es un reconocido experto en ciencias de la computacion estadounidense y matematico, famoso por su fructifera investigacion dentro del analisis de algoritmos y compiladores.​  es profesor emerito de la universidad de stanford.​  knuth nacio en milwaukee, wisconsin, hijo de ervin henry knuth y louise marie bohning.​ describe su herencia como \"alemana luterana del medio oeste\".​: 66  su padre tenia una pequeña imprenta y enseñaba contabilidad.​ donald, estudiante del milwaukee lutheran high school, penso en formas ingeniosas de resolver problemas. por ejemplo, en octavo grado, participo en un concurso para encontrar el numero de palabras que las letras en \"ziegler's giant bar\"  (\"barra gigante de ziegler\") podian ser reordenadas; los jueces habian identificado 2.500 palabras de este tipo. con el tiempo ganado fuera de la escuela debido a un fingido dolor de estomago, y trabajando el problema en sentido contrario, knuth utilizo un diccionario no abreviado y determino si cada entrada del diccionario podia formarse utilizando las letras de la frase. usando este algoritmo, identifico mas de 4.500 palabras, ganando el concurso.​{rp|3} como premios, el colegio recibio un nuevo televisor y suficientes chocolatinas para que todos sus compañeros se las comieran.​  knuth recibio una beca en fisica en la case institute of technology (ahora parte de la case western reserve university) en cleveland, ohio, matriculandose en 1956.​ tambien se unio al capitulo beta nu de la fraternidad theta chi. mientras estudiaba fisica en case, knuth conocio el ibm 650, un primer ordenador comercial. despues de leer el manual del ordenador, knuth decidio reescribir el codigo ensamblador y compilador de la maquina utilizada en su escuela, porque creia que podia hacerlo mejor.​  en 1958, knuth creo un programa para ayudar al equipo de baloncesto de su colegio a ganar sus partidos.​ asigno \"valores\" a los jugadores para calibrar su probabilidad de obtener puntos, un enfoque novedoso del que posteriormente informaron newsweek y cbs evening news.​  knuth fue uno de los editores fundadores de la revista engineering and science review del instituto case, que gano un premio nacional como mejor revista tecnica en 1959.​​ luego cambio la fisica por las matematicas, y recibio dos titulos de case en 1960:​ su licenciatura en ciencias, y simultaneamente un master en ciencias por un premio especial de la facultad, que considero su trabajo excepcionalmente destacado.​​  en 1963, con el matematico marshall hall como asesor,​ se doctoro en matematicas en el california institute of technology.​  despues de recibir su doctorado, knuth se unio a la facultad de caltech como profesor asistente.​  acepto el encargo de escribir un libro sobre lenguaje de programacion informatico compilador. mientras trabajaba en este proyecto, knuth decidio que no podia tratar adecuadamente el tema sin desarrollar primero una teoria fundamental de la programacion de ordenadores, que se convirtio en el arte de la programacion de ordenadores. originalmente planeo publicarlo como un solo libro. a medida que knuth desarrollaba su esquema para el libro, llego a la conclusion de que necesitaba seis volumenes, y luego siete, para cubrir completamente el tema. publico el primer volumen en 1968.​  justo antes de publicar el primer volumen de the art of computer programming, knuth dejo caltech para aceptar un empleo en el division de investigacion de comunicaciones del instituto de analisis de defensa, situado entonces en el campus de la princeton university, que realizaba investigaciones matematicas en criptografia para apoyar a la national security agency.  en 1967, knuth asistio a una conferencia de la sociedad de matematica industrial y aplicada y alguien le pregunto a que se dedicaba. en aquella epoca, la informatica se dividia en analisis numerico, inteligencia artificial y lenguajes de programacion. basandose en su estudio y en el libro the art of computer programming, knuth decidio que la proxima vez que alguien le preguntara diria: \"analisis de algoritmos\".\"​  knuth dejo entonces su puesto para unirse a la facultad de la universidad de stanford en 1969,​ donde ahora es profesor emerito de ciencias de la computacion fletcher jones.​​  esta casado con jill carter knuth. tienen dos hijos.  ha sido galardonado con el premio fundacion bbva fronteras del conocimiento 2010 en la categoria de tecnologias de la informacion y la comunicacion.​  se le conoce principalmente por ser el autor de la obra the art of computer programming (el arte de programar computadoras), una de las mas respetadas referencias en el campo de las ciencias de la computacion. sento las bases y dio nombre al analisis de algoritmos, y ha realizado numerosos aportes a varias ramas teoricas de la informatica. es el creador de tex, del sistema de diseño de tipos metafont y del estilo de programacion conocido como programacion literaria (literate programming).​ knuth es conocido como el \"padre del analisis de algoritmos\".​  knuth es un programador conocido por su humor geek: ofrece una recompensa de 2,56 dolares a quien encuentre errores conceptuales o tipograficos en sus libros (la razon detras de la extraña cifra es que «256 centavos son 1 dolar hexadecimal»), y por otro lado ofrecia 3,16 por errores en 3:16 bible texts illuminated. enumero las distintas versiones de tex de manera que se aproximaran al numero π (3, 3.1, 3.14, etc.), al igual que los numeros de version de metafont se van aproximando a e. su cita mas celebre, al enviarle sus comentarios a un colega autor de un algoritmo, es: «cuidado con los errores en el codigo anterior; solo he demostrado que es correcto, no lo he probado».  knuth es el autor de 3:16 bible texts illuminated (1991, isbn 0-89579-252-4), libro en el que intenta examinar la biblia por un proceso de «muestreo estratificado aleatorio», es decir, un analisis del capitulo 3, versiculo 16 de cada libro. cada versiculo se acompaña de un renderizado en arte caligrafico, realizado por un grupo de caligrafos capitaneado por hermann zapf.    knuth es tambien el autor de numeros surrealistas,​ una novela matematica sobre la construccion de john conway de la teoria de conjuntos de un sistema alternativo de numeros. en lugar de limitarse a explicar el tema, el libro pretende mostrar el desarrollo de las matematicas. knuth queria que el libro preparara a los estudiantes para realizar una investigacion original y creativa.  en 1995, knuth escribio el prologo del libro a=b de marko petkovsek, herbert wilf y doron zeilberger.​ knuth tambien es un colaborador ocasional de rompecabezas linguisticos en word ways: the journal of recreational linguistics.​  knuth tambien ha profundizado en la matematica recreativa.  contribuyo con articulos al journal of recreational mathematics a partir de la decada de 1960, y fue reconocido como uno de los principales colaboradores en el libro de joseph madachy mathematics on vacation.​  knuth tambien ha aparecido en una serie de numberphile​ y videos de computerphile en youtube donde ha tratado temas desde la escritura de numeros surreales​ a por que no utiliza el correo electronico.​   ",
        "snippet": "Donald Ervin Knuth (Milwaukee, Wisconsin; 10 de enero 1938) es un reconocido experto en ciencias de la computación estadounidense y matemático, famoso por su fructífera investigación dentro del análisis de algoritmos y compiladores.[1]​",
        "enlaces_salientes": [
            "/wiki/Donald_Knuth",
            "/wiki/Donald_Knuth",
            "/wiki/Donald_Knuth",
            "/wiki/10_de_enero",
            "/wiki/1938",
            "/wiki/Milwaukee",
            "/wiki/Wisconsin",
            "/wiki/Estados_Unidos",
            "/wiki/Estados_Unidos",
            "/wiki/Luteranismo",
            "/wiki/Universidad_Case_de_la_Reserva_Occidental",
            "/wiki/Master_of_Science",
            "/wiki/Bachelor_of_Science",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Instituto_Tecnol%C3%B3gico_de_California",
            "/wiki/Philosophi%C3%A6_doctor",
            "/wiki/Marshall_Hall_(matem%C3%A1tico)",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Escritor",
            "/wiki/Programador",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Ingeniero",
            "/wiki/Acad%C3%A9mico_(ocupaci%C3%B3n)",
            "/wiki/Combinatoria",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Catedr%C3%A1tico_de_universidad",
            "/wiki/Universidad_Stanford",
            "/wiki/Burroughs_Corporation",
            "/wiki/Instituto_de_An%C3%A1lisis_de_la_Defensa",
            "/wiki/Michael_Fredman",
            "/wiki/Vaughan_Pratt",
            "/wiki/%C3%93rgano_(m%C3%BAsica)",
            "/wiki/TeX",
            "/wiki/METAFONT",
            "/wiki/The_Art_of_Computer_Programming",
            "/wiki/Computer_Modern",
            "/wiki/Programaci%C3%B3n_literaria",
            "/wiki/Academia_Noruega_de_Ciencias_y_Letras",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Academia_Nacional_de_Ingenier%C3%ADa_(Estados_Unidos)",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Institute_of_Electrical_and_Electronics_Engineers",
            "/wiki/Academia_de_Ciencias_de_Francia",
            "/wiki/Academia_de_Ciencias_de_Baviera",
            "/wiki/Royal_Society",
            "/wiki/Academia_de_Ciencias_de_Rusia",
            "/wiki/Sociedad_de_Matem%C3%A1ticas_Aplicadas_e_Industriales",
            "/wiki/British_Computer_Society",
            "/wiki/American_Philosophical_Society",
            "/wiki/American_Mathematical_Society",
            "/wiki/London_Mathematical_Society",
            "/wiki/Milwaukee",
            "/wiki/Wisconsin",
            "/wiki/10_de_enero",
            "/wiki/1938",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Matem%C3%A1tico",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Compilador",
            "/wiki/Profesor_Em%C3%A9rito",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Milwaukee",
            "/wiki/Wisconsin",
            "/wiki/Case_Western_Reserve_University",
            "/wiki/Case_Western_Reserve_University",
            "/wiki/Cleveland",
            "/wiki/IBM_650",
            "/wiki/Ordenador",
            "/wiki/Newsweek",
            "/wiki/CBS_Evening_News",
            "/wiki/Marshall_Hall_(matem%C3%A1tico)",
            "/wiki/California_Institute_of_Technology",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Compilador",
            "/wiki/Princeton_University",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/National_Security_Agency",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Premios_Fundaci%C3%B3n_BBVA_Fronteras_del_Conocimiento",
            "/wiki/Tecnolog%C3%ADas_de_la_informaci%C3%B3n_y_la_comunicaci%C3%B3n",
            "/wiki/The_Art_of_Computer_Programming",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Inform%C3%A1tica",
            "/wiki/TeX",
            "/wiki/METAFONT",
            "/wiki/Programaci%C3%B3n_literaria",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Programador",
            "/wiki/Geek",
            "/wiki/D%C3%B3lar",
            "/wiki/Hexadecimal",
            "/wiki/N%C3%BAmero_%CF%80",
            "/wiki/METAFONT",
            "/wiki/N%C3%BAmero_e",
            "/wiki/Algoritmo",
            "/wiki/1991",
            "/wiki/Biblia",
            "/wiki/Caligraf%C3%ADa",
            "/wiki/Hermann_Zapf",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/John_Horton_Conway",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Herbert_Wilf",
            "/wiki/Doron_Zeilberger",
            "/wiki/Matem%C3%A1tica_recreativa",
            "/wiki/YouTube",
            "/wiki/Premio_Knuth",
            "/wiki/Algoritmo_Knuth-Morris-Pratt",
            "/wiki/Notaci%C3%B3n_flecha_de_Knuth",
            "/wiki/Wayback_Machine",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Edward_Feigenbaum",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Quanta_Magazine",
            "/wiki/Stanford_University",
            "/wiki/Richard_M._Karp",
            "/wiki/Digital_object_identifier",
            "/wiki/Charles_Bachman",
            "/wiki/Premio_Turing",
            "/wiki/1974",
            "/wiki/Allen_Newell",
            "/wiki/Herbert_Alexander_Simon",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Scopus",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Royal_Society",
            "/wiki/Open_Library",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Pers%C3%A9e_(portal)"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/TeX",
        "titulo": "TeX",
        "contenido": "tex, estilizado como t e x \\!x} } , es un sistema de tipografia escrito por donald e. knuth, muy popular en el entorno academico, especialmente entre las comunidades de matematicos, fisicos e informaticos. ha conseguido sustituir con creces a troff, otro programa de tipografia habitual en unix.  tex se considera generalmente la mejor forma de componer formulas matematicas complejas pero, especialmente en la forma de latex y otros paquetes de macros, se puede usar para otras tareas de composicion.  knuth empezo a escribir tex porque se sentia molesto con la calidad cada vez menor de la tipografia en los volumenes i a iii de su obra el arte de programar ordenadores. empezo por ello a diseñar su propio lenguaje de tipografia. penso que podria acabarlo en su año sabatico, 1978; se equivoco por tan solo ocho años. el lenguaje se finalizo y congelo (no se hicieron mas modificaciones) alrededor de 1985.  guy steele coincidio en stanford en el verano de 1978, cuando knuth estaba desarrollando su primera version de tex. cuando volvio al mit a finales de año, reescribio la entrada/salida de tex para que se ejecutase en el its.  la primera version de tex se escribio usando el lenguaje de programacion sail que se ejecutaba en una pdp-10 en el sistema operativo waits de la universidad de stanford. para las versiones posteriores de tex, knuth invento el concepto de programacion literaria, una forma de producir codigo fuente compilable y documentacion con referencias de alta calidad (por supuesto, escrito en tex) partiendo del mismo archivo original. el lenguaje usado se llama web y produce programas en pascal.  tex tiene un sistema de numeracion de versiones peculiar. desde la version 3, las actualizaciones se indican añadiendo una cifra decimal extra al final, de modo que el numero de version se aproxime asintoticamente a π. la version mas reciente es la 3,14159265 y por ser muy estable solo se preven pequeñas actualizaciones.  knuth ha indicado que el \"ultimo cambio final (hecho despues de mi muerte)\" sera cambiar el numero de version a π, y que en ese momento todos los errores que queden seran considerados caracteristicas.  las ordenes de tex empiezan con una barra invertida (\"\\\") y sus argumentos se indican mediante llaves (\"{}\"). sin embargo, casi todas las propiedades sintacticas de tex pueden cambiarse sobre la marcha, con lo que la entrada de tex es algo dificil de analizar salvo por el propio tex. tex es un lenguaje basado en ordenes basicas y macros: muchas ordenes, incluidas la mayoria de las que definen los usuarios, se sustituyen sobre la marcha hasta que solo quedan ordenes basicas, que entonces se ejecutan. la sustitucion en si misma esta libre de efectos secundarios. la recursion de macros no consume memoria y asimismo se dispone de construcciones if-then-else. todo ello hace de tex un lenguaje turing completo incluso al nivel de sustitucion.  el sistema tex tiene un conocimiento preciso de los tamaños de los caracteres y simbolos, y usando esta informacion calcula el alineamiento optimo de letras por linea y de lineas en cada pagina. posteriormente produce un archivo dvi (de las siglas en ingles device independent, independiente del dispositivo) que contiene la posicion final de todos los caracteres. el archivo dvi se puede imprimir directamente usando un controlador de impresora adecuado, o puede convertirse a otros formatos. actualmente, pdftex se usa para generar archivos pdf saltandose la generacion del dvi.  la mayor parte de la funcionalidad viene dada por diversas macros: las originales de knuth englobadas en lo que se llama plaintex, latex (mayoritario en las ciencias tecnicas) y context (usado principalmente para publicaciones).  la referencia principal de tex son los dos primeros volumenes de la obra computers and typesetting de knuth: `the texbook'´ y `tex: the program´ (este incluye el codigo fuente de tex completo y documentado).  la organizacion de los directorios en una instalacion de tex esta normalizada en un arbol llamado texmf.  la licencia de tex permite la distribucion y modificacion libres, pero exige que cualquier version modificada no se llame tex, tex o algo similar, que pueda ser confundido con la version original. la licencia da derechos similares a aquellos de una marca registrada.  aunque esta bien escrito, tex es tan grande (y tan lleno de tecnica avanzada) que se dice haber descubierto al menos un error en cada sistema pascal en el que se ha compilado, ya que tex se ejecuta en la mayoria de los sistemas operativos.  knuth ofrece recompensas monetarias para la gente que encuentre e informe de un error en el programa. el premio por error empezo con un centavo y se doblaba cada año hasta que quedo congelado en su valor actual de 327,68 dolares. esto, sin embargo, no ha arruinado a knuth, porque se han encontrado muy pocos errores y en cualquier caso el cheque que prueba que el propietario encontro un error en tex se suele enmarcar en vez de cobrarlo.  donald knuth explica en su obra the texbook que la palabra technology (\"tecnologia\") tiene raiz griega y esta comienza por las letras τεχ. por tanto, el nombre tex en español se tiene que pronunciar [tej], y no [teks]. ello se debe a que tex no quiere decir tex sino τεχ, acabado en la letra griega χ [ji]. la misma palabra griega τεχνη (τεχνη – techne) significa \"arte\", una referencia a que la tecnica no esta reñida con el arte ni con la presentacion elegante.  cuando se esta escribiendo un archivo en tex y se quiere hacer referencia al nombre se dispone de la orden \\tex, definida asi:  o asi en l a t e x _}\\!\\!\\!\\!\\!\\;\\;t\\!_\\!x} } :  y que fue creada por knuth para demostrar lo que es posible hacer con tex. la letra \"e\" queda por debajo de la linea base y mas unida a la t; en los otros sistemas se escribe usando la aproximacion \"tex\".  varios sistemas de procesamiento de documentos estan basados en tex; destacan entre ellos:  todos estos sistemas estan escritos en el lenguaje de programacion tex (algunos con complementos en otros lenguajes de programacion). ademas, hay programas que extienden el lenguaje de programacion con nuevas ordenes y capacidades:  ademas, hay programas asociados como bibtex para el manejo de bibliografias, makeindex y xindy para los indices alfabeticos y metafont para graficos.  todas las extensiones estan disponibles en el ctan, (comprehensive tex archive network).  en sistemas compatibles unix, tex se distribuye bajo la forma tetex. en sistemas windows existen miktex y fptex. en sistemas mac os x existe mactex con utilidades como texshop.  el editor de texto texmacs es un editor de textos cientificos wysiwyg que pretende ser compatible con tex. usa las tipografias de knuth y puede generar un archivo tex. otra herramienta similar es lyx.  un ejemplo simple en tex: crea un archivo llamado miprimer.tex que contenga lo siguiente:  abre un interprete de ordenes y escribe  tex creara un archivo llamado miprimer.dvi. usa un programa adecuado para visualizarlo. por ejemplo, miktex incluye el visor yap  el visor muestra hola en una pagina. \\bye es la orden tex que marca el final de un archivo y no se muestra en la salida final.  el archivo dvi puede ser impreso directamente desde el visor o convertido a un formato mas comun tal como postscript usando el programa dvips.  es posible crear directamente archivos pdf usando pdftex:  pdftex se creo originalmente porque al convertir los postscript generados en pdf se obtenia una visualizacion de las tipografias de baja calidad, aunque la impresion era buena. la causa es que tex usa de forma nativa tipografias tipo 3 de mapas de bits, que no se visualizan tan bien como las tipografias tipo 1 escalables.  es posible actualmente hacer que dvips use las tipografias escalables con un poco de configuracion (versiones recientes de ghostscript lo permiten), pero una conversion directa a pdf tiene otros beneficios: es un proceso en un solo paso, en lugar de dos, y pdftex incluye cosas tales como marcadores e hipervinculos, ausentes en postscript.  para ver a tex en accion, prueba a escribir la conocida formula de la ecuacion cuadratica:  con el texto de arriba deberias obtener algo que se viese como esto  en un documento, para entrar en el  modo matematico se escribe un signo $, a continuacion la formula de manera que la entienda tex y se cierra con otro signo $. otro modo de presentacion, que deja la formula centrada en una nueva linea, se consigue usando $$. por ejemplo, la formula anterior se escribiria  y se veria como  aplicacion de formula del cociente ",
        "snippet": "TeX, estilizado como T E X {\\displaystyle \\mathbf {T\\!_{\\displaystyle E}\\!X} } , es un sistema de tipografía escrito por Donald E. Knuth, muy popular en el entorno académico, especialmente entre las comunidades de matemáticos, físicos e informáticos. Ha conseguido sustituir con creces a troff, otro programa de tipografía habitual en Unix.",
        "enlaces_salientes": [
            "/wiki/TeX",
            "/wiki/TeX",
            "/wiki/TeX",
            "/wiki/Tipograf%C3%ADa",
            "/wiki/Donald_Knuth",
            "/wiki/Desarrollador_de_software",
            "/wiki/Donald_Knuth",
            "/wiki/1978",
            "/wiki/Licencia_de_software",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Ciclo_de_vida_del_lanzamiento_de_software",
            "/wiki/DVI_(TeX)",
            "/wiki/Tipograf%C3%ADa",
            "/wiki/Donald_E._Knuth",
            "/wiki/Comunidad",
            "/wiki/Matem%C3%A1tico",
            "/wiki/F%C3%ADsico",
            "/wiki/Inform%C3%A1tico",
            "/wiki/Troff",
            "/wiki/Unix",
            "/wiki/LaTeX",
            "/wiki/El_arte_de_programar_ordenadores",
            "/wiki/1978",
            "/wiki/1985",
            "/wiki/Instituto_Tecnol%C3%B3gico_de_Massachussets",
            "/wiki/PDP-10",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Programaci%C3%B3n_literaria",
            "/wiki/Web_sem%C3%A1ntica",
            "/wiki/Lenguaje_de_programaci%C3%B3n_Pascal",
            "/wiki/As%C3%ADntota",
            "/wiki/N%C3%BAmero_%CF%80",
            "/wiki/Macro",
            "/wiki/Turing_completo",
            "/wiki/DVI_(TeX)",
            "/wiki/PdfTeX",
            "/wiki/ConTeXt",
            "/wiki/Marca_registrada",
            "/wiki/Cheque",
            "/wiki/Donald_Knuth",
            "/wiki/Ji",
            "/wiki/LaTeX",
            "/wiki/Leslie_Lamport",
            "/wiki/ConTeXt",
            "/wiki/AMS-TeX",
            "/wiki/Sociedad_Matem%C3%A1tica_Americana",
            "/wiki/Texinfo",
            "/wiki/GNU",
            "/wiki/PdfTeX",
            "/wiki/Omega_(TeX)",
            "/wiki/Lua",
            "/wiki/BibTeX",
            "/wiki/Metafont",
            "/wiki/CTAN",
            "/wiki/Microsoft_Windows",
            "/wiki/Mac_OS_X",
            "/wiki/TeXmacs",
            "/wiki/WYSIWYG",
            "/wiki/LyX",
            "/wiki/Tipo_de_letra_PostScript#Tipos_de_letra",
            "/wiki/Ecuaci%C3%B3n_cuadr%C3%A1tica",
            "/wiki/Software_libre",
            "/wiki/BibTeX",
            "/wiki/CervanTeX",
            "/wiki/LaTeX",
            "/wiki/LyX",
            "/wiki/Tex",
            "/wiki/LaTeX",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Metafont",
            "/wiki/MetaPost",
            "/wiki/MiKTeX",
            "/wiki/Microsoft_Windows",
            "/wiki/TeX_Live",
            "/wiki/TUG",
            "/wiki/WinShell",
            "/wiki/TeXnicCenter",
            "/wiki/Html",
            "/wiki/ISBN",
            "/wiki/GFDL",
            "/wiki/ISBN",
            "/wiki/GFDL",
            "/wiki/Wayback_Machine",
            "/wiki/ConTeXt",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Lenguaje_de_programaci%C3%B3n_Java",
        "titulo": "Java (lenguaje de programación)",
        "contenido": "java es un lenguaje de programacion y una plataforma informatica que fue comercializada por primera vez en 1995 por sun microsystems.​​  el lenguaje de programacion java fue desarrollado originalmente por james gosling, de sun microsystems (constituida en 1983 y posteriormente adquirida el 27 de enero de 2010 por la compañia oracle),​ y publicado en 1995 como un componente fundamental de la plataforma java de sun microsystems. su sintaxis deriva en gran medida de c y c++, pero tiene menos utilidades de bajo nivel que cualquiera de ellos. las aplicaciones de java son compiladas a bytecode (clase java), que puede ejecutarse en cualquier maquina virtual java (jvm) sin importar la arquitectura de la computadora subyacente.  la compañia sun desarrollo la implementacion de referencia original para los compiladores de java, maquinas virtuales y librerias de clases en 1991, y las publico por primera vez en 1995. a partir de mayo de 2007, en cumplimiento de las especificaciones del proceso de la comunidad java, sun volvio a licenciar la mayoria de sus tecnologias de java bajo la licencia publica general de gnu. otros han desarrollado tambien implementaciones alternas a estas tecnologias de sun, tales como el compilador de java de gnu y el gnu classpath.  java se creo como una herramienta de programacion para ser usada en un proyecto de set-top-box en una pequeña operacion denominada the green project en sun microsystems en 1991. el equipo (green team), compuesto por trece personas y dirigido por james gosling, trabajo durante 18 meses en sand hill road,  menlo park (california), para desarrollarlo.  el lenguaje se denomino inicialmente oak (por un roble que habia fuera de la oficina de gosling), luego paso a llamarse red tras descubrir que oak era ya una marca comercial registrada para adaptadores de tarjetas graficas, y finalmente se le renombro java.  es frecuentada por algunos de los miembros del equipo. pero no esta claro si es un acronimo o no, aunque algunas fuentes señalan que podria tratarse de las iniciales de sus diseñadores: james gosling, arthur van hoff y andy bechtolsheim. otros abogan por el siguiente acronimo, just another vague acronym (\"simplemente otro acronimo ambiguo mas\"). la hipotesis que mas fuerza tiene es la de que java debe su nombre a un tipo de cafe disponible en la cafeteria cercana; de ahi que el icono de java sea una taza de cafe caliente. un pequeño signo que da fuerza a esta teoria es que los cuatro primeros bytes (el numero magico) de los archivos.class que genera el compilador, son en hexadecimal, 0xcafebabe. a pesar de todas estas teorias, el nombre fue sacado al parecer de una lista aleatoria de palabras.​  los objetivos de gosling eran implementar una maquina virtual y un lenguaje con una estructura y sintaxis similar a c++. entre junio y julio de 1994, tras una sesion maratoniana de tres dias entre john gage, james gosling, patrick naughton, wayne rosing y eric schmidt, el equipo reoriento la plataforma hacia la web. sintieron que la llegada del navegador web mosaic propiciaria que internet se convirtiese en un medio interactivo, como el que pensaban era la television por cable. naughton creo entonces un prototipo de navegador, webrunner, que mas tarde seria conocido como hotjava.  en 1994, se les hizo una demostracion de hotjava y la plataforma java a los ejecutivos de sun. java 1.0a pudo descargarse por primera vez en 1994, pero hubo que esperar al 23 de mayo de 1995, durante las conferencias de sunworld, a que vieran la luz publica java y hotjava, el navegador web. el acontecimiento fue anunciado por john gage, el director cientifico de sun microsystems. el acto estuvo acompañado por una pequeña sorpresa adicional, el anuncio por parte de marc andreessen, vicepresidente ejecutivo de netscape, de que java seria soportado en sus navegadores. el 9 de enero del año siguiente, 1996, sun fundo el grupo empresarial javasoft para que se encargase del desarrollo tecnologico. dos semanas mas tarde la primera version de java fue publicada.  la promesa inicial de gosling era write once, run anywhere (escribelo una vez, ejecutalo en cualquier lugar), proporcionando un lenguaje independiente de la plataforma y un entorno de ejecucion (la jvm) ligero y gratuito para las plataformas mas populares, de forma que los binarios (bytecode) de las aplicaciones java pudiesen ejecutarse en cualquier plataforma.  el entorno de ejecucion era relativamente seguro, y los principales navegadores web pronto incorporaron la posibilidad de ejecutar applets java incrustadas en las paginas web.  java ha experimentado numerosos cambios desde la version primigenia, jdk 1.0, asi como un enorme incremento en el numero de clases y paquetes que componen la biblioteca estandar.​  desde j2se 1.4, la evolucion del lenguaje ha sido regulada por el jcp (java community process), que usa java specification requests (jsrs) para proponer y especificar cambios en la plataforma java. el lenguaje en si mismo esta especificado en la java language specification (jls), o especificacion del lenguaje java. los cambios en los jls son gestionados en jsr 901.  este ejemplo itera sobre el objeto iterable widgets, asignando, en orden, cada uno de los elementos a la variable w, y llamando al metodo display() de cada uno de ellos. (especificado por jsr 201.)  en el 2005 se calculaba en 4,5 millones el numero de desarrolladores y 2500 millones de dispositivos habilitados con tecnologia java.  el lenguaje java se creo con cinco objetivos principales:  para conseguir la ejecucion de codigo remoto y el soporte de red, los programadores de java a veces recurren a extensiones como corba (common object request broker architecture), internet communications engine u osgi, respectivamente.  la primera caracteristica, orientado a objetos (“oo”), se refiere a un metodo de programacion y al diseño del lenguaje. aunque hay muchas interpretaciones para oo, una primera idea es diseñar el software de forma que los distintos tipos de datos que usen esten unidos a sus operaciones. asi, los datos y el codigo (funciones o metodos) se combinan en entidades llamadas objetos. un objeto puede verse como un paquete que contiene el “comportamiento” (el codigo) y el “estado” (datos). el principio es separar aquello que cambia de las cosas que permanecen inalterables. frecuentemente, cambiar una estructura de datos implica un cambio en el codigo que opera sobre los mismos, o viceversa. esta separacion en objetos coherentes e independientes ofrece una base mas estable para el diseño de un sistema software. el objetivo es hacer que grandes proyectos sean faciles de gestionar y manejar, mejorando como consecuencia su calidad y reduciendo el numero de proyectos fallidos.  otra de las grandes promesas de la programacion orientada a objetos es la creacion de entidades mas genericas (objetos) que permitan la reutilizacion del software entre proyectos, una de las premisas fundamentales de la ingenieria del software. un objeto generico “cliente”, por ejemplo, deberia en teoria tener el mismo conjunto de comportamiento en diferentes proyectos, sobre todo cuando estos coinciden en cierta medida, algo que suele suceder en las grandes organizaciones. en este sentido, los objetos podrian verse como piezas reutilizables que pueden emplearse en multiples proyectos distintos, posibilitando asi a la industria del software construir proyectos de envergadura empleando componentes ya existentes y de comprobada calidad, conduciendo esto finalmente a una reduccion drastica del tiempo de desarrollo. podemos usar como ejemplo de objeto el aluminio. una vez definidos datos (densidad, maleabilidad, etc.), y su “comportamiento” (soldar dos piezas, etc.), el objeto “aluminio” puede ser reutilizado en el campo de la construccion, del automovil, de la aviacion, etc.  la reutilizacion del software ha experimentado resultados dispares, encontrando dos dificultades principales: el diseño de objetos realmente genericos es pobremente comprendido, y falta una metodologia para la amplia comunicacion de oportunidades de reutilizacion. algunas comunidades de “codigo abierto” (open source) quieren ayudar en este problema dando medios a los desarrolladores para diseminar la informacion sobre el uso y versatilidad de objetos reutilizables y bibliotecas de objetos.  la segunda caracteristica, la independencia de la plataforma, significa que programas escritos en el lenguaje java pueden ejecutarse igualmente en cualquier tipo de hardware. este es el significado de ser capaz de escribir un programa una vez y que pueda ejecutarse en cualquier dispositivo, tal como reza el axioma de java, \"write once, run anywhere\".  para ello, se compila el codigo fuente escrito en lenguaje java, para generar un codigo conocido como “bytecode” (especificamente java bytecode), instrucciones maquina simplificadas especificas de la plataforma java. esta pieza esta “a medio camino” entre el codigo fuente y el codigo maquina que entiende el dispositivo destino. el bytecode es ejecutado entonces en la maquina virtual (jvm), un programa escrito en codigo nativo de la plataforma destino (que es el que entiende su hardware), que interpreta y ejecuta el codigo. ademas, se suministran bibliotecas adicionales para acceder a las caracteristicas de cada dispositivo (como los graficos, ejecucion mediante hebras o threads, la interfaz de red) de forma unificada. se debe tener presente que, aunque hay una etapa explicita de compilacion, el bytecode generado es interpretado o convertido a instrucciones maquina del codigo nativo por el compilador jit (just in time).  hay implementaciones del compilador de java que convierten el codigo fuente directamente en codigo objeto nativo, como gcj. esto elimina la etapa intermedia donde se genera el bytecode, pero la salida de este tipo de compiladores solamente puede ejecutarse en un tipo de arquitectura.  la licencia sobre java de sun insiste en que todas las implementaciones sean “compatibles”. esto dio lugar a una disputa legal entre microsoft y sun, cuando este ultimo alego que la implementacion de microsoft no daba soporte a las interfaces rmi y jni ademas de haber añadido caracteristicas ‘’dependientes’’ de su plataforma. sun demando a microsoft y gano por daños y perjuicios (unos 20 millones de dolares), asi como una orden judicial forzando el acatamiento de la licencia de sun. como respuesta, microsoft no ofrece java con su version de sistema operativo, y en recientes versiones de windows, su navegador internet explorer no admite la ejecucion de applets sin un conector (o plugin) aparte. sin embargo, sun y otras fuentes ofrecen versiones gratuitas para distintas versiones de windows.  las primeras implementaciones del lenguaje usaban una maquina virtual interpretada para conseguir la portabilidad. sin embargo, el resultado eran programas que se ejecutaban comparativamente mas lentos que aquellos escritos en c o c++. esto hizo que java se ganase una reputacion de lento en rendimiento. las implementaciones recientes de la jvm dan lugar a programas que se ejecutan considerablemente mas rapido que las versiones antiguas, empleando diversas tecnicas, aunque sigue siendo mucho mas lentos que otros lenguajes.  la primera de estas tecnicas es simplemente compilar directamente en codigo nativo como hacen los compiladores tradicionales, eliminando la etapa del bytecode. esto da lugar a un gran rendimiento en la ejecucion, pero tapa el camino a la portabilidad. otra tecnica, conocida como compilacion jit (just in time, o \"compilacion al vuelo\"), convierte el bytecode a codigo nativo cuando se ejecuta la aplicacion. otras maquinas virtuales mas sofisticadas usan una \"recompilacion dinamica\" en la que la vm es capaz de analizar el comportamiento del programa en ejecucion y recompila y optimiza las partes criticas. la recompilacion dinamica puede lograr mayor grado de optimizacion que la compilacion tradicional (o estatica), ya que puede basar su trabajo en el conocimiento que de primera mano tiene sobre el entorno de ejecucion y el conjunto de clases cargadas en memoria. la compilacion jit y la recompilacion dinamica permiten a los programas java aprovechar la velocidad de ejecucion del codigo nativo sin por ello perder la ventaja de la portabilidad en ambos.  la portabilidad es tecnicamente dificil de lograr, y el exito de java en ese campo ha sido dispar. aunque es de hecho posible escribir programas para la plataforma java que actuen de forma correcta en multiples plataformas de distinta arquitectura, el gran numero de estas con pequeños errores o inconsistencias llevan a que a veces se parodie el eslogan de sun, \"write once, run anywhere\" como \"write once, debug everywhere\" (o “escribelo una vez, ejecutalo en cualquier parte” por “escribelo una vez, depuralo en todas partes”).  el concepto de independencia de la plataforma de java cuenta, sin embargo, con un gran exito en las aplicaciones en el entorno del servidor, como los servicios web, los servlets, los java beans, asi como en sistemas empotrados basados en osgi, usando entornos java empotrados.  en java el problema de fugas de memoria se evita en gran medida gracias a la recoleccion de basura (o automatic garbage collector). el programador determina cuando se crean los objetos, y el entorno, en tiempo de ejecucion de java (java runtime), es el responsable de gestionar el ciclo de vida de los objetos. el programa, u otros objetos, pueden tener localizado un objeto mediante una referencia a este. cuando no quedan referencias a un objeto, el recolector de basura de java borra el objeto, liberando asi la memoria que ocupaba previniendo posibles fugas (ejemplo: un objeto creado y unicamente usado dentro de un metodo solamente tiene entidad dentro de este; al salir del metodo el objeto es eliminado). aun asi, es posible que se produzcan fugas de memoria si el codigo almacena referencias a objetos que ya no son necesarios; es decir, pueden aun ocurrir, pero en un nivel conceptual superior. en definitiva, el recolector de basura de java permite una facil creacion y eliminacion de objetos y mayor seguridad.  la sintaxis de java se deriva en gran medida de c++. pero a diferencia de este, que combina la sintaxis para programacion generica, estructurada y orientada a objetos, java fue construido desde el principio para ser completamente orientado a objetos. todo en java es un objeto (salvo algunas excepciones), y todo en java reside en alguna clase (recordemos que una clase es un molde a partir del cual pueden crearse varios objetos).  a diferencia de c++, java no tiene sobrecarga de operadores​ o herencia multiple para clases, aunque la herencia multiple esta disponible para interfaces.  este ejemplo necesita una pequeña explicacion.  las applet java son programas incrustados en otras aplicaciones, normalmente una pagina web que se muestra en un navegador.  actualmente html 5 ha eliminado el uso de la etiqueta <applet>. pero todavia existe la forma de usarlo en html5. (texto en ingles) java applets in html5.  la sentencia import indica al compilador de java que incluya las clases java.applet. applet y java.awt. graphics, para poder referenciarlas por sus nombres, sin tener que anteponer la ruta completa cada vez que se quieran usar en el codigo fuente.  la clase hola extiende (extends) a la clase applet;es decir, es una subclase de esta. la clase applet permite a la aplicacion mostrar y controlar el estado del applet. la clase applet es un componente del awt (abstract window toolkit), que permite al applet mostrar una interfaz grafica de usuario o gui (graphical user interface), y responder a eventos generados por el usuario.  la clase hola sobrecarga el metodo paint (graphics) heredado de la superclase contenedora (applet en este caso), para acceder al codigo encargado de dibujar. el metodo paint() recibe un objeto graphics que contiene el contexto grafico para dibujar el applet. el metodo paint() llama al metodo drawstring (string, int, int) del objeto.  los servlets son componentes de la parte del servidor de java ee encargados de generar respuestas a las peticiones recibidas de los clientes.  las sentencias import indican al compilador de java la inclusion de todas las clases publicas e interfaces de los paquetes java.io y javax.servlet en la compilacion.  la clase hola extiende (extends) es heredera de la clase genericservlet. esta clase proporciona la interfaz para que el servidor le pase las peticiones al servlet y el mecanismo para controlar el ciclo de vida del servlet.  la clase hola sobrecarga el metodo service (servletrequest, servletresponse), definido por la interfaz servlet para acceder al manejador de la peticion de servicio. el metodo service() recibe un objeto de tipo servletrequest que contiene la peticion del cliente y un objeto de tipo servletresponse, usado para generar la respuesta que se devuelve al cliente. el metodo service() puede lanzar (throws) excepciones de tipo servletexception e ioexception si ocurre algun tipo de anomalia.  el metodo setcontenttype (string) en el objeto respuesta establece el tipo de contenido mime a \"text/html\", para indicar al cliente que la respuesta a su peticion es una pagina con formato html. el metodo getwriter() del objeto respuesta devuelve un objeto de tipo printwriter, usado como una tuberia por la que viajaran los datos al cliente. el metodo println (string) escribe la cadena \"¡hola, mundo!\" en la respuesta y finalmente se llama al metodo close() para cerrar la conexion, que hace que los datos escritos en la tuberia o stream sean devueltos al cliente.  swing es la biblioteca para la interfaz grafica de usuario avanzada de la plataforma java se.  las instrucciones import indican al compilador de java que las clases e interfaces del paquete javax.swing se incluyan en la compilacion.  la clase hola extiende (extends) la clase javax.swing.jframe, que implementa una ventana con una barra de titulo y un control para cerrarla.  el constructor hola() inicializa el marco o frame llamando al metodo setdefaultcloseoperation (int) heredado de jframe para establecer las operaciones por defecto cuando el control de cierre en la barra de titulo es seleccionado al valor windowconstants.dispose_on_close. esto hace que se liberen los recursos tomados por la ventana cuando es cerrada, y no simplemente ocultada, lo que permite a la maquina virtual y al programa acabar su ejecucion. a continuacion se crea un objeto de tipo jlabel con el texto \"¡hola, mundo!\", y se añade al marco mediante el metodo add (component), heredado de la clase container. el metodo pack(), heredado de la clase window, es invocado para dimensionar la ventana y distribuir su contenido.  el metodo main() es llamado por la jvm al comienzo del programa. crea una instancia de la clase hola y hace la ventana sea mostrada invocando al metodo setvisible (boolean) de la superclase (clase de la que hereda) con el parametro a true. vease que, una vez el marco es dibujado, el programa no termina cuando se sale del metodo main(), ya que el codigo del que depende se encuentra en un hilo de ejecucion independiente ya lanzado, y que permanecera activo hasta que todas las ventanas hayan sido destruidas.  el diseño de java, su robustez, el respaldo de la industria y su facil portabilidad han hecho de java uno de los lenguajes con un mayor crecimiento y amplitud de uso en distintos ambitos de la industria de la informatica.  desde la creacion de la especificacion j2me (java 2 platform, micro edition), una version del entorno de ejecucion java reducido y altamente optimizado, especialmente desarrollado para el mercado de dispositivos electronicos de consumo, se ha producido toda una revolucion en lo que a la extension de java se refiere.  es posible encontrar microprocesadores diseñados para ejecutar bytecode java y software java para tarjetas inteligentes (javacard), telefonos moviles, buscapersonas, set-top-boxes, sintonizadores de tv y otros pequeños electrodomesticos.  el modelo de desarrollo de estas aplicaciones es muy semejante a las applets de los navegadores, salvo que en este caso se denominan midlets.  vease sun mobile device tecnology  desde la primera version de java existe la posibilidad de desarrollar pequeñas aplicaciones (applets) en java que luego pueden ser incrustadas en una pagina html para que sean descargadas y ejecutadas por el navegador web. estas miniaplicaciones se ejecutan en una jvm que el navegador tiene configurada como extension (plug-in) en un contexto de seguridad restringido configurable para impedir la ejecucion local de codigo potencialmente malicioso.  el exito de este tipo de aplicaciones (la vision del equipo de gosling) no fue realmente el esperado debido a diversos factores, siendo quizas el mas importante la lentitud y el reducido ancho de banda de las comunicaciones en aquel entonces que limitaba el tamaño de las applets que se incrustaban en el navegador. la aparicion posterior de otras alternativas (aplicaciones web dinamicas de servidor) dejo un reducido ambito de uso para esta tecnologia, quedando hoy relegada fundamentalmente a componentes especificos para la intermediacion desde una aplicacion web dinamica de servidor con dispositivos ubicados en la maquina cliente donde se ejecuta el navegador.  las applets java no son las unicas tecnologias (aunque si las primeras) de componentes complejos incrustados en el navegador. otras tecnologias similares pueden ser: activex de microsoft, flash, java web start, etc.  en la parte del servidor, java es mas popular que nunca, desde la aparicion de la especificacion de servlets y jsp (java server pages).  hasta entonces, las aplicaciones web dinamicas de servidor que existian se basaban fundamentalmente en componentes cgi y lenguajes interpretados. ambos tenian diversos inconvenientes (fundamentalmente lentitud, elevada carga computacional o de memoria y propension a errores por su interpretacion dinamica).  los servlets y las jsp supusieron un importante avance ya que:  la especificacion de servlets y jsp define un api de programacion y los requisitos para un contenedor (servidor) dentro del cual se puedan desplegar estos componentes para formar aplicaciones web dinamicas completas. hoy dia existen multitud de contenedores (libres y comerciales) compatibles con estas especificaciones.  a partir de su expansion entre la comunidad de desarrolladores, estas tecnologias han dado paso a modelos de desarrollo mucho mas elaborados con frameworks (pe struts, webwork) que se sobreponen sobre los servlets y las jsp para conseguir un entorno de trabajo mucho mas poderoso y segmentado en el que la especializacion de roles sea posible (desarrolladores, diseñadores graficos,...) y se facilite la reutilizacion y robustez de codigo. a pesar de todo ello, las tecnologias que subyacen (servlets y jsp) son substancialmente las mismas.  este modelo de trabajo se ha convertido en uno de los estandar de facto para el desarrollo de aplicaciones web dinamicas de servidor.  hoy en dia existen multitud de aplicaciones graficas de usuario basadas en java. el entorno de ejecucion java (jre) se ha convertido en un componente habitual en los pc de usuario de los sistemas operativos mas usados en el mundo. ademas, muchas aplicaciones java lo incluyen dentro del propio paquete de la aplicacion de modo que se ejecuten en cualquier pc.  en las primeras versiones de la plataforma java existian importantes limitaciones en las api de desarrollo grafico (awt). desde la aparicion de la biblioteca swing la situacion mejoro substancialmente y posteriormente con la aparicion de bibliotecas como swt hacen que el desarrollo de aplicaciones de escritorio complejas y con gran dinamismo, usabilidad, etc. sea relativamente sencillo.  una version del entorno de ejecucion java jre (java runtime environment) esta disponible en la mayoria de equipos de escritorio. sin embargo, microsoft no lo ha incluido por defecto en sus sistemas operativos. en el caso de apple, este incluye una version propia del jre en su sistema operativo, el mac os. tambien es un producto que por defecto aparece en la mayoria de las distribuciones de gnu/linux. debido a incompatibilidades entre distintas versiones del jre, muchas aplicaciones prefieren instalar su propia copia del jre antes que confiar su suerte a la aplicacion instalada por defecto. los desarrolladores de applets de java o bien deben insistir a los usuarios en la actualizacion del jre, o bien desarrollar bajo una version antigua de java y verificar el correcto funcionamiento en las versiones posteriores.  las expresiones son un conjunto de elementos o tokens junto con literales que son evaluados para devolver un resultado. los tokens son elemento mas pequeño de un programa que es significativo, e interpretado o entendido por el compilador, en java los tokens se dividen en cinco categorias que son:  identificadores: son las representaciones que se les da a los nombres que se asignan a las variables, clases, paquetes, metodos y constantes en el codigo de java para que el compilador los identifique y el programador pueda entenderlos. en java los identificadores pueden diferenciar entre mayusculas o minusculas por ser case sensitive, por lo que la variable cuyo nombre sea “mivariable”, no es igual a “mivariable”, ya que java identifica estas como variables diferentes por ser case sensitive, tambien se puede utilizar numeros, o el signo “_” para asignar un identificador.  palabras claves: son los identificadores reservados por java para cumplir con un objetivo especifico en el codigo y el compilador, se usan de forma limitada y en casos especificos. las palabras claves que usa java son las siguientes:  las palabras que se encuentran en negrilla, son palabras claves para java aunque actualmente no se utilicen en la version de java, pero se pretenden integrar en las siguientes versiones de java.  literales y constantes: los literales son sintaxis para asignar valores a una variable, es decir el valor que puede tomar una variable, tambien es un valor constante que puede ser de tipo numerico. las constantes son variables que tienen un valor fijo y no puede ser modificado en el trascurso de la ejecucion del codigo, estas se declaran por medio de los modificadores final y static.  operadores: son los que nos indican una evaluacion que se aplica a un objeto o un dato, sobre un identificador o constante. un ejemplo de operadores puede ser la suma, resta o multiplicacion.  separadores: se utilizan para indicarle al compilador de java donde se ubican los elementos del codigo, los separadores que admite java son: { },:;  tambien el compilador de java identifica y elimina los comentarios, retornos de carros espacios vacios y de tabulacion a la hora de compilar por lo que no son considerados parte de un token.  las expresiones pueden ser una combinacion en secuencia de variables, operadores y metodos. las expresiones son utilizadas para realizar calculos, para asignar valores a variables, o para controlar la ejecucion del flujo del programa.  son las expresiones de java que tras realizar una operacion devuelven un resultado. segun el numero de operandos que maneje un operador, puede ser de dos tipos: unario o binario.  los operadores unarios son aquellos que solo necesitan un operando para devolver un valor.  los operadores binarios son aquellos que necesitan dos o mas operandos para devolver un valor.  no existe  ~ complemento a 1, este operador invierte los digitos, cambiando los 0 por 1 y los 1 por 0, un ejemplo puede ser:  como se puede ver se cambian los valores de 0 a 1 y de 1 a 0.  & and a nivel de bit, este operador realiza una operacion and o suma entre dos numeros de bit, en donde si dos bit son igual a 1 el resultado sera 1, de lo contrario sera 0, un ejemplo puede ser:  | or a nivel de bit, este operador realiza una operacion or en donde si alguno de los dos numeros es 1 el resultado sera 1, un ejemplo puede ser:  ^ xor a nivel de bit, este operador realiza la operacion xor en donde si los dos numeros son iguales el resultado sera 0 de lo contrario sera 1, un ejemplo puede ser:  << desplazamiento a la izquierda, este operador desplaza n cantidad de espacios a la izquierda un bit, un ejemplo puede ser;  como se puede ver al realizar el desplazamiento se realiza una insercion de un digito 0 a la derecha  los operadores son una parte principal en las expresiones, el tipo y forma de uso es fundamental a la hora de programar, pero para su uso se tiene que tener en cuenta una serie de normas, como lo son la precedencia de los operadores.  los operadores son ejecutados segun su precedencia: si cuentan con una precedencia mayor seran evaluados antes que los de precedencia menor; si por casualidad se llegasen a presentar operadores con el mismo nivel de precedencia, estos se evaluaran de derecha a izquierda; y si son operadores binarios (menos los operadores de asignacion) se evaluaran de izquierda a derecha. a java se le puede indicar que operadores debe evaluar primero sin importar su precedencia por medio de parentesis \"( )\", de esta forma el compilador de java interpreta que primero debe ejecutar las operaciones que se encuentran dentro de los parentesis, y luego continuar con los demas operadores.  la siguiente tabla clasifica los operadores utilizados en java segun su nivel de precedencia, siendo arriba el nivel mas alto:  un ejemplo de la precedencia de los operadores en java podria ser el siguiente, en donde tenemos un codigo que se encargara de realizar una serie de operaciones aritmeticas:  segun la precedencia de los operadores, la multiplicacion \"*\" tiene mayor prioridad que la suma \"+\", por lo que primero se ejecuta la multiplicacion y luego se realiza la suma.  en este caso el resultado cambia ya que primero se evaluan los parametros que estan dentro del parentesis y luego se evalua el resto de parametros. una de las recomendaciones que da java para el desarrollo es el uso de los parentesis en las operaciones con mas de 3 operandos, asi de esta forma el codigo se hace mas legible y se evitan errores al momento de compilar.  las sentencias son una representacion de una secuencia de acciones que se realizan en java. la clave fundamental de las sentencias es su punto final que indica que ha finalizado la sentencia y puede continuar con la siguiente, el indicador utilizado es el signo de punto y coma (;). en java contamos con sentencias que pueden ser de asignacion, de bucles, de salto y condicionales. las sentencias se conforman comunmente por una instancia y un operador; un ejemplo es la sentencia de asignacion que se conforma por una instancia de una variable, el signo de asignacion y una expresion; un ejemplo es:  las sentencias de asignacion son aquellas en las que se asigna un valor a una variable o constante. las sentencias condicionales son las que expresan una condicion para definir el flujo de ejecucion del programa; entre ellas tenemos if, else y switch. las sentencias de bucles se encargan de realizar una accion cierta cantidad de tiempo dado, o hasta que se cumpla con una condicion; entre ellas tenemos while, do-while, y for. las sentencias de salto llevan al compilador a un punto especifico del programa o hacia la siguiente sentencia de ejecucion; entre ellas tenemos break, continue, y return.  en algunos casos suele ser necesario convertir un tipo de dato a otro, esto se le conoce como conversion de tipos, modelado, o tipado, asi de esta forma poder realizar las operaciones necesarias sobre el valor que se desea convertir. se debe tener en cuenta el tipo de dato que se va a convertir, ya que si se convierte un dato que tenga una cantidad menor de bit al anterior este tendra perdida de informacion, un ejemplo de tipado puede ser un numero long que se desea convertir a int, el compilador eliminara los primeros 32bit del long para ajustarlo al int ya que el int es de 32bit y el long de 64. si la conversion se realiza a un tipo de datos de menos bit a un tipo de datos con mayor bit, la conversion se realiza automaticamente llamada conversion implicita, pero si se realiza de un tipo de datos con mayor bit a menor bit se tiene que realizar una conversion explicita, la cual se realiza con un casting, al usar este metodo se obliga a realizar la conversion por lo cual puede haber perdida de datos en la conversion. para realizar una conversion explicita se tiene que poner el tipo de dato que se desea realizar la conversion entre parentesis, luego el valor o la variable que se desea convertir. un ejemplo de conversion de tipo explicito puede ser:  un ejemplo de una conversion de tipo implicita puede ser:  la siguiente tabla muestra los tipos de datos que se pueden realizar una conversion implicita desde el dato origen, hasta el dato destino que es el dato en el que se va a convertir.  los tipos de datos booleanos no pueden ser convertidos a otro tipo de datos, por ningun metodo mencionado anteriormente. otro tipo de conversion que no se encuentre en esta tabla desde el origen al destino, tiene que realizarse por medio de una conversion explicita por casting. cuando se desea realizar una conversion de un tipo string como origen a otro tipo, es necesario utilizar una funcion que se encarga de convertir el tipo de dato, la funcion necesaria se compone de la variable que va almacenar el resultado, y dependiendo de la variable se usa el parametro que inicia con el tipo de dato a convertir, integer, byte, short, o long, seguida de punto “. “, el cual indica que se cargaran los atributos del parametro, en donde cargaremos el parseint si queremos convertir a interger o parsebyte si queremos convertir a byte, o dependiendo del tipo de dato, seguido de parentesis en donde se agregara el valor de string a convertir. algunos ejemplos puede ser:  esto suele ser usado para realizar una conversion de texto cuando se ingresan valores numericos por una entrada a java, la cual los detecta como string, asi de esta forma puede convertir el texto que se ingresa a un numero para realizar operaciones, como una calculadora.  sun microsystem, como creador del lenguaje de programacion java y de la plataforma jdk, mantiene fuertes politicas para mantener una especificacion del lenguaje​ asi como de la maquina virtual​ a traves del jcp. es debido a este esfuerzo que se mantiene un estandar de facto.  son innumerables las compañias que desarrollan aplicaciones para java y/o estan volcadas con esta tecnologia:​  en 1995 alguien dijo[¿quien?] que java fue creado para abrir una nueva via en la gestion de software complejo, y es por regla general aceptado que se ha comportado bien en ese aspecto. sin embargo no puede decirse que java no tenga grietas ni que se adapta completamente a todos los estilos de programacion, todos los entornos, o todas las necesidades.  la apariencia externa (el ‘‘‘look and feel’’’) de las aplicaciones gui (graphical user interface) escritas en java usando la plataforma swing difiere a menudo de la que muestran aplicaciones nativas. aunque el programador puede usar el juego de herramientas awt (abstract windowing toolkit) que genera objetos graficos de la plataforma nativa, el awt no es capaz de funciones graficas avanzadas sin sacrificar la portabilidad entre plataformas; ya que cada una tiene un conjunto de api distinto, especialmente para objetos graficos de alto nivel. las herramientas de swing, escritas completamente en java, evitan este problema construyendo los objetos graficos a partir de los mecanismos de dibujo basicos que deben estar disponibles en todas las plataformas. el inconveniente es el trabajo extra requerido para conseguir la misma apariencia de la plataforma destino. aunque esto es posible (usando gtk+ y el look-and-feel de windows), la mayoria de los usuarios no saben como cambiar la apariencia que se proporciona por defecto por aquella que se adapta a la de la plataforma.  el bytecode de java puede ser interpretado en tiempo de ejecucion por la maquina virtual, o bien compilado al cargarse el programa, o durante la propia ejecucion, para generar codigo nativo que se ejecuta directamente sobre el hardware. si es interpretado, sera mas lento que usando el codigo maquina intrinseco de la plataforma destino. si es compilado, durante la carga inicial o la ejecucion, la penalizacion esta en el tiempo necesario para llevar a cabo la compilacion.  algunas caracteristicas del propio lenguaje conllevan una penalizacion en tiempo, aunque no son unicas de java. algunas de ellas son el chequeo de los limites de arrays, chequeo en tiempo de ejecucion de tipos, y la indireccion de funciones virtuales.  el uso de un recolector de basura para eliminar de forma automatica aquellos objetos no requeridos, añade una sobrecarga que puede afectar al rendimiento, o ser apenas apreciable, dependiendo de la tecnologia del recolector y de la aplicacion en concreto. las jvm modernas usan recolectores de basura que gracias a rapidos algoritmos de manejo de memoria, consiguen que algunas aplicaciones puedan ejecutarse mas eficientemente.  el rendimiento entre un compilador jit y los compiladores nativos puede ser parecido, aunque la distincion no esta clara en este punto. la compilacion mediante el jit puede consumir un tiempo apreciable, un inconveniente principalmente para aplicaciones de corta duracion o con gran cantidad de codigo. sin embargo, una vez compilado, el rendimiento del programa puede ser comparable al que consiguen compiladores nativos de la plataforma destino, inclusive en tareas numericas. aunque java no permite la expansion manual de llamadas a metodos, muchos compiladores jit realizan esta optimizacion durante la carga de la aplicacion y pueden aprovechar informacion del entorno en tiempo de ejecucion para llevar a cabo transformaciones eficientes durante la propia ejecucion de la aplicacion. esta recompilacion dinamica, como la que proporciona la maquina virtual hotspot de sun, puede llegar a mejorar el resultado de compiladores estaticos tradicionales, gracias a los datos que solamente estan disponibles durante el tiempo de ejecucion.  java fue diseñado para ofrecer seguridad y portabilidad, y no ofrece acceso directo al hardware de la arquitectura ni al espacio de direcciones. java no soporta expansion de codigo ensamblador, aunque las aplicaciones pueden acceder a caracteristicas de bajo nivel usando bibliotecas nativas (jni, java native interfaces).  caracteristicas de java:  1. lenguaje simple: “se lo conoce como lenguaje simple porque viene de la misma estructura de c y c++; ya que c++ fue un referente para la creacion de java por eso utiliza determinadas caracteristicas de c++ y se han eliminado otras.”  2. orientado a objetos.  3. multihilos: java tiene una facilidad de cumplir varias funciones al mismo tiempo, gracias a su funcion de multihilos, ya que por cada hilo que el programa tenga se ejecutaran en tiempo real muchas funciones al mismo tiempo.  alto rendimiento: java es considerado de alto rendimiento por ser tan veloz en el momento de correr los programas y por ahorrarse muchas lineas de codigo.  el jre (java runtime environment, o entorno en tiempo de ejecucion de java) es el software necesario para ejecutar cualquier aplicacion desarrollada para la plataforma java. el usuario final usa el jre como parte de paquetes software o plugins (o conectores) en un navegador web. sun ofrece tambien el sdk de java 2, o jdk (java development kit) en cuyo seno reside el jre, e incluye herramientas como el compilador de java, javadoc para generar documentacion o el depurador. puede tambien obtenerse como un paquete independiente, y puede considerarse como el entorno necesario para ejecutar una aplicacion java, mientras que un desarrollador debe ademas contar con otras facilidades que ofrece el jdk.  se define tres plataformas en un intento por cubrir distintos entornos de aplicacion. asi, ha distribuido muchas de sus api (application program interface) de forma que pertenezcan a cada una de las plataformas:  las clases en las api de java se organizan en grupos disjuntos llamados paquetes. cada paquete contiene un conjunto de interfaces, clases y excepciones relacionadas. la informacion sobre los paquetes que ofrece cada plataforma puede encontrarse en la documentacion de esta.  el conjunto de las api es controlado por sun microsystems junto con otras entidades o personas a traves del programa jcp (java community process). las compañias o individuos participantes del jcp pueden influir de forma activa en el diseño y desarrollo de las api, algo que ha sido motivo de controversia.  las extensiones​ de java estan en paquetes que cuelgan de la raiz javax: javax.*. no se incluyen en la jdk o el jre. algunas de las extensiones y arquitecturas ligadas estrechamente al lenguaje java son:  la evolucion basada en un comite en el que participen todos los implicados no es suficiente y la comunidad demandaba desde hace tiempo la liberacion de las api y bibliotecas basicas de la jdk.  en diciembre de 2006, sun microsystems comenzo el relanzamiento de su plataforma java​ bajo la licencia gpl de gnu.  en abril de 2009 oracle adquirio sun microsystems, lo que genero temor en la comunidad ante la posible mercantilizacion del lenguaje de programacion orientado a objetos mas popular actualmente. por ahora oracle ha seguido manteniendo java, estando las versiones posteriores a la 6 bajo su control.  se instala una version homebrew de pspkvm (0.5.5) para emular la plataforma de java en psp. esto permite usar programas java en esta videoconsola.  existen alternativas para el entorno de ejecucion y de desarrollo de java con una gran cobertura de funcionalidades con respecto a las implementaciones comerciales de sun, ibm, bea, etc.  notar que este articulo fue escrito antes de la liberacion del codigo fuente de java. en la actualidad la postura de la free software foundation y de richard stallman han cambiado[cita requerida], mostrandose partidarios ambos de su uso en software libre. ",
        "snippet": "Java es un lenguaje de programación y una plataforma informática que fue comercializada por primera vez en 1995 por Sun Microsystems.[2]​[3]​",
        "enlaces_salientes": [
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/JavaScript",
            "/wiki/James_Gosling",
            "/wiki/Sun_Microsystems",
            "/wiki/Extensi%C3%B3n_de_archivo",
            "/wiki/Paradigma_de_programaci%C3%B3n",
            "/wiki/Programaci%C3%B3n_orientada_a_objetos",
            "/wiki/Programaci%C3%B3n_imperativa",
            "/wiki/Sun_Microsystems",
            "/wiki/Oracle_Corporation",
            "/wiki/Sistema_de_tipos",
            "/wiki/Tipado_fuerte",
            "/wiki/Variable_est%C3%A1tica",
            "/wiki/OpenJDK",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%2B%2B",
            "/wiki/Objective-C",
            "/wiki/C_Sharp",
            "/wiki/J_Sharp",
            "/wiki/JavaScript",
            "/wiki/PHP",
            "/wiki/Python",
            "/wiki/Sistema_operativo",
            "/wiki/Multiplataforma",
            "/wiki/Licencia_de_software",
            "/wiki/Licencia_p%C3%BAblica_general_de_GNU",
            "/wiki/Java_Community_Process",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Plataforma_(inform%C3%A1tica)",
            "/wiki/Sun_Microsystems",
            "/wiki/James_Gosling",
            "/wiki/Sun_Microsystems",
            "/wiki/Oracle_Corporation",
            "/wiki/Java_(plataforma_de_software)",
            "/wiki/C_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/C%2B%2B",
            "/wiki/Lenguaje_de_bajo_nivel",
            "/wiki/Compilador",
            "/wiki/Bytecode_Java",
            "/wiki/M%C3%A1quina_virtual_Java",
            "/wiki/Arquitectura_de_computadoras",
            "/wiki/Sun_Microsystems",
            "/wiki/Implementaci%C3%B3n_de_referencia",
            "/wiki/Compilador",
            "/wiki/Biblioteca_(inform%C3%A1tica)",
            "/wiki/GNU_General_Public_License",
            "/wiki/GNU_Compiler_for_Java",
            "/wiki/GNU_Classpath",
            "/wiki/Set-top_box",
            "/wiki/James_Gosling",
            "/wiki/C%2B%2B",
            "/wiki/Mosaic",
            "/wiki/HotJava",
            "/wiki/Sun_Microsystems",
            "/wiki/Navegador_web",
            "/wiki/M%C3%A1quina_virtual_Java",
            "/wiki/Applet",
            "/wiki/JDK",
            "/wiki/Java_SE",
            "/wiki/Java_Community_Process",
            "/wiki/23_de_enero",
            "/wiki/1996",
            "/wiki/19_de_febrero",
            "/wiki/1997",
            "/wiki/JavaBeans",
            "/wiki/JDBC",
            "/wiki/Java_Remote_Method_Invocation",
            "/wiki/8_de_diciembre",
            "/wiki/1998",
            "/wiki/Strictfp",
            "/wiki/Reflexi%C3%B3n_(inform%C3%A1tica)",
            "/wiki/Swing_(biblioteca_gr%C3%A1fica)",
            "/wiki/Sun_Microsystems",
            "/wiki/Compilador",
            "/wiki/Compilaci%C3%B3n_en_tiempo_de_ejecuci%C3%B3n",
            "/wiki/Java_IDL",
            "/wiki/Interfaz_(Java)",
            "/wiki/CORBA",
            "/wiki/8_de_mayo",
            "/wiki/2000",
            "/wiki/Java_Remote_Method_Invocation",
            "/wiki/CORBA",
            "/wiki/JavaSound",
            "/wiki/JNDI",
            "/wiki/Java_Platform_Debugger_Architecture",
            "/wiki/6_de_febrero",
            "/wiki/2002",
            "/wiki/Expresiones_regulares",
            "/wiki/Perl_programming_language",
            "/wiki/JPEG",
            "/wiki/PNG",
            "/wiki/XML",
            "/wiki/XSLT",
            "/wiki/JSSE",
            "/wiki/JAAS",
            "/wiki/Java_Web_Start",
            "/wiki/30_de_septiembre",
            "/wiki/2004",
            "/wiki/Programaci%C3%B3n_gen%C3%A9rica",
            "/wiki/Tiempo_de_compilaci%C3%B3n",
            "/wiki/Conversi%C3%B3n_de_tipos",
            "/wiki/Metadatos",
            "/wiki/Tipo_primitivo",
            "/wiki/Enumeraci%C3%B3n",
            "/wiki/Bucle_(programaci%C3%B3n)",
            "/wiki/11_de_diciembre",
            "/wiki/2006",
            "/wiki/2006",
            "/wiki/Clausura_(inform%C3%A1tica)",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/2005",
            "/wiki/CORBA",
            "/wiki/OSGi",
            "/wiki/Lenguaje_orientado_a_objetos",
            "/wiki/Objeto_(programaci%C3%B3n)",
            "/wiki/Orientado_a_objetos",
            "/wiki/Objetos_(programaci%C3%B3n_orientada_a_objetos)",
            "/wiki/GCJ",
            "/wiki/Sun_Microsystems",
            "/wiki/Sun_Microsystems",
            "/wiki/Sun_Microsystems",
            "/wiki/Sun_Microsystems",
            "/wiki/Sun_Microsystems",
            "/wiki/Debug",
            "/wiki/OSGi",
            "/wiki/Recolector_de_basura",
            "/wiki/Fuga_de_memoria",
            "/wiki/Recolecci%C3%B3n_de_basura",
            "/wiki/C%2B%2B",
            "/wiki/Sobrecarga_(inform%C3%A1tica)",
            "/wiki/Herencia_m%C3%BAltiple",
            "/wiki/Interfaz_(Java)",
            "/wiki/Array",
            "/wiki/M%C3%A9todo_(programaci%C3%B3n_orientada_a_objetos)",
            "/wiki/Unix",
            "/wiki/Windows",
            "/wiki/Applet_Java",
            "/wiki/HTML_5#Diferencias_entre_HTML5_y_HTML4.2FXHTML",
            "/wiki/Abstract_Window_Toolkit",
            "/wiki/Java_Servlet",
            "/wiki/Servlets",
            "/wiki/Interfaz_(Java)",
            "/wiki/Swing_(biblioteca_gr%C3%A1fica)",
            "/wiki/Interfaz_(Java)",
            "/wiki/Hilo_(inform%C3%A1tica)",
            "/wiki/Android",
            "/wiki/Applet_Java",
            "/wiki/ActiveX",
            "/wiki/Macromedia_Flash",
            "/wiki/Java_Web_Start",
            "/wiki/Java_Servlet",
            "/wiki/Java_Server_Pages",
            "/wiki/Common_Gateway_Interface",
            "/wiki/Interfaz_de_programaci%C3%B3n_de_aplicaciones",
            "/wiki/Framework",
            "/wiki/Struts",
            "/wiki/Computador_personal",
            "/wiki/Abstract_Window_Toolkit",
            "/wiki/Swing_(biblioteca_gr%C3%A1fica)",
            "/wiki/SWT",
            "/wiki/JRE",
            "/wiki/Microsoft",
            "/wiki/Apple_Inc.",
            "/wiki/Mac_OS",
            "/wiki/GNU/Linux",
            "/wiki/Applets",
            "/wiki/Case_sensitive",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Telefon%C3%ADa_m%C3%B3vil",
            "/wiki/Entorno_de_desarrollo_integrado",
            "/wiki/IntelliJ_IDEA",
            "/wiki/Netbeans",
            "/wiki/Eclipse_(software)",
            "/wiki/Apache",
            "/wiki/IBM",
            "/wiki/Oracle",
            "/wiki/Minecraft",
            "/wiki/Pokemon_Go",
            "/wiki/C%2B%2B",
            "/wiki/C",
            "/wiki/IEEE_754",
            "/wiki/GPL",
            "/wiki/Ruby",
            "/wiki/Smalltalk",
            "/wiki/Funci%C3%B3n_virtual",
            "/wiki/C%C3%B3digo_ensamblador",
            "/wiki/JRE",
            "/wiki/Javadoc",
            "/wiki/Depurador",
            "/wiki/Estructuras_de_datos",
            "/wiki/Lista_(inform%C3%A1tica)",
            "/wiki/Array",
            "/wiki/%C3%81rbol_(inform%C3%A1tica)",
            "/wiki/Conjunto",
            "/wiki/XML",
            "/wiki/JDBC",
            "/wiki/Interfaz_(Java)",
            "/wiki/Java_Remote_Method_Invocation",
            "/wiki/CORBA",
            "/wiki/Abstract_Window_Toolkit",
            "/wiki/Swing_(biblioteca_gr%C3%A1fica)",
            "/wiki/Interfaz_de_programaci%C3%B3n_de_aplicaciones",
            "/wiki/Paquete_Java",
            "/wiki/Java_EE",
            "/wiki/Interfaz_de_programaci%C3%B3n_de_aplicaciones",
            "/wiki/Diciembre_de_2006",
            "/wiki/Sun_Microsystems",
            "/wiki/Licencia_p%C3%BAblica_general_de_GNU",
            "/wiki/GNU",
            "/wiki/Oracle",
            "/wiki/Sun_Microsystems",
            "/wiki/Homebrew",
            "/wiki/PlayStation_Portable",
            "/wiki/Richard_Stallman",
            "/wiki/12_de_abril",
            "/wiki/2004",
            "/wiki/Free_Software_Foundation",
            "/wiki/Richard_Stallman",
            "/wiki/Applet_Java",
            "/wiki/JavaOne",
            "/wiki/JavaOS",
            "/wiki/Javapedia",
            "/wiki/Java_Community_Process",
            "/wiki/Java_User_Group",
            "/wiki/M%C3%A1quina_virtual_Java",
            "/wiki/OpenJDK",
            "/wiki/Plataforma_Java",
            "/wiki/James_Gosling",
            "/wiki/James_Gosling",
            "/wiki/Bill_Joy",
            "/wiki/Bruce_Eckel",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Open_Hub"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/JSTOR",
        "titulo": "JSTOR",
        "contenido": "jstor (abreviatura en ingles de journal storage, «almacen de publicaciones periodicas») es un sistema de almacenamiento en linea de publicaciones academicas. fundada en 1995, jstor es una sociedad estadounidense con base en la ciudad de nueva york.  jstor fue concebida como la solucion a uno de los mayores problemas que deben enfrentar hoy las bibliotecas (especialmente las universitarias y las de investigacion) debido al creciente aumento de publicaciones academicas en la actualidad. william g. bowen, su fundador, fue presidente de la universidad de princeton desde el año 1972 al 1988.​ en general, a muchas bibliotecas se les hacia excesivamente costoso el mantener una interesante coleccion de publicaciones debido a cuestiones de espacio, por lo que encontraron en jstor una solucion viable a dicha cuestion, digitalizando muchos de sus titulos y almacenandolos en su base de datos en linea con la confianza en que estos permanecerian disponibles a largo plazo.  a partir del exito alcanzado con el proyecto inicial, bowen y kevin guthrie (quien seria mas tarde presidente de jstor) se interesaron en ampliar el numero de publicaciones participantes hasta la fecha. de esta manera se reunieron con representantes de la real sociedad de londres y, como resultado, se pacto la digitalizacion de sus principales articulos que se remiten a sus origenes en 1665. el trabajo de inclusion de dichos volumenes en la base de datos en linea fue finalizado en diciembre de 2000.​  hacia junio de 2007, la base de datos contaba con mas de 23 millones de paginas de texto.​ hacia julio de 2007, el material de jstor es provisto por 446 editores. cerca de 53 millones de busquedas de archivos fueron realizadas entre enero y julio de 2007.​  el acceso a jstor se encuentra autorizado a bibliotecas, universidades y editores de todo el mundo que han firmado un acuerdo con la institucion. estas, a su vez, facilitan el acceso de sus miembros a jstor de manera gratuita a traves de internet. tambien existe la posibilidad de suscribirse, mediante pago, de manera individual o privada.  el programador y activista de internet aaron swartz, que fue coautor de los rss y colaboro en la creacion de las licencias creative commons, fue acusado el 19 de julio de 2011 de descargar 4.8 millones de articulos y otros documentos de la base de datos de jstor, presuntamente con el fin de compartirlos a traves de sitios de descarga gratuita.​ poco antes de que se iniciara el juicio, aaron swartz aparecio muerto en su casa a la edad de 26 años. segun la investigacion del caso, se trataria de un suicidio debido al acoso por parte del deficiente sistema de justicia de estados unidos y del fiscal stephen heymann, el cual intento avanzar su carrera con el caso de aaron swartz.​   ",
        "snippet": "JSTOR (abreviatura en inglés de Journal STORage, «almacén de publicaciones periódicas») es un sistema de almacenamiento en línea de publicaciones académicas. Fundada en 1995, JSTOR es una sociedad estadounidense con base en la ciudad de Nueva York.",
        "enlaces_salientes": [
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/Dominio_de_Internet",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Biblioteca_digital",
            "/wiki/Sitio_web",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/1995",
            "/wiki/Alexa_Internet",
            "/wiki/Estadounidense",
            "/wiki/Nueva_York",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Royal_Society_de_Londres",
            "/wiki/Internet",
            "/wiki/Aaron_Swartz",
            "/wiki/RSS",
            "/wiki/Licencias_Creative_Commons",
            "/wiki/Wayback_Machine",
            "/wiki/Princeton_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/BIBSYS"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/George_Boolos",
        "titulo": "George Boolos",
        "contenido": "george stephen boolos (4 de septiembre de 1940, nueva york – 27 de mayo de 1996) fue un filosofo y estudioso de logica matematica que enseño en el massachusetts institute of technology.  boolos se graduo en la universidad de princeton en 1961 con un ba en matematicas. en 1963 obtuvo el b.plilosophy de la universidad de oxford. en 1966, obtuvo el primer ph.d. en filosofia que otorgaba el massachusetts institute of technology, bajo la direccion de hilary putnam. luego de tres años de docencia en la universidad de columbia, regreso al mit en 1969, donde permanecio por el resto de su carrera hasta su muerte de cancer.​  un presentador carismatico, famoso por su claridad e inteligencia, una vez dio una clase (1994a) sobre el segundo teorema de incompletitud de godel , empleando solo palabras de una silaba. al final de su exposicion, hilary putnam le pregunto, \"sr. boolos, podria explicarnos que es lo que tiene que ver la jerarquia analitica con el mundo real?\" sin dudarlo boolos respondio: it's part of it (\"es parte de el\").  boolos era un experto en todo tipo de acertijos, en 1993 boolos llego a la final regional de londres de la competencia de palabras cruzadas del times. su puntaje se ubico entre los mas altos conseguidos alguna vez por un jugador estadounidense. escribio un articulo sobre \"el acertijo logico mas dificil\", uno de los muchos acertijos creados por raymond smullyan.  junto con richard jeffrey, boolos escribieron un texto clasico universitario sobre logica matematica, llamado computability and logic.  si bien kurt godel escribio el primer articulo sobre logica demostrativa, que aplica la logica modal — la logica de la necesidad y posibilidad — a la teoria de la demostracion matematica, pero godel nunca desarrollo el tema de una manera significativa. boolos fue uno de los primeros pioneros, y escribio el primer analisis sobre el mismo en un libro llamado, la in-demostrabilidad de la consistencia, publicado en 1979. algunos años mas tarde publico otra obra al encontrar la solucion de un problema insoluble en, la logica de la demostrabilidad, publicado en 1993.  boolos era una autoridad en el matematico y filosofo aleman del siglo xix gottlob frege. boolos demostro una conjetura postulada por crispin wright (que fuera tambien probada por otros en forma independiente), que el sistema de grundgesetze de frege, por mucho tiempo considerado viciado por la paradoja de russell, podia ser librado de su inconsistencia si se reemplazaba uno de sus axiomas, la famosa ley basica v por el principio de hume. desde entonces el sistema resultante ha sido objeto de intensos trabajos.  boolos sostenia que si uno lee las variables de segundo orden en logica de segundo orden monadica en forma plural, entonces la logica de segundo orden puede ser interpretada como que no posee vinculos ontologicos con otras entidades que no sean aquellas pertenecientes al rango de las variables de primer orden. el resultado es la cuantificacion plural. david lewis empleo cuantificacion plural en su parts of classes para obtener un sistema en el cual la teoria de conjuntos zermelo-fraenkel y los axiomas de peano eran todos teoremas. mientras que por lo general se identifica a boolos como el creador de la cuantificacion plural, peter simons (1982) sostiene que la idea seminal se encuentra en trabajos de stanislaw lesniewski.  poco antes de fallecer, boolos eligio 30 de sus trabajos para ser publicados en un libro. este libro postumo titulado logica, logica, y logica es tal vez su obra mas reconocida. el libro es una reimpresion de gran parte del trabajo de boolos sobre la rehabilitacion de frege, como tambien incluye trabajos sobre teoria de conjuntos, logica de segundo orden y no encuadrable por una logica de primer orden, cuantificacion plural, teoria de la demostracion, y tres trabajos profundos sobre el teorema de la incompletitud de godel. tambien hay trabajos sobre dedekind, cantor, y russell.  lll = reimpreso en logic, logic, and logic.  fpm = reimpreso en demopoulos, w., ed., 1995. frege's philosophy of mathematics. harvard univ. press.  1968 (with hilary putnam), \"degrees of unsolvability of constructible sets of integers,\" journal of symbolic logic 33: 497-513.  1969, \"effectiveness and natural languages\" in sidney hook, ed., language and philosophy. new york university press.  1970, \"on the semantics of the constructible levels,\" ' 16: 139-148.  1970a, \"a proof of the lowenheim-skolem theorem,\" notre dame journal of formal logic 11: 76-78.  1971, \"the iterative conception of set,\" journal of philosophy 68: 215-231. reprinted in paul benacerraf and hilary putnam, eds.,1984. philosophy of mathematics: selected readings, 2nd ed. cambridge univ. press: 486-502. lll  1973, \"a note on evert willem beth's theorem,\" bulletin de l'academie polonaise des sciences 2: 1-2.  1974, \"arithmetical functions and minimization,\" zeitschrift fur mathematische logik und grundlagen der mathematik 20: 353-354.  1974a, \"reply to charles parsons' 'sets and classes'.\" first published in lll.  1975, \"friedman's 35th problem has an affirmative solution,\" notices of the american mathematical society 22: a-646.  1975a, \"on kalmar's consistency proof and a generalization of the notion of omega-consistency,\" archiv fur mathematische logik und grundlagenforschung 17: 3-7.  1975a, \"on second-order logic,\" journal of philosophy 72: 509-527. lll.  1976, \"on deciding the truth of certain statements involving the notion of consistency,\" journal of symbolic logic 41: 779-781.  1977, \"on deciding the provability of certain fixed point statements,\" journal of symbolic logic 42: 191-193.  1979, \"reflection principles and iterated consistency assertions,\" journal of symbolic logic 44: 33-35.  1980, \"omega-consistency and the diamond,\" studia logica 39: 237-243.  1980a, \"on systems of modal logic with provability interpretations,\" theoria 46: 7-18.  1980b, \"provability in arithmetic and a schema of grzegorczyk,\" fundamenta mathematicae 106: 41-45.  1980c, \"provability, truth, and modal logic,\" journal of philosophical logic 9: 1-7.  1980d, review of raymond m. smullyan, what is the name of this book? the philosophical review 89: 467-470.  1981, \"for every a there is a b,\" linguistic inquiry 12: 465-466.  1981a, review of robert m. solovay, provability interpretations of modal logic,\" journal of symbolic logic 46: 661-662.  1982, \"extremely undecidable sentences,\" journal of symbolic logic 47: 191-196.  1982a, \"on the nonexistence of certain normal forms in the logic of provability,\" journal of symbolic logic 47: 638-640.  1984, \"don't eliminate cut,\" journal of philosophical logic 13: 373-378. lll.  1984a, \"the logic of provability,\" american mathematical monthly 91: 470-480.  1984b, \"nonfirstorderizability again,\" linguistic inquiry 15: 343.  1984c, \"on 'syllogistic inference',\" cognition 17: 181-182.  1984d, \"to be is to be the value of a variable (or some values of some variables),\" journal of philosophy 81: 430-450. lll.  1984e, \"trees and finite satisfiability: proof of a conjecture of john burgess,\" notre dame journal of formal logic 25: 193-197.  1984f, \"the justification of mathematical induction,\" psa 2: 469-475. lll.  1985, \"1-consistency and the diamond,\" notre dame journal of formal logic 26: 341-347.  1985a, \"nominalist platonism,\" the philosophical review 94: 327-344. lll.  1985b, \"reading the begriffsschrift,\" mind 94: 331-344. lll; fpm: 163-81.  1985c (with giovanni sambin), \"an incomplete system of modal logic,\" journal of philosophical logic 14: 351-358.  1986, review of yuri manin, a course in mathematical logic, journal of symbolic logic 51: 829-830.  1986-87, \"saving frege from contradiction,\" proceedings of the aristotelian society 87: 137-151. lll; fpm 438-52.  1987, \"the consistency of frege's foundations of arithmetic\" in j. j. thomson, ed., 1987. on being and saying: essays for richard cartwright. mit press: 3-20. lll; fpm: 211-233.  1987a, \"a curious inference,\" journal of philosophical logic 16: 1-12. lll.  1987b, \"on notions of provability in provability logic,\" abstracts of the 8th international congress of logic, methodology and philosophy of science 5: 236-238.  1987c (with vann mcgee), \"the degree of the set of sentences of predicate provability logic that are true under every interpretation,\" journal of symbolic logic 52: 165-171.  1988, \"alphabetical order,\" notre dame journal of formal logic 29: 214-215.  1988a, review of craig smorynski, self-reference and modal logic, journal of symbolic logic 53: 306-309.  1989, \"iteration again,\" philosophical topics 17: 5-21. lll.  1989a, \"a new proof of the godel incompleteness theorem,\" notices of the american mathematical society 36: 388-390. lll. an afterword appeared under the title \"a letter from george boolos,\" ibid., p. 676. lll.  1990, \"on 'seeing' the truth of the godel sentence,\" behavioral and brain sciences 13: 655-656. lll.  1990a, review of jon barwise and john etchemendy, turing's world and tarski's world, journal of symbolic logic 55: 370-371.  1990b, review of v. a. uspensky, godel's incompleteness theorem, journal of symbolic logic 55: 889-891.  1990c, \"the standard of equality of numbers\" in boolos, g., ed., meaning and method: essays in honor of hilary putnam. cambridge univ. press: 261-278. lll; fpm: 234-254.  1991, \"zooming down the slippery slope,\" nous 25: 695-706. lll.  1991a (with giovanni sambin), \"provability: the emergence of a mathematical modality,\" studia logica 50: 1-23.  1993, \"the analytical completeness of dzhaparidze's polymodal logics,\" annals of pure and applied logic 61: 95-111.  1993a, \"whence the contradiction?\" aristotelian society supplementary volume 67: 213-233. lll.  1994, \"1879?\" in p. clark and b. hale, eds. reading putnam. oxford: blackwell: 31-48. lll.  1994a, \"the advantages of honest toil over theft,\" in a. george, ed., mathematics and mind. oxford university press: 27-44. lll.  1994a, \"godel's second incompleteness theorem explained in words of one syllable,\" mind 103: 1-3. lll.  1995, \"frege's theorem and the peano postulates,\" bulletin of symbolic logic 1: 317-326. lll.  1995a, \"introductory note to *1951\" in solomon feferman et al., eds., kurt godel, collected works, vol. 3. oxford university press: 290-304. lll. *1951 is godel’s 1951 gibbs lecture, \"some basic theorems on the foundations of mathematics and their implications.\"  1995b, \"quotational ambiguity\" in leonardi, p., and santambrogio, m., eds. on quine. cambridge university press: 283-296. lll  1996, \"the hardest logical puzzle ever,\" harvard review of philosophy 6: 62-65. lll. italian translation by massimo piattelli-palmarini, \"l'indovinello piu difficile del mondo,\" la repubblica (16 de abril de 1992): 36-37.  1996a, \"on the proof of frege's theorem\" in a. morton and s. p. stich, eds., paul benacerraf and his critics. cambridge ma: blackwell. lll.  1997, \"constructing cantorian counterexamples,\" journal of philosophical logic 26: 237-239. lll.  1997a, \"is hume's principle analytic?\" in richard g. heck, jr., ed., language, thought, and logic: essays in honour of michael dummett. oxford univ. press: 245-61. lll.  1997b (with richard heck), \"die grundlagen der arithmetik, §§82-83\" in matthias schirn, ed., philosophy of mathematics today. oxford univ. press. lll.  1998, \"gottlob frege and the foundations of arithmetic.\" first published in lll. french translation in mathieu marion and alain voizard eds., 1998. frege. logique et philosophie. montreal and paris: l'harmattan: 17-32.  2000, \"must we believe in set theory?\" in gila sher and richard tieszen, eds., between logic and intuition: essays in honour of charles parsons. cambridge university press. lll. ",
        "snippet": "George Stephen Boolos (4 de septiembre de 1940, Nueva York – 27 de mayo de 1996) fue un filósofo y estudioso de lógica matemática que enseñó en el Massachusetts Institute of Technology.",
        "enlaces_salientes": [
            "/wiki/George_Boolos",
            "/wiki/George_Boolos",
            "/wiki/George_Boolos",
            "/wiki/Nueva_York",
            "/wiki/Estados_Unidos",
            "/wiki/Cambridge_(Massachusetts)",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Instituto_de_Tecnolog%C3%ADa_de_Massachusetts",
            "/wiki/Hilary_Putnam",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Universidad_de_Columbia",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Beca_Guggenheim",
            "/wiki/4_de_septiembre",
            "/wiki/1940",
            "/wiki/Nueva_York",
            "/wiki/27_de_mayo",
            "/wiki/1996",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Massachusetts_Institute_of_Technology",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Universidad_de_Oxford",
            "/wiki/Massachusetts_Institute_of_Technology",
            "/wiki/Hilary_Putnam",
            "/wiki/Universidad_de_Columbia",
            "/wiki/1969",
            "/wiki/C%C3%A1ncer",
            "/wiki/Teoremas_de_la_incompletitud_de_G%C3%B6del",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Hilary_Putnam",
            "/wiki/Jerarqu%C3%ADa_anal%C3%ADtica",
            "/wiki/Palabras_cruzadas",
            "/wiki/The_Times",
            "/wiki/El_acertijo_l%C3%B3gico_m%C3%A1s_dif%C3%ADcil",
            "/wiki/Raymond_Smullyan",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/L%C3%B3gica_demostrativa",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/Demostraci%C3%B3n_matem%C3%A1tica",
            "/wiki/Gottlob_Frege",
            "/wiki/Paradoja_de_Russell",
            "/wiki/Gottlob_Frege",
            "/wiki/El_principio_de_Hume",
            "/wiki/L%C3%B3gica_de_segundo_orden",
            "/wiki/Cuantificaci%C3%B3n_plural",
            "/wiki/Ontolog%C3%ADa",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/Cuantificaci%C3%B3n_plural",
            "/wiki/David_Kellogg_Lewis",
            "/wiki/Axiomas_de_Zermelo-Fraenkel",
            "/wiki/Axiomas_de_Peano",
            "/wiki/Cuantificaci%C3%B3n_plural",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/L%C3%B3gica_de_segundo_orden",
            "/wiki/Cuantificaci%C3%B3n_plural",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Teoremas_de_la_incompletitud_de_G%C3%B6del",
            "/wiki/Richard_Dedekind",
            "/wiki/Georg_Cantor",
            "/wiki/Bertrand_Russell",
            "/wiki/L%C3%B3gica_demostrativa",
            "/wiki/El_acertijo_l%C3%B3gico_m%C3%A1s_dif%C3%ADcil",
            "/wiki/Cambridge_University_Press",
            "/wiki/Hilary_Putnam",
            "/wiki/Harvard_University_Press",
            "/wiki/Hilary_Putnam",
            "/wiki/Sidney_Hook",
            "/wiki/Paul_Benacerraf",
            "/wiki/Hilary_Putnam",
            "/wiki/Raymond_M._Smullyan",
            "/wiki/Robert_M._Solovay",
            "/wiki/MIT_Press",
            "/wiki/Hilary_Putnam",
            "/wiki/Oxford_University_Press",
            "/wiki/Frege",
            "/wiki/Solomon_Feferman",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Frege",
            "/wiki/Paul_Benacerraf",
            "/wiki/David_Hume",
            "/wiki/Michael_Dummett",
            "/wiki/Gottlob_Frege",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Alonzo_Church",
        "titulo": "Alonzo Church",
        "contenido": "alonzo church (14 de junio de 1903 - 11 de agosto de 1995), matematico y logico estadounidense creador de la base de la computacion teorica. nacido en la ciudad de washington, se diplomo en 1924 y obtuvo su doctorado en 1927 en la universidad de princeton, donde ejercio como profesor entre 1929 y 1967.  su obra mas conocida es el desarrollo del calculo lambda, y su trabajo de 1936 que muestra la existencia de problemas indecidibles. este trabajo precedio el famoso trabajo de su alumno alan turing sobre el problema de parada que tambien demostro la existencia de problemas irresolubles por dispositivos mecanicos. luego de revisar la tesis doctoral de turing, demostraron que el calculo lambda y la maquina de turing utilizada para expresar el problema de parada tenian igual poder de expresion; posteriormente demostraron que una variedad de procesos mecanicos alternos para realizar calculos tenian poder de computo equivalente. como resultado se postulo la tesis de church-turing.​  entre los mas conocidos estudiantes de doctorado de church estan stephen kleene, j. barkley rosser, leon henkin, john george kemeny, michael o. rabin, dana scott, simon kochen y raymond smullyan.  church publico entre 1924 y 1995 trabajos sobre logica, filosofia, matematicas y computacion. en su trabajo de 1936 an unsolvable problem of elementary number theory church formulo por primera vez lo que ahora se conoce como la tesis de church que es la identificacion del concepto vago de calculabilidad efectiva con la nocion precisa de funcion recursiva. su articulo a note on the entscheidungsproblem presento lo que ahora se conoce como el teorema de church: la indecidibilidad de la validez de la logica de primer orden. en 1941 publico su monografia the calculi of lambda-conversion. este trabajo tiene gran influencia en el area de computacion teorica.​  el calculo lambda influyo en el diseño del lenguaje lisp, asi como en los lenguajes de programacion funcional. ",
        "snippet": "Alonzo Church (14 de junio de 1903 - 11 de agosto de 1995), matemático y lógico estadounidense creador de la base de la computación teórica. Nacido en la ciudad de Washington, se diplomó en 1924 y obtuvo su doctorado en 1927 en la Universidad de Princeton, donde ejerció como profesor entre 1929 y 1967.",
        "enlaces_salientes": [
            "/wiki/Alonzo_Church",
            "/wiki/Alonzo_Church",
            "/wiki/Alonzo_Church",
            "/wiki/14_de_junio",
            "/wiki/1903",
            "/wiki/Washington,_D._C.",
            "/wiki/EE._UU.",
            "/wiki/11_de_agosto",
            "/wiki/1995",
            "/wiki/EEUU",
            "/wiki/Presbiterianismo",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Oswald_Veblen",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Universidad_de_Princeton",
            "/wiki/UCLA",
            "/wiki/Martin_Davis",
            "/wiki/Leon_Henkin",
            "/wiki/David_Kaplan",
            "/wiki/John_George_Kemeny",
            "/wiki/Stephen_Kleene",
            "/wiki/Michael_O._Rabin",
            "/wiki/Dana_Scott",
            "/wiki/Raymond_Smullyan",
            "/wiki/Alan_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Asociaci%C3%B3n_Estadounidense_para_el_Avance_de_la_Ciencia",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/14_de_junio",
            "/wiki/1903",
            "/wiki/11_de_agosto",
            "/wiki/1995",
            "/wiki/L%C3%B3gico",
            "/wiki/Estadounidense",
            "/wiki/Computaci%C3%B3n_te%C3%B3rica",
            "/wiki/Washington_D.C.",
            "/wiki/1924",
            "/wiki/1927",
            "/wiki/Universidad_de_Princeton",
            "/wiki/1929",
            "/wiki/1967",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/1936",
            "/wiki/Problema_indecidible",
            "/wiki/Alan_Turing",
            "/wiki/Problema_de_parada",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Stephen_Kleene",
            "/wiki/Leon_Henkin",
            "/wiki/John_George_Kemeny",
            "/wiki/Michael_O._Rabin",
            "/wiki/Dana_Scott",
            "/wiki/Raymond_Smullyan",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Entscheidungsproblem",
            "/wiki/Computaci%C3%B3n_te%C3%B3rica",
            "/wiki/Lisp",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/L%C3%B3gica_combinatoria",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Find_a_Grave",
            "/wiki/The_New_York_Times",
            "/wiki/The_Independent",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Pers%C3%A9e_(portal)"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/JSTOR",
        "titulo": "JSTOR",
        "contenido": "jstor (abreviatura en ingles de journal storage, «almacen de publicaciones periodicas») es un sistema de almacenamiento en linea de publicaciones academicas. fundada en 1995, jstor es una sociedad estadounidense con base en la ciudad de nueva york.  jstor fue concebida como la solucion a uno de los mayores problemas que deben enfrentar hoy las bibliotecas (especialmente las universitarias y las de investigacion) debido al creciente aumento de publicaciones academicas en la actualidad. william g. bowen, su fundador, fue presidente de la universidad de princeton desde el año 1972 al 1988.​ en general, a muchas bibliotecas se les hacia excesivamente costoso el mantener una interesante coleccion de publicaciones debido a cuestiones de espacio, por lo que encontraron en jstor una solucion viable a dicha cuestion, digitalizando muchos de sus titulos y almacenandolos en su base de datos en linea con la confianza en que estos permanecerian disponibles a largo plazo.  a partir del exito alcanzado con el proyecto inicial, bowen y kevin guthrie (quien seria mas tarde presidente de jstor) se interesaron en ampliar el numero de publicaciones participantes hasta la fecha. de esta manera se reunieron con representantes de la real sociedad de londres y, como resultado, se pacto la digitalizacion de sus principales articulos que se remiten a sus origenes en 1665. el trabajo de inclusion de dichos volumenes en la base de datos en linea fue finalizado en diciembre de 2000.​  hacia junio de 2007, la base de datos contaba con mas de 23 millones de paginas de texto.​ hacia julio de 2007, el material de jstor es provisto por 446 editores. cerca de 53 millones de busquedas de archivos fueron realizadas entre enero y julio de 2007.​  el acceso a jstor se encuentra autorizado a bibliotecas, universidades y editores de todo el mundo que han firmado un acuerdo con la institucion. estas, a su vez, facilitan el acceso de sus miembros a jstor de manera gratuita a traves de internet. tambien existe la posibilidad de suscribirse, mediante pago, de manera individual o privada.  el programador y activista de internet aaron swartz, que fue coautor de los rss y colaboro en la creacion de las licencias creative commons, fue acusado el 19 de julio de 2011 de descargar 4.8 millones de articulos y otros documentos de la base de datos de jstor, presuntamente con el fin de compartirlos a traves de sitios de descarga gratuita.​ poco antes de que se iniciara el juicio, aaron swartz aparecio muerto en su casa a la edad de 26 años. segun la investigacion del caso, se trataria de un suicidio debido al acoso por parte del deficiente sistema de justicia de estados unidos y del fiscal stephen heymann, el cual intento avanzar su carrera con el caso de aaron swartz.​   ",
        "snippet": "JSTOR (abreviatura en inglés de Journal STORage, «almacén de publicaciones periódicas») es un sistema de almacenamiento en línea de publicaciones académicas. Fundada en 1995, JSTOR es una sociedad estadounidense con base en la ciudad de Nueva York.",
        "enlaces_salientes": [
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/Dominio_de_Internet",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Biblioteca_digital",
            "/wiki/Sitio_web",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/1995",
            "/wiki/Alexa_Internet",
            "/wiki/Estadounidense",
            "/wiki/Nueva_York",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Royal_Society_de_Londres",
            "/wiki/Internet",
            "/wiki/Aaron_Swartz",
            "/wiki/RSS",
            "/wiki/Licencias_Creative_Commons",
            "/wiki/Wayback_Machine",
            "/wiki/Princeton_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/BIBSYS"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Alonzo_Church",
        "titulo": "Alonzo Church",
        "contenido": "alonzo church (14 de junio de 1903 - 11 de agosto de 1995), matematico y logico estadounidense creador de la base de la computacion teorica. nacido en la ciudad de washington, se diplomo en 1924 y obtuvo su doctorado en 1927 en la universidad de princeton, donde ejercio como profesor entre 1929 y 1967.  su obra mas conocida es el desarrollo del calculo lambda, y su trabajo de 1936 que muestra la existencia de problemas indecidibles. este trabajo precedio el famoso trabajo de su alumno alan turing sobre el problema de parada que tambien demostro la existencia de problemas irresolubles por dispositivos mecanicos. luego de revisar la tesis doctoral de turing, demostraron que el calculo lambda y la maquina de turing utilizada para expresar el problema de parada tenian igual poder de expresion; posteriormente demostraron que una variedad de procesos mecanicos alternos para realizar calculos tenian poder de computo equivalente. como resultado se postulo la tesis de church-turing.​  entre los mas conocidos estudiantes de doctorado de church estan stephen kleene, j. barkley rosser, leon henkin, john george kemeny, michael o. rabin, dana scott, simon kochen y raymond smullyan.  church publico entre 1924 y 1995 trabajos sobre logica, filosofia, matematicas y computacion. en su trabajo de 1936 an unsolvable problem of elementary number theory church formulo por primera vez lo que ahora se conoce como la tesis de church que es la identificacion del concepto vago de calculabilidad efectiva con la nocion precisa de funcion recursiva. su articulo a note on the entscheidungsproblem presento lo que ahora se conoce como el teorema de church: la indecidibilidad de la validez de la logica de primer orden. en 1941 publico su monografia the calculi of lambda-conversion. este trabajo tiene gran influencia en el area de computacion teorica.​  el calculo lambda influyo en el diseño del lenguaje lisp, asi como en los lenguajes de programacion funcional. ",
        "snippet": "Alonzo Church (14 de junio de 1903 - 11 de agosto de 1995), matemático y lógico estadounidense creador de la base de la computación teórica. Nacido en la ciudad de Washington, se diplomó en 1924 y obtuvo su doctorado en 1927 en la Universidad de Princeton, donde ejerció como profesor entre 1929 y 1967.",
        "enlaces_salientes": [
            "/wiki/Alonzo_Church",
            "/wiki/Alonzo_Church",
            "/wiki/Alonzo_Church",
            "/wiki/14_de_junio",
            "/wiki/1903",
            "/wiki/Washington,_D._C.",
            "/wiki/EE._UU.",
            "/wiki/11_de_agosto",
            "/wiki/1995",
            "/wiki/EEUU",
            "/wiki/Presbiterianismo",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Oswald_Veblen",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Universidad_de_Princeton",
            "/wiki/UCLA",
            "/wiki/Martin_Davis",
            "/wiki/Leon_Henkin",
            "/wiki/David_Kaplan",
            "/wiki/John_George_Kemeny",
            "/wiki/Stephen_Kleene",
            "/wiki/Michael_O._Rabin",
            "/wiki/Dana_Scott",
            "/wiki/Raymond_Smullyan",
            "/wiki/Alan_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Asociaci%C3%B3n_Estadounidense_para_el_Avance_de_la_Ciencia",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/14_de_junio",
            "/wiki/1903",
            "/wiki/11_de_agosto",
            "/wiki/1995",
            "/wiki/L%C3%B3gico",
            "/wiki/Estadounidense",
            "/wiki/Computaci%C3%B3n_te%C3%B3rica",
            "/wiki/Washington_D.C.",
            "/wiki/1924",
            "/wiki/1927",
            "/wiki/Universidad_de_Princeton",
            "/wiki/1929",
            "/wiki/1967",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/1936",
            "/wiki/Problema_indecidible",
            "/wiki/Alan_Turing",
            "/wiki/Problema_de_parada",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Stephen_Kleene",
            "/wiki/Leon_Henkin",
            "/wiki/John_George_Kemeny",
            "/wiki/Michael_O._Rabin",
            "/wiki/Dana_Scott",
            "/wiki/Raymond_Smullyan",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Entscheidungsproblem",
            "/wiki/Computaci%C3%B3n_te%C3%B3rica",
            "/wiki/Lisp",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/L%C3%B3gica_combinatoria",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Find_a_Grave",
            "/wiki/The_New_York_Times",
            "/wiki/The_Independent",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Pers%C3%A9e_(portal)"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/JSTOR",
        "titulo": "JSTOR",
        "contenido": "jstor (abreviatura en ingles de journal storage, «almacen de publicaciones periodicas») es un sistema de almacenamiento en linea de publicaciones academicas. fundada en 1995, jstor es una sociedad estadounidense con base en la ciudad de nueva york.  jstor fue concebida como la solucion a uno de los mayores problemas que deben enfrentar hoy las bibliotecas (especialmente las universitarias y las de investigacion) debido al creciente aumento de publicaciones academicas en la actualidad. william g. bowen, su fundador, fue presidente de la universidad de princeton desde el año 1972 al 1988.​ en general, a muchas bibliotecas se les hacia excesivamente costoso el mantener una interesante coleccion de publicaciones debido a cuestiones de espacio, por lo que encontraron en jstor una solucion viable a dicha cuestion, digitalizando muchos de sus titulos y almacenandolos en su base de datos en linea con la confianza en que estos permanecerian disponibles a largo plazo.  a partir del exito alcanzado con el proyecto inicial, bowen y kevin guthrie (quien seria mas tarde presidente de jstor) se interesaron en ampliar el numero de publicaciones participantes hasta la fecha. de esta manera se reunieron con representantes de la real sociedad de londres y, como resultado, se pacto la digitalizacion de sus principales articulos que se remiten a sus origenes en 1665. el trabajo de inclusion de dichos volumenes en la base de datos en linea fue finalizado en diciembre de 2000.​  hacia junio de 2007, la base de datos contaba con mas de 23 millones de paginas de texto.​ hacia julio de 2007, el material de jstor es provisto por 446 editores. cerca de 53 millones de busquedas de archivos fueron realizadas entre enero y julio de 2007.​  el acceso a jstor se encuentra autorizado a bibliotecas, universidades y editores de todo el mundo que han firmado un acuerdo con la institucion. estas, a su vez, facilitan el acceso de sus miembros a jstor de manera gratuita a traves de internet. tambien existe la posibilidad de suscribirse, mediante pago, de manera individual o privada.  el programador y activista de internet aaron swartz, que fue coautor de los rss y colaboro en la creacion de las licencias creative commons, fue acusado el 19 de julio de 2011 de descargar 4.8 millones de articulos y otros documentos de la base de datos de jstor, presuntamente con el fin de compartirlos a traves de sitios de descarga gratuita.​ poco antes de que se iniciara el juicio, aaron swartz aparecio muerto en su casa a la edad de 26 años. segun la investigacion del caso, se trataria de un suicidio debido al acoso por parte del deficiente sistema de justicia de estados unidos y del fiscal stephen heymann, el cual intento avanzar su carrera con el caso de aaron swartz.​   ",
        "snippet": "JSTOR (abreviatura en inglés de Journal STORage, «almacén de publicaciones periódicas») es un sistema de almacenamiento en línea de publicaciones académicas. Fundada en 1995, JSTOR es una sociedad estadounidense con base en la ciudad de Nueva York.",
        "enlaces_salientes": [
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/Dominio_de_Internet",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Biblioteca_digital",
            "/wiki/Sitio_web",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/1995",
            "/wiki/Alexa_Internet",
            "/wiki/Estadounidense",
            "/wiki/Nueva_York",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Royal_Society_de_Londres",
            "/wiki/Internet",
            "/wiki/Aaron_Swartz",
            "/wiki/RSS",
            "/wiki/Licencias_Creative_Commons",
            "/wiki/Wayback_Machine",
            "/wiki/Princeton_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/BIBSYS"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/JSTOR",
        "titulo": "JSTOR",
        "contenido": "jstor (abreviatura en ingles de journal storage, «almacen de publicaciones periodicas») es un sistema de almacenamiento en linea de publicaciones academicas. fundada en 1995, jstor es una sociedad estadounidense con base en la ciudad de nueva york.  jstor fue concebida como la solucion a uno de los mayores problemas que deben enfrentar hoy las bibliotecas (especialmente las universitarias y las de investigacion) debido al creciente aumento de publicaciones academicas en la actualidad. william g. bowen, su fundador, fue presidente de la universidad de princeton desde el año 1972 al 1988.​ en general, a muchas bibliotecas se les hacia excesivamente costoso el mantener una interesante coleccion de publicaciones debido a cuestiones de espacio, por lo que encontraron en jstor una solucion viable a dicha cuestion, digitalizando muchos de sus titulos y almacenandolos en su base de datos en linea con la confianza en que estos permanecerian disponibles a largo plazo.  a partir del exito alcanzado con el proyecto inicial, bowen y kevin guthrie (quien seria mas tarde presidente de jstor) se interesaron en ampliar el numero de publicaciones participantes hasta la fecha. de esta manera se reunieron con representantes de la real sociedad de londres y, como resultado, se pacto la digitalizacion de sus principales articulos que se remiten a sus origenes en 1665. el trabajo de inclusion de dichos volumenes en la base de datos en linea fue finalizado en diciembre de 2000.​  hacia junio de 2007, la base de datos contaba con mas de 23 millones de paginas de texto.​ hacia julio de 2007, el material de jstor es provisto por 446 editores. cerca de 53 millones de busquedas de archivos fueron realizadas entre enero y julio de 2007.​  el acceso a jstor se encuentra autorizado a bibliotecas, universidades y editores de todo el mundo que han firmado un acuerdo con la institucion. estas, a su vez, facilitan el acceso de sus miembros a jstor de manera gratuita a traves de internet. tambien existe la posibilidad de suscribirse, mediante pago, de manera individual o privada.  el programador y activista de internet aaron swartz, que fue coautor de los rss y colaboro en la creacion de las licencias creative commons, fue acusado el 19 de julio de 2011 de descargar 4.8 millones de articulos y otros documentos de la base de datos de jstor, presuntamente con el fin de compartirlos a traves de sitios de descarga gratuita.​ poco antes de que se iniciara el juicio, aaron swartz aparecio muerto en su casa a la edad de 26 años. segun la investigacion del caso, se trataria de un suicidio debido al acoso por parte del deficiente sistema de justicia de estados unidos y del fiscal stephen heymann, el cual intento avanzar su carrera con el caso de aaron swartz.​   ",
        "snippet": "JSTOR (abreviatura en inglés de Journal STORage, «almacén de publicaciones periódicas») es un sistema de almacenamiento en línea de publicaciones académicas. Fundada en 1995, JSTOR es una sociedad estadounidense con base en la ciudad de Nueva York.",
        "enlaces_salientes": [
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/Dominio_de_Internet",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Biblioteca_digital",
            "/wiki/Sitio_web",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/1995",
            "/wiki/Alexa_Internet",
            "/wiki/Estadounidense",
            "/wiki/Nueva_York",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Royal_Society_de_Londres",
            "/wiki/Internet",
            "/wiki/Aaron_Swartz",
            "/wiki/RSS",
            "/wiki/Licencias_Creative_Commons",
            "/wiki/Wayback_Machine",
            "/wiki/Princeton_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/BIBSYS"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/G%C3%B6del",
        "titulo": "Kurt Gödel",
        "contenido": "kurt friedrich godel ([ˈkʊʁt ˈɡøːdəl]; brunn, imperio austrohungaro, actual republica checa, 28 de abril de 1906-princeton, estados unidos; 14 de enero de 1978), conocido como kurt godel, fue un logico, matematico y filosofo austriaco.​  se le considera uno de los logicos mas importantes de todos los tiempos. su trabajo ha tenido un impacto inmenso en el pensamiento cientifico y filosofico del siglo xx. al igual que otros pensadores —como gottlob frege, bertrand russell, a. n. whitehead y david hilbert—, godel intento emplear la logica y la teoria de conjuntos para comprender los fundamentos de la matematica.  se le conoce sobre todo por sus dos teoremas de la incompletitud, publicados en 1931, un año despues de finalizar su doctorado en la universidad de viena. el mas celebre establece que para todo sistema axiomatico recursivo autoconsistente lo suficientemente poderoso como para describir la aritmetica de los numeros naturales (la aritmetica de peano), existen proposiciones verdaderas sobre los naturales que no pueden demostrarse a partir de los axiomas. para demostrar este teorema, desarrollo una tecnica denominada ahora numeracion de godel, que codifica expresiones formales como numeros naturales.  tambien demostro que la hipotesis del continuo no puede refutarse desde los axiomas aceptados de la teoria de conjuntos, si dichos axiomas son consistentes. realizo importantes contribuciones a la teoria de la demostracion al esclarecer las conexiones entre la logica clasica, la logica intuicionista y la logica modal.  kurt friedrich godel nacio el 28 de abril de 1906 en brunn, la capital de la moravia austrohungara (actualmente brno, republica checa) en una familia acomodada de etnia germana. su padre, rudolf august godel, era un hombre de negocios y administrador de una fabrica de textiles. su madre, marianne godel (nacida handschuh), una mujer educada y culta, que permanecio cercana a godel durante toda su vida, tal como puede observarse en la extensa correspondencia entre ambos.​ en el momento de su nacimiento, la mayoria de la poblacion de su ciudad era de habla alemana​ y este era el idioma de sus padres.​  godel, que hablaba muy poco el checo, se convirtio automaticamente en checoslovaco a la edad de 12 años, tras la caida del imperio austrohungaro al final de la primera guerra mundial. posteriormente le conto a su biografo john w. dawson que durante ese tiempo se sentia como un «exiliado austriaco en checoslovaquia» (ein osterreicher im exil in der tschechoslowakei). decidio convertirse en ciudadano austriaco a los 23 años. cuando la alemania nazi anexiono austria, godel se convirtio automaticamente en ciudadano aleman, a los 32 años. despues de la segunda guerra mundial, a los 42 años, se convirtio en ciudadano estadounidense.  su familia llamaba al joven kurt herr warum (sr. por que), debido a su insaciable curiosidad. la unica excepcion a una infancia sin incidentes fue que a partir de los cuatro años sufrio quebrantos de salud y fiebres reumaticas. se recupero completamente, pero toda su vida quedo convencido de que su corazon habia sufrido un daño permanente.  asistio a la escuela primaria y secundaria en idioma aleman en brno. de la que se graduo con honores en 1923 y sobresalio en matematicas, idiomas y religion. en el transcurso de su adolescencia estudio, entre otras materias, la  teoria de los colores de goethe, criticas de isaac newton y la obra de immanuel kant.  a los 18 años, kurt se reunio con su hermano mayor rudolf (nacido en 1902) e ingreso en la universidad de viena. entonces ya dominaba las matematicas a nivel universitario. aunque al principio pretendio estudiar fisica teorica, tambien asistio a cursos de filosofia impartidos por heinrich gomperz y de matematicas. durante este periodo adopto ideas del empirismo matematico, leyo los metaphysische anfangsgrunde der naturwissenschaft (fundamentos metafisicos de la ciencia natural) de kant. aunque el mismo no fue un positivista logico, participo en reuniones del circulo de viena con moritz schlick, hans hahn y rudolf carnap, siendo estos dos ultimos de quienes aprendio logica. despues estudio tambien la teoria de los numeros. asistio a un seminario dirigido por schlick, en que se estudiaba el libro introduccion a la logica matematica de bertrand russell, lo que le motivo a interesarse por la logica matematica.  su asistencia a una conferencia de hilbert sobre la completud y la consistencia de los sistemas matematicos pudo decidir el curso de su vida. en 1928, hilbert y wilhelm ackermann publicaron los grundzuge der theoretischen logik (principios de logica teorica), una introduccion a la logica de primer orden en la cual se planteaba el problema de la completitud: «¿son suficientes los axiomas de un sistema formal para derivar cada una de las proposiciones verdaderas en todos los modelos del sistema?». este fue el tema elegido por godel para su disertacion doctoral. en 1929, a los 23 años, completo su disertacion bajo la supervision de hans hahn, en la cual godel establecio la completud del calculo de predicados de primer orden (este resultado se conoce ahora como el teorema de completitud de godel). el doctorado se le concedio en 1930. su tesis, junto a trabajo adicional, fue publicada por la academia de ciencias de viena.​  en 1931 godel publico sus celebres teoremas de la incompletud en uber formal unentscheidbare satze der principia mathematica und verwandter systeme (sobre proposiciones formalmente indecidibles de principia mathematica y sistemas relacionados). en dicho articulo demostro que para todo sistema axiomatico computable que sea lo suficientemente poderoso como para describir la aritmetica de los numeros naturales (p. ej. los axiomas de peano (o zfc), entonces:  estos teoremas finalizaron medio siglo de intentos academicos (comenzando con el trabajo de frege y culminando en los principia mathematica y en el formalismo de hilbert) por encontrar un conjunto de axiomas suficiente para toda la matematica. el teorema de la incompletud implica tambien que no toda la matematica es computable.  la idea basica del teorema de la incompletud es bastante simple. esencialmente, godel construyo una formula que asegura ser no-demostrable para cierto sistema formal. si fuera demostrable seria falsa, lo cual contradice el hecho de que en un sistema consistente las proposiciones demostrables son siempre verdaderas. de modo que siempre habra por lo menos una proposicion verdadera pero no demostrable. esto es, para todo conjunto de axiomas de la aritmetica construible por el hombre existe una formula que se obtiene de la aritmetica pero es indemostrable en ese sistema. sin embargo, para precisar esto godel necesitaba resolver varias cuestiones tecnicas, tales como proposiciones de codificacion y el concepto mismo de demostrabilidad en la teoria de los numeros naturales. esto ultimo lo realizo mediante un proceso denominado numeracion de godel.  en su ensayo de dos paginas zum intuitionistischen aussagenkalkul (1932) godel refuto la “valuabilidad” finita de la logica intuicionista. en la demostracion empleo implicitamente lo que despues se conocio como la logica intermedia de godel–dummett (o godel fuzzy logic).  godel recibio su habilitacion en la universidad de viena en 1932, y en 1933 se convirtio en privatdozent (permiso para enseñar y examinar de forma independiente en la universidad). la ascension de hitler en alemania en 1933 afecto poco a godel en viena, ya que tenia poco interes en la politica. sin embargo, en 1936 se vio muy afectado por el asesinato de moritz schlick (cuyo seminario habia despertado su interes por la logica) a manos del estudiante hans nelbock, quien declaro que mato a schlick «por difundir ideas antimetafisicas que minan la moral y la cohesion de la vida».​ este incidente le provoco un colapso nervioso y su primera crisis de paranoia. dos años despues, tras el anschluss, el asesino fue liberado y se declaro nazi.​  en 1933, godel viajo por primera vez a los estados unidos donde conocio a albert einstein, con quien estrecho lazos de amistad. presento una conferencia en la reunion anual de la sociedad norteamericana de matematicas. en el transcurso de ese año, godel tambien desarrollo ideas sobre la computabilidad y la funcion recursiva, e impartio una conferencia sobre dichas funciones y sobre el concepto de verdad. posteriormente, este trabajo se desarrollo en la teoria de los numeros, empleando la numeracion de godel.  en 1934, godel impartio una serie de conferencias en el instituto de estudios avanzados (iea) en princeton, titulada sobre las proposiciones indecidibles de los sistemas matematicos formales. stephen kleene, quien acababa de finalizar su doctorado en princeton, tomo notas de esta conferencia, que se publicaron posteriormente.  godel visitaria nuevamente el iea en otoño de 1935, pero los viajes y el intenso trabajo lo habian extenuado. el año siguiente convalecio recuperandose de una depresion. no regreso a la docencia hasta 1937. durante ese tiempo, se dedico a probar la consistencia del axioma de eleccion y a la hipotesis del continuo, trabajo que continuo hasta mostrar que estas hipotesis no pueden refutarse desde el sistema comun de axiomas de la teoria de conjuntos.  el 20 de septiembre de 1938 contrajo matrimonio con adele nimbursky (nacida porkert, 1899-1981), a la que conocia desde hacia 10 años. los padres de godel se oponian a esta relacion. porque se trataba de una bailarina divorciada y seis años mayor que el. nunca tuvieron hijos.  posteriormente realizo otra visita a los estados unidos, donde paso el otoño de 1938 en el iea y la primavera de 1939 en la universidad de notre dame. durante sus vacaciones del iea, godel y su esposa adele pasaron el verano de 1942 en blue hill, maine. sin embargo godel no solo estaba descansando, pues tuvo un verano de trabajo muy productivo. john w. dawson, jr. conjetura que durante esas vacaciones godel, empleando el volumen 15 de su obra todavia sin publicar arbeitshefte (cuadernos de notas), descubrio una prueba de la independencia del axioma de eleccion de la teoria finita de tipos, una forma debilitada de la teoria de conjuntos. hao wang, amigo cercano de godel, apoya dicha conjetura, señalando que los cuadernos de notas de blue hill contienen su tratamiento mas extenso del problema.  despues del anschluss en 1938, austria paso a formar parte de la alemania nazi. alemania abolio el titulo de privatdozent, de modo que godel tuvo que concursar a un cargo diferente en el nuevo orden. sin embargo, sus vinculos anteriores con miembros judios del circulo de viena, especialmente con hans hahn, pesaban en su contra. su situacion se precipito a finales de 1939, cuando se le encontro apto para el servicio militar, arriesgandolo a ser llamado a las filas del ejercito aleman durante la ii guerra mundial. por esta razon emigro hacia los estados unidos para asumir un cargo docente en el iea. godel y su esposa tuvieron que tomar el ferrocarril transiberiano hasta el pacifico, navegando desde japon hasta san francisco (donde llegaron el 4 de marzo de 1940), y luego cruzaron los estados unidos en tren hasta princeton.​  rapidamente retomo su trabajo en matematicas y en 1940 publico su obra consistencia del axioma de eleccion y de la hipotesis del continuo generalizada con los axiomas de la teoria de conjuntos, que constituye un clasico de la matematica moderna. en dicho trabajo introdujo el universo construible, un modelo de la teoria de conjuntos en el cual los unicos conjuntos que existen son aquellos que pueden construirse a partir de conjuntos mas simples. godel mostro que tanto el axioma de eleccion (ac) y la hipotesis del continuo generalizada (hcg) son verdaderas en el universo construible y por lo tanto deben de ser consistentes con los axiomas de zermelo-fraenkel para la teoria de conjuntos (zf). posteriormente paul cohen construyo un modelo de zf en el cual ac y hcg son falsos. en conjunto, estas demostraciones significan que ac y hcg son independientes de los axiomas de zf para la teoria de conjuntos.  hacia el final de la decada de 1940, godel demostro la existencia de soluciones paradojicas a las ecuaciones de campo de la relatividad general de albert einstein. estos «universos rotatorios» permitirian viajar en el tiempo y provocaron dudas en einstein sobre su propia teoria. sus soluciones se conocen como la metrica de godel (o el universo de godel).  durante sus muchos años en el instituto, los intereses de godel se tornaron hacia la filosofia y la fisica. estudio y admiro las obras de gottfried leibniz, pero llego a la conclusion (sin evidencia) de que la mayor parte del trabajo de leibniz habia sido suprimida. en menor medida tambien estudio a kant y a edmund husserl. al principio de los años 1970, godel distribuyo entre sus amistades una elaboracion de la demostracion ontologica de leibniz sobre la existencia de dios, la cual se conoce ahora como la demostracion ontologica de godel.  en 1946, godel se convirtio en miembro permanente del iea. alrededor de este periodo dejo de publicar, aunque continuo trabajando. se convirtio plenamente en profesor del instituto en 1955 y en profesor emerito en 1976.  en 1951, fue reconocido (junto a julian schwinger) con el primer premio albert einstein, y tambien recibio la national medal of science en 1974.  en sus ultimos años, godel sufrio de periodos de inestabilidad y enfermedad mental. tenia temores obsesivos a ser envenenado, y no comia a menos que su esposa adele preparara su comida. a finales de 1977, adele fue hospitalizada durante seis meses y no pudo continuar preparandole la comida. en su ausencia, godel rehuso comer, hasta el punto de dejarse morir de hambre. en el momento de su muerte pesaba unos 30 kg. el certificado de defuncion en el hospital de princeton, el 14 de enero de 1978, dice que murio de «desnutricion e inanicion causadas por perturbaciones en la personalidad».​  en su honor, en 1987 se fundo la kurt godel society, una organizacion internacional dedicada a la promocion de la investigacion en logica, filosofia e historia de las matematicas. en 1951, la universidad de yale le nombro doctor honorario en literatura. tambien recibio un doctorado honorario en ciencias por la universidad de harvard en 1952, con una mencion en la que se le declaro «el descubridor de la verdad matematica mas significativa del siglo». fue elegido miembro de la academia nacional de ciencias en 1955 y de la academia norteamericana de las artes y las ciencias en 1957. en 1961 ingreso en la sociedad filosofica de america y en 1967 fue elegido miembro honorario de la sociedad matematica de londres. finalmente, en 1975 el presidente gerald ford le entrego la medalla nacional de las ciencias.  albert einstein y godel entablaron una amistad legendaria, compartida en las caminatas que daban juntos en el iea de princeton. la naturaleza de sus conversaciones -que realizaban en aleman, el idioma nativo de ambos- permanecio en el misterio para los otros miembros del instituto. el economista oskar morgenstern recuerda que, hacia el final de su vida, einstein le confio que «su propio trabajo ya no importaba mucho, que llegaba al instituto unicamente para tener el privilegio de caminar a casa junto a godel».​  einstein y morgenstern asesoraron a godel para el examen de su ciudadania estadounidense, preocupados por que el comportamiento impredecible de su amigo pusiera en riesgo su oportunidad. cuando se menciono brevemente el regimen nazi, godel informo al juez que presidia el examen que habia descubierto una manera por la que una dictadura podria instaurarse legalmente en los ee. uu., mediante una contradiccion logica en la constitucion. el juez, einstein y morgenstern le impidieron terminar la elaboracion de su pensamiento y se le entrego la ciudadania.​  en aleman:  en ingles:  en traduccion al ingles:  en aleman e ingles    en la comedia romantica i.q. (1994) dirigida por fred schepisi, se dramatizo a godel como un personaje secundario encarnado por el actor lou jacobi; en el filme aparece sin su paranoia y disfrutando plenamente de su jubilacion. en 2007 estudiantes de la nederlandse filmacademie (dutch) (dutch film academy) se graduaron con un corto de 25 minutos, dirigido por igor kramer con el actor austriaco robert stuc en el papel principal; un godel retirado se percata de que sus alrededores son el decorado de un rodaje, lo cual alimenta su paranoia.  fuentes primarias:  fuentes secundarias: ",
        "snippet": "Kurt Friedrich Gödel ([ˈkʊʁt ˈɡøːdəl]; Brünn, Imperio austrohúngaro, actual República Checa, 28 de abril de 1906-Princeton, Estados Unidos; 14 de enero de 1978), conocido como Kurt Gödel, fue un lógico, matemático y filósofo austríaco.[1]​",
        "enlaces_salientes": [
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/G%C3%B6del_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/28_de_abril",
            "/wiki/1906",
            "/wiki/Brno",
            "/wiki/Imperio_austroh%C3%BAngaro",
            "/wiki/14_de_enero",
            "/wiki/1978",
            "/wiki/Princeton_(Nueva_Jersey)",
            "/wiki/Estados_Unidos",
            "/wiki/Inanici%C3%B3n",
            "/wiki/Austria",
            "/wiki/Estados_Unidos",
            "/wiki/Checoslovaquia",
            "/wiki/Austria",
            "/wiki/Estados_Unidos",
            "/wiki/Cristianismo",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/Adele_G%C3%B6del",
            "/wiki/Universidad_de_Viena",
            "/wiki/Hans_Hahn",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Teorema_de_incompletitud_de_G%C3%B6del",
            "/wiki/Instituto_de_Estudios_Avanzados_de_Princeton",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Teorema_de_completitud_de_G%C3%B6del",
            "/wiki/Numeraci%C3%B3n_de_G%C3%B6del",
            "/wiki/Teor%C3%ADa_de_conjuntos_de_Von_Neumann-Bernays-G%C3%B6del",
            "/wiki/Universo_de_G%C3%B6del",
            "/wiki/Universo_constructible",
            "/wiki/Prueba_ontol%C3%B3gica_de_G%C3%B6del",
            "/wiki/Funci%C3%B3n_beta_de_G%C3%B6del",
            "/wiki/Primer_teorema_de_la_incompletitud_de_G%C3%B6del",
            "/wiki/Royal_Society",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Academia_de_Ciencias_de_Francia",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Premio_Albert_Einstein",
            "/wiki/Brno",
            "/wiki/Imperio_austroh%C3%BAngaro",
            "/wiki/Rep%C3%BAblica_Checa",
            "/wiki/Princeton_(Nueva_Jersey)",
            "/wiki/Estados_Unidos",
            "/wiki/L%C3%B3gico",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Austria",
            "/wiki/Siglo_XX",
            "/wiki/Gottlob_Frege",
            "/wiki/Bertrand_Russell",
            "/wiki/Alfred_North_Whitehead",
            "/wiki/David_Hilbert",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Teoremas_de_la_incompletitud_de_G%C3%B6del",
            "/wiki/Universidad_de_Viena",
            "/wiki/Sistema_axiom%C3%A1tico",
            "/wiki/Recursivo",
            "/wiki/Consistencia_(l%C3%B3gica)",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Axiomas_de_Peano",
            "/wiki/Axioma",
            "/wiki/Numeraci%C3%B3n_de_G%C3%B6del",
            "/wiki/Hip%C3%B3tesis_del_continuo",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/L%C3%B3gica_cl%C3%A1sica",
            "/wiki/L%C3%B3gica_intuicionista",
            "/wiki/L%C3%B3gica_modal",
            "/wiki/28_de_abril",
            "/wiki/1906",
            "/wiki/Brno",
            "/wiki/Moravia",
            "/wiki/Imperio_austroh%C3%BAngaro",
            "/wiki/Rep%C3%BAblica_Checa",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/Idioma_checo",
            "/wiki/Checoslovaquia",
            "/wiki/Imperio_austroh%C3%BAngaro",
            "/wiki/Primera_Guerra_Mundial",
            "/wiki/Alemania_nazi",
            "/wiki/Anschluss",
            "/wiki/Alemania",
            "/wiki/Estados_Unidos",
            "/wiki/Teor%C3%ADa_de_los_colores",
            "/wiki/Johann_Wolfgang_von_Goethe",
            "/wiki/Isaac_Newton",
            "/wiki/Immanuel_Kant",
            "/wiki/Universidad_de_Viena",
            "/wiki/F%C3%ADsica_te%C3%B3rica",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Immanuel_Kant",
            "/wiki/Empirismo_l%C3%B3gico",
            "/wiki/C%C3%ADrculo_de_Viena",
            "/wiki/Moritz_Schlick",
            "/wiki/Hans_Hahn",
            "/wiki/Rudolf_Carnap",
            "/wiki/L%C3%B3gica",
            "/wiki/Teor%C3%ADa_de_los_n%C3%BAmeros",
            "/wiki/Bertrand_Russell",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Wilhelm_Ackermann",
            "/wiki/L%C3%B3gica_de_primer_orden",
            "/wiki/Hans_Hahn",
            "/wiki/Teorema_de_completitud_de_G%C3%B6del",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Sobre_proposiciones_formalmente_indecidibles_de_Principia_Mathematica_y_sistemas_relacionados",
            "/wiki/Sistema_axiom%C3%A1tico",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/N%C3%BAmeros_naturales",
            "/wiki/Axiomas_de_Peano",
            "/wiki/ZFC",
            "/wiki/Sistema_formal",
            "/wiki/Demostraci%C3%B3n_de_coherencia",
            "/wiki/Completitud_sem%C3%A1ntica",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Axioma",
            "/wiki/Sistema_axiom%C3%A1tico",
            "/wiki/Frege",
            "/wiki/Principia_Mathematica",
            "/wiki/Filosof%C3%ADa_de_la_matem%C3%A1tica#formalismo",
            "/wiki/Computabilidad",
            "/wiki/Numeraci%C3%B3n_de_G%C3%B6del",
            "/wiki/L%C3%B3gica_intuicionista",
            "/wiki/Habilitaci%C3%B3n",
            "/wiki/Privatdozent",
            "/wiki/Moritz_Schlick",
            "/wiki/Trastorno_delirante",
            "/wiki/Anschluss",
            "/wiki/Nazi",
            "/wiki/1933",
            "/wiki/Estados_Unidos",
            "/wiki/Albert_Einstein",
            "/wiki/Sociedad_Norteamericana_de_Matem%C3%A1ticas",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Teor%C3%ADa_de_los_n%C3%BAmeros",
            "/wiki/1934",
            "/wiki/Instituto_de_Estudios_Avanzados_de_Princeton",
            "/wiki/Princeton_(Nueva_Jersey)",
            "/wiki/Stephen_Kleene",
            "/wiki/1935",
            "/wiki/1937",
            "/wiki/Axioma_de_elecci%C3%B3n",
            "/wiki/Hip%C3%B3tesis_del_continuo",
            "/wiki/Adele_G%C3%B6del",
            "/wiki/Universidad_de_Notre_Dame",
            "/wiki/Maine",
            "/wiki/Anschluss",
            "/wiki/Alemania_nazi",
            "/wiki/Privatdozent",
            "/wiki/C%C3%ADrculo_de_Viena",
            "/wiki/Hans_Hahn",
            "/wiki/II_Guerra_Mundial",
            "/wiki/Transiberiano",
            "/wiki/Jap%C3%B3n",
            "/wiki/Axioma_de_elecci%C3%B3n",
            "/wiki/Universo_construible",
            "/wiki/Hip%C3%B3tesis_del_continuo#La_hipótesis_del_continuo_generalizada",
            "/wiki/Axiomas_de_Zermelo-Fraenkel",
            "/wiki/Paul_Cohen",
            "/wiki/A%C3%B1os_1940",
            "/wiki/Relatividad_general",
            "/wiki/Viajes_en_el_tiempo",
            "/wiki/M%C3%A9trica_de_G%C3%B6del",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Kant",
            "/wiki/Edmund_Husserl",
            "/wiki/A%C3%B1os_1970",
            "/wiki/Argumento_ontol%C3%B3gico",
            "/wiki/Dios",
            "/wiki/Prueba_ontol%C3%B3gica_de_G%C3%B6del",
            "/wiki/1955",
            "/wiki/1976",
            "/wiki/1951",
            "/wiki/Julian_Schwinger",
            "/wiki/Premio_Albert_Einstein",
            "/wiki/National_Medal_of_Science",
            "/wiki/1974",
            "/wiki/Princeton_(Nueva_Jersey)",
            "/wiki/Enfermedad_mental",
            "/wiki/Envenenamiento",
            "/wiki/1977",
            "/wiki/1978",
            "/wiki/Universidad_de_Yale",
            "/wiki/Universidad_de_Harvard",
            "/wiki/Academia_Nacional_de_Ciencias_de_Estados_Unidos",
            "/wiki/Sociedad_Matem%C3%A1tica_de_Londres",
            "/wiki/Gerald_Ford",
            "/wiki/Albert_Einstein",
            "/wiki/Albert_Einstein",
            "/wiki/Oskar_Morgenstern",
            "/wiki/R%C3%A9gimen_nazi",
            "/wiki/Dictadura",
            "/wiki/Constituci%C3%B3n_de_los_Estados_Unidos",
            "/wiki/Principia_Mathematica",
            "/wiki/Princeton_University_Press",
            "/wiki/Paul_Benacerraf",
            "/wiki/Hilary_Putnam",
            "/wiki/Wayback_Machine",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/Solomon_Feferman",
            "/wiki/I.Q.",
            "/wiki/Fred_Schepisi",
            "/wiki/Lou_Jacobi",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/M%C3%A9trica_de_G%C3%B6del",
            "/wiki/Ecuaci%C3%B3n_de_campo_de_Einstein",
            "/wiki/Premio_G%C3%B6del",
            "/wiki/G%C3%B6del_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/G%C3%B6del,_Escher,_Bach",
            "/wiki/Oxford_University_Press",
            "/wiki/ISBN",
            "/wiki/Rebecca_Goldstein",
            "/wiki/ISBN",
            "/wiki/Jes%C3%BAs_Padilla_G%C3%A1lvez",
            "/wiki/Jes%C3%BAs_Padilla_G%C3%A1lvez",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/G%C3%B6del,_Escher,_Bach",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Jes%C3%BAs_Padilla_G%C3%A1lvez",
            "/wiki/Wayback_Machine",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_Nacional_de_Chile",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Scopus",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Dialnet"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Alonzo_Church",
        "titulo": "Alonzo Church",
        "contenido": "alonzo church (14 de junio de 1903 - 11 de agosto de 1995), matematico y logico estadounidense creador de la base de la computacion teorica. nacido en la ciudad de washington, se diplomo en 1924 y obtuvo su doctorado en 1927 en la universidad de princeton, donde ejercio como profesor entre 1929 y 1967.  su obra mas conocida es el desarrollo del calculo lambda, y su trabajo de 1936 que muestra la existencia de problemas indecidibles. este trabajo precedio el famoso trabajo de su alumno alan turing sobre el problema de parada que tambien demostro la existencia de problemas irresolubles por dispositivos mecanicos. luego de revisar la tesis doctoral de turing, demostraron que el calculo lambda y la maquina de turing utilizada para expresar el problema de parada tenian igual poder de expresion; posteriormente demostraron que una variedad de procesos mecanicos alternos para realizar calculos tenian poder de computo equivalente. como resultado se postulo la tesis de church-turing.​  entre los mas conocidos estudiantes de doctorado de church estan stephen kleene, j. barkley rosser, leon henkin, john george kemeny, michael o. rabin, dana scott, simon kochen y raymond smullyan.  church publico entre 1924 y 1995 trabajos sobre logica, filosofia, matematicas y computacion. en su trabajo de 1936 an unsolvable problem of elementary number theory church formulo por primera vez lo que ahora se conoce como la tesis de church que es la identificacion del concepto vago de calculabilidad efectiva con la nocion precisa de funcion recursiva. su articulo a note on the entscheidungsproblem presento lo que ahora se conoce como el teorema de church: la indecidibilidad de la validez de la logica de primer orden. en 1941 publico su monografia the calculi of lambda-conversion. este trabajo tiene gran influencia en el area de computacion teorica.​  el calculo lambda influyo en el diseño del lenguaje lisp, asi como en los lenguajes de programacion funcional. ",
        "snippet": "Alonzo Church (14 de junio de 1903 - 11 de agosto de 1995), matemático y lógico estadounidense creador de la base de la computación teórica. Nacido en la ciudad de Washington, se diplomó en 1924 y obtuvo su doctorado en 1927 en la Universidad de Princeton, donde ejerció como profesor entre 1929 y 1967.",
        "enlaces_salientes": [
            "/wiki/Alonzo_Church",
            "/wiki/Alonzo_Church",
            "/wiki/Alonzo_Church",
            "/wiki/14_de_junio",
            "/wiki/1903",
            "/wiki/Washington,_D._C.",
            "/wiki/EE._UU.",
            "/wiki/11_de_agosto",
            "/wiki/1995",
            "/wiki/EEUU",
            "/wiki/Presbiterianismo",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Oswald_Veblen",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/C%C3%A1lculo_Lambda",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Universidad_de_Princeton",
            "/wiki/UCLA",
            "/wiki/Martin_Davis",
            "/wiki/Leon_Henkin",
            "/wiki/David_Kaplan",
            "/wiki/John_George_Kemeny",
            "/wiki/Stephen_Kleene",
            "/wiki/Michael_O._Rabin",
            "/wiki/Dana_Scott",
            "/wiki/Raymond_Smullyan",
            "/wiki/Alan_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Asociaci%C3%B3n_Estadounidense_para_el_Avance_de_la_Ciencia",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/14_de_junio",
            "/wiki/1903",
            "/wiki/11_de_agosto",
            "/wiki/1995",
            "/wiki/L%C3%B3gico",
            "/wiki/Estadounidense",
            "/wiki/Computaci%C3%B3n_te%C3%B3rica",
            "/wiki/Washington_D.C.",
            "/wiki/1924",
            "/wiki/1927",
            "/wiki/Universidad_de_Princeton",
            "/wiki/1929",
            "/wiki/1967",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/1936",
            "/wiki/Problema_indecidible",
            "/wiki/Alan_Turing",
            "/wiki/Problema_de_parada",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Stephen_Kleene",
            "/wiki/Leon_Henkin",
            "/wiki/John_George_Kemeny",
            "/wiki/Michael_O._Rabin",
            "/wiki/Dana_Scott",
            "/wiki/Raymond_Smullyan",
            "/wiki/Funci%C3%B3n_recursiva",
            "/wiki/Entscheidungsproblem",
            "/wiki/Computaci%C3%B3n_te%C3%B3rica",
            "/wiki/Lisp",
            "/wiki/Programaci%C3%B3n_funcional",
            "/wiki/L%C3%B3gica_combinatoria",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Find_a_Grave",
            "/wiki/The_New_York_Times",
            "/wiki/The_Independent",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Pers%C3%A9e_(portal)"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Alan_Turing",
        "titulo": "Alan Turing",
        "contenido": "alan mathison turing (paddington, londres; 23 de junio de 1912-wilmslow, cheshire; 7 de junio de 1954) fue un matematico, logico, informatico teorico, criptografo, filosofo y biologo teorico britanico.​​​​​  es considerado como uno de los padres de la ciencia de la computacion y precursor de la informatica moderna. proporciono una formalizacion influyente de los conceptos de algoritmo y computacion: la maquina de turing. formulo su propia version que hoy es ampliamente aceptada como la tesis de church-turing (1936).  durante la segunda guerra mundial, trabajo en descifrar los codigos nazis, particularmente los de la maquina enigma, y durante un tiempo fue el director de la seccion naval enigma de bletchley park. se ha estimado que su trabajo acorto la duracion de esa guerra entre dos y cuatro años.​ tras la guerra, diseño uno de los primeros computadores electronicos programables digitales en el laboratorio nacional de fisica del reino unido y poco tiempo despues construyo otra de las primeras maquinas en la universidad de manchester.  en el campo de la inteligencia artificial, es conocido sobre todo por la concepcion de la prueba de turing (1950), un criterio segun el cual puede juzgarse la inteligencia de una maquina si sus respuestas en la prueba son indistinguibles de las de un ser humano.  la carrera de turing termino subitamente tras ser procesado por homosexualidad en 1952. dos años despues de su condena, murio —segun la version oficial por suicidio; sin embargo, su muerte ha dado lugar a otras hipotesis, incluida la del envenenamiento accidental —. despues de una campaña publica en 2009, el primer ministro britanico, gordon brown, se disculpo publicamente en nombre del gobierno britanico por «la forma espantosa en la que turing habia sido tratado». la reina isabel ii le otorgo un indulto postumo en 2013. el termino «ley alan turing» ahora se usa de manera informal para referirse a una ley de 2017 en el reino unido que perdona retroactivamente a hombres amonestados o condenados en virtud de la legislacion que prohibia los actos homosexuales.​  turing tiene un extenso legado con estatuas y muchas cosas que llevan su nombre, incluido un premio anual por innovacion en informatica. aparece en el billete actual de 50 libras del banco de inglaterra,​ que se lanzo el 23 de junio de 2021, coincidiendo con su cumpleaños. un programa de la bbc de 2019, votado por la audiencia, lo nombro la persona mas grande del siglo xx.​  turing nacio en el distrito londinense de maida vale.​ su padre, julius mathison turing (1873-1944), era miembro del cuerpo de funcionarios britanicos en la india. su madre, ethel sara stoney, hija de edward waller stoney, ingeniero jefe de madras railways. los stoney eran una familia de la nobleza protestante angloirlandesa de los condados de tipperary y longford, mientras que la propia ethel habia pasado gran parte de su infancia en el condado de clare.  por razones de trabajo, la familia residia en la india britanica. sin embargo, tanto julius como ethel querian que sus hijos se criaran en gran bretaña, por lo que se mudaron a maida vale (londres). alli nacio alan turing el 23 de junio de 1912.[n. 1]​ turing tuvo un hermano mayor.  durante su infancia, sus padres viajaron constantemente entre hastings, reino unido, y la india debido a que su padre seguia activo en la administracion colonial, por lo que paso algunos años viviendo con su hermano en la casa de un matrimonio retirado del ejercito.  muy pronto turing mostro signos del genio que luego seria. desde temprana edad mostro un gran interes por la lectura, por los numeros y los rompecabezas.  entre enero de 1922 y 1926, turing estudio en la preparatoria hazelhurst, una escuela independiente en el pueblo de frant en sussex (hoy east oriental).​  en 1926, con trece años, ingreso en el internado de sherborne, en dorset. su primer dia de clase coincidio con la huelga general en inglaterra, pero su determinacion por asistir a clase era tan firme que recorrio con su bicicleta los mas de 96 km que separaban southampton de su escuela, pasando la noche en una posada.​  la inclinacion natural de turing hacia la matematica y la ciencia no le atrajo el respeto de sus profesores de sherborne, cuyo concepto de educacion hacia mayor enfasis en los clasicos. en la escuela de sherbone, gano la mayor parte de los premios matematicos que se otorgaban y, ademas, realizaba experimentos quimicos por su cuenta, aunque la opinion del profesorado respecto a la independencia y ambicion de turing no era demasiado favorable. a pesar de ello, el joven continuo mostrando una singular habilidad para los estudios que realmente le gustaban, y llego a resolver problemas muy avanzados para su edad (16 años) sin ni siquiera haber estudiado calculo elemental.​  christopher morcom estudiaba junto con turing en la escuela de sherborne y ambos compartian la pasion por la ciencia. durante las clases de matematica o fisica, se intercambiaban notas de comentarios sobre rompecabezas. alan se enamoro de el. fue su primer amor y la primera persona que creyo en sus ideas y con quien podia continuar desarrollandolas.​​​  el 13 de febrero de 1930,​ solo unas pocas semanas despues de su ultima temporada en sherborne, morcom fallecio debido a complicaciones de la tuberculosis bovina contraida tras beber leche de alguna vaca infectada. al recordarlo, turing afirmaba: «mis recuerdos mas vividos de chris son casi siempre de las cosas tan amables que me decia».​  a raiz de esas vivencias, su fe religiosa se resquebrajo y se hizo ateo. tambien se obsesiono por entender la naturaleza de la consciencia, su estructura y origenes. adopto la conviccion de que todos los fenomenos, incluyendo el funcionamiento del cerebro humano, son materialistas.​ sin embargo, siguio creyendo en la supervivencia del espiritu despues de la muerte.  debido a su falta de voluntad para esforzarse con la misma intensidad en el estudio de los clasicos que en el de la ciencia y la matematica, turing suspendio sus examenes finales varias veces y tuvo que ingresar en la escuela universitaria que eligio en segundo lugar, king's college, universidad de cambridge, en vez de en la que era su primera eleccion, trinity. tras su graduacion, se traslado a la universidad estadounidense de princeton, donde trabajo con el logico alonzo church. recibio las enseñanzas de godfrey harold hardy, un respetado matematico que ocupo la catedra sadleirian en cambridge, y que posteriormente, fue responsable de un centro de estudios e investigaciones matematicas entre 1931 y 1934. en 1935 turing fue nombrado profesor del king's college.  el entscheidungsproblem, que se traduce como «problema de decision», fue un reto en logica simbolica para encontrar un algoritmo general que decidiera si una formula de calculo de primer orden es un teorema. el problema fue planteado inicialmente por leibniz en el siglo xvii luego de construir su maquina mecanica de calculo. david hilbert formalizo el problema en el vii congreso internacional de matematicas (bolonia, 1928), planteando la busqueda de un procedimiento algoritimico valido para solucionar las posibles cuestiones matematicas, a traves de tres preguntas:  si bien hilbert suponia que la respuesta a las preguntas era afirmativa, kurt godel, mediante los teoremas de incompletitud demostro que las dos primeras preguntas no podrian serlo ya que, tal como afirma godel:  «en cualquier formalizacion consistente de las matematicas que sea lo bastante fuerte para definir el concepto de los numeros naturales, se puede construir una afirmacion que ni se puede demostrar ni se puede refutar dentro de ese sistema», mientras que el primero afirma: «ningun sistema consistente se puede usar para demostrarse a si mismo».​  sin embargo, no podian resolver la ultima pregunta. la dificultad estaba en la ausencia de significado de lo que se entiende por un «procedimiento mecanico». en 1936, alan turing en su trabajo acerca de los numeros computables,  introduce el concepto de la maquina de turing y, junto a  alonzo church demostraron ambos que es imposible escribir tal algoritmo. como consecuencia, es tambien imposible decidir con un algoritmo general si ciertas frases concretas de la aritmetica son ciertas o falsas.  la tesis de church-turing formula hipoteticamente la equivalencia entre los conceptos de funcion computable y maquina de turing, que expresado en lenguaje corriente vendria a ser: «todo algoritmo es equivalente a una maquina de turing». no es en si un teorema matematico: es una afirmacion formalmente indemostrable, una hipotesis que, no obstante, tiene una aceptacion practicamente universal.  la tesis church-turing postula que cualquier modelo computacional existente tiene las mismas capacidades algoritmicas, o un subconjunto, de las que tiene una maquina de turing.  en su estudio los numeros computables, con una aplicacion al entscheidungsproblem (publicado el 28 de mayo de 1936), turing reformulo los resultados obtenidos por kurt godel en 1931 sobre los limites de la demostrabilidad y la computacion, sustituyendo al lenguaje formal universal descrito por godel por lo que hoy se conoce como maquina de turing, unos dispositivos formales y simples.​  turing demostro que dicha maquina era capaz de resolver cualquier problema matematico que pudiera representarse mediante un algoritmo. las maquinas de turing siguen siendo el objeto central de estudio en la teoria de la computacion. llego a probar que no habia ninguna solucion para el problema de decision, entscheidungsproblem, demostrando primero que el problema de la parada para las maquinas de turing es irresoluble: no es posible decidir algoritmicamente si una maquina de turing dada llegara a pararse o no. aunque su demostracion se publico despues de la demostracion equivalente de alonzo church respecto a su calculo lambda, el estudio de turing es mucho mas accesible e intuitivo.​ tambien fue pionero con su concepto de «maquina universal (de turing)», con la tesis de que dicha maquina podria realizar las mismas tareas que cualquier otro tipo de maquina. su estudio tambien introduce el concepto de numeros definibles.​  la mayor parte de 1937 y 1938 la paso en la universidad de princeton, estudiando bajo la direccion de alonzo church. entre 1938 y 1939 volvio a inglaterra y estudio filosofia de las matematicas. en 1938 obtuvo el doctorado en princeton; en su discurso introdujo el concepto de hipercomputacion, en el que ampliaba las maquinas de turing con las llamadas maquinas oracle, las cuales permitian el estudio de los problemas para los que no existe una solucion algoritmica.​  tras su regreso a cambridge en 1939, asistio a las conferencias de ludwig wittgenstein sobre las bases de las matematicas. ambos discutieron y mantuvieron un vehemente desencuentro, ya que turing defendia el formalismo matematico y wittgenstein criticaba que la matematica estaba sobrevalorada y no descubria ninguna verdad absoluta.​  un dia despues de la declaracion de guerra de gran bretaña, en septiembre de 1939, turing fue convocado a bletchley park, donde se encontraba la escuela gubernamental de codigo y cifrado (gc&cs). las nueve mil personas que trabajaban alli se dedicaron a intentar interpretar las comunicaciones alemanas cifradas en codigo morse.  el cifrado lo hacian a traves de una maquina de sistema rotatorio llamada enigma (maquina). enigma habia sido inventada en 1918 por arthur scherbius. era similar a una maquina de escribir, en la cual cada vez que una letra era pulsada, era sustituida por otra mediante el uso de tres rotores internos (las maquinas militares llegaron a usar cinco), cuyo resultado era mas de diez mil billones de configuraciones distintas. debido al caracter portatil de la maquina, los operadores podian estar ubicados en los puestos de mando, interior de los tanques, submarinos, en bombardeos, etc. independientemente de su locacion, los operadores, llevaban las instrucciones de como debian colocarse los rotores, y las posiciones cambiaban cada pocos dias.​  el equipo liderado por turing, a traves de ecuaciones y calculos, encontraron pautas en los mensajes con lo que pudieron detectar una pequeña parte de su funcionamiento. sin embargo, todavia no podian descifrarlos. fue entonces, cuando turing se pregunto:  ¿y si para luchar contra una maquina como enigma hiciese falta otra maquina?​  a raiz de esta pregunta, turing pudo poner en practica sus teorias: diseño la maquina bombe. bombe buscaba la configuracion de los rotores de la maquina alemana, implementando una cadena de deducciones logicas para cada combinacion posible. gracias a las mejoras del matematico,  gordon welchman, el 14 de marzo de 1940, el primer prototipo estaba terminado. al cabo de un tiempo disponian con mas de doscientas bombes.​  los trabajos de la gc&cs, dirigidos por turing, fueron determinantes para acortar la guerra. algunos historiadores afirman que su trabajo acorto dos años la duracion de la guerra, salvando alrededor de catorce millones de vidas.​ al finalizar la guerra, las maquinas bombe se desmantelaron y todo el trabajo permanecio en secreto hasta los setenta. en 1974 el capitan w. f. winterbotham escribio el libro the ultra secret.​  de 1945 a 1948 turing vivio en richmond, londres, donde trabajo en el laboratorio nacional de fisica (npl). en 1947 empezo a trabajar en el diseño del ace (automatic computer engine o motor de computacion automatica). paralelamente, existia un proyecto similar en estados unidos llamado edvac de von neumann. el ace de turing se diferenciaba en que incluia la implementacion de funciones aritmeticas en circuitos electronicos. su deseo era crear una maquina que pudiera ser configurada para hacer calculos algebraicos, desencriptar codigos, manipular archivos y jugar al ajedrez. aunque diseñar el ace era factible, el secretismo que reinaba durante la guerra desemboco en retrasos para iniciar el proyecto por lo que turing se sintio desilusionado.  tiempo mas tarde creo el abbreviated code instruction, que dio origen a los lenguajes de programacion. en 1947 se tomo un año sabatico en cambridge, tiempo durante el cual escribio un trabajo pionero sobre la inteligencia artificial que no fue publicado en vida. en 1948, con la ayuda de frederic calland williams, se dio, por primera vez, la demostracion del principio de la maquina de turing.  mientras se encontraba en cambridge y a pesar de su ausencia, se siguio construyendo el prototipo piloto del ace, que ejecuto su primer programa en mayo de 1950. aunque la version completa del ace de turing jamas fue construida, el diseño de otras computadoras en todo el mundo le debio mucho a su concepcion.​  a mediados de 1948 fue nombrado director delegado del laboratorio de informatica de la universidad de manchester y trabajo en el software de una de las primeras computadoras reales, la manchester mark i. durante esta etapa tambien realizo estudios mas abstractos y en su articulo de octubre de 1950 «computing machinery and intelligence» turing trato el problema de la inteligencia artificial y propuso un experimento que hoy se conoce como prueba de turing, con la intencion de definir una prueba estandar por la que una maquina podria catalogarse como «sensible» o «sintiente». en el documento, turing sugirio que en lugar de construir un programa para simular la mente adulta, seria mejor producir uno mas simple para simular la mente de un niño y luego someterlo a educacion. una forma invertida de la prueba de turing se usa ampliamente en internet, el test captcha que esta diseñado para determinar si un usuario es un humano y no un ordenador.  la prueba de turing es un metodo para determinar si una maquina puede pensar.​  nace de un juego de imitacion, en donde hay tres personas: un interrogador, un hombre y una mujer. el interrogador esta separado de los otros dos, y solo puede comunicarse con ellos a traves de un lenguaje que entiendan. el objetivo del interrogador es descubrir quien es la mujer, y quien es el hombre, mientras que el de los otros dos, es convencerlo de que son la mujer. en su ensayo de 1950, «computing machinery and intelligence», turing sustituye a uno de los interrogados por una computadora y cambia los objetivos del juego: reconocer a la maquina.  «una computadora puede ser llamada inteligente si logra engañar a una persona haciendole creer que es un humano» - alan turing.​  la forma de hacer pasar la prueba a una maquina consiste basicamente en una persona hablando con una computadora en otra habitacion mediante un sistema de chat. si la persona es incapaz de determinar si habla con un humano o con un ordenador, entonces la computadora se considera inteligente.  en el año 2014, por primera vez, el chatbot de eugene gootsman, logro convencer a treinta jueces que estaban participando en la prueba de que estaban chateando con un niño ucraniano de trece años.​​  entre 1948 y 1950 en conjunto con un antiguo compañero, d. g. champernowne, empezo a escribir un programa de ajedrez para un ordenador que aun no existia. en 1952 trato de implementarlo en el ferranti mark 1, pero por falta de potencia, el ordenador no fue capaz de ejecutar el programa. en su lugar turing jugo una partida en la que reprodujo manualmente los calculos que hubiera hecho el ordenador, costando alrededor de hora y media en efectuar un movimiento. una de las partidas llego a registrarse, y el programa perdio frente a un colega de turing, alick glennie. su test fue significativo, caracteristicamente provocativo y una gran contribucion para empezar el debate alrededor de la inteligencia artificial que aun hoy continua.​  trabajo junto a norbert wiener en el desarrollo de la cibernetica. esta rama de estudios se genera a partir de la demanda de sistemas de control que exige el progresivo desarrollo de las tecnicas de produccion a partir del siglo xx. la cibernetica pretende establecer un sistema de comunicacion entre el hombre y la maquina como premisa fundamental para administrar los sistemas de control. sus estudios profundizaron en esta relacion estableciendo el concepto de interfaz y cuestionando los limites de simulacion del razonamiento humano.  turing trabajo desde 1952 hasta que fallecio en 1954 en la biologia matematica, concretamente en la morfogenesis. publico un trabajo sobre esta materia titulado «fundamentos quimicos de la morfogenesis» en 1952. su principal interes era comprender la filotaxis de fibonacci, es decir, la existencia de los numeros de fibonacci en las estructuras vegetales. utilizo ecuaciones de reaccion-difusion que actualmente son cruciales para entender la formacion de patrones en el campo de biologia del desarrollo ontogenetico (embriologia). sus trabajos posteriores no se publicaron hasta 1992 en el libro obras completas de a. m. turing.  las teorias de turing han ido ganando la aceptacion de biologos experimentales, como uno de los mecanismos mediante los cuales celulas que son geneticamente identicas pueden diferenciarse y dar origen a organismos complejos.​  la carrera profesional de turing se vio truncada cuando lo procesaron por su homosexualidad. en 1952, arnold murray, un amante de turing, ayudo a un complice a entrar en la casa de turing para robarle. turing acudio a la policia a denunciar el delito. durante la investigacion policial turing reconocio su homosexualidad, con lo que se le imputaron los cargos de «indecencia grave y perversion sexual» (los actos de homosexualidad eran ilegales en el reino unido en esa epoca), los mismos que a oscar wilde mas de 50 años antes.  convencido de que no tenia de que disculparse, no se defendio de los cargos y fue condenado. segun su ampliamente difundido proceso judicial, se le dio la opcion de ir a prision o de someterse a castracion quimica mediante un tratamiento hormonal de reduccion de la libido. finalmente escogio las inyecciones de estrogenos, que duraron un año y le produjeron importantes alteraciones fisicas, como la aparicion de pechos o un apreciable aumento de peso, que lo condujeron a padecer de disfuncion erectil.   en una carta de esta epoca a su amigo norman routledge, turing escribio en forma de falso silogismo una reflexion, relacionando el rechazo social que provoca la homosexualidad con el desafio intelectual que supone demostrar la posibilidad de inteligencia en los ordenadores. en particular, le preocupaba que los ataques a su persona pudieran oscurecer sus razonamientos sobre la inteligencia artificial:​ dos años despues del juicio, en 1954, fallecio por envenenamiento con cianuro, aparentemente tras comerse una manzana envenenada que no llego a ingerir completamente, en un contexto que se estimo oficialmente como suicidio.​​ varias personas pensaron que su muerte fue intencionada, aunque su madre nego la causa de su muerte, atribuyendola a una ingestion accidental provocada por la falta de precauciones de turing en el almacenamiento de sustancias quimicas de laboratorio. los ultimos años de su vida fueron amargos y reservados. esta muerte no esclarecida ha dado lugar a diversas hipotesis, incluida la del asesinato.​ para jack copeland, experto en la vida y obra del cientifico, las pruebas presentadas para el veredicto oficial de la muerte de alan turing no serian consideradas hoy dia como suficientes: «siempre se llevaba una manzana que dejaba a medio comer antes de dormirse (...) lo cierto es que es imposible estar seguros de lo que paso. la idea de una muerte accidental es coherente con las pruebas que tenemos. lo mejor hubiera sido un veredicto abierto porque la verdad es que probablemente nunca sepamos que paso».​  el 10 de septiembre de 2009, el primer ministro del reino unido, gordon brown, emitio un comunicado declarando sus disculpas en nombre de su gobierno por el trato que recibio alan turing durante sus ultimos años de vida. este comunicado fue consecuencia de una movilizacion publica solicitando al gobierno que ofreciera disculpas oficialmente por la persecucion contra alan turing.​​ sin embargo, en 2012 el gobierno britanico de david cameron denego el indulto al cientifico,​ aduciendo que la homosexualidad era considerada entonces un delito.​ finalmente, el 24 de diciembre de 2013 recibio el indulto de todo tipo de culpa, por orden de la reina isabel ii.​  el 23 de junio de 2001 se inauguro una estatua de turing en manchester. se encuentra en sackville park, entre el edificio de la universidad de manchester en la calle de whitworth y la gay village de la calle del canal. coincidiendo con el 50.º aniversario de su muerte, se descubrio una placa conmemorativa en su antiguo domicilio, hollymeade, en wilmslow el 7 de junio de 2004.  la association for computing machinery otorga anualmente el premio turing a personas destacadas por sus contribuciones tecnicas al mundo de la informatica. este premio esta ampliamente considerado como el equivalente del premio nobel en el mundo de la computacion.  el instituto alan turing fue inaugurado por el umist (instituto de ciencia y tecnologia de la universidad de manchester) y la universidad de manchester en el verano de 2004.  el 5 de junio de 2004 se celebro un acontecimiento conmemorativo de la vida y la obra de turing en la universidad de manchester, organizado por el british logic colloquium y la british society for the history of mathematics.  el 28 de octubre de 2004 se descubrio una estatua de bronce de alan turing esculpida por john w. mills en la universidad de surrey. la estatua conmemora el 50.º aniversario de la muerte de turing. representa a turing transportando sus libros a traves del campus.​  el 23 de junio de 2012, dia en el que se conmemoro el centenario del nacimiento de turing, google presento entre sus habituales doodles una pequeña maquina de turing capaz de comparar dos cadenas de caracteres binarios.  una leyenda urbana asegura que el logo de apple computers (mordisco de la manzana) rinde homenaje a turing y su suicidio comiendo una manzana envenenada con cianuro. incluso, el arco iris en el logo seria un homenaje a la homosexualidad de turing. sin embargo, estas suposiciones fueron desmentidas por rob janoff, creador del logo de apple y de hecho, los colores ni siquiera se muestran en el mismo orden que en la bandera arco iris, dado que esta fue diseñada dos años mas tarde de la creacion de dicha imagen.​ ",
        "snippet": "Alan Mathison Turing (Paddington, Londres; 23 de junio de 1912-Wilmslow, Cheshire; 7 de junio de 1954) fue un matemático, lógico, informático teórico, criptógrafo, filósofo y biólogo teórico británico.[1]​[2]​[3]​[4]​[5]​",
        "enlaces_salientes": [
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Alan_Turing",
            "/wiki/Turing_(desambiguaci%C3%B3n)",
            "/wiki/Maida_Vale",
            "/wiki/Reino_Unido_de_Gran_Breta%C3%B1a_e_Irlanda",
            "/wiki/Wilmslow",
            "/wiki/Reino_Unido",
            "/wiki/Intoxicaci%C3%B3n_cianh%C3%ADdrica",
            "/wiki/Ate%C3%ADsmo",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/King%27s_College_(Cambridge)",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Alonzo_Church",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Estad%C3%ADstico",
            "/wiki/Criptoan%C3%A1lisis",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/GCHQ",
            "/wiki/National_Physical_Laboratory",
            "/wiki/Computing_machinery_and_intelligence",
            "/wiki/Problema_de_la_parada",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Prueba_de_Turing",
            "/wiki/Turing_completo",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/M%C3%A1quina_de_Turing_universal",
            "/wiki/Bombe",
            "/wiki/M%C3%A1quina_de_Turing_probabil%C3%ADstica",
            "/wiki/Royal_Society",
            "/wiki/Premio_Smith",
            "/wiki/Oficial_de_la_Orden_del_Imperio_brit%C3%A1nico",
            "/wiki/Miembro_de_la_Royal_Society",
            "/wiki/Delito",
            "/wiki/Paddington",
            "/wiki/Londres",
            "/wiki/Wilmslow",
            "/wiki/Cheshire",
            "/wiki/Matem%C3%A1tico",
            "/wiki/L%C3%B3gico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Cript%C3%B3grafo",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Biolog%C3%ADa_te%C3%B3rica",
            "/wiki/Reino_Unido",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Algoritmo",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Segunda_guerra_mundial",
            "/wiki/Nazismo",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Bletchley_Park",
            "/wiki/Laboratorio_Nacional_de_F%C3%ADsica_(Reino_Unido)",
            "/wiki/Universidad_de_M%C3%A1nchester",
            "/wiki/Inteligencia_artificial",
            "/wiki/Prueba_de_Turing",
            "/wiki/Gordon_Brown",
            "/wiki/Ley_Alan_Turing",
            "/wiki/Premio_Turing",
            "/wiki/Libra_esterlina",
            "/wiki/Banco_de_Inglaterra",
            "/wiki/BBC",
            "/wiki/Maida_Vale",
            "/wiki/Anglo-Irland%C3%A9s",
            "/wiki/Tipperary",
            "/wiki/Longford_(Condado_de_Longford)",
            "/wiki/Condado_de_Clare_(Irlanda)",
            "/wiki/Maida_Vale",
            "/wiki/Rompecabezas",
            "/wiki/Frant",
            "/wiki/Sussex",
            "/wiki/Sherborne",
            "/wiki/Dorset",
            "/wiki/Huelga_general_en_Reino_Unido_de_1926",
            "/wiki/Southampton",
            "/wiki/Posada_(establecimiento)",
            "/wiki/C%C3%A1lculo",
            "/wiki/Tuberculosis_de_los_mam%C3%ADferos",
            "/wiki/Ate%C3%ADsmo",
            "/wiki/King%27s_College_(Cambridge)",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/King%27s_College,_Cambridge",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Trinity_College,_Cambridge",
            "/wiki/Alonzo_Church",
            "/wiki/Godfrey_Harold_Hardy",
            "/wiki/1931",
            "/wiki/1934",
            "/wiki/1935",
            "/wiki/Entscheidungsproblem",
            "/wiki/Entscheidungsproblem",
            "/wiki/Problema_de_decisi%C3%B3n",
            "/wiki/L%C3%B3gica_simb%C3%B3lica",
            "/wiki/C%C3%A1lculo_de_primer_orden",
            "/wiki/Teorema",
            "/wiki/Gottfried_Leibniz",
            "/wiki/David_Hilbert",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Alonzo_Church",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Tesis_de_Church-Turing",
            "/wiki/Funci%C3%B3n_computable",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Algoritmo",
            "/wiki/Independencia_(l%C3%B3gica_matem%C3%A1tica)",
            "/wiki/Hip%C3%B3tesis_(m%C3%A9todo_cient%C3%ADfico)",
            "/wiki/Consenso_cient%C3%ADfico",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Entscheidungsproblem",
            "/wiki/1936",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/1931",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Entscheidungsproblem",
            "/wiki/Problema_de_la_parada",
            "/wiki/Alonzo_Church",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/M%C3%A1quina_oracle",
            "/wiki/1937",
            "/wiki/1938",
            "/wiki/Universidad_de_Princeton",
            "/wiki/1938",
            "/wiki/1938",
            "/wiki/Hipercomputaci%C3%B3n",
            "/wiki/M%C3%A1quina_oracle",
            "/wiki/1939",
            "/wiki/Ludwig_Wittgenstein",
            "/wiki/Bases_de_las_matem%C3%A1ticas",
            "/wiki/Bombe",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Bletchley_Park",
            "/wiki/Government_Communications_Headquarters",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Arthur_Scherbius",
            "/wiki/M%C3%A1quina_de_escribir",
            "/wiki/Bombe",
            "/wiki/Gordon_Welchman",
            "/wiki/Prueba_de_Turing",
            "/wiki/Inteligencia",
            "/wiki/Richmond_(Londres)",
            "/wiki/Laboratorio_Nacional_de_F%C3%ADsica_(Reino_Unido)",
            "/wiki/Estados_Unidos",
            "/wiki/EDVAC",
            "/wiki/John_von_Neumann",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Inteligencia_artificial",
            "/wiki/Frederic_Calland_Williams",
            "/wiki/Universidad_de_M%C3%A1nchester",
            "/wiki/Manchester_Mark_I",
            "/wiki/Computing_machinery_and_intelligence",
            "/wiki/Inteligencia_artificial",
            "/wiki/Prueba_de_Turing",
            "/wiki/CAPTCHA",
            "/wiki/Prueba_de_Turing",
            "/wiki/Computing_machinery_and_intelligence",
            "/wiki/Eugene_Goostman",
            "/wiki/Ajedrez_por_computadora",
            "/wiki/Ajedrez_por_computadora",
            "/wiki/1952",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Norbert_Wiener",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Patrones_de_Turing",
            "/wiki/Biolog%C3%ADa_matem%C3%A1tica",
            "/wiki/Morfog%C3%A9nesis",
            "/wiki/Filotaxis",
            "/wiki/Fibonacci",
            "/wiki/N%C3%BAmero_de_Fibonacci",
            "/wiki/Sistemas_de_reacci%C3%B3n-difusi%C3%B3n",
            "/wiki/Patr%C3%B3n_(estructura)",
            "/wiki/Biolog%C3%ADa_del_desarrollo",
            "/wiki/Embriolog%C3%ADa",
            "/wiki/1992",
            "/wiki/Homosexualidad",
            "/wiki/Oscar_Wilde",
            "/wiki/Castraci%C3%B3n_qu%C3%ADmica",
            "/wiki/Hormona",
            "/wiki/Libido",
            "/wiki/Estr%C3%B3geno",
            "/wiki/Disfunci%C3%B3n_er%C3%A9ctil",
            "/wiki/Monumento_a_Alan_Turing",
            "/wiki/M%C3%A1nchester",
            "/wiki/Reino_Unido",
            "/wiki/Silogismo",
            "/wiki/Envenenamiento",
            "/wiki/Cianuro",
            "/wiki/Suicidio",
            "/wiki/Jack_Copeland",
            "/wiki/Reino_Unido",
            "/wiki/Gordon_Brown",
            "/wiki/David_Cameron",
            "/wiki/Isabel_II_del_Reino_Unido",
            "/wiki/Monumento_a_Alan_Turing",
            "/wiki/M%C3%A1nchester",
            "/wiki/Universidad_de_M%C3%A1nchester",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Premio_Turing",
            "/wiki/Premios_Nobel",
            "/wiki/Instituto_Alan_Turing",
            "/wiki/Google",
            "/wiki/Doodle",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Cadena_de_caracteres",
            "/wiki/C%C3%B3digo_binario",
            "/wiki/Leyenda_urbana",
            "/wiki/Cianuro",
            "/wiki/Alex_Garland",
            "/wiki/Ex_Machina_(pel%C3%ADcula)",
            "/wiki/Prueba_de_Turing",
            "/wiki/Androide",
            "/wiki/Inteligencia_artificial",
            "/wiki/Breaking_the_Code",
            "/wiki/Derek_Jacobi",
            "/wiki/The_Imitation_Game",
            "/wiki/Morten_Tyldum",
            "/wiki/Benedict_Cumberbatch",
            "/wiki/Keira_Knightley",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Enigma_(m%C3%A1quina)",
            "/wiki/Nazi",
            "/wiki/Bletchley_Park",
            "/wiki/Netflix",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/RuPaul%27s_Drag_Race_UK",
            "/wiki/Criptonomic%C3%B3n",
            "/wiki/Neal_Stephenson",
            "/wiki/Breaking_the_Code",
            "/wiki/Greg_Egan",
            "/wiki/2001",
            "/wiki/Arthur_C._Clarke",
            "/wiki/Neuromante",
            "/wiki/William_Gibson",
            "/wiki/Norma_Editorial",
            "/wiki/Ian_McEwan",
            "/wiki/Harry_Harrison",
            "/wiki/Marvin_Minsky",
            "/wiki/Robert_Harris",
            "/wiki/Matmos",
            "/wiki/EP",
            "/wiki/Hidrogenesse",
            "/wiki/Un_d%C3%ADgito_binario_dudoso._Recital_para_Alan_Turing",
            "/wiki/M%C3%A1quina_or%C3%A1culo",
            "/wiki/M%C3%A1quina_universal_de_Turing",
            "/wiki/M%C3%A1quina_de_Turing_alternante",
            "/wiki/M%C3%A1quina_de_Turing_probabil%C3%ADstica",
            "/wiki/Turing_completo",
            "/wiki/N%C3%BAmero_computable",
            "/wiki/Colossus",
            "/wiki/John_von_Neumann",
            "/wiki/El_Pa%C3%ADs",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/David_Leavitt",
            "/wiki/ISBN",
            "/wiki/BBC",
            "/wiki/ISSN",
            "/wiki/Jack_Copeland",
            "/wiki/Oxford_University_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Springer_Science%2BBusiness_Media",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/Conel_Hugh_O%27Donel_Alexander",
            "/wiki/ISBN",
            "/wiki/Harvard_University_Press",
            "/wiki/ISBN",
            "/wiki/Charles_Babbage",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Alonzo_Church",
            "/wiki/American_Journal_of_Mathematics",
            "/wiki/ISSN",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Jack_Copeland",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Jack_Copeland",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Rolf_Hochhuth",
            "/wiki/ISBN",
            "/wiki/David_Leavitt",
            "/wiki/ISBN",
            "/wiki/Janna_Levin",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Indianapolis",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Cambridge_University_Press",
            "/wiki/Martin_Davis",
            "/wiki/Derek_Jacobi",
            "/wiki/Oxford",
            "/wiki/Englewood_Cliffs",
            "/wiki/New_Jersey",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Scopus",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Internet_Movie_Database"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Emil_Post",
        "titulo": "Emil Leon Post",
        "contenido": "emil leon post (11 de febrero de 1897 en augustow - 21 de abril de 1954 en nueva york) fue un matematico estadounidense.  creo el sistema formal llamado maquina de post, el cual es equivalente a la maquina de turing. ",
        "snippet": "Emil Leon Post (11 de febrero de 1897 en Augustów - 21 de abril de 1954 en Nueva York) fue un matemático estadounidense.",
        "enlaces_salientes": [
            "/wiki/Emil_Leon_Post",
            "/wiki/Emil_Leon_Post",
            "/wiki/Emil_Leon_Post",
            "/wiki/11_de_febrero",
            "/wiki/1897",
            "/wiki/Polonia",
            "/wiki/21_de_abril",
            "/wiki/1954",
            "/wiki/Estados_Unidos",
            "/wiki/Nueva_York",
            "/wiki/Polonia",
            "/wiki/Estados_Unidos",
            "/wiki/Idioma_polaco",
            "/wiki/Universidad_de_Columbia",
            "/wiki/City_College_(Nueva_York)",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Universidad_Cornell",
            "/wiki/Problema_de_correspondencia_de_Post",
            "/wiki/11_de_febrero",
            "/wiki/1897",
            "/wiki/August%C3%B3w",
            "/wiki/21_de_abril",
            "/wiki/1954",
            "/wiki/Nueva_York",
            "/wiki/Estados_Unidos",
            "/wiki/Sistema_formal",
            "/wiki/M%C3%A1quina_de_Post",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Gottfried_Leibniz",
        "titulo": "Gottfried Leibniz",
        "contenido": "gottfried wilhelm leibniz, a veces gottfried wilhelm von leibniz​ (leipzig, 1 de julio de 1646-hannover, 14 de noviembre de 1716), fue un polimata, filosofo, matematico, logico, teologo, jurista, bibliotecario y politico aleman.  fue uno de los grandes pensadores de los siglos xvii y xviii, y se le reconoce como el «ultimo genio universal», esto es, la ultima persona que pudo formarse suficientemente en todos los campos del conocimiento; despues ya solo hubo especialistas. realizo profundas e importantes contribuciones en las areas de metafisica, epistemologia, logica, filosofia de la religion, asi como en la matematica, fisica, geologia, jurisprudencia e historia. incluso denis diderot, el filosofo deista frances del siglo xviii, cuyas opiniones no podrian estar en mayor oposicion a las de leibniz, no podia evitar sentirse sobrecogido ante sus logros, y escribio en la encyclopedie: «quizas nunca haya un hombre que haya leido tanto, estudiado tanto, meditado mas y escrito mas que leibniz… lo que ha elaborado sobre el mundo, sobre dios, la naturaleza y el alma es de la mas sublime elocuencia. si sus ideas hubiesen sido expresadas con el olfato de platon, el filosofo de leipzig no cederia en nada al filosofo de atenas».​  de hecho, el tono de diderot es casi de desesperanza en otra observacion, que contiene igualmente mucha verdad: «cuando uno compara sus talentos con los de leibniz, uno tiene la tentacion de tirar todos sus libros e ir a morir silenciosamente en la oscuridad de algun rincon olvidado». la reverencia de diderot contrasta con los ataques que otro importante filosofo, voltaire, lanzaria contra el pensamiento filosofico de leibniz, consecuencia del aprecio que sentia por  newton  y del desprecio que sentia por el optimismo en que desembocaba su sistema filosofico. a pesar de reconocer la vastedad de la obra de este, voltaire sostenia que en toda ella no habia nada util que fuera original, ni nada original que no fuera absurdo y risible.  ocupa un lugar igualmente importante tanto en la historia de la filosofia como en la de la matematica. de manera independiente al trabajo de newton (quien lo habia desarrollado 10 años antes pero no lo habia publicado debido a su trauma por la critica que una vez le hiciera hooke) desarrollo el calculo infinitesimal y su notacion que es la que se emplea desde entonces.​​ tambien invento el sistema binario, fundamento virtual de todas las arquitecturas de las computadoras actuales.​ fue uno de los primeros intelectuales europeos que reconocieron el valor y la importancia del pensamiento chino y de china como potencia desde todos los puntos de vista.​​  rene descartes, baruch spinoza y leibniz integran la terna de los tres grandes racionalistas del siglo xvii. su filosofia se vincula tambien con la tradicion escolastica y anticipa la logica moderna y la filosofia analitica. leibniz hizo asimismo contribuciones a la tecnologia y anticipo nociones que aparecieron mucho mas tarde en biologia, medicina, geologia, teoria de la probabilidad, psicologia, ingenieria y ciencias de la computacion. sus contribuciones a esta vasta lista de temas se recoge en diarios y en decenas de miles de cartas y manuscritos ineditos. hasta el momento, no se ha realizado una edicion completa de sus escritos, y por ello no es posible aun hacer un recuento integral de sus logros.​  gottfried leibniz nacio el 1 de julio de 1646 en leipzig, dos años antes de que terminara la guerra de los treinta años, hijo de federico leibniz, jurista y profesor de filosofia moral en la universidad de leipzig, y catherina schmuck, hija de un profesor de leyes. siendo adulto, frecuentemente firmaba como «von leibniz» y numerosas ediciones postumas de sus obras lo nombran como «freiherr [baron] g. w. von leibniz»; sin embargo, no se ha encontrado documento alguno que confirme que se le haya concedido un titulo nobiliario.​  su padre fallecio cuando tenia seis años, de modo que su educacion quedo en manos de su madre y de su tio, y segun sus propias palabras, de si mismo. al morir su padre, dejo una biblioteca personal de la que leibniz pudo hacer uso libremente a partir de los siete años, y procedio a beneficiarse de su contenido, en particular los volumenes de historia antigua y de los padres de la iglesia.  para cuando tenia doce años habia aprendido por si mismo latin, el cual utilizo durante el resto de su vida, y habia empezado a estudiar griego. en 1661, a la edad de catorce años, se matriculo en la universidad de leipzig y completo sus estudios a los veinte años, especializandose en leyes y mostrando dominio de los clasicos, logica y filosofia escolastica. sin embargo, su educacion en matematicas no estaba a la altura de franceses o britanicos.  en 1666 publico su primer libro y tambien su tesis de habilitacion, disertacion acerca del arte combinatorio. cuando la universidad declino el asegurarle un puesto docente en leyes tras su graduacion, leibniz opto por entregar su tesis a la universidad de altdorf y obtuvo su doctorado en cinco meses. declino despues la oferta de un puesto academico en altdorf y dedico el resto de su vida al servicio de dos prominentes familias de la nobleza alemana.  el primer puesto de leibniz fue como alquimista asalariado en nuremberg, aunque no tenia ningun conocimiento sobre el tema. entro en contacto con johann christian von boineburg (1622–1672), antiguo ministro en jefe del elector de maguncia, johann philipp franz von schonborn, quien lo contrato como asistente y poco despues lo presento al elector, tras reconciliarse con el. leibniz le dedico un ensayo al elector con la esperanza de obtener un empleo. la estrategia funciono, pues el elector le solicito ayuda para una nueva redaccion del codigo legal de su electorado, y en 1669 fue nombrado asesor de la corte de apelaciones. aunque von boineburg murio en 1672, permanecio al servicio de su viuda hasta 1674.  von boineburg hizo mucho por promover su reputacion, y su servicio con el elector pronto tomo un rol mas diplomatico. publico un ensayo bajo el seudonimo de un noble polaco, en el que argumentaba (sin exito) en favor del candidato aleman a la corona polaca. el principal factor en la geopolitica europea durante su vida adulta fueron las ambiciones de luis xiv de francia, respaldadas por su ejercito y su poderio economico. la guerra de los treinta años habia dejado exhausta a la europa de habla alemana, ademas de fragmentada y economicamente atrasada. leibniz propuso protegerla distrayendo a luis xiv de la siguiente manera: se invitaria a francia a tomar egipto como un primer paso hacia una eventual conquista de las indias orientales neerlandesas. a cambio, francia se comprometeria a no perturbar a alemania ni a paises bajos. el plan recibio un apoyo cauteloso del elector. en 1672 el gobierno frances invito a leibniz a paris para su discusion, pero el plan se vio pronto superado por los acontecimientos y se torno irrelevante.  de esta forma leibniz inicio una estancia de varios años en paris, durante la cual incremento considerablemente sus conocimientos de matematicas y fisica y empezo a realizar contribuciones en ambas disciplinas. conocio a malebranche y a antoine arnauld, el principal filosofo frances de la epoca, estudio los escritos de descartes, de pascal, tanto los publicados como los ineditos y entablo amistad con el matematico aleman ehrenfried walther von tschirnhaus, con quien mantuvo correspondencia hasta el final de su vida. especialmente oportuno fue el conocer al fisico y matematico neerlandes christiaan huygens, quien por entonces tambien se encontraba en paris. al llegar a paris, leibniz recibio un duro despertar, pues sus conocimientos de fisica y matematicas eran fragmentarios. con huygens como mentor, inicio un programa autodidacta que pronto resulto en la realizacion de grandes contribuciones en ambos campos, incluyendo el descubrimiento de su version del calculo diferencial y su trabajo en las series infinitas.  a principios de 1673, cuando quedo claro que francia no llevaria adelante su parte del plan de leibniz respecto de egipto, el elector envio a su propio sobrino, acompañado por leibniz, en una mision diplomatica ante el gobierno britanico. en londres leibniz conocio a henry oldenburg y a john collins. despues de mostrar ante la royal society una maquina capaz de realizar calculos aritmeticos conocida como la stepped reckoner, que habia estado diseñando y construyendo desde 1670, la primera maquina de este tipo que podia ejecutar las cuatro «operaciones aritmeticas basicas», la sociedad le nombro miembro externo. la mision concluyo abruptamente al recibir la noticia de la muerte del elector. leibniz regreso inmediatamente a paris y no a maguncia, como tenia planeado.  la muerte repentina de los dos mecenas de leibniz en el mismo invierno significo que debia buscar un nuevo rumbo para su carrera. a este respecto, fue oportuna una invitacion del duque de brunswick en 1669 para visitar hannover. alli declino la invitacion, pero empezo a escribirse con el duque en 1671. en 1673 este le ofrecio un puesto de consejero, que acepto con renuencia dos años mas tarde, solo despues de que estuviera claro que no obtendria ningun empleo en paris (cuyo estimulo intelectual apreciaba) o en la corte imperial de los habsburgo.  logro retrasar su arribo a hannover hasta finales de 1676, despues de otro breve viaje a londres, donde posiblemente le mostraron algunas de las obras sin publicar de isaac newton (claro que esto es simplemente una conjetura dada la conocida renuencia de newton a mostrar sus escritos), aunque la mayor parte de los historiadores de las matematicas afirman ahora que newton y leibniz desarrollaron sus ideas de forma independiente: newton desarrollo las ideas primero y leibniz fue el primero en publicarlas.  en el viaje de londres a hannover se detuvo en la haya, donde conocio a leeuwenhoek, quien mejoro el microscopio y descubrio los microorganismos. igualmente dedico varios dias de intensa discusion con spinoza, quien recientemente habia concluido su obra maestra, etica. leibniz sentia respeto por el poderoso intelecto de spinoza, pero estaba consternado por sus conclusiones, que contradecian la ortodoxia cristiana.  en 1677 fue promovido, por propia peticion, a consejero privado de justicia, cargo que mantuvo durante el resto de su vida. leibniz sirvio a tres gobernantes consecutivos de la casa de brunswick como historiador, consejero politico y como bibliotecario de la biblioteca ducal.​ desde entonces empleo su pluma en los diversos asuntos politicos, historicos y teologicos que involucraban a la casa de brunswick; los documentos resultantes constituyen una parte valiosa de los registros historicos del periodo.  entre las pocas personas que acogieron a leibniz en el norte de alemania se contaban la electora, su hija sofia carlota de hannover (1630–1714), la reina de prusia y su discipulo confeso, y carolina de brandeburgo-ansbach, la consorte de su nieto, el futuro jorge ii. para cada una de estas mujeres, leibniz fue correspondiente, consejero y amigo. cada una de ellas lo acogio con mas calidez de lo que lo hicieron sus respectivos esposos y el futuro rey jorge i de gran bretaña.​  hannover contaba entonces solo con unos 10 000 habitantes y su provincianismo desagradaba a leibniz. sin embargo, ser un cortesano importante en la casa de brunswick constituia un gran honor, especialmente en vista del meteorico ascenso en el prestigio de dicha casa mientras duro la relacion de leibniz con ella. en 1692, el duque de brunswick se convirtio en elector hereditario del sacro imperio romano germanico. la ley de asentamiento de 1701 designo a la electora sofia y a su descendencia como la familia real del reino unido, una vez que tanto el rey guillermo iii como su cuñada y sucesora, la reina ana, hubieran muerto. leibniz participo en las iniciativas y negociaciones que condujeron a la ley, pero no siempre de manera eficaz. por ejemplo, algo que publico en inglaterra, pensando que promoveria la causa de brunswick, fue formalmente censurado por el parlamento britanico.  los brunswick toleraron los enormes esfuerzos que dedicaba leibniz a sus proyectos intelectuales sin relacion con sus deberes de cortesano, proyectos tales como el perfeccionamiento del calculo, sus escritos sobre matematicas, logica, fisica y filosofia, y el mantenimiento de una vasta correspondencia. empezo a trabajar en calculo en 1674, y para 1677 tenia ya entre manos un sistema coherente, pero no lo publico hasta 1684. sus documentos mas importantes de matematicas salieron a luz entre 1682 y 1692, por lo general en una revista que el y otto mencke habian fundado en 1682, la acta eruditorum. dicha revista jugo un papel clave en los progresos de su reputacion cientifica y matematica, la cual a su vez incremento su eminencia en la diplomacia, en historia, en teologia y en filosofia.  el elector ernesto augusto le comisiono a leibniz una tarea de enorme importancia, la historia de la casa de brunswick, remontandose a la epoca de carlomagno o antes, con la esperanza de que el libro resultante ayudaria a sus ambiciones dinasticas. entre 1687 y 1690 leibniz viajo extensamente por alemania, austria e italia en busca de materiales de archivo de relevancia para este proyecto. pasaron las decadas y el libro no llegaba, de modo que el siguiente elector se mostro bastante molesto ante la evidente falta de progresos. leibniz nunca concluyo el proyecto, en parte a causa de su enorme produccion en otros ambitos, pero tambien debido a su insistencia en escribir un libro meticulosamente investigado y erudito basado en fuentes de archivo. sus patrones habrian quedado bastante satisfechos con un breve libro popular, un libro que fuera quizas un poco mas que una genealogia comentada, a ser completada en tres años o menos. nunca supieron que, de hecho, habia llevado a cabo una buena parte de la tarea asignada: cuando los escritos de leibniz se publicaron en el siglo xix, el resultado fueron tres volumenes.  en 1711 john keill, al escribir en la revista de la royal society y, con la supuesta bendicion de newton, acuso a leibniz de haber plagiado el calculo de newton, dando inicio de esta manera a la disputa sobre la paternidad del calculo. comenzo una investigacion formal por parte de la royal society (en la cual newton fue participante reconocido) en respuesta a la solicitud de retraccion de leibniz, respaldando de esta forma las acusaciones de keill.  ese mismo año, durante un viaje por el norte de europa, el zar ruso pedro el grande se detuvo en hannover y se reunio con leibniz, quien despues mostro interes por los asuntos rusos durante el resto de su vida. en 1712 leibniz inicio una estancia de dos años en viena, donde se le nombro consejero de la corte imperial de los habsburgo.  tras la muerte de la reina ana en 1714, el elector jorge luis se convirtio en el rey jorge i de gran bretaña bajo los terminos de la ley de asentamiento de 1711. aunque leibniz habia hecho bastante para favorecer dicha causa, no habria de ser su hora de gloria. a pesar de la intervencion de la princesa de gales carolina de brandeburgo-ansbach, jorge i le prohibio a leibniz reunirse con el en londres hasta que hubiera completado por lo menos un volumen de la historia de la familia brunswick encargada por su padre casi 30 años atras. ademas, la inclusion de leibniz en su corte de londres habria resultado insultante para newton, quien era visto como el triunfador de la disputa sobre la prioridad del calculo y cuya posicion en los circulos oficiales britanicos no podria haber sido mejor. finalmente, su querida amiga y defensora, la dignataria electora sofia de wittelsbach, murio en 1714.  leibniz fallecio en hannover en 1716: para entonces, estaba tan fuera del favor en la corte que ni jorge i (quien se encontraba cerca de hannover en ese momento) ni ningun otro cortesano, mas que su secretario personal, asistieron al funeral. aun cuando leibniz era miembro vitalicio de la royal society y de la academia prusiana de las ciencias, ninguna de las dos entidades considero conveniente honrar su memoria.  su tumba permanecio en el anonimato hasta que leibniz fue exaltado por fontenelle ante la academia de ciencias de francia, la cual lo habia admitido como miembro extranjero en 1700. la exaltacion se redacto a peticion de la duquesa de orleans, nieta de la electora sofia.  1646-1666 1666-1674 ademas de su ministro, el baron von boineburg.  1672-1676 1676-1716 1677-1698 despues de su hermano, el duque y mas tarde elector ernesto augusto de hanover.  1687-1690 comisionado por el elector sobre la historia de la casa de brunswick.  1698-1716 1712-1714 carlos vi del sacro imperio romano germanico, en la corte de los habsburgo en viena.  1714-1716 seguirlo a londres. leibniz termina sus dias en un relativo olvido y abandono.  leibniz escribio principalmente en tres idiomas: latin escolastico (ca. 40 %), frances (ca. 35 %) y aleman (menos del 25 %). durante su vida publico muchos panfletos y articulos academicos, pero solo dos libros filosoficos, disertacion acerca del arte combinatorio y la theodicee.  publico numerosos panfletos, con frecuencia anonimos, en nombre de la casa de brunswick, entre los que se destaca de jure suprematum, una importante consideracion sobre la naturaleza de la soberania. otro libro sustancial aparecio postumamente: su nouveaux essais sur l'entendement humain (nuevos ensayos sobre el entendimiento humano), el cual habia evitado publicar tras la muerte de john locke.  hasta 1895, cuando bodemann completo su catalogo de los manuscritos y la correspondencia de leibniz, no se esclarecio la enorme extension de su legado: aproximadamente 15 000 cartas a mas de 1000 destinatarios, ademas de 40 000 items adicionales, sin contar que muchas de dichas cartas tienen la extension de un ensayo. gran parte de su vasta correspondencia, en particular las cartas fechadas despues de 1685, permanecen ineditas, y mucho de lo que se ha publicado lo ha sido apenas en decadas recientes. la cantidad, la variedad y el desorden de los escritos de leibniz son el resultado predecible de una situacion que el describio de la siguiente manera:  las partes existentes de los escritos en edicion critica de leibniz estan organizadas de la siguiente manera:​  la catalogacion de la totalidad del legado de leibniz se inicio en 1901. dos guerras mundiales (con el holocausto judio de por medio, incluyendo a un empleado del proyecto y otras consecuencias personales) y decadas de division alemana (dos estados divididos por una cortina de hierro, que separaron a los academicos y dispersaron tambien partes de su legado literario) obstaculizaron grandemente el ambicioso proyecto de edicion que debe tratar con el empleo de siete idiomas en cerca de 200 000 paginas de material impreso.  en 1985 fue reorganizado e incluido en un programa conjunto de academias federales y estatales alemanas. desde entonces las ramas en potsdam, munster, hannover y berlin han publicado en conjunto 25 volumenes de la edicion critica (hasta 2006), con un promedio de 870 paginas por volumen (comparado con los 19 volumenes desde 1923), mas la preparacion de indices y la labor de concordancia.  al momento de fallecer leibniz, su reputacion estaba en declive; se le recordaba unicamente por un libro, la theodicee, cuyo supuesto argumento central fue caricaturizado por voltaire en su candido. la descripcion que hizo voltaire de las ideas de leibniz fue tan influyente que muchos la tomaron como una descripcion precisa (esta malinterpretacion puede seguir ocurriendo entre ciertas personas legas). de modo que voltaire tiene algo de responsabilidad en el hecho de que muchas de las ideas de leibniz sigan sin ser comprendidas. ademas, leibniz tuvo un ardiente discipulo, el filosofo christian wolff, cuya apariencia dogmatica y superficial contribuyo a dañar considerablemente la reputacion de leibniz. en cualquier caso, el movimiento filosofico se estaba apartando del racionalismo y de la construccion de sistemas del siglo xvii, del cual leibniz habia sido un gran exponente. su trabajo en derecho, diplomacia e historia fue percibido como efimero en su interes, y la vastedad y la riqueza de su correspondencia se paso por alto.  gran parte de europa llego a dudar de que hubiera descubierto el calculo independientemente de newton, y por ende se desprecio la totalidad de su trabajo en matematicas y fisica. voltaire, quien admiraba a newton, tambien escribio su candido, al menos en parte, para desacreditar la aseveracion de leibniz de su descubrimiento del calculo y su opinion de que la teoria de la gravitacion universal de newton era incorrecta. el surgimiento de la relatividad y el trabajo subsiguiente en la historia de las matematicas situaron la posicion de leibniz bajo una luz mas favorable.  el largo recorrido de leibniz hasta su gloria presente empezo con la publicacion en 1765 de sus nouveaux essais, los cuales fueron leidos rigurosamente por kant. en 1768 dutens publico la primera edicion en varios volumenes de la obra de leibniz, seguida en el siglo xix por varias mas, incluyendo la de  erdmann, foucher de careil, gerhardt, gerland, klopp y mollat, asi como la publicacion de su correspondencia con personajes notables, como antoine arnauld, samuel clarke, sofia de hannover y la hija de esta, sofia carlota de hannover.  en 1900 bertrand russell publico un estudio critico acerca de la metafisica de leibniz, y poco despues louis couturat publico un importante estudio sobre leibniz​ y edito un volumen de escritos hasta entonces no divulgados, principalmente de logica. aunque dichas conclusiones, especialmente las de russell, se pusieron en duda y a menudo se desecharon, le dieron a leibniz algo mas de respetabilidad entre los filosofos analiticos y linguisticos del siglo xx del mundo de habla inglesa (leibniz habia sido ya de gran influencia para varios alemanes, como bernhard riemann). sin embargo, la literatura secundaria en habla inglesa sobre leibniz no florecio realmente hasta despues de la segunda guerra mundial, en la bibliografia de brown.​ menos de treinta de las entradas en ingles se publicaron antes de 1946.  nicholas jolley​ ha dicho que la reputacion de leibniz como filosofo es quizas ahora mas alta de lo que lo fue en cualquier momento desde la epoca de leibniz, por las siguientes razones:  en 1985 el gobierno aleman instituyo el premio gottfried wilhelm leibniz, que se entrega anualmente. el importe economico del premio en 2018, para cada uno de los once premiados, ascendio a 2,5 millones de euros para nueve de ellos y a 1,25 millones de euros para otros dos premiados. es el premio mas importante que se concede en alemania para las contribuciones cientificas.​  en 1970 la union astronomica internacional decidio llamar en su honor «leibniz» a un crater de impacto ubicado en el hemisferio sur de la cara oculta de la luna.​  en 2006, la universidad de hannover fue renombrada «gottfried wilhelm leibniz» en su honor.  el pensamiento filosofico de leibniz aparece de forma fragmentada, ya que sus escritos filosoficos consisten principalmente en una multitud de textos cortos: articulos de revistas, manuscritos publicados mucho despues de su muerte y gran cantidad de cartas con multiples personas. escribio unicamente dos tratados de filosofia, y el que se publico durante su vida, la theodicee de 1710, es tanto teologico como filosofico.  el propio leibniz fecha su inicio como filosofo con su discurso de metafisica, el cual elaboro en 1686 como un comentario a una disputa entre malebranche y antoine arnauld. esto condujo a una extensa y valiosa disputa con arnauld;​​ dicho comentario y el discurso no se publicaron sino hasta el siglo xix.  en 1695 leibniz realizo su entrada publica a la filosofia europea con un articulo titulado nuevo sistema de la naturaleza y comunicacion de las sustancias.​​​ en el periodo 1695-1705 elaboro sus nuevos ensayos sobre el entendimiento humano, un extenso comentario sobre ensayo sobre el entendimiento humano (1690) de john locke, pero al enterarse de la muerte de locke en 1704 perdio el deseo de publicarlo, de modo que los nuevos ensayos no se publicaron sino hasta 1765. la monadologia, otra de sus obras importantes, compuesta en 1714 y publicada postumamente, consta de noventa aforismos; en ella se ha visto la influencia de giordano bruno, cuya obra conocia, y para su composicion se utilizaron los legajos que el autor confecciono durante su ultima etapa en hannover.​  leibniz conocio a spinoza en 1676 y leyo algunos de sus escritos sin publicar, y se sospecha desde entonces que se apropio de algunas de sus ideas. a diferencia de descartes, leibniz y spinoza tenian una educacion filosofica rigurosa. la disposicion escolastica y aristotelica de su mente revelan la fuerte influencia de uno de sus profesores en leipzig, jakob thomasius, quien superviso ademas su tesis de grado. leibniz tambien leyo vorazmente a francisco suarez, el jesuita español respetado incluso en las universidades luteranas. tenia un profundo interes por los nuevos metodos y conclusiones de descartes, huygens, newton y boyle, pero observaba sus trabajos desde una perspectiva bastante influida por las nociones escolasticas. sin embargo, sigue siendo notable el que sus metodos y preocupaciones anticipan con frecuencia la logica y la filosofia analitica y linguistica del siglo xx.  fue uno de los primeros intelectuales europeos que reconocieron el valor y la importancia del pensamiento chino.​​  leibniz recurria de forma libre a uno u otro de nueve principios fundamentales:​​  el principio de razon suficiente, enunciado en su forma mas acabada por gottfried leibniz en su teodicea, afirma que no se produce ningun hecho sin que haya una razon suficiente para que sea asi y no de otro modo. de ese modo, sostiene que los eventos considerados azarosos o contingentes parecen tales porque no disponemos de un conocimiento acabado de las causas que lo motivaron.  el principio de razon suficiente es complementario del principio de no contradiccion, y su terreno de aplicacion preferente son los enunciados de hecho; el ejemplo tradicional es el enunciado «cesar paso el rubicon», del cual se afirma que, si tal cosa sucedio, algo debio motivarlo.  de acuerdo a la concepcion racionalista, el principio de razon suficiente es el fundamento de toda verdad, porque nos permite establecer cual es la condicion —esto es, la razon— de la verdad de una proposicion. para leibniz, sin una razon suficiente no se puede afirmar cuando una proposicion es verdadera. y dado que todo lo que sucede por algo, es decir, si todo lo que sucede responde siempre a una razon determinante, conociendo esa razon se podria saber lo que sucedera en el futuro. este es el fundamento de la ciencia experimental.  sin embargo, dados los limites del intelecto humano, hemos de limitarnos a aceptar que nada ocurre sin razon, a pesar de que dichas razones muy a menudo no pueden ser conocidas por nosotros.  una de las consecuencias generales para la fisica del principio de razon suficiente fue condensada por leibniz en forma de aforismo: «en el mejor de los mundos posibles la naturaleza no da saltos y nada sucede de golpe», lo cual vincula dicho principio con el problema del continuo y de la infinita divisibilidad de la materia.  la contribucion mas importante de leibniz a la metafisica es su teoria de las monadas, tal como la expuso en la monadologia. las monadas son al ambito metafisico, lo que los atomos, al ambito fisico/fenomenal; las monadas son los elementos ultimos del universo. son «formas del ser substanciales» con las consiguientes propiedades: son eternas, no pueden descomponerse, son individuales, estan sujetas a sus propias leyes, no son interactivas y cada una es un reflejo de todo el universo en una armonia preestablecida (un ejemplo historicamente importante de pampsiquismo).  las monadas, sin entrar en un gran misterio, son sustancias simples. ademas, no tienen extension, el primer accidente de la materia, cada monada es una sustancia espiritual, cada monada tiene un apetito, y cada monada, como se dijo, se desarrolla segun su ley interior.  las monadas son centros de fuerza;​ la substancia es fuerza, mientras el espacio, la materia, y el movimiento son meramente fenomenales. el espacio es fenomenico y no absoluto,​ sino relativo, y consiste en la percepcion de las relaciones espaciales entre unas monadas y otras (o conjunto de ellas). asi, la espacialidad se da cuando percibo que una silla esta frente a una mesa, la mesa en el centro de las paredes de la habitacion, la ventana en una de ellas, etc. no puede ser absoluto porque no hay una razon suficiente para considerar que el universo esta situado en un area y no en otra. en cuanto a la materialidad o extension de las monadas, no existe porque entonces habriamos de aceptar que un objeto, al dividirse en dos por algo externo, esta siendo modificado por una causa ajena a si, lo que entraria en contradiccion con la autocausacion inherente de la sustancia. esto se resuelve, en lo que al mundo fenomenico concierne (es decir, el mundo de las ciencias naturales), con el principio de armonia preestablecida, en la que todo sucede segun un orden simultaneo y coherente de «reflejos».  la esencia ontologica de una monada es su simpleza irreductible. a diferencia de los atomos, las monadas no poseen un caracter material o espacial. tambien difieren de los atomos en su completa independencia mutua, de modo que las interacciones entre monadas son solo aparentes. por el contrario, en virtud del principio de la armonia preestablecida, cada monada obedece un conjunto particular de «instrucciones» preprogramadas, de modo que una monada «sabe» que hacer en cada momento (estas «instrucciones» pueden entenderse como analogas a las leyes cientificas que gobiernan a las particulas subatomicas). en virtud de estas instrucciones intrinsecas, cada monada es como un pequeño espejo del universo. las monadas son necesariamente «pequeñas»; p. ej., cada ser humano constituye una monada, en cuyo caso el libre albedrio se torna problematico. igualmente, dios es una monada, y su existencia puede inferirse de la armonia prevaleciente entre las monadas restantes; dios desea la armonia preestablecida.  se supone que las monadas se han deshecho de lo problematico:  la monadologia fue vista como arbitraria, excentrica incluso, en la epoca de leibniz y desde entonces.  el dios de leibniz no es el motor inmovil de aristoteles, la natura naturans de spinoza, ni el gran ser de newton o el espiritu universal en hegel; sino «un dios vivo y personal que se revela tanto al corazon como a la razon», tratando asi de fundamentar racionalmente al dios cristiano con sus atributos clasicos.​ dentro de la filosofia de leibniz se pueden encontrar cuatro tipos de argumentos respecto a la existencia de dios:​  leibniz sostuvo que el concepto de dios es posible​ y escribio varias formulaciones del argumento ontologico de san anselmo en sus obras y cartas. en su monadologia escribio:​  (44)\t“pues si alguna realidad hay en las esencias o posibilidades o bien en las verdades eternas, es preciso que dicha realidad este fundada en algo existente y actual, y, por consiguiente, en la existencia del ser necesario, en el cual la esencia encierra la existencia, o en el cual ser posible basta para ser actual.  ademas, leibniz formulo un argumento cosmologico de la contingencia a favor de la existencia de dios con su principio de razon suficiente en su monadologia. «no se puede encontrar ningun hecho que sea verdadero o existente, ni ninguna proposicion verdadera», escribio, «sin que haya una razon suficiente para que sea asi y no de otra manera, aunque no podemos conocer estos motivos en la mayoria de los casos». formulo el argumento cosmologico sucintamente: «¿por que hay algo en lugar de nada? la razon suficiente [...] se encuentra en una sustancia que [...] es un ser necesario que lleva la razon de su existencia dentro de si mismo».​ martin heidegger llamo a esta pregunta «la cuestion fundamental de la metafisica».​​ este argumento es uno de los argumentos cosmologicos mas populares en filosofia de la religion y ha sido reformulado por alexander pruss​ y william lane craig.​ filosofos como kant y bertrand russell criticaron ambos argumentos respectivamente.​  el argumento de las verdades eternas se apoya tambien en el principio de razon suficiente: «las verdades eternas no tienen en si mismas la razon de su existencia y, por tanto, esta debe buscarse en el ser supremo. [...] la razon suficiente de las verdades eternas es dios mismo, ya que el conjunto de todas ellas no es otra cosa que el propio entendimiento divino».​ el argumento de la armonia preestablecida se basa en la armonia de la monadas: «segun leibniz, el mundo y cada una de las criaturas que lo componen se desarrollan con sus propias fuerzas, pero estas ultimas fueron creadas y elegidas por dios de modo necesario para preestablecer la mejor organizacion del mundo».​  el termino «optimismo» es utilizado aqui en el sentido de «optimo», y no en el mas comun de la palabra, es decir, «estado de animo», contrario al pesimismo.  la teodicea intenta justificar las evidentes imperfecciones del mundo, afirmando que se trata del mejor de los mundos posibles. tiene que ser el mejor y mas equilibrado de los mundos posibles, ya que fue creado por un dios perfecto. en rutherford (1998) se encuentra un estudio academico detallado acerca de la teodicea de leibniz.  la concepcion de «el mejor de los mundos posibles» se justifica por la existencia de un dios con capacidad ordenadora, no moral sino matematicamente. para leibniz, este es el mejor de los mundos posibles, sin entender «mejor» de un modo moralmente bueno, sino matematicamente bueno, ya que dios, de las infinitas posibilidades de mundos, ha encontrado la mas estable entre variedad y homogeneidad. es el mundo matematica y fisicamente mas perfecto, puesto que sus combinaciones (sean moralmente buenas o malas, no importa) son las mejores posibles. leibniz reescribe al final de este libro una fabula que viene a simbolizar esto mismo: la perfeccion matematica de este mundo real frente a todos los mundos posibles, que siempre se encuentran en la imperfeccion y descompensacion de hetereogeneidad y homogeneidad, siendo el infierno el maximo homogeneo (los pecados se repiten eternamente) y el paraiso el maximo heterogeneo.  la afirmacion de que «vivimos en el mejor de los mundos posibles» le atrajo a leibniz numerosas burlas, especialmente de voltaire, quien lo caricaturizo en su novela comica candido, al introducir el personaje del dr. pangloss (una parodia de leibniz) quien repite la frase como un mantra cada vez que el infortunio caia sobre sus acompañantes. de ahi proviene el adjetivo «panglosiano», para describir a alguien tan ingenuo como para creer que nuestro mundo es el mejor de los mundos posibles.  el matematico paul du bois-reymond escribio, en sus pensamientos de leibniz sobre la ciencia moderna, que leibniz pensaba en dios como un matematico.  una defensa cautelosa del optimismo de leibniz recurriria a ciertos principios cientificos que emergieron en los dos siglos desde su muerte y que estan ahora establecidos: el principio de minima accion, la ley de conservacion de la masa y la conservacion de la energia.  las monadas tienen percepciones. pueden ser claras u oscuras. las cosas tienen percepciones sin conciencia. cuando las percepciones tienen claridad y conciencia y a un tiempo van acompañadas por la memoria, son apercepcion, propia de las almas. las humanas pueden conocer verdades universales y necesarias. asi, el alma es espiritu. en la cumbre de la escala de las monadas esta la divina. una buena fuente para profundizar esto ultimo se encuentra en la monadologia.  leibniz distingue entre verdades de razon y verdades de hecho. las primeras son necesarias. las segundas no se justifican a priori, sin mas. «dos y dos son cuatro» es una verdad de razon. «colon descubrio america» es una verdad de hecho, porque pudo haber sido de otra manera, es decir, «colon no descubrio america». pero colon descubrio america porque ello estaba en su ser individual, colon (monada). las verdades de hecho estan incluidas en la esencia de la monada. pero solamente dios conoce todas las verdades de hecho, porque en su omnisciencia y omnipotencia no puede haber distinciones de verdades de razon y de hecho de cada monada. solo dios puede comprender las verdades de hecho, pues ello presupone un analisis infinito.  leibniz, en el orden del conocimiento, afirmara un tipo de innatismo. todas las ideas sin exclusion proceden de la actividad interna que le es propia a cada monada. las ideas, por ello, son innatas. leibniz se opondra a locke y a todo el empirismo ingles.   leibniz creia que gran parte del razonamiento humano podia reducirse a algun tipo de calculo, y que tales calculos podian resolver muchas diferencias de opinion: la unica manera de rectificar nuestros razonamientos es hacerlos tan tangibles como los de los matematicos, para que podamos encontrar nuestro error de un vistazo, y cuando haya disputas entre personas, podemos simplemente decir: calculemos [calculemus], sin mas dilacion, a ver quien tiene razon.​ el calculus ratiocinator de leibniz, que se asemeja a la logica simbolica, puede verse como una forma de hacer factibles tales calculos. leibniz escribio memorandos​ que ahora pueden leerse como intentos de levantar la logica simbolica y, por lo tanto, su calculo. estos escritos permanecieron ineditos hasta la aparicion de una seleccion editada por carl immanuel gerhardt (1859). louis couturat publico una seleccion en 1901; en ese momento los principales desarrollos de la logica moderna habian sido creados por charles sanders peirce y por gottlob frege.  leibniz penso que los simbolos eran importantes para la comprension humana. le dio tanta importancia al desarrollo de buenas notaciones que atribuyo todos sus descubrimientos en matematicas a esto. su notacion para el calculo es un ejemplo de su habilidad en este sentido. la pasion de leibniz por los simbolos y la notacion, asi como su creencia de que estos son esenciales para el buen funcionamiento de la logica y las matematicas, lo convirtio en un precursor de la semiotica.​   pero leibniz llevo sus especulaciones mucho mas alla. definiendo un caracter como cualquier signo escrito, luego definio un caracter \"real\" como aquel que representa una idea directamente y no simplemente como la palabra que encarna la idea. algunos caracteres reales, como la notacion de la logica, sirven unicamente para facilitar el razonamiento. muchos caracteres bien conocidos en su epoca, incluidos los jeroglificos egipcios, los caracteres chinos y los simbolos de la astronomia y la quimica, los considero no reales.​ en cambio, propuso la creacion de una characteristica universalis o \"caracteristica universal\", construida sobre un alfabeto del pensamiento humano (alphabetum cogitationum humanarum) en el que cada concepto fundamental estaria representado por un unico caracter \"real\": es obvio que si pudieramos encontrar caracteres o signos adecuados para expresar todos nuestros pensamientos con tanta claridad y exactitud como la aritmetica expresa los numeros o la geometria expresa las lineas, podriamos hacer en todas las materias en cuanto estan sujetas al razonamiento todo lo que podemos hacer en aritmetica y geometria. porque todas las investigaciones que dependan del razonamiento se realizarian por transposicion de estos caracteres y por una especie de calculo.​ los pensamientos complejos se representarian combinando caracteres para obtener pensamientos mas simples. leibniz vio que la unicidad de la descomposicion en factores primos sugiere un papel central para los numeros primos en la caracteristica universal, una sorprendente anticipacion de la numeracion de godel. por supuesto, no existe una forma intuitiva o mnemotecnica de numerar cualquier conjunto de conceptos elementales utilizando los numeros primos.  debido a que leibniz era un novato en matematicas cuando escribio por primera vez sobre la caracteristica, al principio no la concibio como un algebra sino como un lenguaje o escritura universal. recien en 1676 concibio una especie de \"algebra del pensamiento\", modelada e incluyendo el algebra convencional y su notacion. la caracteristica resultante incluia un calculo logico, algo de combinatoria, algebra, su analysis situs (geometria de la situacion), un lenguaje conceptual universal y mas. es posible que nunca se establezca lo que leibniz realmente pretendia con sus characteristica universalis y calculus ratiocinator, y hasta que punto la logica formal moderna hace justicia al calculo.​ la idea de leibniz de razonar a traves de un lenguaje universal de simbolos y calculos presagia notablemente los grandes desarrollos del siglo xx en los sistemas formales, como la completitud de turing, donde se utilizo la computacion para definir lenguajes universales equivalentes (ver: grado de turing).  leibniz ha sido señalado como uno de los logicos mas importantes entre los tiempos de aristoteles y gottlob frege.​ leibniz enuncio las principales propiedades de lo que ahora llamamos conjuncion, disyuncion, negacion, identidad, subconjunto y el conjunto vacio. los principios de la logica de leibniz y, posiblemente, de toda su filosofia, se reducen a dos:  la logica formal que surgio a principios del siglo xx tambien requiere, como minimo, una negacion unaria y variables cuantificadas que abarquen algun universo de discurso.  leibniz no publico nada sobre logica formal durante su vida; la mayor parte de lo que escribio sobre el tema consiste en borradores de trabajo. en su historia de la filosofia occidental, bertrand russell llego a afirmar que leibniz habia desarrollado la logica en sus escritos ineditos hasta un nivel que alcanzo solo 200 años despues.  el trabajo principal de russell sobre leibniz encontro que muchas de las ideas y afirmaciones filosoficas mas sorprendentes de leibniz (por ejemplo, que cada una de las monadas fundamentales refleja el universo entero) se derivan logicamente de la eleccion consciente de leibniz de rechazar las relaciones entre las cosas como irreales. consideraba tales relaciones como cualidades (reales) de las cosas (leibniz admitia unicamente predicados unarios): para el, \"maria es la madre de juan\" describe cualidades separadas de maria y de juan. esta vision contrasta con la logica relacional de de morgan, peirce, schroder y el mismo russell, ahora estandar en la logica de predicados. en particular, leibniz tambien declaro que el espacio y el tiempo son inherentemente relacionales.​  el descubrimiento de leibniz en 1690 de su algebra de conceptos​​ (deductivamente equivalente al algebra booleana)​ y la metafisica asociada, son de interes en la metafisica computacional actual.​  los escritos de leibniz sobre derecho, etica y politica​ fueron pasados ​​por alto durante mucho tiempo por los estudiosos de habla inglesa, pero esto ha cambiado ultimamente.​   si bien leibniz no fue un apologista de la monarquia absoluta como thomas hobbes, o de la tirania en cualquier forma, tampoco se hizo eco de las opiniones politicas y constitucionales de su contemporaneo john locke, opiniones invocadas en apoyo del liberalismo, en la america del siglo xviii y mas tarde en otros lugares. el siguiente extracto de una carta de 1695 al hijo del baron jc boyneburg, philipp, es muy revelador de los sentimientos politicos de leibniz: en cuanto a... la gran cuestion del poder de los soberanos y la obediencia que les deben sus pueblos, suelo decir que seria bueno que los principes se convencieran de que su pueblo tiene derecho a resistirlos, y que el pueblo, en por otro lado, ser persuadido a obedecerlos pasivamente. soy, sin embargo, bastante de la opinion de grocio, que uno debe obedecer como regla, siendo el mal de la revolucion mas grande sin comparacion que los males que la causan. sin embargo, reconozco que un principe puede llegar a tal exceso y poner en tal peligro el bienestar del estado, que cesa la obligacion de soportar. esto es muy raro, sin embargo, y el teologo que autoriza la violencia bajo este pretexto debe cuidarse de los excesos; el exceso es infinitamente mas peligroso que la deficiencia.​ en 1677, leibniz convoco a una confederacion europea, gobernada por un consejo o senado, cuyos miembros representarian a naciones enteras y serian libres de votar en conciencia;​ esto a veces se considera una anticipacion de la union europea. creia que europa adoptaria una religion uniforme. reitero estas propuestas en 1715.  pero, al mismo tiempo, llego a proponer un proyecto interreligioso y multicultural para crear un sistema universal de justicia, lo que requeria de el una amplia perspectiva interdisciplinaria. para proponerlo combino la linguistica (especialmente la sinologia), la filosofia moral y juridica, la gestion, la economia y la politica.​  leibniz se formo como academico del derecho, pero bajo la tutela del simpatizante cartesiano erhard weigel ya vemos un intento de resolver problemas legales mediante metodos matematicos racionalistas (la influencia de weigel es mas explicita en el specimen quaestionum philosophicarum ex jure collectarum (an essay of collected philosophical problemas de derecho). por ejemplo, la disputacion inaugural sobre casos desconcertantes​ utiliza la combinatoria temprana para resolver algunas disputas legales, mientras que la disertacion sobre el arte combinatorio de 1666​ incluye problemas legales simples a modo de ilustracion.  el uso de metodos combinatorios para resolver problemas juridicos y morales parece, a traves de athanasius kircher y daniel schwenter, de inspiracion lullista: ramon llull intento resolver disputas ecumenicas recurriendo a un modo de razonamiento combinatorio que consideraba universal (a mathesis universalis).​  a fines de la decada de 1660, el ilustrado principe-obispo de maguncia, johann philipp franz von schonborn, anuncio una revision del sistema legal y puso a disposicion un puesto para apoyar a su comisionado legal actual. leibniz dejo franconia y se dirigio a maguncia antes incluso de obtener el papel. al llegar a francfort del meno, leibniz escribio el nuevo metodo de enseñanza y aprendizaje de la ley, a modo de aplicacion.​ el texto proponia una reforma de la educacion juridica y es caracteristicamente sincretico, integrando aspectos del tomismo, el hobbesianismo, el cartesianismo y la jurisprudencia tradicional. el argumento de leibniz de que la funcion de la enseñanza del derecho no era imprimir reglas como se podria adiestrar a un perro, sino ayudar al estudiante a descubrir su propia razon publica, evidentemente impresiono a von schonborn cuando consiguio el puesto.  el proximo gran intento de leibniz de encontrar un nucleo racional universal para el derecho y asi fundar una “ciencia del derecho” legal, se produjo cuando leibniz trabajo en maguncia entre 1667 y 1672. partiendo inicialmente de la doctrina mecanicista del poder de hobbes, leibniz volvio a los metodos logico-combinatorios en un intento de definir la justicia. como avanzo el llamado elementa juris naturalis de leibniz, incorporo nociones modales de derecho (posibilidad) y obligacion (necesidad) en las que vemos quizas la elaboracion mas temprana de su doctrina de los mundos posibles dentro de un marco deontico.​ ​​mientras que finalmente los elementa permanecieron ineditos, leibniz continuo trabajando en sus borradores y promoviendo sus ideas a los corresponsales hasta su muerte.  en el campo de logica, gottfried wilhelm leibniz desarrollo la doctrina de analisis y sintesis. entendia la logica como la ciencia de todos los mundos posibles. leibniz pertenece a la primera en la historia de la formulacion de la ley de la razon suficiente; tambien es el autor de la expresion ley de identidad adoptada en la logica moderna​. consideraba que la ley de identidad era el principio supremo de la logica​. \"la naturaleza de la verdad en general consiste en el hecho de que es algo identico\".​  la ley de identidad formulada por leibniz se usa actualmente en la mayoria de los calculos logico-matematicos modernos​. el principio de sustitucion es equivalente a la ley de identidad: “si a es b y b es a, entonces a y b se llaman  'lo mismo' '“. o: a y b son iguales si pueden sustituirse por uno en lugar de otro \".​  para leibniz, los principios de identidad, sustitucion equivalente y contradiccion son los medios principales de cualquier prueba deductiva; confiando en ellos, leibniz intento probar algunos de los llamados axiomas​. creia que los axiomas son oraciones no comprobables, que son identidades, pero en matematicas no todas las posiciones dadas como axiomas son identidades y, por lo tanto, desde el punto de vista de leibniz, es necesario probarla​. el criterio de identificacion y distincion de los nombres introducidos por leibniz corresponde en cierta medida a la distincion moderna entre el significado y el significado de los nombres y expresiones, por ejemplo, el ejemplo bien conocido con la equivalencia de las expresiones \"sir walter scott\" y \"el autor de waverley\", que se remonta a russell, literalmente repite este pensamiento.   leibniz no desarrollo un sistema unificado de designaciones, desarrollo el calculo de signo mas negativo.​ la exitosa presentacion de leibniz de los modos de silogismo correctos fue la presentacion de juicios por medio de segmentos o circulos paralelos (\"experiencia de silogistica basada en evidencia\" en el libro opuscules et fragments inedits de leibniz).​ el importante lugar de leibniz estaba ocupado por la proteccion del objeto y el metodo de la logica formal​. escribio a g. wagner el siguiente​:  … aunque el sr. antoine arnauld (hijo), en su arte de pensar, argumento que las personas rara vez cometen errores de forma, pero casi en esencia, de hecho, la situacion es completamente diferente y ya huygens, junto conmigo, noto que generalmente los errores matematicos, llamados paralogismo, son causados por desorden de forma. y, por supuesto, aristoteles no derivo en nada leyes estrictas para estas formas y, por lo tanto, fue el primero en escribir matematicamente fuera de las matematicas.  leibniz hizo la clasificacion mas completa de definiciones para su epoca, ademas, desarrollo una teoria de definiciones geneticas. en su trabajo \"el arte de la combinatoria\", escrito en 1666, leibniz anticipo algunos aspectos de la logica matematica​. combinatoria llamada leibniz desarrollada por el bajo la influencia de  r. lully la idea del \"gran arte\" del descubrimiento, que, basada en las \"primeras verdades\" obvias, permitiria logicamente derivar de ellos todo el sistema de conocimiento​. este tema se ha convertido en uno de los temas clave de toda la vida y desarrollo los principios de la \"ciencia universal\", sobre los cuales, segun el, \"el bienestar de la humanidad depende sobre todo de\". gottfried wilhelm leibniz escribio la idea de utilizar  simbolos matematicos en logica y la construccion de calculos logicos. avanzo en la tarea de corroborar verdades matematicas sobre principios logicos generales, y tambien propuso usar un sistema numerico binario, es decir, binario, para los propositos de las matematicas computacionales. leibniz justifico la importancia del simbolismo racional para la logica y para las conclusiones heuristicas; argumento que el conocimiento se reduce a pruebas de afirmaciones, pero para encontrar pruebas es necesario mediante un cierto metodo.​  segun leibniz, el metodo matematico en si mismo no es suficiente para descubrir todo lo que estamos buscando, pero protege de los errores​. esto ultimo se explica por el hecho de que, en matematicas, las declaraciones se formulan con la ayuda de ciertos signos y actuan de acuerdo con ciertas reglas, y el chequeo, que es posible en cada etapa, requiere \"solo papel y tinta\" ​. leibniz tambien expreso por primera vez la idea de la posibilidad del modelado a maquina de funciones humanas, tambien posee el termino \"modelo\" ​. leibniz hizo una gran contribucion al desarrollo del concepto de \"necesidad\". entendio la necesidad como algo que debe ser. segun leibniz, la primera necesidad es metafisica, absoluta, asi como la necesidad logica y geometrica. se basa en las leyes de identidad y contradiccion, por lo tanto admite la unica posibilidad de eventos. leibniz tambien observo otras caracteristicas de la necesidad. contrasto la necesidad de azar, entendiendola no como una apariencia subjetiva, sino como una conexion objetiva de fenomenos, que depende de decisiones libres y del curso de los procesos en el universo. lo entendio como un accidente relativo, de naturaleza objetiva y que surge en la interseccion de ciertos procesos necesarios. en \"nuevas experiencias\" (libro 4), leibniz hizo un analisis deductivo de la logica tradicional, mostrando que las figuras 2 y 3 del silogismo pueden obtenerse como consecuencia del modo \"barbara\" usando la ley de la contradiccion, y la 4ta figura. - utilizar la ley de tratamiento; aqui dio una nueva clasificacion de los modos de silogismo.​ las ideas logicas originales de leibniz, las mas valoradas hoy en dia, solo se conocieron en el siglo xx.​ los resultados de leibniz tuvieron que ser redescubiertos, ya que su propio trabajo fue enterrado en pilas de manuscritos de la biblioteca real en hannover.​  antes de leibniz se crearon varias tecnicas para resolver los problemas de tangente, encontrar extremos y calcular cuadratura, pero en las obras de sus antecesores no habia ningun estudio limitado principalmente por funciones algebraicas completas a cualquier fraccional e irracional y especialmente a  funciones trascendentales. en estos trabajos, los conceptos basicos de analisis no se distinguieron claramente de ninguna manera, y sus interrelaciones no se establecieron, no hubo un simbolismo desarrollado y uniforme. gottfried leibniz reunio tecnicas privadas y dispares en un solo sistema de conceptos de analisis interrelacionados, expresados en notacion, permitiendo realizar acciones con infinitamente pequeñas de acuerdo con las reglas de un cierto algoritmo.  el documento de leibniz establece los conceptos basicos del calculo diferencial, las reglas de  diferenciacion de las expresiones. utilizando la interpretacion geometrica de la relacion d y d x {dx}}} , explica brevemente los signos de aumento y disminucion,  maximo y minimo, convexidad y concavidad (por lo tanto, condiciones suficientes extremo y para el caso mas simple), asi como puntos de inflexion. en el camino, las \"diferenciales de diferenciales\" (multiplos de diferenciales), denotadas por \" d d v \", se introducen sin ninguna explicacion. leibniz escribio: «lo que una persona versada en este calculo puede resolver en tres lineas, otros hombres eruditos se vieron obligados a buscar siguiendo complejos desvios».  en el enfoque de leibniz para el analisis matematico habia algunas caracteristicas. leibniz concibio el analisis mas alto no de forma cinematica, sino que algebraicamente, a diferencia de newton. en sus primeros articulos, parecia entender infinitesimales como objetos reales comparables entre si solo si son del mismo orden. tal vez esperaba establecer su conexion con su concepto de monadas. al final de su vida, hablo bastante a favor de variables potencialmente infinitas, aunque no explico lo que queria decir con eso. en terminos filosoficos generales, consideraba el infinitesimal como el soporte de la continuidad en la naturaleza. los intentos de leibniz de realizar un analisis riguroso del analisis no tuvieron exito, dudo entre varias interpretaciones de infinitamente pequeñas, a veces intento recurrir a ideas no especificadas de limite y continuidad. las opiniones de leibniz sobre la naturaleza de lo infinitamente pequeño y sobre la razon de las operaciones en ellas causaron criticas incluso durante su vida, y la razon para el analisis que satisface los requisitos cientificos modernos solo podria darse en el siglo xix.  gottfried wilhelm leibniz demostro la solidez de sus metodos generales al resolver varios problemas dificiles. por ejemplo, en 1691 establecio que un hilo pesado y uniforme que colgaba en dos extremos tenia la forma de una catenaria y, junto con isaac newton, jacob y johann bernoulli, y tambien l'hopital, en 1696, resolvio el problema de la curva braquistocrona.  un papel importante en la difusion de ideas de leibniz fue desempeñado por su extensa correspondencia. leibniz declaro algunos descubrimientos solo con letras: los inicios de la teoria de determinantes en 1693 y, una generalizacion del concepto de un diferencial a indicadores negativos y fraccionarios en 1695 y, un signo de convergencia de una serie de signos alternos (atributo leibniz, 1682), metodos para resolver cuadraturas de varios tipos de ecuaciones diferenciales ordinarias.  leibniz introdujo los siguientes terminos: \" diferencial\", \"calculo diferencial\", \"ecuacion diferencial\", \" funcion\", \" variable\", \"constante\", \"coordenadas\", \"abscisa\", \"curvas algebraicas y trascendentales\", \"algoritmo\"(en un sentido cercano al moderno). aunque el concepto matematico de una funcion estaba implicito en trigonometria y en las tablas logaritmicas que existian en su epoca, leibniz fue el primero en usarlo explicitamente para referirse a cualquiera de varios conceptos geometricos derivados de una curva, como la abscisa, ordenada, tangente,  cuerda y normal.​  leibniz formulo el concepto de diferencial como una diferencia infinitamente pequeña entre dos valores infinitamente cercanos de una variable e integral como la suma de un numero infinito de diferenciales y dio las reglas mas simples para la diferenciacion e integracion ya en sus notas manuscritas de paris relativas a octubre y noviembre de 1675; aqui en leibniz por primera vez hay signos modernos del diferencial \" d \" y la integral. leibniz dio la definicion y el signo del diferencial en 1684, en la primera memoria sobre calculo diferencial, \"un nuevo metodo de maximos y minimos\". en el mismo trabajo, las reglas para diferenciar la suma, diferencia, producto, parcial, cualquier grado constante, funcion de la funcion (invariancia del primer diferencial), asi como las reglas para encontrar y distinguir (usando el segundo diferencial) maximos y minimos y encontrar puntos de inflexion. el diferencial de una funcion se definio como la relacion de la ordenada al sub-tangente, multiplicada por el diferencial del argumento, cuyo valor puede tomarse arbitrariamente; al mismo tiempo, leibniz indico que los diferenciales son proporcionales a incrementos infinitesimales de magnitudes y que, en base a esto, es facil obtener una prueba de sus reglas.  el ensayo de 1684 fue seguido por una serie de otros ensayos de leibniz, que cubren en su totalidad todas las divisiones basicas de calculo diferencial e integral. en estas obras, gottfried wilhelm leibniz definio y el signo integral (1686), enfatizando la naturaleza reciproca de las dos operaciones de analisis principales, indico las reglas para diferenciar la funcion exponencial y la diferenciacion multiple de una obra (formula leibniz, ), y tambien inicio la integracion de fracciones racionales (1702 - 1703). ademas, leibniz otorgo una importancia fundamental al uso de series de potencias infinitas para el estudio de funciones y la solucion de ecuaciones diferenciales (1693).  debido no solo a publicaciones anteriores, sino tambien a designaciones significativamente mas convenientes y transparentes del trabajo de leibniz sobre el calculo diferencial e integral, tuvieron una influencia mucho mayor en los contemporaneos que la teoria de newton. incluso los compatriotas de newton, que durante mucho tiempo prefirieron el metodo de fluxiones, aprendieron gradualmente la notacion leibniz mas conveniente. leibniz tambien describio sistemas binarios con los numeros 0 y 1. el moderno sistema binario fue completamente descrito por el en la obra  explication de l’arithmetique binair. como una persona interesada en la cultura china, leibniz conocio el libro de cambios y noto que los  hexagramas corresponden a numeros binarios del 0 al 111111. admiro el hecho de que este mapeo es evidencia de importantes logros chinos en las matematicas filosoficas de la epoca.​ leibniz pudo haber sido el primer programador y teorico de la informacion.​ encontro que si escribes ciertos grupos de numeros binarios uno debajo del otro, entonces los ceros y los de las columnas verticales se repetiran con regularidad, y este descubrimiento lo llevo a creer que hay leyes completamente nuevas de las matematicas. leibniz se dio cuenta de que el codigo binario es optimo para el sistema de mecanica, que puede funcionar sobre la base de ciclos activos, pasivos y pasivos intermitentes. intento aplicar codigo binario en mecanica e incluso hizo un dibujo de una computadora que funcionaba sobre la base de sus nuevas matematicas, pero pronto se dio cuenta de que las capacidades tecnologicas de su tiempo no permitian crear una maquina de este tipo. el proyecto de la computadora que opera en el sistema binario, en el que se uso el prototipo tarjeta perforada, leibniz describio en un trabajo escrito en 1679 y (antes describio la aritmetica binaria en detalle en 1703 a  explication de l'arithmetique binaire ). las unidades y los ceros en una maquina imaginaria estaban representados respectivamente por orificios abiertos o cerrados en un frasco en movimiento, a traves de los cuales se suponia que pasaban bolas cayendo en las ranuras debajo de el. leibniz tambien escribio sobre la posibilidad de modelar a maquina las funciones del cerebro humano.  al proponer que la tierra tiene un nucleo fundido, se anticipo a la geologia moderna. en embriologia, fue un preformista, pero tambien propuso que los organismos son el resultado de una combinacion de un numero infinito de microestructuras posibles y de sus poderes. en las ciencias de la vida y la paleontologia, revelo una asombrosa intuicion transformista, alimentada por su estudio de la anatomia comparada y los fosiles. uno de sus principales trabajos sobre este tema, protogaea, inedito en vida, se ha publicado recientemente en ingles por primera vez. el elaboro ​​una teoria organismica primaria.​ en medicina, exhorto a los medicos de su epoca, con algunos resultados, a fundamentar sus teorias en detalladas observaciones comparativas y experimentos verificados, ya distinguir firmemente los puntos de vista cientifico y metafisico.  la psicologia habia sido un interes central de leibniz.​​ parece ser un \"pionero subestimado de la psicologia\".​ escribio sobre temas que ahora se consideran campos de la psicologia: atencion, conciencia, memoria, aprendizaje (asociacion), motivacion (el acto de \"esfuerzo\"), la individualidad emergente, la dinamica general del desarrollo (psicologia evolutiva).[cita requerida] sus discusiones en nuevos ensayos and monadologia menudo se basa en observaciones cotidianas, como el comportamiento de un perro o el ruido del mar, y desarrolla analogias intuitivas (el funcionamiento sincronico de los relojes o el resorte de equilibrio de un reloj). tambien ideo postulados y principios que se aplican a la psicologia: el continuo de las pequeñas percepciones inadvertidas a la apercepcion distinta autoconsciente, y el paralelismo psicofisico desde el punto de vista de la causalidad y del proposito: \"las almas actuan de acuerdo con las leyes de la final\". causas, a traves de aspiraciones, fines y medios. los cuerpos actuan segun las leyes de las causas eficientes, es decir, las leyes del movimiento. y estos dos reinos, el de las causas eficientes y el de las causas finales, armonizan entre si\".​ esta idea se refiere al problema mente-cuerpo, afirmando que la mente y el cerebro no actuan uno sobre el otro, sino que actuan uno al lado del otro por separado pero en armonia.​ leibniz, sin embargo, no utilizo el termino psicologia. la posicion epistemologica de leibniz, contra john locke y el empirismo ingles (sensualismo), quedo clara: \"nihil est in intellectu quod non fuerit in sensu, nisi intellectu ipse\". – \"nada hay en el intelecto que no haya sido primero en los sentidos, excepto el intelecto mismo\".​ principios que no estan presentes en las impresiones sensoriales pueden reconocerse en la percepcion y la conciencia humanas: inferencias logicas, categorias de pensamiento, el principio de causalidad y el principio de proposito (teleologia).  leibniz encontro a su interprete mas importante en wilhelm wundt, fundador de la psicologia como disciplina. wundt uso la cita \"... nisi intellectu ipse\" de 1862 en la portada de su beitrage zur theorie der sinneswahrnehmung (contribuciones sobre la teoria de la percepcion sensorial) y publico una detallada y aspirante monografia sobre leibniz.​ wundt dio forma al termino apercepcion, introducido por leibniz, en una psicologia de la apercepcion basada en la psicologia experimental que incluia el modelado neuropsicologico, un excelente ejemplo de como un concepto creado por un gran filosofo podria estimular un programa de investigacion psicologica. un principio en el pensamiento de leibniz desempeño un papel fundamental: \"el principio de igualdad de puntos de vista separados pero correspondientes\". wundt caracterizo este estilo de pensamiento (perspectivismo) de una manera que tambien se aplicaba a el: puntos de vista que \"se complementan entre si, al mismo tiempo que pueden aparecer como opuestos que solo se resuelven cuando se consideran mas profundamente\".​​ gran parte del trabajo de leibniz tuvo un gran impacto en el campo de la psicologia. leibniz penso que hay muchas percepciones pequeñas de las que percibimos pero de las que no somos conscientes. creia que por el principio de que los fenomenos que se encuentran en la naturaleza eran continuos por defecto, era probable que la transicion entre los estados consciente e inconsciente tuviera pasos intermedios. para que esto sea cierto, tambien debe haber una parte de la mente de la que no somos conscientes en un momento dado.​ su teoria sobre la conciencia en relacion con el principio de continuidad puede verse como una teoria temprana sobre las etapas del sueño. de esta manera, la teoria de la percepcion de leibniz puede verse como una de las muchas teorias que conducen a la idea del inconsciente. leibniz fue una influencia directa en ernst platner, a quien se le atribuye haber acuñado originalmente el termino unbewußtseyn (inconsciente).​ ademas, la idea de los estimulos subliminales se remonta a su teoria de las pequeñas percepciones.​ las ideas de leibniz sobre la musica y la percepcion tonal influyeron en los estudios de laboratorio de wilhelm wundt.​  aunque la nocion matematica de funcion estaba implicita en la trigonometria y las tablas logaritmicas, las cuales ya existian en sus tiempos, leibniz fue el primero, en 1692 y 1694, en emplearlas explicitamente para denotar alguno de los varios conceptos geometricos derivados de una curva, tales como abscisa, ordenada, tangente, cuerda y perpendicular.​ leibniz fue el primero en proponer el uso del punto como multiplicador en la notacion matematica en vez de la letra equis (x) que usaban en inglaterra para ello. la letra equis (x) se utilizo desde entonces como nombre de variable, especialmente para el calculo en tres dimensiones xyz.​ en el siglo xviii, el concepto de «funcion» perdio estas asociaciones meramente geometricas.  leibniz fue el primero en ver que los coeficientes de un sistema de ecuaciones lineales podian ser organizados en un arreglo, ahora conocido como matriz, el cual podia ser manipulado para encontrar la solucion del sistema, si la hubiera. este metodo fue conocido mas tarde como «eliminacion gaussiana». leibniz tambien hizo aportes en el campo del algebra booleana y la logica simbolica.  la invencion del calculo infinitesimal es atribuida a leibniz y newton. de acuerdo con los cuadernos de leibniz, el 11 de noviembre de 1675 tuvo lugar un acontecimiento fundamental. ese dia empleo por primera vez el calculo integral para encontrar el area bajo la curva de una funcion y=f(x).  leibniz introdujo varias notaciones usadas en la actualidad, tal como, por ejemplo, el signo «integral» ∫, que representa una s alargada, derivado del latin summa, y la letra «d» para referirse a los «diferenciales», del latin differentia. esta ingeniosa y sugerente notacion para el calculo es probablemente su legado matematico mas perdurable. actualmente se emplea la notacion del calculo creada por leibniz, no la de newton.  leibniz no publico nada acerca de su calculus hasta 1684.​ la regla del producto del calculo diferencial es aun denominada «regla de leibniz para la derivacion de un producto». ademas, el teorema que dice cuando y como diferenciar bajo el simbolo integral, se llama la «regla de leibniz para la derivacion de una integral».  desde 1711 hasta su muerte, la vida de leibniz estuvo emponzoñada con una larga disputa con john keill, newton y otros sobre si habia inventado el calculo independientemente de newton, o si meramente habia inventado otra notacion para las ideas de newton.​ leibniz paso entonces el resto de su vida tratando de demostrar que no habia plagiado las ideas de newton.  la formula de leibniz para π/4 establece que:   1 − 1 3 + 1 5 − 1 7 + 1 9 − ⋯ = π 4 {3}}\\,+\\,{5}}\\,-\\,{7}}\\,+\\,{9}}\\,-\\,\\cdots \\,=\\,{4}}}  leibniz escribio que los circulos \"pueden expresarse de la manera mas simple mediante esta serie, es decir, el agregado de fracciones alternativamente sumadas y restadas\".​ sin embargo, esta formula solo es precisa con un gran numero de terminos, utilizando 10 000 000 terminos para obtener el valor correcto de π/4 a 8 decimales.​ leibniz intento crear una definicion para una linea recta al intentar probar el postulado de las paralelas.​ si bien la mayoria de los matematicos definieron una linea recta como la linea mas corta entre dos puntos, leibniz creia que esto era simplemente una propiedad de una linea recta en lugar de la definicion.​  leibniz tambien publico la idea de la ciencia que ahora se llama topologia, que se ocupa de las propiedades del espacio que se conservan bajo deformaciones continuas, a la que llamo \"geometria de posicion\" (geometria situs) y \"analisis de posicion\" (analysis situs). leibniz fue el primero en utilizar el termino analysis situs, que luego se utilizaria en el siglo xix para referirse a lo que se conoce como topologia.  ademas de los distintos conceptos matematicos que llevan su nombre, se tiene que: ",
        "snippet": "Gottfried Wilhelm Leibniz, a veces Gottfried Wilhelm von Leibniz[1]​ (Leipzig, 1 de julio de 1646-Hannover, 14 de noviembre de 1716), fue un polímata, filósofo, matemático, lógico, teólogo, jurista, bibliotecario y político alemán.",
        "enlaces_salientes": [
            "/wiki/Gottfried_Leibniz",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Gottfried_Leibniz",
            "/wiki/Leibnitz",
            "/wiki/Museo_Herzog_Anton_Ulrich",
            "/wiki/Brunswick",
            "/wiki/Leipzig",
            "/wiki/Electorado_de_Sajonia",
            "/wiki/Hannover",
            "/wiki/Electorado_de_Brunswick-L%C3%BCneburg",
            "/wiki/Sacro_Imperio_Romano_Germ%C3%A1nico",
            "/wiki/Luteranismo",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/Thomasschule_zu_Leipzig",
            "/wiki/Universidad_de_Leipzig",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Derecho",
            "/wiki/Universidad_de_Jena",
            "/wiki/Universidad_de_Altdorf",
            "/wiki/Jakob_Thomasius",
            "/wiki/Erhard_Weigel",
            "/wiki/Christiaan_Huygens",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Pol%C3%ADtica",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Consejo_%C3%81ulico",
            "/wiki/Nicolas_Malebranche",
            "/wiki/Christian_Wolff",
            "/wiki/Jakob_Bernoulli",
            "/wiki/Johann_Bernoulli",
            "/wiki/Racionalismo",
            "/wiki/Discurso_de_metaf%C3%ADsica",
            "/wiki/Th%C3%A9odic%C3%A9e",
            "/wiki/Stepped_Reckoner",
            "/wiki/Monadolog%C3%ADa",
            "/wiki/Royal_Society",
            "/wiki/Pontificia_Academia_de_las_Ciencias",
            "/wiki/Academia_Prusiana_de_las_Ciencias",
            "/wiki/Academia_de_Ciencias_de_Francia",
            "/wiki/Miembro_de_la_Royal_Society",
            "/wiki/Isaac_Newton",
            "/wiki/Controversia_del_c%C3%A1lculo",
            "/wiki/Leipzig",
            "/wiki/Hannover",
            "/wiki/Pol%C3%ADmata",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Matem%C3%A1tico",
            "/wiki/L%C3%B3gico",
            "/wiki/Te%C3%B3logo",
            "/wiki/Jurista",
            "/wiki/Bibliotecario",
            "/wiki/Pol%C3%ADtico",
            "/wiki/Alemania",
            "/wiki/Siglo_XVII",
            "/wiki/Siglo_XVIII",
            "/wiki/Metaf%C3%ADsica",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/L%C3%B3gica",
            "/wiki/Filosof%C3%ADa_de_la_religi%C3%B3n",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/F%C3%ADsica",
            "/wiki/Geolog%C3%ADa",
            "/wiki/Jurisprudencia",
            "/wiki/Historia",
            "/wiki/Denis_Diderot",
            "/wiki/De%C3%ADsmo",
            "/wiki/L%27Encyclop%C3%A9die",
            "/wiki/Voltaire",
            "/wiki/Isaac_Newton",
            "/wiki/Optimismo",
            "/wiki/Historia_de_la_filosof%C3%ADa_occidental",
            "/wiki/Historia_de_la_matem%C3%A1tica",
            "/wiki/Isaac_Newton",
            "/wiki/Robert_Hooke",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Sistema_binario",
            "/wiki/Filosof%C3%ADa_china",
            "/wiki/Rep%C3%BAblica_Popular_China",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Baruch_Spinoza",
            "/wiki/Racionalismo",
            "/wiki/Escol%C3%A1stica",
            "/wiki/Filosof%C3%ADa_anal%C3%ADtica",
            "/wiki/Tecnolog%C3%ADa",
            "/wiki/Biolog%C3%ADa",
            "/wiki/Medicina",
            "/wiki/Teor%C3%ADa_de_la_probabilidad",
            "/wiki/Psicolog%C3%ADa",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Ciencias_de_la_informaci%C3%B3n_(tecnolog%C3%ADa)",
            "/wiki/1_de_julio",
            "/wiki/1646",
            "/wiki/Leipzig",
            "/wiki/Guerra_de_los_Treinta_A%C3%B1os",
            "/wiki/Universidad_de_Leipzig",
            "/wiki/Padres_de_la_Iglesia",
            "/wiki/Lat%C3%ADn",
            "/wiki/Idioma_griego",
            "/wiki/1661",
            "/wiki/1666",
            "/wiki/Habilitaci%C3%B3n",
            "/wiki/Disertaci%C3%B3n_acerca_del_arte_combinatorio",
            "/wiki/Universidad_de_Altdorf",
            "/wiki/Altdorf_bei_N%C3%BCrnberg",
            "/wiki/Alquimia",
            "/wiki/N%C3%BAremberg",
            "/wiki/Primer_ministro",
            "/wiki/Electorado_de_Maguncia",
            "/wiki/Johann_Philipp_Franz_von_Sch%C3%B6nborn",
            "/wiki/Tribunal_de_apelaci%C3%B3n",
            "/wiki/Diplom%C3%A1tico",
            "/wiki/Alias",
            "/wiki/Polonia",
            "/wiki/Geopol%C3%ADtica",
            "/wiki/Luis_XIV_de_Francia",
            "/wiki/Francia",
            "/wiki/Egipto",
            "/wiki/Indias_Orientales_Neerlandesas",
            "/wiki/Provincias_Unidas_de_los_Pa%C3%ADses_Bajos",
            "/wiki/Nicolas_Malebranche",
            "/wiki/Antoine_Arnauld",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Blaise_Pascal",
            "/wiki/Ehrenfried_Walther_von_Tschirnhaus",
            "/wiki/Christiaan_Huygens",
            "/wiki/C%C3%A1lculo_diferencial",
            "/wiki/Serie_matem%C3%A1tica",
            "/wiki/Henry_Oldenburg",
            "/wiki/John_Collins_(matem%C3%A1tico)",
            "/wiki/Royal_Society",
            "/wiki/C%C3%A1lculo",
            "/wiki/Arim%C3%A9tica",
            "/wiki/Stepped_Reckoner",
            "/wiki/Mecenazgo",
            "/wiki/Electorado_de_Brunswick-Luneburgo",
            "/wiki/Hannover",
            "/wiki/Casa_de_Habsburgo",
            "/wiki/1676",
            "/wiki/Isaac_Newton",
            "/wiki/La_Haya",
            "/wiki/Anton_van_Leeuwenhoek",
            "/wiki/Microscopio",
            "/wiki/Microorganismo",
            "/wiki/Baruch_Spinoza",
            "/wiki/%C3%89tica_(Spinoza)",
            "/wiki/Ortodoxia",
            "/wiki/Cristianismo",
            "/wiki/1677",
            "/wiki/Casa_de_Han%C3%B3ver",
            "/wiki/Bibliotheca_Augusta",
            "/wiki/Sof%C3%ADa_Carlota_de_Hannover",
            "/wiki/Carolina_de_Brandeburgo-Ansbach",
            "/wiki/Jorge_II_de_Gran_Breta%C3%B1a",
            "/wiki/Jorge_I_de_Gran_Breta%C3%B1a",
            "/wiki/Ducado_de_Brunswick",
            "/wiki/Sacro_Imperio_Romano_Germ%C3%A1nico",
            "/wiki/Acta_de_Establecimiento",
            "/wiki/Guillermo_III_de_Inglaterra",
            "/wiki/Ana_de_Gran_Breta%C3%B1a",
            "/wiki/Parlamento_del_Reino_Unido",
            "/wiki/Baja_Sajonia",
            "/wiki/C%C3%A1lculo",
            "/wiki/Otto_Mencke",
            "/wiki/Acta_Eruditorum",
            "/wiki/Ernesto_Augusto_de_Brunswick-Luneburgo",
            "/wiki/Carlomagno",
            "/wiki/Genealog%C3%ADa",
            "/wiki/Fotocromo",
            "/wiki/1711",
            "/wiki/John_Keill",
            "/wiki/Controversia_del_c%C3%A1lculo",
            "/wiki/Zar",
            "/wiki/Pedro_I_de_Rusia",
            "/wiki/1712",
            "/wiki/Viena",
            "/wiki/1714",
            "/wiki/Carolina_de_Brandeburgo-Ansbach",
            "/wiki/Sof%C3%ADa_de_Wittelsbach",
            "/wiki/1714",
            "/wiki/Hannover",
            "/wiki/Hannover",
            "/wiki/1716",
            "/wiki/Academia_Prusiana_de_las_Ciencias",
            "/wiki/Bernard_Le_Bovier_de_Fontenelle",
            "/wiki/Academia_de_Ciencias_de_Francia",
            "/wiki/Isabel_Carlota_del_Palatinado",
            "/wiki/Electorado_de_Maguncia",
            "/wiki/Par%C3%ADs",
            "/wiki/Londres",
            "/wiki/Casa_de_Han%C3%B3ver",
            "/wiki/Juan_Federico_de_Brunswick-Luneburgo",
            "/wiki/Electorado_de_Brunswick-Luneburgo",
            "/wiki/Ernesto_Augusto_de_Brunswick-Luneburgo",
            "/wiki/Alemania",
            "/wiki/Austria",
            "/wiki/Italia",
            "/wiki/Jorge_I_de_Gran_Breta%C3%B1a",
            "/wiki/Viena",
            "/wiki/1713",
            "/wiki/Carlos_VI_del_Sacro_Imperio_Romano_Germ%C3%A1nico",
            "/wiki/Habsburgo",
            "/wiki/Reino_de_Gran_Breta%C3%B1a",
            "/wiki/Lat%C3%ADn_medieval",
            "/wiki/Idioma_franc%C3%A9s",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/Th%C3%A9odic%C3%A9e",
            "/wiki/Biblioteca_Nacional_de_Polonia",
            "/wiki/Kiel",
            "/wiki/Biblioteca_Gottfried_Wilhelm_Leibniz",
            "/wiki/Hamburgo",
            "/wiki/Soberan%C3%ADa",
            "/wiki/Nouveaux_essais_sur_l%27entendement_humain",
            "/wiki/John_Locke",
            "/wiki/1895",
            "/wiki/1685",
            "/wiki/1695",
            "/wiki/Edici%C3%B3n_cr%C3%ADtica",
            "/wiki/Catalogaci%C3%B3n",
            "/wiki/1901",
            "/wiki/Holocausto",
            "/wiki/Ocupaci%C3%B3n_aliada_de_Alemania",
            "/wiki/Cortina_de_hierro",
            "/wiki/1985",
            "/wiki/Potsdam",
            "/wiki/M%C3%BCnster",
            "/wiki/Hannover",
            "/wiki/Berl%C3%ADn",
            "/wiki/2006",
            "/wiki/Concordancia_gramatical",
            "/wiki/Universidad_de_Leipzig",
            "/wiki/Ernst_Julius_H%C3%A4hnel",
            "/wiki/1883",
            "/wiki/Voltaire",
            "/wiki/C%C3%A1ndido",
            "/wiki/Christian_Wolff",
            "/wiki/Ley_de_gravitaci%C3%B3n_universal",
            "/wiki/Teor%C3%ADa_de_la_relatividad",
            "/wiki/Immanuel_Kant",
            "/wiki/1768",
            "/wiki/Johann_Eduard_Erdmann",
            "/wiki/Gerland",
            "/wiki/Antoine_Arnauld",
            "/wiki/Samuel_Clarke",
            "/wiki/Sof%C3%ADa_del_Palatinado",
            "/wiki/Sof%C3%ADa_Carlota_de_Hannover",
            "/wiki/Bertrand_Russell",
            "/wiki/Metaf%C3%ADsica",
            "/wiki/Louis_Couturat",
            "/wiki/L%C3%B3gica",
            "/wiki/Bernhard_Riemann",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Historia_de_las_ideas",
            "/wiki/Revoluci%C3%B3n_industrial",
            "/wiki/Filosof%C3%ADa_anal%C3%ADtica",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Identidad_(filosof%C3%ADa)",
            "/wiki/Individuaci%C3%B3n",
            "/wiki/Mundo_posible",
            "/wiki/Plat%C3%B3n",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Universo",
            "/wiki/Raz%C3%B3n",
            "/wiki/Premio_Gottfried_Wilhelm_Leibniz",
            "/wiki/2018",
            "/wiki/1970",
            "/wiki/Uni%C3%B3n_Astron%C3%B3mica_Internacional",
            "/wiki/Leibnitz_(cr%C3%A1ter)",
            "/wiki/Cr%C3%A1ter_de_impacto",
            "/wiki/Cara_oculta_de_la_Luna",
            "/wiki/Universidad_de_Hannover",
            "/wiki/1700",
            "/wiki/Th%C3%A9odic%C3%A9e",
            "/wiki/1710",
            "/wiki/Discurso_de_metaf%C3%ADsica",
            "/wiki/1686",
            "/wiki/Malebranche",
            "/wiki/Antoine_Arnauld",
            "/wiki/Nuevos_ensayos_sobre_el_entendimiento_humano",
            "/wiki/Ensayo_sobre_el_entendimiento_humano",
            "/wiki/John_Locke",
            "/wiki/Monadolog%C3%ADa",
            "/wiki/Aforismo",
            "/wiki/Giordano_Bruno",
            "/wiki/Baruch_Spinoza",
            "/wiki/Ren%C3%A9_Descartes",
            "/wiki/Filosof%C3%ADa_escol%C3%A1stica",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Universidad_de_Leipzig",
            "/wiki/Jakob_Thomasius",
            "/wiki/Francisco_Su%C3%A1rez",
            "/wiki/Compa%C3%B1%C3%ADa_de_Jes%C3%BAs",
            "/wiki/Luteranismo",
            "/wiki/Christiaan_Huygens",
            "/wiki/Isaac_Newton",
            "/wiki/Robert_Boyle",
            "/wiki/L%C3%B3gica",
            "/wiki/Filosof%C3%ADa_china",
            "/wiki/Identidad_(filosof%C3%ADa)",
            "/wiki/Contradicci%C3%B3n",
            "/wiki/Sustancia_(filosof%C3%ADa)",
            "/wiki/Identidad_de_los_indiscernibles",
            "/wiki/Mec%C3%A1nica_cu%C3%A1ntica",
            "/wiki/Principio_de_raz%C3%B3n_suficiente",
            "/wiki/Armon%C3%ADa_preestablecida",
            "/wiki/Mec%C3%A1nica_de_medios_continuos",
            "/wiki/Natura_non_facit_saltum",
            "/wiki/Funci%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Dominio_de_definici%C3%B3n",
            "/wiki/Rango_(matem%C3%A1ticas)",
            "/wiki/Conjunto_denso",
            "/wiki/Optimismo",
            "/wiki/El_mejor_de_los_mundos_posibles",
            "/wiki/Principio_de_raz%C3%B3n_suficiente",
            "/wiki/Azar",
            "/wiki/Contingencia",
            "/wiki/Principio_de_no_contradicci%C3%B3n",
            "/wiki/Ciencia_experimental",
            "/wiki/Aforismo",
            "/wiki/Continuo",
            "/wiki/Monadolog%C3%ADa",
            "/wiki/M%C3%B3nada_(filosof%C3%ADa)",
            "/wiki/%C3%81tomo",
            "/wiki/Universo",
            "/wiki/Pampsiquismo",
            "/wiki/Espiritual",
            "/wiki/Apetito",
            "/wiki/Fuerza",
            "/wiki/Espacio_(f%C3%ADsica)",
            "/wiki/Materia",
            "/wiki/Movimiento_(f%C3%ADsica)",
            "/wiki/Ciencias_naturales",
            "/wiki/Ontolog%C3%ADa",
            "/wiki/Ley_cient%C3%ADfica",
            "/wiki/Part%C3%ADcula_subat%C3%B3mica",
            "/wiki/Libre_albedr%C3%ADo",
            "/wiki/Dios",
            "/wiki/Existencia_de_Dios",
            "/wiki/Mente",
            "/wiki/Cuerpo_humano",
            "/wiki/Problema_mente-cuerpo",
            "/wiki/Individuaci%C3%B3n",
            "/wiki/Berl%C3%ADn",
            "/wiki/Primer_motor_inm%C3%B3vil",
            "/wiki/Arist%C3%B3teles_Onassis",
            "/wiki/Baruch_Spinoza",
            "/wiki/Isaac_Newton",
            "/wiki/Hegel",
            "/wiki/Dios_en_el_cristianismo",
            "/wiki/Te%C3%ADsmo_cl%C3%A1sico",
            "/wiki/Existencia_de_Dios",
            "/wiki/Argumento_ontol%C3%B3gico",
            "/wiki/Argumento_cosmol%C3%B3gico",
            "/wiki/Armon%C3%ADa_preestablecida",
            "/wiki/Argumento_teleol%C3%B3gico",
            "/wiki/Immanuel_Kant",
            "/wiki/Argumento_ontol%C3%B3gico",
            "/wiki/Anselmo_de_Canterbury",
            "/wiki/Monadolog%C3%ADa",
            "/wiki/Monadolog%C3%ADa",
            "/wiki/Argumento_cosmol%C3%B3gico",
            "/wiki/Contingencia",
            "/wiki/Existencia_de_Dios",
            "/wiki/Principio_de_raz%C3%B3n_suficiente",
            "/wiki/Monadolog%C3%ADa",
            "/wiki/Por_qu%C3%A9_existe_algo",
            "/wiki/Martin_Heidegger",
            "/wiki/William_Lane_Craig",
            "/wiki/Immanuel_Kant",
            "/wiki/Bertrand_Russell",
            "/wiki/Armon%C3%ADa_preestablecida",
            "/wiki/Optimismo",
            "/wiki/Estado_de_%C3%A1nimo",
            "/wiki/Pesimismo",
            "/wiki/Th%C3%A9odic%C3%A9e",
            "/wiki/El_mejor_de_los_mundos_posibles",
            "/wiki/1998",
            "/wiki/El_mejor_de_los_mundos_posibles",
            "/wiki/Infierno",
            "/wiki/Para%C3%ADso",
            "/wiki/Voltaire",
            "/wiki/C%C3%A1ndido",
            "/wiki/Pangloss",
            "/wiki/Mantra",
            "/wiki/Paul_du_Bois-Reymond",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Tangente_(geometr%C3%ADa)",
            "/wiki/Mal",
            "/wiki/Principio_de_m%C3%ADnima_acci%C3%B3n",
            "/wiki/Ley_de_conservaci%C3%B3n_de_la_materia",
            "/wiki/Conservaci%C3%B3n_de_la_energ%C3%ADa",
            "/wiki/Nuevos_ensayos_sobre_el_entendimiento_humano",
            "/wiki/Percepci%C3%B3n",
            "/wiki/Conciencia",
            "/wiki/Memoria_(proceso)",
            "/wiki/Apercepci%C3%B3n",
            "/wiki/Alma",
            "/wiki/Verdad_de_raz%C3%B3n",
            "/wiki/Distinci%C3%B3n_anal%C3%ADtico-sint%C3%A9tico",
            "/wiki/A_priori_y_a_posteriori",
            "/wiki/Omnisciencia",
            "/wiki/Omnipotencia",
            "/wiki/Infinito",
            "/wiki/Conocimiento",
            "/wiki/Innatismo",
            "/wiki/John_Locke",
            "/wiki/Empirismo",
            "/wiki/Calculus_ratiocinator",
            "/wiki/L%C3%B3gica_simb%C3%B3lica",
            "/wiki/Louis_Couturat",
            "/wiki/Charles_Sanders_Peirce",
            "/wiki/Gottlob_Frege",
            "/wiki/S%C3%ADmbolo",
            "/wiki/C%C3%A1lculo",
            "/wiki/Semiolog%C3%ADa",
            "/wiki/Grafema",
            "/wiki/Jerogl%C3%ADficos_egipcios",
            "/wiki/Caracteres_chinos",
            "/wiki/Astronom%C3%ADa",
            "/wiki/Qu%C3%ADmica",
            "/wiki/Characteristica_universalis",
            "/wiki/Descomposici%C3%B3n_en_factores_primos",
            "/wiki/N%C3%BAmero_primo",
            "/wiki/Numeraci%C3%B3n_de_G%C3%B6del",
            "/wiki/Mnemot%C3%A9cnica",
            "/wiki/%C3%81lgebra",
            "/wiki/Characteristica_universalis",
            "/wiki/Completitud_de_Turing",
            "/wiki/L%C3%B3gica",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Gottlob_Frege",
            "/wiki/Conjunci%C3%B3n_l%C3%B3gica",
            "/wiki/Disyunci%C3%B3n_l%C3%B3gica",
            "/wiki/Negaci%C3%B3n_l%C3%B3gica",
            "/wiki/Identidad_(matem%C3%A1tica)",
            "/wiki/Subconjunto",
            "/wiki/Conjunto_vac%C3%ADo",
            "/wiki/Variable_(matem%C3%A1tica)",
            "/wiki/Cuantificador",
            "/wiki/Historia_de_la_filosof%C3%ADa_occidental_(Russell)",
            "/wiki/Bertrand_Russell",
            "/wiki/M%C3%B3nada_(filosof%C3%ADa)",
            "/wiki/Predicado_(l%C3%B3gica)",
            "/wiki/Operaci%C3%B3n_unaria",
            "/wiki/Augustus_De_Morgan",
            "/wiki/Charles_Sanders_Peirce",
            "/wiki/Ernst_Schr%C3%B6der",
            "/wiki/L%C3%B3gica_de_predicados",
            "/wiki/%C3%81lgebra_booleana",
            "/wiki/Derecho",
            "/wiki/%C3%89tica",
            "/wiki/Pol%C3%ADtica",
            "/wiki/Monarqu%C3%ADa_absoluta",
            "/wiki/Thomas_Hobbes",
            "/wiki/Tiran%C3%ADa",
            "/wiki/John_Locke",
            "/wiki/Derecho_de_rebeli%C3%B3n",
            "/wiki/Hugo_Grocio",
            "/wiki/Uni%C3%B3n_Europea",
            "/wiki/Erhard_Weigel",
            "/wiki/Atanasio_Kircher",
            "/wiki/Ramon_Llull",
            "/wiki/Johann_Philipp_Franz_von_Sch%C3%B6nborn",
            "/wiki/Fr%C3%A1ncfort_del_Meno",
            "/wiki/Ciencia_del_derecho",
            "/wiki/Justicia",
            "/wiki/L%C3%B3gica",
            "/wiki/An%C3%A1lisis",
            "/wiki/Principio_de_raz%C3%B3n_suficiente",
            "/wiki/Principio_de_identidad",
            "/wiki/Walter_Scott",
            "/wiki/Antoine_Arnauld",
            "/wiki/1666",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Tabla_de_s%C3%ADmbolos_matem%C3%A1ticos",
            "/wiki/Modelo",
            "/wiki/Siglo_XX",
            "/wiki/Tangente",
            "/wiki/Extremos_de_una_funci%C3%B3n",
            "/wiki/Cuadratura_(geometr%C3%ADa)",
            "/wiki/Funci%C3%B3n_trascendental",
            "/wiki/1675",
            "/wiki/1684",
            "/wiki/C%C3%A1lculo_diferencial",
            "/wiki/Isaac_Newton",
            "/wiki/1704",
            "/wiki/Funci%C3%B3n_derivada",
            "/wiki/Extremo",
            "/wiki/Funci%C3%B3n_convexa",
            "/wiki/Extremo",
            "/wiki/Punto_de_inflexi%C3%B3n",
            "/wiki/Diferencial_de_una_funci%C3%B3n",
            "/wiki/1686",
            "/wiki/Integral",
            "/wiki/Derivada",
            "/wiki/1692",
            "/wiki/Envolvente_(matem%C3%A1ticas)",
            "/wiki/1692",
            "/wiki/1694",
            "/wiki/1693",
            "/wiki/Sistema_de_ecuaciones_lineales",
            "/wiki/Determinante",
            "/wiki/%C3%81lgebra_lineal",
            "/wiki/1695",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/1697",
            "/wiki/Johann_Bernoulli",
            "/wiki/1702",
            "/wiki/Descomposici%C3%B3n_en_fracciones_simples",
            "/wiki/Integraci%C3%B3n",
            "/wiki/Cinem%C3%A1tica",
            "/wiki/Infinitesimal",
            "/wiki/1691",
            "/wiki/Catenaria",
            "/wiki/Guillaume_de_l%27H%C3%B4pital",
            "/wiki/1696",
            "/wiki/Curva_braquist%C3%B3crona",
            "/wiki/Determinante",
            "/wiki/1693",
            "/wiki/1695",
            "/wiki/1682",
            "/wiki/Diferencial_(matem%C3%A1ticas)",
            "/wiki/C%C3%A1lculo_diferencial",
            "/wiki/Ecuaci%C3%B3n_diferencial",
            "/wiki/Funci%C3%B3n_(matem%C3%A1ticas)",
            "/wiki/Variable_(matem%C3%A1ticas)",
            "/wiki/Abscisa",
            "/wiki/Algoritmo",
            "/wiki/Trigonometr%C3%ADa",
            "/wiki/Ordenada",
            "/wiki/Cuerda_(geometr%C3%ADa)",
            "/wiki/Recta_normal",
            "/wiki/1675",
            "/wiki/1684",
            "/wiki/Punto_de_inflexi%C3%B3n",
            "/wiki/1686",
            "/wiki/Funci%C3%B3n_exponencial",
            "/wiki/1702",
            "/wiki/1703",
            "/wiki/1693",
            "/wiki/Sistema_binario",
            "/wiki/Hexagrama_(I_Ching)",
            "/wiki/Programador",
            "/wiki/Tarjeta_perforada",
            "/wiki/1679",
            "/wiki/1703",
            "/wiki/Tierra",
            "/wiki/N%C3%BAcleo_interno_de_la_Tierra",
            "/wiki/Geolog%C3%ADa",
            "/wiki/Embriolog%C3%ADa",
            "/wiki/Preformacionismo",
            "/wiki/Ciencias_de_la_vida",
            "/wiki/Paleontolog%C3%ADa",
            "/wiki/Protogaea",
            "/wiki/Teor%C3%ADa_organ%C3%ADsmica",
            "/wiki/Medicina",
            "/wiki/Psicolog%C3%ADa",
            "/wiki/Atenci%C3%B3n",
            "/wiki/Conciencia",
            "/wiki/Memoria_(proceso)",
            "/wiki/Aprendizaje",
            "/wiki/Asociaci%C3%B3n_(psicolog%C3%ADa)",
            "/wiki/Motivaci%C3%B3n",
            "/wiki/Resiliencia_(psicolog%C3%ADa)",
            "/wiki/Individuo",
            "/wiki/Psicolog%C3%ADa_del_desarrollo",
            "/wiki/Nuevos_ensayos_sobre_el_entendimiento_humano",
            "/wiki/Monadolog%C3%ADa",
            "/wiki/Apercepci%C3%B3n",
            "/wiki/John_Locke",
            "/wiki/Empirismo",
            "/wiki/Sensualismo",
            "/wiki/Causalidad_(filosof%C3%ADa)",
            "/wiki/Teleolog%C3%ADa",
            "/wiki/Wilhelm_Wundt",
            "/wiki/Apercepci%C3%B3n",
            "/wiki/Perspectivismo",
            "/wiki/Sue%C3%B1o",
            "/wiki/Inconsciente",
            "/wiki/Ernst_Platner",
            "/wiki/Mensaje_subliminal",
            "/wiki/M%C3%BAsica",
            "/wiki/Funci%C3%B3n_matem%C3%A1tica",
            "/wiki/Trigonometr%C3%ADa",
            "/wiki/Logaritmo",
            "/wiki/1692",
            "/wiki/1694",
            "/wiki/Horizontal",
            "/wiki/Vertical",
            "/wiki/Tangente_(geometr%C3%ADa)",
            "/wiki/Cuerda_(geometr%C3%ADa)",
            "/wiki/Perpendicularidad",
            "/wiki/Inglaterra",
            "/wiki/Matriz_(matem%C3%A1ticas)",
            "/wiki/Eliminaci%C3%B3n_gaussiana",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Isaac_Newton",
            "/wiki/Museo_de_Historia_Natural_(Londres)",
            "/wiki/Universidad_de_Oxford",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Isaac_Newton",
            "/wiki/1675",
            "/wiki/S_larga",
            "/wiki/1684",
            "/wiki/Regla_del_producto_(c%C3%A1lculo)",
            "/wiki/1711",
            "/wiki/Controversia_del_c%C3%A1lculo",
            "/wiki/John_Keill",
            "/wiki/Serie_de_Leibniz",
            "/wiki/Recta",
            "/wiki/Postulado_de_las_paralelas",
            "/wiki/Topolog%C3%ADa",
            "/wiki/Topolog%C3%ADa",
            "/wiki/Leibnitz_(cr%C3%A1ter)",
            "/wiki/Asteroide",
            "/wiki/(5149)_Leibniz",
            "/wiki/N%C3%BAmero_%CF%80#En_análisis_matemático",
            "/wiki/Notaci%C3%B3n_de_Leibniz",
            "/wiki/Regla_del_producto_(c%C3%A1lculo)",
            "/wiki/Serie_de_Leibniz",
            "/wiki/Criterio_de_Leibniz",
            "/wiki/La_garra_del_le%C3%B3n",
            "/wiki/Metaf%C3%ADsica",
            "/wiki/Monadolog%C3%ADa",
            "/wiki/Vis_viva",
            "/wiki/El_Pa%C3%ADs",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Juan_Arnau",
            "/wiki/Universidad_de_San_Diego",
            "/wiki/Deutsche_Forschungsgemeinschaft",
            "/wiki/OCLC",
            "/wiki/Wilhelm_Dilthey",
            "/wiki/ISBN",
            "/wiki/Dinamismo",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/Nicholas_Rescher",
            "/wiki/Wayback_Machine",
            "/wiki/ISBN",
            "/wiki/Wayback_Machine",
            "/wiki/Edward_N._Zalta",
            "/wiki/Edward_N._Zalta",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Biblioteca_de_Grandes_Pensadores",
            "/wiki/Editorial_Gredos",
            "/wiki/ISBN",
            "/wiki/Martin_Heidegger",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Louis_Couturat",
            "/wiki/Fran%C3%A7ois_F%C3%A9dier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Martin_Heidegger",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Felipe_Mart%C3%ADnez_Marzoa",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Jos%C3%A9_Ortega_y_Gasset",
            "/wiki/ISBN",
            "/wiki/Lourdes_Rensoli",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Encyclop%C3%A6dia_Britannica",
            "/wiki/Encyclop%C3%A6dia_Britannica_(edici%C3%B3n_de_1911)",
            "/wiki/Dominio_p%C3%BAblico",
            "/wiki/Wayback_Machine",
            "/wiki/ISSN",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Argentina",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_Nacional_de_Chile",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Union_List_of_Artist_Names",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Biblioteca_Virtual_Miguel_de_Cervantes",
            "/wiki/Dialnet",
            "/wiki/Proyecto_Gutenberg",
            "/wiki/Europeana",
            "/wiki/Fornminnesregistret",
            "/wiki/ISBN",
            "/wiki/OCLC"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/George_Boole",
        "titulo": "George Boole",
        "contenido": "george boole (/buːl/) (lincoln, lincolnshire, inglaterra, 2 de noviembre de 1815-ballintemple, condado de cork, irlanda, 8 de diciembre de 1864) fue un matematico y logico britanico.  como inventor del algebra de boole, que marca los fundamentos de la aritmetica computacional moderna, boole es considerado como uno de los fundadores del campo de las ciencias de la computacion. en 1854 publico an investigation of the laws of thought on which are founded the mathematical theories of logic and probabilities, donde desarrollo un sistema de reglas que le permitian expresar, manipular y simplificar problemas logicos y filosoficos cuyos argumentos admiten dos estados (verdadero o falso) por procedimientos matematicos. se podria decir que es el padre de los operadores logicos simbolicos y que gracias a su algebra hoy en dia es posible operar simbolicamente para realizar operaciones logicas.  el padre de george boole, john boole (1779-1848), fue un comerciante de escasos recursos. estuvo especialmente interesado en las matematicas y la logica. john dio a su hijo sus primeras lecciones, pero el extraordinario talento matematico de george boole no se manifesto durante la juventud, ya que al principio mostraba mayor interes por las humanidades.  la combinacion de sus intereses por la teologia y las matematicas le llevo a comparar la trinidad cristiana del padre, hijo y espiritu santo con las tres dimensiones del espacio, y se sintio atraido por el concepto hebreo de dios como una unidad absoluta. boole considero la adopcion del judaismo, pero al final opto por el unitarismo.  no fue hasta su establecimiento exitoso en una escuela en lincoln, su traslado a waddington, y mas tarde su nombramiento en 1849 como el primer profesor de matematicas del entonces queen's college en cork (en la actualidad, university college cork) que sus habilidades matematicas se realizaron plenamente.  en 1855, se caso con mary everest, sobrina de george everest, que mas tarde, como la señora de boole, escribio varios trabajos educativos utiles en los inicios de su marido.  pese a que boole publico poco, excepto su logica y obras matematicas, su conocimiento de la literatura en general era amplio y profundo. dante fue su poeta favorito, prefiriendo el paraiso al infierno. la metafisica de aristoteles, la etica de spinoza, las obras filosoficas de ciceron y muchas otras afines fueron tambien temas frecuentes de estudio. sus reflexiones sobre cuestiones filosoficas y religiosas de caracter cientifico estaban orientadas en cuatro direcciones: el genio de sir isaac newton; el uso correcto del ocio; las demandas de la ciencia; y el aspecto social de la cultura intelectual.  el caracter personal de boole inspiro a todos sus amigos la estima mas profunda. se caracterizo por la modestia, y entrego su vida a la busqueda de la verdad. pese a que recibio una medalla de la royal society por sus memorias de 1844, y el titulo honorifico de doctor honoris causa en derecho de la universidad de dublin, no solicito ni recibio los beneficios ordinarios a los que sus descubrimientos le habrian dado derecho.  el 8 de diciembre de 1864, en pleno vigor de sus facultades intelectuales, murio de un ataque de fiebre, que termino en un derrame pleural.​​ fue enterrado en el cementerio de la iglesia de st. michael, church road, blackrock (un barrio de la ciudad de cork, en irlanda). hay una placa conmemorativa en la iglesia contigua.  para el publico general boole es conocido fundamentalmente como el autor de numerosos trabajos abstrusos en el campo matematico, y de distintas publicaciones que se han convertido en tratados. su primer trabajo publicado fue «investigaciones en la teoria de las transformaciones de analisis, con una aplicacion especial a la reduccion de la ecuacion general de segundo orden», impreso en el the cambridge mathematical journal en febrero de 1840 (volumen 2, n.º 8, pp. 64-73) y que llevo a propiciar la amistad entre boole y d. f. gregory, el editor de la revista, que duro hasta la muerte prematura de este ultimo en 1844.  una larga lista de las memorias y documentos de boole, tanto en temas de logica como de matematicas, se encuentran en el catalogo de memorias de la ciencia publicado por la royal society, y en el volumen suplementario sobre ecuaciones diferenciales, editado por isaac todhunter.  en 1841 boole publico un influyente articulo sobre la naciente teoria de invariantes.​ recibio una medalla de la royal society por su memoria de 1844 titulada on a general method of analysis, una contribucion a las ecuaciones diferenciales lineales, partiendo del caso de los coeficientes constantes en los que ya habia trabajado, para abordar el caso de los coeficientes variables.​ su principal innovacion en metodos operacionales consistio en admitir que las operaciones podian no ser conmutativas.​ en 1847 boole publico the mathematical analysis of logic, el primero de sus trabajos sobre logica simbolica.​  boole publicaria veintidos articulos en the cambridge mathematical journal y en su sucesor, the cambridge and dublin mathematical journal. asimismo, publicaria dieciseis articulos en la tercera y cuarta series del philosophical magazine. la royal society tiene impresas seis memorias importantes en las philosophical transactions, y las memorias de algunos otros trabajos se encuentran en las transactions of the royal society of edinburgh y de la real academia de irlanda, en el bulletin de l'academie de st-petersbourg de 1862 (bajo el nombre de g. boldt, vol. iv, pp. 198-215), y en la revista de crelle. tambien se incluye un documento sobre la base matematica de la logica, publicado en el mechanic's magazine en 1848.  las obras de boole figuran de manera dispersa entre unos cincuenta articulos y otras publicaciones independientes. solo dos tratados sistematicos sobre temas matematicos fueron completados por boole durante su vida. el conocido tratado sobre ecuaciones diferenciales aparecio en 1859, y fue seguido, al año siguiente, por un tratado sobre el calculo de las diferencias finitas, diseñado para servir como una secuela de la obra anterior. estos tratados son valiosas contribuciones a las ramas importantes de la matematica que se tratan en ellos. hasta cierto punto, estas obras representan los mas relevantes descubrimientos de su autor en el campo del calculo. en los capitulos decimosexto y decimoseptimo de las ecuaciones diferenciales pueden encontrarse, por ejemplo, el desarrollo del metodo simbolico general, con el habil y audaz empleo del procedimiento que condujo a boole hacia sus demas descubrimientos, y de un metodo general de analisis, descrito originalmente en su famosa memoria impresa en las philosophical transactions de 1844. boole fue uno de los primeros y mas eminentes matematicos que percibieron que los simbolos de las operaciones podian ser separados de las cantidades sobre las que operan, y ser tratados como objetos distintos del propio calculo. la principal caracteristica de boole fue su absoluta confianza en cualquier resultado obtenido por el tratamiento de los simbolos de conformidad con sus leyes primarias y condiciones, y una habilidad casi inigualable para poder localizar aplicaciones para estos resultados.  durante los ultimos años de su vida boole se dedico constantemente a la ampliacion de sus investigaciones con el objeto de producir una segunda edicion de sus ecuaciones diferenciales mucho mas completa que la primera edicion, y parte de sus ultimas vacaciones las paso en las bibliotecas de la royal society y del museo britanico, pero esta nueva edicion nunca se completo. los manuscritos dejados a su muerte fueron tan incompletos que incluso isaac todhunter, a cargo de quien se dejaron, fue incapaz de completar una segunda edicion del tratado original, y los publico en 1865 en un volumen suplementario.  con la excepcion de augustus de morgan, boole fue probablemente el primer matematico ingles desde los tiempos de john wallis que escribio sobre logica. sus puntos de vista sobre la aplicacion del metodo logico se debian a la misma confianza profunda en el razonamiento simbolico con el que habia irrumpido, con exito, en la investigacion matematica. las especulaciones sobre un calculo del razonamiento ocuparon los pensamientos de boole, pero no fue hasta la primavera de 1847 cuando expreso sus ideas en el folleto titulado analisis matematico de la logica. considero esta publicacion como una precipitada e imperfecta exposicion de su sistema logico. posteriormente, boole manifesto que su trabajo mas importante, su investigacion sobre las leyes del pensamiento (1854), en el que se sustentan sus teorias matematicas sobre la logica y la probabilidad, solo debia ser considerado como una declaracion madurada de sus puntos de vista. esta obra marco el comienzo de un nuevo enfoque sobre la naturaleza de la validacion de argumentos y pruebas. sin embargo, es facil apreciar un innegable encanto en la originalidad de su obra logica anterior.  boole no consideraba la logica como una rama de las matematicas, como podria interpretarse por el titulo de su folleto anterior, pero señalo una profunda analogia entre los simbolos del algebra y la representacion simbolica, en su opinion, necesaria para representar formas logicas y silogismos, haciendo coincidir la logica formal con la matematica limitada al uso de operaciones con ceros y unos. para unificar distintos sistemas de operadores logicos, boole organizo el universo de todos estos objetos imaginables; creando una notacion simbolica adecuada a sus propositos, con simbolos tales como x, y, z, v, u, etc., que utiliza para caracterizar los atributos correspondientes a adjetivos y sustantivos comunes. propuso que las proposiciones logicas se deben expresar en forma de ecuaciones algebraicas, de forma que la manipulacion algebraica de los simbolos en las ecuaciones proporciona un metodo a prueba de fallos de la deduccion logica, es decir, la logica se reduce al algebra. mediante el uso de simbolos, tales proposiciones se podrian reducir a la forma de ecuaciones, y la conclusion silogistica a partir de dos premisas se obtiene eliminando el termino medio de acuerdo con las reglas ordinarias algebraicas.  aun mas original y notable, sin embargo, fue que parte de su sistema, totalmente basado en sus leyes del pensamiento, permitio estructurar un metodo simbolico general de la logica de la inferencia. dada una proposicion que implique un numero cualquiera de terminos, boole demostro como, por el tratamiento puramente simbolico de estas premisas, se podia deducir cualquier conclusion logica contenida en dichas premisas. la segunda parte de sus leyes del pensamiento contiene su correspondiente intento de descubrir un metodo general de las probabilidades, que como consecuencia, debe permitir determinar la probabilidad de cualquier evento logicamente relacionado con un sistema de acontecimientos dados, a partir de las probabilidades del citado sistema de acontecimientos dados.  en 1921 el economista john maynard keynes publico un libro que se ha convertido en un clasico en la teoria de la probabilidad, a treatise of probability (tratado de la probabilidad). en su libro, keynes comentaba la teoria de boole sobre la probabilidad, y sostenia que boole habia cometido un error fundamental acerca del concepto de independencia estocastica​ que a su juicio viciaba la mayor parte del trabajo de su predecesor. en su libro, the last challenge problem: george boole's theory of probability (2009), david miller proporciona un metodo general de acuerdo con el sistema de boole, e intenta resolver los problemas reconocidos anteriormente por keynes y otros autores.  en 1857, boole publico su tratado on the comparison of transcendents, with certain applications to the theory of definite integrals (comparacion de transcendentes, con ciertas aplicaciones a la teoria de integrales definidas),​ donde estudiaba la suma de residuos de una funcion racional. entre otros resultados, probo la conocida como identidad de boole:  para cualesquiera numeros reales ak > 0, bk, y t > 0.​ la generalizacion de esta identidad juega un importante papel en la teoria de la transformada de hilbert.​  boole tuvo cinco hijas: ",
        "snippet": "George Boole (/buːl/) (Lincoln, Lincolnshire, Inglaterra, 2 de noviembre de 1815-Ballintemple, Condado de Cork, Irlanda, 8 de diciembre de 1864) fue un matemático y lógico británico.",
        "enlaces_salientes": [
            "/wiki/George_Boole",
            "/wiki/George_Boole",
            "/wiki/George_Boole",
            "/wiki/Lincoln_(Lincolnshire)",
            "/wiki/Lincolnshire",
            "/wiki/Inglaterra",
            "/wiki/Condado_de_Cork",
            "/wiki/Irlanda",
            "/wiki/Neumon%C3%ADa",
            "/wiki/Cork",
            "/wiki/Reino_Unido",
            "/wiki/George_Everest",
            "/wiki/Alicia_Boole_Stott",
            "/wiki/Lucy_Everest_Boole",
            "/wiki/Ethel_Lilian_Voynich",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/University_College_Cork",
            "/wiki/Royal_Society",
            "/wiki/Royal_Society",
            "/wiki/Lincoln_(Lincolnshire)",
            "/wiki/Lincolnshire",
            "/wiki/Inglaterra",
            "/wiki/2_de_noviembre",
            "/wiki/1815",
            "/wiki/Condado_de_Cork",
            "/wiki/Irlanda",
            "/wiki/8_de_diciembre",
            "/wiki/1864",
            "/wiki/Matem%C3%A1tico",
            "/wiki/L%C3%B3gico",
            "/wiki/Reino_Unido",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/Teolog%C3%ADa",
            "/wiki/Trinidad_cristiana",
            "/wiki/Tres_dimensiones",
            "/wiki/Juda%C3%ADsmo",
            "/wiki/Unitarismo",
            "/wiki/Lincoln_(Lincolnshire)",
            "/wiki/Cork",
            "/wiki/University_College_Cork",
            "/wiki/George_Everest",
            "/wiki/Dante",
            "/wiki/Para%C3%ADso_(La_Divina_Comedia)",
            "/wiki/Infierno_(La_Divina_Comedia)",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Spinoza",
            "/wiki/Cicer%C3%B3n",
            "/wiki/Isaac_Newton",
            "/wiki/Royal_Society",
            "/wiki/Doctor_honoris_causa",
            "/wiki/Universidad_de_Dubl%C3%ADn",
            "/wiki/Derrame_pleural",
            "/wiki/Royal_Society",
            "/wiki/Ecuaciones_diferenciales",
            "/wiki/Isaac_Todhunter",
            "/wiki/Teor%C3%ADa_de_invariantes",
            "/wiki/Ecuaci%C3%B3n_diferencial_lineal",
            "/wiki/Conmutatividad",
            "/wiki/Philosophical_Magazine",
            "/wiki/Royal_Society_of_Edinburgh",
            "/wiki/Crelle_(revista)",
            "/wiki/Museo_Brit%C3%A1nico",
            "/wiki/Isaac_Todhunter",
            "/wiki/Augustus_De_Morgan",
            "/wiki/John_Wallis",
            "/wiki/Diagrama_de_Hasse",
            "/wiki/John_Maynard_Keynes",
            "/wiki/Residuo_(an%C3%A1lisis_complejo)",
            "/wiki/Funci%C3%B3n_racional",
            "/wiki/Transformada_de_Hilbert",
            "/wiki/Charles_Howard_Hinton",
            "/wiki/Barras_de_mono",
            "/wiki/Geoffrey_Ingram_Taylor",
            "/wiki/Alicia_Boole_Stott",
            "/wiki/Lucy_Everest_Boole",
            "/wiki/Wilfrid_Michael_Voynich",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/Tipo_de_dato#Booleanos",
            "/wiki/Pascal_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Java_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/William_Stanley_Jevons",
            "/wiki/Augustus_De_Morgan",
            "/wiki/Charles_Sanders_Peirce",
            "/wiki/Ernst_Schr%C3%B6der",
            "/wiki/Louis_Couturat",
            "/wiki/Clarence_Irving_Lewis",
            "/wiki/Claude_Shannon",
            "/wiki/Universidad_de_Michigan",
            "/wiki/Instituto_de_Tecnolog%C3%ADa_de_Massachusetts",
            "/wiki/Claude_Shannon",
            "/wiki/Sofia_Yanovskaya",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/Medalla_Keith",
            "/wiki/Royal_Society_of_Edinburgh",
            "/wiki/Royal_Society",
            "/wiki/Universidad_de_Dubl%C3%ADn",
            "/wiki/Universidad_de_Oxford",
            "/wiki/University_College_Cork",
            "/wiki/Berkshire",
            "/wiki/Boole_(cr%C3%A1ter)",
            "/wiki/Asteroide",
            "/wiki/(17734)_Boole",
            "/wiki/Wayback_Machine",
            "/wiki/Google",
            "/wiki/Google_Doodle",
            "/wiki/Proposici%C3%B3n_categ%C3%B3rica",
            "/wiki/David_Hilbert",
            "/wiki/Bertrand_Russell",
            "/wiki/Andrei_Nikolaevich_Kolmogorov",
            "/wiki/Adolf_Pavlovich_Yushkevich",
            "/wiki/JSTOR",
            "/wiki/Digital_object_identifier",
            "/wiki/Mathematical_Reviews",
            "/wiki/ISBN",
            "/wiki/Ivor_Grattan-Guinness",
            "/wiki/OCLC",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Proyecto_Gutenberg",
            "/wiki/Europeana"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Gottlob_Frege",
        "titulo": "Gottlob Frege",
        "contenido": "friedrich ludwig gottlob frege (wismar, 8 de noviembre de 1848 - bad kleinen, 26 de julio de 1925) fue un matematico, logico y filosofo aleman. se le considera el padre de la logica matematica y de la filosofia analitica, concentrandose en la filosofia del lenguaje y de las matematicas. frege desarrollo su carrera en relativa oscuridad como catedratico de matematicas de la universidad de jena, largamente ignorado por la comunidad filosofica y matematica. es principalmente gracias a giuseppe peano (1858-1932) y a bertrand russell (1872-1970), que hicieron una gran labor de divulgacion de la obra de frege, que frege llego a ser conocido por generaciones posteriores de filosofos y matematicos.  frege ideo un programa logicista destinado a explorar los fundamentos logicos y filosoficos de las matematicas y del lenguaje natural. estaba convencido de que las matematicas y el lenguaje podian ser reducidos a la logica. para demostrar este fin, frege exploro los fundamentos logicos de ambos campos, y en ese proceso dio a luz a la logica moderna (en contraposicion a la logica clasica que habia imperado desde aristoteles), a la logica matematica, y a los primeros trabajos modernos de la filosofia del lenguaje. sus intereses filosoficos, su estilo simple, claro y riguroso, y su influencia sobre bertrand russell, ludwig wittgenstein, y el circulo de viena fueron el germen de la filosofia analitica.  las dos obras fundamentales de frege son su begriffsschrift (1879, habitualmente traducido como ideografia), que sento las bases de la logica moderna, y su grundlagen der arithmetik (1884, fundamentos de la aritmetica), donde establecio los fundamentos filosoficos de las matematicas. su obra mas leida en la actualidad es su articulo seminal uber sinn und bedeutung (1892, sobre el sentido y la referencia), obra fundamental de la filosofia del lenguaje.  frege nacio en 1848 en wismar, por entonces perteneciente al gran ducado de mecklemburgo-schwerin, actual alemania. su padre, carl (karl) alexander frege (1809–1866), era el cofundador y director de un colegio femenino. a la muerte de carl en 1866, el colegio paso a ser dirigido por su madre auguste wilhelmine sophie frege (apellido de soltera bialloblotzky, 1815-1898), descendiente de una familia noble polaca y, por via materna, del humanista philipp melanchthon.​​  durante su infancia, frege fue expuesto a muchos de los aspectos que marcarian su carrera filosofica. por ejemplo, su padre escribio un libro de texto sobre la lengua alemana tituladohulfsbuch zum unterrichte in der deutschen sprache fur kinder von 9 bis 13 jahren (2 ed., wismar 1850; 3rd ed., wismar and ludwigslust: hinstorff, 1862). la primera seccion de dicho libro trata sobre la estructura logica del lenguaje.  frege estudio en el gymnasium de wismar, donde se graduo en 1869. fue su profesor de literatura, gustav adolf leo sachse (1843-1909), quien insistio en que frege continuara sus estudios en ciencias naturales en la universidad de jena.  frege se matriculo en matematicas la universidad de jena en la primavera de 1869 como ciudadano de la confederacion alemana del norte. estudio durante dos años en jena, donde atendio 20 asignaturas, la mayoria en matematicas y en fisica, aunque tambien atendio clases de filosofia kantiana. frege fue estudiante de los fisicos christian philipp karl snell (1806-1886) y hermann karl julius traugott schaeffer (1824-1900), y del filosofo kantiano kuno fischer (1824–1907). sin embargo, su profesor mas importante fue el fisico ernst karl abbe (1840–1905), que enseñaba gravitacion, electrodinamica, mecanica de solidos, y analisis de variable compleja. frege mantuvo una relacion de estrecha amistad con abbe, que actuaria como el mentor de frege a lo largo de toda su carrera.​  abbe era una figura crucial en jena. habia ayudado a la familia zeiss a establecer la empresa de productos opticos carl zeiss ag, y como director tecnico de la misma desde 1866 habia revolucionado su produccion hasta convertirla en uno de los grandes conglomerados empresariales alemanes. abbe habia sido nombrado director de la fundacion carl zeiss, que recibia casi la mitad de los beneficios de la empresa de productos opticos carl zeiss ag, y usaba su puesto para promover la investigacion cientifica.​ frege seria uno de los grandes beneficiarios de la generosidad de la fundacion zeiss por via de abbe.  en 1871, una vez graduado en jena, frege paso a estudiar en la universidad de gotinga, por entonces la universidad mas reputada en matematicas. estudio con rudolf friedrich alfred clebsch (1833–72; geometria analitica), ernst christian julius schering (1824–97; teoria de funciones), wilhelm eduard weber (1804–91; fisica aplicada), eduard riecke (1845–1915; electricidad), y hermann lotze (1817–81; filosofia de las religiones). muchas de las doctrinas filosoficas de frege tienen paralelos con las de lotze; hasta que punto lotze influyo en frege es un debate que continua abierto en la actualidad  en 1873 frege obtuvo su doctorado bajo la direccion de ernst schering, con una tesis doctoral titulada \"ueber eine geometrische darstellung der imaginaren gebilde in der ebene\" (\"sobre una representacion geometrica de formas imaginarias en el plano\"), en la que trato de resolver problemas fundamentales relacionados con la interpretacion matematica de la proyeccion geometrica de puntos imaginarios en el infinito.  en mayo de 1874, frege regreso a jena tras completar su habilitationsschrift con una tesis sobre la teoria de los numeros complejos titulada rechnungsmethoden, die sich auf einer erweiterung des großenbegriffes grunden (\"metodos de calculo basados en una generalizacion del concepto de talla\"). habia obtenido por mediacion de abbe el puesto de privatdozent, un puesto no remunerado que por entonces era el primer escalafon en la carrera academica en alemania.  durante sus primeros años en jena, frege enseño matematicas. igualmente, los primeros trabajos de frege fueron en analisis complejo y geometria, donde parecia tener una carrera prometedora. que le llevo a realizar el salto a la filosofia de las matematicas no esta claro. parece que su interes por los fundamentos filosoficos de las matematicas fueron relativamente precoces, y que comenzo a estudiar la justificacion matematica de los numeros enteros a su regreso a jena. en este proceso, hubo de darse cuenta de que las matematicas contemporaneas eran incapaces de ofrecer una justificacion formal, lo que podria haberle llevado a desarrollar un nuevo tipo de logica capaz de abordar este problema. esto podria haberle llevado a los resultados que presento en su ideografia.  parece que en el transcurso de estas investigaciones preliminares, frege llego a la conclusion de que la aritmetica tenia que ser parte de (o podia ser reducida a) la logica formal. como reflejaria posteriormente, la capacidad de una persona para familiarizarse con los numeros naturales no podia estar relacionada con su experiencia directa o con el espacio geometrico, sino con el lenguaje y la capacidad analitica de raciocinio generalmente conocida como logica. este tipo de interpretacion filosofica de las matematicas es habitualmente conocido como logicismo.  en 1879, frege se establecio como uno de los defensores maximos de esta escuela al publicar su primera gran obra, la ideografia (begriffsschrift). la ideografia que da nombre a la obra se refiere al conjunto de simbolos y a la sintaxis formal que frege desarrollo a fin de clarificar las relaciones logicas contenidas en el lenguaje ordinario. desde aristoteles, la logica habia estado fundamentada en el calculo proposicional, en base al cual la verdad o falsedad de una oracion se establecia por medio de una serie de operadores logicos (negacion, conjuncion, disyuncion,...) que permitian desarrollar silogismos.  la ideografia de frege contenia el primer tratamiento sistematico de la logica proposicional, que era introducida de una forma axiomatica, por medio de la cual todas las leyes de la logica podia ser deducidas. la mayor contribucion de frege fue, en todo caso, la invencion de la teoria de la cuantificacion. con base en esta, frege fue capaz de expandir el ambito de los operadores logicos para poder estudiar la validez logica de expresiones que contuvieran afirmaciones como todo, nada, algunos, cualquiera, etc. esto constituyo un hito en la historia de la logica formal, y la mayor aportacion al campo desde aristoteles.​  la notacion que frege introdujo en su ideografia, aunque elegante, era dificil de reproducir en la imprenta, y muy laboriosa y extensa: era tabular y bidimensional, lo cual no fue apreciado ni por los editores y ni por lectores del libro. frege fue ademas incapaz de separar su compleja notacion de la semantica y logica sintactica que ejemplificaba. ocultos bajo una notacion muy dificil de penetrar, la mayor parte de los teoremas de logica proposicional y de las muchas ideas cruciales que desarrollaba en la ideografia fueron completamente ignorados por la comunidad academica.  de hecho, la ideografia fue recibida con una inusitada hostilidad, generalmente causada por la dificultad de la notacion que usaba. ademas, frege habia ignorado abiertamente los recientes trabajos de george boole y de ernst schroder en logica formal. aunque la obra de tanto boole como de schroder era sobre todo un intento de algebrificar la logica clasica, frege no hizo ningun intento de comparar los sistemas de ambos al suyo propio. esto supuso que su creacion de la logica proposicional y de segundo orden quedaran ocultos para la mayor parte del publico bajo una patina de notacion. schroder en particular fue muy hostil; en su reseña de la ideografia, comparo la notacion a \"introducir nociones de japones sin hacer nada mejor que boole, y haciendo muchas cosas peor.\"​  aunque pobremente recibida, la ideografia le valio para que, con la ayuda de abbe, frege consiguiera el puesto de profesor que ocuparia hasta su retiro. entre 1879 y 1884 frege se dedico a responder a reseñas hostiles del begriffsschrift y a tratar de explicar en que se distinguia esta obra de la boole.  a fin de evitar las criticas que su notacion ideografica habia recibido, frege escribio su siguiente gran obra, el grundlagen der arithmetik (\"leyes fundamentales de la aritmetica\") en un estilo completamente distinto, evitando el uso de un lenguaje simbolico.​ el grundlagen es la primera obra donde frege propone que la aritmetica es derivable de la logica aunque, debido a las criticas vertidas al begriffsschrift, la defensa que frege hace de esta tesis no es enteramente formal.  aunque el grundlagen es quizas la obra mas importante de frege, su recepcion fue aun mas fria que la del begriffsschrift: solo recibio tres reseñas, y todas ellas fueron hostiles.​ no esta claro por que el grundlagen fue tan friamente recibido. se ha pensado que, habiendo abandonado toda notacion simbolica, su contenido podria haber resultado aun asi demasiado tecnico para los filosofos, y demasiado filosofico para los matematicos que trabajaban en este campo. dedekind ignoro por completo el libro, cantor lo critico con hostilidad, y hilbert lo rechazo por entero.  pese a la incomprension general, el grundlagen propone dos tesis totalmente radicales: por una lado, que cada numero es un objeto que existe por si mismo; por otro, que asignar un numero a una oracion es una asercion sobre un concepto. esto significa que frege rechazaba que los numeros fueran una propiedad que pertenece a un individuo o un colectivo, y que tambien rechazaba que los numeros fueran una propiedad subjetiva, dependiente del individuo. esto separaba de forma radical a la logica de la psicologia (algo de lo que los filosofos empiricistas habian abusado), y de la epistemologia (algo frecuente entre los filosofos racionalistas en la tradicion de descartes).  en 1887 se caso, tardiamente, con margarete katharina sophia anna liesebe (1856-1904). aunque se desconocen los detalles de su vida privada, tendrian dos hijos que moririan en la infancia, y adoptarian a un niño, alfred frege.  la decada que siguio a la publicacion del grundlagen fue un periodo productivo para frege. es en este tiempo donde se centra en estudiar la filosofia del lenguaje, donde por medio de tres articulos publicados en 1891 y 1892 cambiaria para siempre el campo. el mas importante de estos es uber sinn und bedeutung (\"sobre el sentido y la referencia\"), donde frege traza una distincion entre lo que el llama el sentido de una expresion, y su referencia. segun frege, el sentido y la referencia son dos aspectos distintos del significado. para el tanto las expresiones de objeto como las de concepto tienen una referencia (un objeto al que se refiere) y un sentido (una forma de hablar de ese objeto).  la ultima gran obra de frege fue el grundgesetze der arithmetik (\"leyes basicas de la aritmetica\"), cuyo primer volumen aparecio en 1893. en este libro, frege se dispuso a construir de manera formal la aritmetica a partir de la logica. esto deberia de haber sido su mayor logro: demostrar que las matematicas eran reducibles a (y deducibles de) la logica, algo que habia esbozado ya en el grundlagen y a lo que habia dedicado toda su carrera. el grundgesetze se topo con dos grades problemas. por un lado, escarmentados del fracaso del grundlagen y el begriffsschrift, ningun editor queria publicar la obra.​ frege consiguio finalmente disuadir a hermann pohle, un editor de jena que habia publicado articulos suyos anteriormente, de que accediera a imprimir el grundgesetze, pero pohle solo acepto con la condicion de editarla en dos volumenes, y publicando el segundo volumen solo si el primero tenia exito.​  como ocurriera con el grundlagen, el primer volumen del grundgesetze fue recibido friamente. esto retraso la publicacion del segundo volumen una decada. pese a ello, su publicacion valio a frege su ascenso a una catedra honorifica en jena, financiada con un sustancioso estipendio por la fundacion carl zeiss, conseguida gracias a la intercesion de su ernst abbe.  pese a su fracaso editorial, el grundgesetze consiguio atraer la atencion de la comunidad internacional a la obra de frege. su publicacion espoleo una polemica con el matematico italiano giuseppe peano, quien hubo de modificar su propia axiomatizacion de la aritmetica a fin de acomodar las criticas y tesis de frege a la misma.​ la controversia con peano atrajo la atencion de bertrand russell, por entonces un joven filosofo en el trinity college de la universidad de cambridge.​  entre 1893 y 1903, frege se dedico a escribir agrios articulos criticando a todos los filosofos y matematicos que habian criticado su obra anteriormente. escribio una reseña hostil contra la philosophie der arithmetik de edmund husserl, quien abrazo las criticas que frege vertio en su obra y abandono su psicologismo matematico a favor de las tesis logicistas de frege.​   el otro gran problema el grundgesetze se revelo en 1902, cuando el segundo volumen del grundgesetze estaba en la imprenta. frege recibio una carta de bertrand russell en la que russell señalaba que el quinto axioma del grundgesetze hacia todo el sistema inconsistente. la carta de russell, fechada el 16 de junio de 1902, comenzaba: querido colega: he sabido de tu grundgesetze desde hace un año y medio, pero solo ha sido ahora que he podido encontrar tiempo para el detallado estudio que pretendo dedicar a tus escritos. estoy totalmente de acuerdo contigo en todos sus puntos principales, en particular en tu rechazo de todo elemento psicologicista en logica, y en el valor que asignas a una notacion conceptual para la los fundamentos de las matematicas y de la logica formal que, de paso, a duras penas pueden distinguirse. en muchos detalles, encuentro en las discusiones, distinciones y definiciones de tus escritos todo lo que uno busca en vano en otros logicos. en particular, en lo que respecta a las funciones (seccion 9 de tu notacion conceptual) he llegado independientemente a las mismas conclusiones incluso en detalle. he encontrado una dificultad tan solo en un punto. afirmas (p. 17) que una funcion puede tambien constituir el elemento indeterminado. esto es lo que solia creer yo, pero este punto de vista me parece ahora dudoso debido a la siguiente contradiccion: sea w el predicado de ser un predicado que no puede ser predicado de si mismo. ¿puede w ser un predicado de si mismo? de ambas respuestas se sigue una contradiccion. debemos por tanto concluir que w no es un predicado. igualmente, no hay una clase (en su totalidad) de todas las clases que, en su totalidad, no sean miembros de si mismas. de esto concluyo que bajo ciertas circunstancias un conjunto definible no forma un conjunto completo.​ el quinto axioma afirmaba que si todo a es una b, y todo b es una a, entonces la clase de las as es identica a la clase de las bs. russell, por medio de la paradoja de russell, señalo que este axioma permitia la existencia de una clase de todas las clases de cosas que no son miembros de si mismas; pero si una cosa es miembro de si misma, entonces no es un miembro de si misma; pero si no es un miembro de si misma, entonces es un miembro de dicha clase, lo cual es contradictorio. asi, russell señalaba que el sistema de frege no podia ser logicamente consistente.  frege recibio la carta de russell con autentico estupor.​ a diferencia de peano, a quien russell tambien habia comunicado su paradoja, frege reconocio con integridad intelectual el problema y, a fin de subsanarlo, trato de relajar el quinto axioma de sus sistema en uno de los apendices del segundo volumen del grundgesetze, donde discutio la paradoja de russell y su posible solucion. su solucion resulto ser asimismo logicamente inconsistente, aunque frege sostuvo durante unos años lo contrario.​  antes de su jubilacion en 1918, frege habia abandonado toda pretension de haber solucionado el problema, y aceptaba el fracaso de su sistema logicista. para entonces, la logica matematica de la que frege habia sido pionero habia captado la atencion de la comunidad filosofica y matematica, aunque frege siguio siendo ignorado. dedico el resto de su vida a abordar la relacion entre la logica y la psicologia, en una serie de articulos compilados como investigaciones logicas (1919-1923). la mayor parte de sus escritos de este periodo no fueron publicados hasta 1969.  murio en 1925 en bad kleinen, a donde se habia retirado luego de su jubilacion, dejando todos sus manuscritos a su hijo adoptivo alfred.  frege era una persona reservada e introvertida. sus alumnos decian que se dedicaba a dar clase mirando a la pizarra, salpicando sus explicaciones de vez en cuando con comentarios profundamente sarcasticos. su caracter y relativa oscuridad hace que solo se conozcan sus opiniones personales y caracter a traves de sus propios manuscritos, en particular su diario privado, que fue recuperado por michael dummett en los años 70.  la obra filosofica de frege era de naturaleza extremadamente tecnica, carente de cualquier vertiente practica, tanto asi que el filosofo y biografo ingles dummett, uno de los grandes divulgadores de frege, expreso su \"consternacion al descubrir, mientras leia los diarios de frege, que su heroe era un antisemita.\"​ tras la revolucion de noviembre de 1918, las opiniones politicas de frege se radicalizaron. su diario personal durante los ultimos años de su vida contienen opiniones de extrema derecha, opuestas al sistema parlamentario, a la democracia, a los liberales, los catolicos, los franceses y los judios, que consideraba debian ser privados de sus derechos politicos y expulsados de alemania.​ frege afirmaba que se habia considerado en el pasado como un liberal y un admirador de otto von bismarck, pero paso a simpatizar con el general ludendorff y con adolf hitler.​ frege critico asimismo el sufragio universal y el socialismo. frege tuvo trato amistoso con judios en la vida real: uno de sus estudiantes fue gershom scholem, quien apreciaba mucho a su profesor;​​ y frege animo a ludwig wittgenstein a marchar a estudiar a cambridge.​ el diario de 1924 de frege fue publicado postumamente en 1994.​ las opiniones personales de frege eran ignoradas por sus allegados, puesto que este nunca las expreso en publico.  en 1879, frege publico su revolucionaria obra titulada ideografia o escritura de conceptos (begriffsschrift), en la que sento las bases de la logica matematica moderna, iniciando una nueva era en esta disciplina que habia permanecido practicamente inalterada desde aristoteles. mediante la introduccion de una nueva sintaxis, con la inclusion de los llamados cuantificadores («para todo» o «para al menos un»), permitio formalizar una enorme cantidad de nuevos argumentos. tambien fue el primero en distinguir la caracterizacion formal de las leyes logicas de su contenido semantico.  una vez fijados los principios axiomaticos de la logica, acometio la tarea de edificar la aritmetica sobre la base de aquella. un problema en las revolucionarias obras de frege es la cantidad de espacio impreso que requiere su notacion; no fue realmente hasta la publicacion de los principia mathematica de alfred north whitehead y bertrand russell cuando el poder de la logica formal, en una notacion menos extensa (pero que requiere muchos signos de agrupacion) fue apreciable.  frege fue un defensor del logicismo, la tesis de que las matematicas son reducibles a la logica, en el sentido de que las verdades de la matematica son deducibles de las verdades de la logica. sin embargo su defensa del logicismo era de alcance limitado, aplicandola solo a la aritmetica y a la teoria de conjuntos, puesto que frege permanecio en gran medida kantiano respecto de la geometria. su obra titulada leyes basicas de la aritmetica (grundgesetze der arithmetik) fue un intento de llevar a cabo el proyecto logicista. en 1902, con las pruebas corregidas del segundo volumen ya en la imprenta, recibio una carta de bertrand russell en la que le advertia acerca de una grave inconsistencia en su sistema logico, conocida mas adelante como la paradoja de russell.  frege introdujo a toda prisa una modificacion en uno de sus axiomas, de la que dejo constancia en un apendice de la obra. este golpe a la estructura de su obra practicamente puso fin a su actividad academica. ante la casi total indiferencia de sus contemporaneos, tras la muerte de su esposa se recluyo en su nueva residencia de bad kleinen y permanecio mayormente en el anonimato hasta que bertrand russell lo dio a conocer, ya que habiendo llegado a los mismos resultados que frege de manera independiente estaba en la capacidad de entenderle y fue el primer pensador de importancia en apreciar el gran valor de su obra. pese a que el descubrimiento de la paradoja de russell arruino el proyecto logicista de frege, este continuo trabajando y llego a publicar una serie de importantes articulos, entre los cuales destaca el pensamiento: una investigacion logica, en donde basicamente se examina el contenido de las proposiciones, aquella parte objetiva que es transmisible a todo hablante en un enunciado declarativo. en los años sesenta el filosofo de oxford michael dummett publico una serie de importantes libros sobre la filosofia de frege que revivieron el interes por su obra y lo reincorporaron al debate filosofico.  la teoria del significado de frege se enfrenta a la tradicion psicologista que asigna contenidos mentales a las palabras como sus significados. frege se enfrenta a esta tradicion en su articulo sobre el sentido y la referencia, e inaugura una importante tradicion en la filosofia del lenguaje.  la tesis segun la cual las palabras son signos de ideas es expuesta por john locke en su ensayo sobre el entendimiento humano. locke, partiendo de la finalidad comunicativa del lenguaje, define las palabras como \"signos de concepciones internas\". estas \"concepciones internas\", ideas, son entidades que estan contenidas en nuestra mente; la gente mediante palabras comunica tales ideas. las ideas vienen de nuestra experiencia sensible. para locke no existe una relacion directa entre el lenguaje y el mundo, sino que el lenguaje es una herramienta con la que comunicamos nuestras ideas.  por su parte, en su articulo titulado sobre el sentido y la referencia, frege comienza preguntandose por los enunciados de identidad, de los cuales distingue dos tipos:  y razona de este modo: los enunciados del tipo (1) son triviales, pero no ocurre igual con los enunciados del tipo (2). la relacion de identidad que aparece en estos enunciados no puede ser entre signos de objetos ni entre objetos. si la identidad es entre objetos la informacion que nos proporciona (1) no es diferente de la que nos proporciona (2). si la relacion se da entre nombres de objetos, entonces no estamos diciendo nada extralinguistico. asi pues frege soluciona esta cuestion distinguiendo en las expresiones la referencia y el sentido. la referencia es el objeto mismo que designamos con un signo, el sentido expresa el modo de darse el objeto. es decir, con (2) expresamos dos modos diferentes de referirnos a un mismo objeto.  mientras que segun la tesis de que las palabras son signos de ideas las palabras significan ideas subjetivas que se encuentran contenidas en la mente de los hablantes, la teoria del significado presentada por frege en sobre el sentido y la referencia nos dice que los signos significan los modos de darse los objetos a los que nos referimos con nuestras palabras. el sentido es una aproximacion al objeto mismo. por ejemplo, si profiero una expresion como \"venus es hespero\", se esta diciendo que el objeto al que refiere \"venus\" es el mismo objeto al que refiere \"hespero\". ambas expresiones son nombres para el mismo objeto. ahora bien, venus es un nombre internacionalmente conocido, con el que algunos hablantes asociaran unas propiedades, mientras que al nombre \"hespero\" se le asignaran propiedades diferentes. de esta manera alguien podria llegar a pensar que es falso.  como segun la tesis de locke nuestras palabras son signos de ideas que de hecho estan en nuestra mente, frege rompe con este psicologismo defendiendo en su lugar un realismo, mas objetivo y preciso a la hora de determinar los significados de nuestras expresiones. para frege nuestras palabras refieren a objetos y ademas expresan modos de darse tales objetos, es decir, que tienen sentido. ahora bien, ¿es el sentido de una expresion una representacion subjetiva del hablante? no, pues dice frege: \"de la referencia y del sentido del signo hay que distinguir la representacion a el asociada\". de este modo, la referencia de un signo es un objeto, si el objeto es sensible, la representacion que tengo no es mas que una \"imagen interna\" construida a partir del recuerdo de las sensaciones que tal objeto me produjo, y en esto se diferencia la representacion subjetiva de la referencia.  pero ¿y el sentido? tampoco. el sentido de un signo \"puede ser propiedad comun de muchos\" mientras que \"la representacion es subjetiva\". el sentido de una expresion se entiende en la medida en que se tiene un cierto conocimiento del referente.  hasta ahora se ha hablado de la referencia como si todas nuestras expresiones refiriesen a un objeto. sin embargo para frege esto no es asi. hay expresiones que parece que apuntan hacia un objeto, lo que hace que concibamos su sentido sin que tal referencia exista. es el caso de expresiones como el \"mayor numero natural\" o \"el politico mas inutil\", pues para cada numero natural siempre existe otro mayor, y para cada politico inutil siempre existe otro que lo es mas. a pesar de todo, los significados de esta clase de expresiones tampoco son ideas privadas de la mente de los hablantes.  frege rechaza de plano la tesis de que las palabras son signos de ideas. he tomado la tesis tal y como la expone locke, como que las ideas son entidades que estan contenidas en la mente de los hablantes. a estas ideas solo tiene acceso el mismo hablante, y las palabras las usamos como signos de estas ideas para comunicarlas. frege rompe con este psicologismo, segun el cual los significados y los conceptos son entidades privadas, para abrirse a un nuevo paradigma de corte platonico: el realismo del significado, desde donde defiende que nuestras palabras refieren a objetos del mundo, tienen referencia y, tambien, sentido. el sentido viene dado por el conocimiento que se tiene de la referencia, sin que de aqui se siga que es algo subjetivo, con respecto a esto dice frege que \"la humanidad tiene un tesoro comun de pensamientos, que transmite de una generacion a otra\", es decir, los sentidos, los significados de las palabras pertenecen a comunidades de hablantes y no a las mentes de los individuos; lo que es exclusivo de los hablantes son sus representaciones subjetivas, de las que las palabras no son signos.  el trabajo de frege en los fundamentos de la matematica influyo directamente en los principia mathematica de bertrand russell y alfred north whitehead. ludwig wittgenstein y edmund husserl tambien fueron otros filosofos profundamente influidos por frege. rudolf carnap hizo suyas muchas de las tesis logicistas de frege, y desarrollo gran parte de su filosofia con base en la de frege. de este modo, frege se convirtio en el padrino intelectual del circulo de viena.​ por ello, frege esta considerado como el padre de la escuela analitica de filosofia.​  frege fue una figura clave para la filosofia del lenguaje. la distincion entre sentido y referencia y entre concepto y objeto se deben a el. en 1930, los teoremas de incompletitud de godel socavaron parte del proyecto logicista de frege. los teoremas muestran que para cualquier sistema formal que tenga el poder suficiente para expresar la aritmetica, habra proposiciones verdaderas en el sistema que no pueden ser demostradas, ni sus negaciones refutadas. pese a ello, la contribucion de frege como el gran pionero de la logica matematica es abiertamente reconocida.​​  gilles deleuze articula su logica del sentido con base en la proliferacion infinita de entidades verbales o paradoja de frege, segun la cual \"dada una proposicion siempre puede tomarse su sentido como lo designado de otra proposicion\". ",
        "snippet": "Friedrich Ludwig Gottlob Frege (Wismar, 8 de noviembre de 1848 - Bad Kleinen, 26 de julio de 1925) fue un matemático, lógico y filósofo alemán. Se le considera el padre de la lógica matemática y de la filosofía analítica, concentrándose en la filosofía del lenguaje y de las matemáticas. Frege desarrolló su carrera en relativa oscuridad como catedrático de matemáticas de la Universidad de Jena, largamente ignorado por la comunidad filosófica y matemática. Es principalmente gracias a Giuseppe Peano (1858-1932) y a Bertrand Russell (1872-1970), que hicieron una gran labor de divulgación de la obra de Frege, que Frege llegó a ser conocido por generaciones posteriores de filósofos y matemáticos.",
        "enlaces_salientes": [
            "/wiki/Gottlob_Frege",
            "/wiki/Gottlob_Frege",
            "/wiki/Gottlob_Frege",
            "/wiki/Wismar",
            "/wiki/Confederaci%C3%B3n_Germ%C3%A1nica",
            "/wiki/Bad_Kleinen",
            "/wiki/Alemania",
            "/wiki/Wismar",
            "/wiki/Universidad_de_Jena",
            "/wiki/Universidad_de_Gotinga",
            "/wiki/Alfred_Clebsch",
            "/wiki/Ernst_Abbe",
            "/wiki/Wilhelm_Eduard_Weber",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Filosof%C3%ADa",
            "/wiki/Los_fundamentos_de_la_aritm%C3%A9tica",
            "/wiki/Sobre_el_sentido_y_la_referencia",
            "/wiki/Academia_Alemana_de_las_Ciencias_Naturales_Leopoldina",
            "/wiki/Wismar",
            "/wiki/8_de_noviembre",
            "/wiki/1848",
            "/wiki/Bad_Kleinen",
            "/wiki/26_de_julio",
            "/wiki/1925",
            "/wiki/Matem%C3%A1tico",
            "/wiki/L%C3%B3gica",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Alemania",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Filosof%C3%ADa_anal%C3%ADtica",
            "/wiki/Filosof%C3%ADa_del_lenguaje",
            "/wiki/Filosof%C3%ADa_de_las_matem%C3%A1ticas",
            "/wiki/Universidad_de_Jena",
            "/wiki/Giuseppe_Peano",
            "/wiki/Bertrand_Russell",
            "/wiki/Logicismo",
            "/wiki/L%C3%B3gica",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Bertrand_Russell",
            "/wiki/Ludwig_Wittgenstein",
            "/wiki/C%C3%ADrculo_de_Viena",
            "/wiki/Filosof%C3%ADa_anal%C3%ADtica",
            "/wiki/Los_fundamentos_de_la_aritm%C3%A9tica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Sobre_el_sentido_y_la_referencia",
            "/wiki/Filosof%C3%ADa_del_lenguaje",
            "/wiki/Wismar",
            "/wiki/Gran_Ducado_de_Mecklemburgo-Schwerin",
            "/wiki/Alemania",
            "/wiki/Philipp_Melanchthon",
            "/wiki/Libro_de_texto",
            "/wiki/L%C3%B3gica",
            "/wiki/Gimnasio_(escuela)",
            "/wiki/Universidad_de_Jena",
            "/wiki/Confederaci%C3%B3n_Alemana_del_Norte",
            "/wiki/F%C3%ADsica",
            "/wiki/Kant",
            "/wiki/Kant",
            "/wiki/Kuno_Fischer",
            "/wiki/Ernst_Karl_Abbe",
            "/wiki/Gravitaci%C3%B3n",
            "/wiki/Electrodin%C3%A1mica",
            "/wiki/Mec%C3%A1nica_de_s%C3%B3lidos",
            "/wiki/An%C3%A1lisis",
            "/wiki/Variable_compleja",
            "/wiki/Zeiss",
            "/wiki/Carl_Zeiss",
            "/wiki/Universidad_de_Gotinga",
            "/wiki/Alfred_Clebsch",
            "/wiki/Wilhelm_Eduard_Weber",
            "/wiki/Hermann_Lotze",
            "/wiki/Habilitaci%C3%B3n",
            "/wiki/Numeros_complejos",
            "/wiki/An%C3%A1lisis_complejo",
            "/wiki/Geometr%C3%ADa",
            "/wiki/N%C3%BAmeros_enteros",
            "/wiki/L%C3%B3gica",
            "/wiki/Logicismo",
            "/wiki/L%C3%B3gica_proposicional",
            "/wiki/Negaci%C3%B3n_l%C3%B3gica",
            "/wiki/Conjunci%C3%B3n_l%C3%B3gica",
            "/wiki/Disyunci%C3%B3n_l%C3%B3gica",
            "/wiki/Silogismos",
            "/wiki/Axioma",
            "/wiki/Cuantificador",
            "/wiki/Sem%C3%A1ntica_ling%C3%BC%C3%ADstica",
            "/wiki/Sintaxis",
            "/wiki/George_Boole",
            "/wiki/Ernst_Schr%C3%B6der",
            "/wiki/Ernst_Schr%C3%B6der",
            "/wiki/Dedekind",
            "/wiki/Georg_Cantor",
            "/wiki/David_Hilbert",
            "/wiki/Empirismo",
            "/wiki/Epistemolog%C3%ADa",
            "/wiki/Racionalismo",
            "/wiki/Descartes",
            "/wiki/Filosof%C3%ADa_del_lenguaje",
            "/wiki/Sobre_el_sentido_y_la_referencia",
            "/wiki/Giuseppe_Peano",
            "/wiki/Bertrand_Russell",
            "/wiki/Trinity_College_(Cambridge)",
            "/wiki/Edmund_Husserl",
            "/wiki/Paradoja_de_Russell",
            "/wiki/Paradoja_de_Russell",
            "/wiki/Bad_Kleinen",
            "/wiki/Michael_Dummett",
            "/wiki/Michael_Dummett",
            "/wiki/Antisemita",
            "/wiki/Revoluci%C3%B3n_de_Noviembre",
            "/wiki/Extrema_derecha",
            "/wiki/Otto_von_Bismarck",
            "/wiki/Erich_Ludendorff",
            "/wiki/Adolf_Hitler",
            "/wiki/Sufragio_universal",
            "/wiki/Socialismo",
            "/wiki/Gershom_Scholem",
            "/wiki/Ludwig_Wittgenstein",
            "/wiki/Cambridge",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Arist%C3%B3teles",
            "/wiki/Cuantificador",
            "/wiki/Principia_mathematica",
            "/wiki/Alfred_North_Whitehead",
            "/wiki/Bertrand_Russell",
            "/wiki/L%C3%B3gica_formal",
            "/wiki/Logicismo",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/L%C3%B3gica",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Immanuel_Kant",
            "/wiki/Geometr%C3%ADa",
            "/wiki/Bertrand_Russell",
            "/wiki/Sistema_l%C3%B3gico",
            "/wiki/Paradoja_de_Russell",
            "/wiki/Axioma",
            "/wiki/Bad_Kleinen",
            "/wiki/Michael_Dummett",
            "/wiki/Significado",
            "/wiki/Psicologismo",
            "/wiki/Sobre_el_sentido_y_la_referencia",
            "/wiki/Filosof%C3%ADa_del_lenguaje",
            "/wiki/John_Locke",
            "/wiki/Ensayo_sobre_el_entendimiento_humano",
            "/wiki/Homo_Sapiens",
            "/wiki/Identidad_(filosof%C3%ADa)",
            "/wiki/Referencia",
            "/wiki/Objeto",
            "/wiki/Mente",
            "/wiki/Realismo_filos%C3%B3fico",
            "/wiki/Mundo",
            "/wiki/Ser_humano",
            "/wiki/Wismar",
            "/wiki/Principia_Mathematica",
            "/wiki/Bertrand_Russell",
            "/wiki/Alfred_North_Whitehead",
            "/wiki/Ludwig_Wittgenstein",
            "/wiki/Edmund_Husserl",
            "/wiki/Rudolf_Carnap",
            "/wiki/C%C3%ADrculo_de_Viena",
            "/wiki/Filosof%C3%ADa_anal%C3%ADtica",
            "/wiki/Filosof%C3%ADa_del_lenguaje",
            "/wiki/Referencia",
            "/wiki/Concepto",
            "/wiki/Objeto",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Sistema_formal",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Gilles_Deleuze",
            "/wiki/Los_fundamentos_de_la_aritm%C3%A9tica",
            "/wiki/Sobre_el_sentido_y_la_referencia",
            "/wiki/C%C3%A1lculo_proposicional_de_Frege",
            "/wiki/Logicismo",
            "/wiki/Sobre_el_sentido_y_la_referencia",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Stanford_Encyclopedia_of_Philosophy",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Deutsche_Biographie",
            "/wiki/Deutsche_Akademie_der_Naturforscher_Leopoldina",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Proyecto_Gutenberg",
            "/wiki/Europeana"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Georg_Cantor",
        "titulo": "Georg Cantor",
        "contenido": "georg ferdinand ludwig philipp cantor  (san petersburgo, 3 de marzo de 1845 - halle, 6 de enero de 1918), conocido como georg cantor, fue un matematico nacido en rusia, nacionalizado aleman, de ascendencia austriaca y judia.​ fue inventor con dedekind de la teoria de conjuntos, que es la base de las matematicas modernas. gracias a sus atrevidas investigaciones sobre los conjuntos infinitos fue el primero capaz de formalizar la nocion de infinito bajo la forma de los numeros transfinitos (cardinales y ordinales).  vivio aquejado por episodios de depresion, atribuidos originalmente a las criticas recibidas y sus fallidos intentos de demostracion de la hipotesis del continuo, aunque actualmente se cree que sufria algun tipo de \"enfermedad maniaco-depresiva\".​​ murio de un ataque cardiaco en la clinica psiquiatrica de halle.  era hijo del comerciante georg waldemar cantor y de marie bohm. su padre habia nacido en copenhague (dinamarca), en el seno de una familia judia, pero emigro a san petersburgo y fue bautizado como luterano. alli nacio su hijo y vivieron hasta que en 1856 una enfermedad pulmonar impulso al padre a trasladar a su familia a francfort del meno (alemania). todos estos eventos provocaron que distintas naciones reclamaran como propio a georg cantor, despues de su fallecimiento.  la educacion primaria de georg cantor fue inicialmente confiada a un profesor particular, pasando luego a la escuela elemental de san petersburgo. cuando la familia se mudo a alemania, cantor asistio a escuelas privadas de francfort y darmstadt hasta que a los quince años de edad ingreso al instituto de wiesbaden. se graduo en 1860 con un extraordinario informe en que se hacia especial mencion a su gran talento en matematica,en particular, en trigonometria.​ durante su infancia hizo estudios de musica y fue reconocido como violinista prodigio, pero finalmente dejo la musica para estudiar matematicas.  los estudios universitarios de georg cantor se iniciaron en 1862 en zurich, pero al siguiente año, despues de la muerte de su padre, paso a la universidad de berlin donde se especializo en matematicas, filosofia y fisica, aunque el interes del joven se centro en las dos primeras. alli se hizo amigo de hermann schwarz, que fue su compañero. tuvo como profesores en el campo de las matematicas a ernst kummer, karl weierstrass y leopold kronecker.  durante su estancia en berlin, cantor formo parte de un pequeño grupo de jovenes matematicos que se reunian semanalmente en una vinateria. despues de obtener su doctorado en 1867, cantor fue maestro en una escuela de niñas en berlin. despues, en 1868, se unio al seminario schellbach para maestros de matematicas. durante esta etapa, trabajo en su habilitacion e inmediatamente despues de que obtuvo una plaza en la universidad de halle en 1869, presento su trabajo, de nuevo sobre teoria de numeros, y recibio su habilitacion.  en halle cambio la direccion de la investigacion de cantor de la teoria de numeros al analisis matematico. esto se debio a eduard heine, uno de sus colegas mayores en halle, quien desafio a cantor a que probara el problema abierto sobre la unicidad de la representacion de una funcion como una serie trigonometrica. este era un problema dificil que habia sido atacado por muchos matematicos, incluido el propio heine asi como dirichlet, lipschitz y riemann. cantor resolvio el problema probando la unicidad de la representacion en abril de 1870. entre 1870 y 1872 publico varios articulos que trataron las series trigonometricas, los que mostraron las enseñanzas de weierstrass.  en 1872, cuando contaba con veintisiete años de edad, se convirtio en profesor extraordinario en la universidad de halle, dando inicio entonces a sus principales investigaciones.  sus primeros trabajos con las series de joseph fourier le llevaron al desarrollo de una teoria de los numeros irracionales y en 1874 aparecio su primer trabajo sobre la teoria de conjuntos. en esta epoca mantuvo una correspondencia sumamente interesante con dedekind, en la que iban discutiendo las nuevas ideas y demostraciones de cantor.​ sin embargo, las relaciones entre dedekind y cantor encontraron problemas y tuvieron grandes altibajos.  en 1873 cantor probo que los numeros racionales son numerables, es decir, se pueden poner en correspondencia biunivoca con los numeros naturales. tambien probo que los numeros algebraicos, son numerables. sin embargo, sus intentos por decidir si los numeros reales son numerables resultaron mas dificiles. en diciembre de 1873 logro probar que el conjunto de los numeros reales no era numerable y en 1874 lo publico en un articulo. es en este articulo que aparece por primera vez la idea de una correspondencia biunivoca, aunque solo queda implicita en el trabajo.  en su trabajo de 1874, cantor probo que en cierto sentido 'casi todos' los numeros son trascendentes, al probar que los numeros reales no son numerables, mientras que los numeros algebraicos si lo son.  el año 1874 fue importante en la vida personal de cantor. se comprometio con vally guttmann, una amiga de su hermana, en la primavera de ese año. se casaron el 9 de agosto de 1874 y pasaron su luna de miel en interlaken, suiza, donde cantor paso mucho tiempo en discusiones matematicas con dedekind.  un importante articulo que cantor envio al journal de crelle en 1877 fue tratado con suspicacia por kronecker, y solo fue publicado despues de que dedekind interviniera a favor de cantor. cantor quedo profundamente resentido por la oposicion de kronecker a su trabajo y nunca volvio a enviar un articulo mas al journal de crelle.  en cuanto al estudio de los conjuntos infinitos, que fue considerado por su maestro kronecker como una locura matematica, cantor descubrio que aquellos no tienen siempre el mismo tamaño, o sea el mismo cardinal: por ejemplo, el conjunto de los racionales es numerable, es decir, del mismo tamaño que el conjunto de los naturales, mientras que el de los reales no lo es: existen, por lo tanto, varios infinitos, mas grandes los unos que los otros.  este hecho supuso un desafio para un espiritu tan religioso como el de georg cantor. y las acusaciones de blasfemia por parte de ciertos colegas envidiosos o que no entendian sus descubrimientos no le ayudaron. a finales de mayo de 1884 cantor tuvo su primer ataque de depresion registrado. se recupero despues de unas cuantas semanas pero se sentia mas inseguro. sufrio de depresion, y fue internado repetidas veces en hospitales psiquiatricos.  en algun momento se penso que su depresion era causada por preocupaciones matematicas como varias paradojas de la teoria de los conjuntos, que parecian invalidar toda su teoria (tornarla inconsistente o contradictoria en el sentido de que una cierta propiedad podria ser a la vez cierta y falsa) y como resultado de su relacion con kronecker, en particular. recientemente, sin embargo, una mejor comprension de las enfermedades mentales ha llevado a asegurar que las preocupaciones matematicas de cantor y sus relaciones dificiles resultaban muy exageradas por su depresion, pero no eran la causa principal.  ademas, trato durante muchos años de probar la hipotesis del continuo, lo que se sabe hoy que es imposible, y que tiene que ser aceptada (o rehusada) como axioma adicional de la teoria. el constructivismo negara este axioma, entre otras cosas, desarrollando toda una teoria matematica alternativa a la matematica moderna.  aproximadamente en 1888 adopto la idea de fundar la deutsche mathematiker-vereinigung (asociacion alemana de matematicos) lo que logro en 1890. cantor presidio la primera reunion de la asociacion en halle en septiembre de 1891 y, a pesar de su amargo antagonismo con kronecker, cantor lo invito a dictar una conferencia en la primera reunion. sin embargo, kronecker nunca hablo en la reunion, pues su esposa tuvo un accidente y murio poco despues. cantor resulto elegido presidente de la deutsche mathematiker-vereinigung en la primera reunion, puesto que mantuvo hasta 1893.  empezo a equiparar el concepto de infinito absoluto (que no es concebible por la mente humana) con dios, y escribio articulos religiosos sobre el tema.  sistematizo el conjunto ℝ de los numeros reales y uso el concepto de conjunto abierto.​ impulsor de la investigacion en rusia, en la linea de euler, es el autor  del \"principio de los intervalos encajados\", creador de ciertos conjuntos en topologia y en teoria de la medida.​  sus ultimos articulos importantes sobre la teoria de conjuntos aparecieron en 1895 y 1897, de nuevo en los mathematische annalen editados ahora por klein, y son bellos recuentos de aritmetica transfinita.  cada vez que cantor sufria de periodos de depresion, tendia a alejarse de las matematicas y a voltear hacia la filosofia y a su gran interes literario, pues creia que habia sido francis bacon quien escribio las obras de shakespeare (vease autoria de las obras de shakespeare). empezo a publicar panfletos sobre las cuestiones literarias en 1896 y 1897. la muerte de su madre en octubre de 1896 y la de su hermano menor en 1899 impusieron mas presion sobre la salud de cantor.  en octubre de 1899, cantor solicito y obtuvo un permiso para ausentarse de la docencia durante el semestre de invierno de 1899-1900. despues, el 16 de diciembre de 1899, murio el menor de sus hijos. desde este momento y hasta el final de sus dias lucho contra su enfermedad mental de depresion. continuo enseñando, pero tuvo que ausentarse de la docencia varios semestres de invierno. cantor paso algunas temporadas en sanatorios, cuando sufrio los peores ataques de su enfermedad, de 1899 en adelante. continuo trabajando y publicando sobre su teoria de bacon-shakespeare y ciertamente no abandono las matematicas completamente. dio conferencias sobre las paradojas de la teoria de los conjuntos en una reunion de la deutsche mathematiker-vereinigung en septiembre de 1903 y asistio al congreso internacional de matematicos en heidelberg, en agosto de 1904.  cantor se retiro en 1913 y paso sus ultimos años enfermo y con poco alimento por causa de la guerra en alemania. un importante encuentro planeado en halle para celebrar los setenta años de cantor en 1915 tuvo que cancelarse por causa de la guerra, pero una celebracion mas pequeña se llevo a cabo en su casa. en junio de 1917, entro a un sanatorio por ultima vez, y continuamente le escribia a su esposa, pidiendole que se le permitiera regresar a casa.  georg cantor fallecio en halle, alemania, el 6 de enero de 1918 a los setenta y dos años de edad de un ataque cardiaco. actualmente, su obra es ampliamente reconocida y ha sido acreedora de varios honores. ",
        "snippet": "Georg Ferdinand Ludwig Philipp Cantor (San Petersburgo, 3 de marzo de 1845 - Halle, 6 de enero de 1918), conocido como Georg Cantor, fue un matemático nacido en Rusia, nacionalizado alemán, de ascendencia austríaca y judía.[1]​ Fue inventor con Dedekind de la teoría de conjuntos, que es la base de las matemáticas modernas. Gracias a sus atrevidas investigaciones sobre los conjuntos infinitos fue el primero capaz de formalizar la noción de infinito bajo la forma de los números transfinitos (cardinales y ordinales).",
        "enlaces_salientes": [
            "/wiki/Georg_Cantor",
            "/wiki/Georg_Cantor",
            "/wiki/Georg_Cantor",
            "/wiki/San_Petersburgo",
            "/wiki/Gobernaci%C3%B3n_de_San_Petersburgo",
            "/wiki/Imperio_ruso",
            "/wiki/Halle_(Sajonia-Anhalt)",
            "/wiki/Reino_de_Prusia",
            "/wiki/Imperio_alem%C3%A1n",
            "/wiki/Infarto_agudo_de_miocardio",
            "/wiki/Reich_alem%C3%A1n",
            "/wiki/Luteranismo",
            "/wiki/Universidad_Humboldt_de_Berl%C3%ADn",
            "/wiki/Universidad_Mart%C3%ADn_Lutero_de_Halle-Wittenberg",
            "/wiki/Ernst_Kummer",
            "/wiki/Karl_Weierstra%C3%9F",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Academia_Alemana_de_las_Ciencias_Naturales_Leopoldina",
            "/wiki/Academia_de_Ciencias_de_Gotinga",
            "/wiki/Royal_Society_of_Edinburgh",
            "/wiki/London_Mathematical_Society",
            "/wiki/Medalla_Sylvester",
            "/wiki/San_Petersburgo",
            "/wiki/3_de_marzo",
            "/wiki/1845",
            "/wiki/Halle_(Sajonia-Anhalt)",
            "/wiki/6_de_enero",
            "/wiki/1918",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Pueblo_jud%C3%ADo",
            "/wiki/Julius_Wilhelm_Richard_Dedekind",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Conjunto_infinito",
            "/wiki/Infinito",
            "/wiki/N%C3%BAmero_transfinito",
            "/wiki/Depresi%C3%B3n",
            "/wiki/Hip%C3%B3tesis_del_continuo",
            "/wiki/Copenhague",
            "/wiki/Fr%C3%A1ncfort_del_Meno",
            "/wiki/Darmstadt",
            "/wiki/Z%C3%BArich",
            "/wiki/Universidad_de_Berl%C3%ADn",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Filosof%C3%ADa",
            "/wiki/F%C3%ADsica",
            "/wiki/Ernst_Kummer",
            "/wiki/Karl_Weierstrass",
            "/wiki/Leopold_Kronecker",
            "/wiki/Universidad_Mart%C3%ADn_Lutero_de_Halle-Wittenberg",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/An%C3%A1lisis_matem%C3%A1tico",
            "/wiki/Eduard_Heine",
            "/wiki/Peter_Gustav_Lejeune_Dirichlet",
            "/wiki/Rudolf_Lipschitz",
            "/wiki/Bernhard_Riemann",
            "/wiki/Universidad_de_Halle",
            "/wiki/Serie_de_Fourier",
            "/wiki/Joseph_Fourier",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Richard_Dedekind",
            "/wiki/Conjunto_numerable",
            "/wiki/N%C3%BAmero_algebraico",
            "/wiki/N%C3%BAmero_trascendente",
            "/wiki/Leopold_Kronecker",
            "/wiki/N%C3%BAmero_racional",
            "/wiki/N%C3%BAmero_natural",
            "/wiki/N%C3%BAmero_real",
            "/wiki/Hip%C3%B3tesis_del_continuo",
            "/wiki/Constructivismo_(matem%C3%A1ticas)",
            "/wiki/Deutsche_Mathematiker-Vereinigung",
            "/wiki/Euler",
            "/wiki/Topolog%C3%ADa",
            "/wiki/Teor%C3%ADa_de_la_medida",
            "/wiki/Mathematische_Annalen",
            "/wiki/Francis_Bacon",
            "/wiki/William_Shakespeare",
            "/wiki/Autor%C3%ADa_de_las_obras_de_Shakespeare",
            "/wiki/San_Petersburgo",
            "/wiki/Cantor_(cr%C3%A1ter)",
            "/wiki/Asteroide",
            "/wiki/(16246)_Cantor",
            "/wiki/N%C3%BAmeros_infinitos",
            "/wiki/Conjunto_de_Cantor",
            "/wiki/Argumento_de_la_diagonal_de_Cantor",
            "/wiki/Hotel_Infinito",
            "/wiki/Constructivismo_(matem%C3%A1ticas)",
            "/wiki/ISBN",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/Ernst_Zermelo",
            "/wiki/Richard_Dedekind",
            "/wiki/Adolf_Fraenkel",
            "/wiki/Funci%C3%B3n_de_Cantor",
            "/wiki/Teorema_de_Heine-Cantor",
            "/wiki/Funci%C3%B3n_biyectiva",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Harvard_University_Press",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/Jes%C3%BAs_Moster%C3%ADn",
            "/wiki/ISBN",
            "/wiki/Julio_Rey_Pastor",
            "/wiki/ISBN",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Enciclopedia_Libre_Universal",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_Nacional_de_Chile",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Deutsche_Akademie_der_Naturforscher_Leopoldina",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/David_Hilbert",
        "titulo": "David Hilbert",
        "contenido": "david hilbert (konigsberg, prusia oriental; 23 de enero de 1862-gotinga, alemania; 14 de febrero de 1943) fue un matematico aleman, reconocido como uno de los mas influyentes del siglo xix y principios del xx. establecio su reputacion como gran matematico y cientifico inventando y desarrollando un gran abanico de ideas, como la teoria de invariantes, la axiomatizacion de la geometria y la nocion de espacio de hilbert, uno de los fundamentos del analisis funcional. hilbert y sus estudiantes proporcionaron partes significativas de la infraestructura matematica necesaria para la mecanica cuantica y la relatividad general. fue uno de los fundadores de la teoria de la demostracion, la logica matematica y la distincion entre matematica y metamatematica. adopto y defendio vivamente la teoria de conjuntos y los numeros transfinitos de georg cantor. un ejemplo famoso de su liderazgo mundial en la matematica es su presentacion en 1900 de un conjunto de problemas abiertos que incidio en el curso de gran parte de la investigacion matematica del siglo xx.  hilbert nacio en konigsberg, en prusia oriental (actual kaliningrado, rusia). se graduo en el liceo de su ciudad natal y se matriculo en la universidad de konigsberg (albertina). en esta  se doctoro en 1885, con una disertacion, escrita bajo la supervision de ferdinand von lindemann, titulada uber invariante eigenschaften specieller binarer formen, insbesondere der kugelfunctionen (sobre las propiedades invariantes de formas binarias especiales, en particular las funciones circulares). hermann minkowski coincidio con hilbert, en la misma universidad y momento, como aspirante a doctor, y llegaron a ser amigos intimos, ejerciendo uno sobre el otro una influencia reciproca en varias ocasiones de sus carreras cientificas.  hilbert trabajo como profesor en la universidad de konigsberg de 1886 a 1895, cuando, como resultado de la intervencion en su nombre de felix klein, obtuvo el puesto de catedratico de matematica en la universidad de gottingen, que en aquella fecha era el mejor centro de investigacion matematica en el mundo; aqui permaneceria el resto de su vida.  el primer trabajo de david hilbert sobre funciones invariantes le llevo, en 1888, a la demostracion de su famoso teorema de finitud. veinte años antes, paul gordan habia demostrado el teorema de la finitud de generadores para formas binarias, usando un complejo enfoque computacional. los intentos de generalizar este metodo a funciones con mas de dos variables fallaron por la enorme dificultad de los calculos implicados. hilbert se dio cuenta de que era necesario seguir un camino completamente diferente. como resultado, demostro el teorema fundamental de hilbert: mostrar la existencia de un conjunto finito de generadores, para las invariantes cuanticas en cualquier numero de variables, pero de forma abstracta. esto es, demostro la existencia de dicho conjunto, pero no de forma algoritmica sino mediante un teorema de existencia.  hilbert envio sus resultados a los mathematische annalen. gordan, el experto en teoria de invariantes de los annalen, no fue capaz de apreciar la naturaleza revolucionaria del teorema de hilbert y rechazo el articulo, criticando la exposicion porque era insuficientemente comprensiva. su comentario fue: «esto es teologia, ¡no matematica!»  klein, por otro lado, reconocio la importancia del trabajo y se aseguro de que fuese publicado sin alteraciones. animado por klein y los comentarios de gordan, hilbert extendio su metodo en un segundo articulo, proporcionando estimaciones sobre el grado maximo del conjunto minimo de generadores, y lo envio una vez mas a los annalen. tras leer el manuscrito, klein le escribio, con estos terminos: «sin duda este es el trabajo mas importante en algebra general que los annalen ha publicado nunca». mas adelante, cuando la utilidad del metodo de hilbert habia sido reconocida universalmente, el propio gordan diria: «he de admitir que incluso la teologia tiene sus meritos».  el texto  grundlagen der geometrie (fundamentos de la geometria), que hilbert publico en 1899, sustituye los tradicionales axiomas de euclides por sistema formal de 21 axiomas. evitan las debilidades identificadas en los de euclides, cuya obra clasica elementos seguia siendo usada como libro de texto en aquel momento.  el enfoque de hilbert marco el cambio al sistema axiomatico moderno. los axiomas no se toman como verdades evidentes. la geometria puede tratar de cosas, sobre las que tenemos intuiciones poderosas, pero no es necesario asignar un significado explicito a los conceptos indefinidos. como dice hilbert, los elementos tales como el punto, la recta, el plano y otros, se pueden sustituir con mesas, sillas, jarras de cerveza y otros objetos. lo que se discute y se desarrolla son sus relaciones definidas.  hilbert comienza enumerando los conceptos sin definicion: punto, recta, plano, incidencia (una relacion entre puntos y planos), estar entre, congruencia de pares de puntos y congruencia de angulos. los axiomas unifican la geometria plana y la solida de euclides en un unico sistema.  hilbert propuso una lista amplia de 23 problemas no resueltos en el congreso internacional de matematicos de paris en 1900. se reconoce de forma general que esta es la recopilacion de problemas abiertos mas exitosa y de profunda consideracion producida nunca por un unico matematico.  tras reescribir los fundamentos de la geometria clasica, hilbert podia haberlo extrapolado al resto de las matematicas. este enfoque difiere, sin embargo, de los posteriores «logicistas» russell-whitehead o el «formalismo matematico» de su contemporaneo giuseppe peano y mas recientemente del «conjunto de matematicos» nicolas bourbaki . la comunidad matematica al completo podria embarcarse en problemas que el identifico como aspectos cruciales en las areas de la matematica que el considero como claves.  lanzo el conjunto de problemas en la conferencia \"los problemas de la matematica\" presentada durante el curso del segundo congreso internacional de matematicos celebrado en paris. esta es la introduccion a la conferencia de hilbert:  presento menos de la mitad de los problemas en el congreso, que fueron publicados en las actas. extendio el panorama en una publicacion posterior, con ella llego la formulacion canonica actual de los 23 problemas de hilbert. el texto al completo es importante, dado que la exegesis de las cuestiones puede seguir siendo materia de debate inevitable, cada vez que se preguntan cuantas han sido resueltas:  1. problema de cantor sobre el cardinal del continuo. ¿cual es el cardinal del continuo?  2. la compatibilidad de los axiomas de la aritmetica. ¿son compatibles los axiomas de la aritmetica?  3. la igualdad de los volumenes de dos tetraedros de igual base e igual altura.  4. el problema de la distancia mas corta entre dos puntos. ¿es la linea recta la distancia mas corta entre dos puntos, sobre cualquier superficie, en cualquier geometria?  5. establecer el concepto de grupo de lie, o grupo continuo de transformaciones, sin asumir la diferenciabilidad de las funciones que definen el grupo.  6. axiomatizacion de la fisica. ¿es posible crear un cuerpo axiomatico para la fisica?  7. la irracionalidad y trascendencia de ciertos numeros, como 2 2 }} , etc.  8. el problema de la distribucion de los numeros primos.  9. demostracion de la ley mas general de reciprocidad en un cuerpo de numeros cualesquiera.  10. establecer metodos efectivos de resolucion de ecuaciones diofanticas.  11. formas cuadraticas con coeficientes algebraicos cualesquiera.  12. la extension del teorema de kronecker sobre cuerpos abelianos a cualquier dominio de racionalidad algebraica.  13. imposibilidad de resolver la ecuacion general de septimo grado por medio de funciones de solo dos argumentos.  14. prueba de la condicion finita de ciertos sistemas completos de funciones.  15. fundamentacion rigurosa del calculo enumerativo de schubert o geometria algebraica.  16. problema de la topologia de curvas algebraicas y de superficies.  17. la expresion de formas definidas por sumas de cuadrados.  18. construccion del espacio de los poliedros congruentes.  19. las soluciones de los problemas regulares del calculo de variaciones, ¿son siempre analiticas?  20. el problema general de condiciones de contorno de dirichlet.  21. demostracion de la existencia de ecuaciones diferenciales lineales de clase fuchsiana, conocidos sus puntos singulares y grupo monodromico.  22. uniformidad de las relaciones analiticas por medio de funciones automorficas: siempre es posible uniformizar cualquier relacion algebraica entre dos variables por medio de funciones automorfas de una variable.  23. extension de los metodos del calculo de variaciones.  algunos se resolvieron en poco tiempo. otros se han discutido durante todo el siglo xx, y actualmente se ha llegado a la conclusion de que unos pocos son irrelevantes o imposibles de cerrar. algunos continuan siendo actualmente un reto para los matematicos.  siguiendo la tendencia que se habia convertido en estandar a mitad de siglo, el conjunto de problemas de hilbert tambien constituia una especie de manifiesto, que abrio la via para el desarrollo de la escuela del formalismo matematico, una de las tres escuelas matematicas mas importantes del siglo xx. de acuerdo al formalismo, la matematica es un juego —carente de significado— en el que uno lo practica con simbolos carentes de significado de acuerdo a unas reglas formales establecidas de antemano. por tanto es una actividad de pensamiento autonoma. sin embargo, hay margen para la duda al respecto de si la propia vision de hilbert era simplistamente formalista en este sentido.  en 1920 propuso de forma explicita un proyecto de investigacion (en metamatematica, como se llamo entonces) que acabo siendo conocido como programa de hilbert. queria que la matematica fuese formulada sobre unas bases solidas y completamente logicas. creia que, en principio, esto podia lograrse, mostrando que:  parecia tener razones tecnicas y filosoficas para formular esta propuesta. esto afirmaba su disgusto por lo que se habia dado a conocer como ignorabimus, que aun era un problema activo en su tiempo dentro del pensamiento aleman, y que podia rastrearse en esa formulacion hasta emil du bois-reymond.  el programa sigue siendo reconocible en la filosofia de la matematica mas popular, donde se le llama normalmente formalismo. por ejemplo, el grupo bourbaki adopto una version selectiva y diluida como adecuada para los requisitos de sus proyectos gemelos de (a) escribir trabajos fundamentales enciclopedicos, y (b) dar soporte al sistema axiomatico como herramienta de investigacion. este enfoque ha tenido exito e influencia en relacion con el trabajo de hilbert en el algebra y el analisis funcional, pero no ha conseguido cuajar igual con sus intereses en fisica y logica.  hilbert y los matematicos de talento que trabajaron con el en esta empresa estaban dedicados al proyecto. su intento de dar soporte a la matematica axiomatizada con principios definidos, que eliminara las incertidumbres teoricas, sucumbio en un fracaso inesperado.  godel demostro que no se podia demostrar la completitud de ningun sistema formal no contradictorio que fuera suficientemente amplio para incluir al menos la aritmetica, solo mediante sus propios axiomas. en 1931 su teorema de la incompletitud mostro que el ambicioso plan de hilbert era imposible tal como se planteaba. el segundo requisito no podia combinarse con el primero de forma razonable, mientras el sistema axiomatico sea genuinamente finito.  sin embargo, el teorema de completitud no dice nada al respecto de la demostracion de la completitud de la matematica mediante un sistema formal diferente. los logros posteriores de la teoria de la demostracion como minimo clarificaron la relacion de la consistencia con las teorias de interes principal para los matematicos. el trabajo de hilbert habia empezado logico en su camino a la clarificacion; la necesidad de entender el trabajo de godel llevo entonces al desarrollo de la teoria de la computabilidad y despues de la logica matematica como disciplina autonoma en la decada de 1930–1940. de este 'debate' nacio directamente la base para la informatica teorica de alonzo church y alan turing.  entre los alumnos de hilbert se encuentran hermann weyl, el campeon mundial de ajedrez emanuel lasker, ernst zermelo y carl gustav hempel. john von neumann fue asistente suyo. en la universidad de gottingen, hilbert se encontro rodeado por un circulo social constituido por algunos de los matematicos mas importantes del siglo xx, como emmy noether y alonzo church.  alrededor de 1909, hilbert se dedico al estudio de ecuaciones diferenciales y ecuaciones integrales; su trabajo tuvo consecuencias directas en partes importantes el analisis funcional moderno. para poder llevar a cabo estos estudios, hilbert introdujo el concepto de un espacio euclideo de infinitas dimensiones, llamado mas tarde espacio de hilbert. su trabajo en esta parte del analisis proporciono la base de importantes contribuciones a la fisica matematica en las dos decadas siguientes, aunque en direcciones que por entonces no se podian anticipar. mas tarde, stefan banach amplifico el concepto, definiendo los espacios de banach. el espacio de hilbert es por si misma la idea mas importante del analisis funcional, que crecio a su alrededor durante el siglo xx.  hasta 1912, hilbert fue de forma casi exclusiva un matematico «puro». cuando planeaba hacer una visita a bonn, donde estaba inmerso en el estudio de la fisica, su amigo y colega matematico hermann minkowski hacia chistes diciendo que tenia que pasar 10 dias en cuarentena antes de poder visitar a hilbert. en realidad, minkowski parece ser responsable de la mayoria de investigaciones de hilbert en fisica anteriores a 1912, incluido su seminario conjunto sobre el tema en 1905.  en 1912, tres años tras la muerte de su amigo, cambio su objetivo hacia este tema de forma casi exclusiva. arreglo que se le asignara un «tutor en fisica».​ empezo estudiando la teoria cinetica de los gases y paso luego a la teoria elemental de radiacion y a la teoria molecular de la materia. incluso tras el estallido de la guerra en 1914, continuo celebrando seminarios y clases donde se seguian de cerca los trabajos de einstein entre otros.  hilbert invito a einstein a gottingen para que impartiera una semana de lecciones entre junio y julio de 1915 sobre relatividad general y su teoria de la gravedad en desarrollo (sauer 1999, folsing 1998). el intercambio de ideas llevo a la forma final de las ecuaciones de campo de la relatividad general, en concreto las ecuaciones de campo de einstein y la accion de einstein-hilbert. aunque einstein y hilbert no llegaron nunca a enzarzarse en una disputa publica sobre prioridad, ha habido algo de discusion sobre el descubrimiento de las ecuaciones de campo, aunque las investigaciones sobre documentacion historica, parecen confirmar que einstein se adelanto, ya que el trabajo de hilbert estaba incompleto.​ hilbert en la version impresa de su articulo, añadio una referencia al papel concluyente de einstein y una concesion de la prioridad de este: \"las ecuaciones diferenciales de la gravitacion que resultan estan, segun me parece, de acuerdo con la magnifica teoria de la relatividad general establecida por einstein en sus trabajos posteriores \"[(3), p. 404].​  ademas, el trabajo de hilbert anticipo y asistio a varios avances en la formulacion matematica de la mecanica cuantica. su trabajo fue clave para el de hermann weyl y john von neumann sobre la equivalencia matematica de la mecanica de matrices de werner heisenberg y la ecuacion de onda de erwin schrodinger, y su espacio de hilbert juega un papel importante en la teoria cuantica. en 1926, von neumann mostro que si los estados atomicos se entendiesen como vectores en el espacio de hilbert, entonces se corresponderian tanto con la teoria de funcion de onda de schrodinger como con las matrices de heisenberg.  mediante esta inmersion en la fisica, trabajo en darle rigor a la matematica que la sostiene. aunque es muy dependiente de la matematica avanzada, el fisico tiende a ser «descuidado» con ella. para un matematico «puro» como hilbert, esto era «feo» y dificil de entender. al empezar a comprender la fisica y la manera en que los fisicos usaban la matematica, desarrollo una teoria matematicamente coherente para lo que encontro, principalmente en el area de las ecuaciones integrales. cuando su colega richard courant escribio el clasico metodos de fisica matematica incluyo algunas ideas de hilbert, y añadio su nombre como coautor incluso aunque hilbert no llego a contribuir al escrito. hilbert dijo que «la fisica es demasiado dura para los fisicos», implicando que la matematica necesaria estaba lejos de su alcance por lo general; el libro de courant-hilbert les facilito las cosas.  hilbert unifico el campo de la teoria algebraica de numeros con su tratado de 1897 zahlbericht (literalmente 'informe sobre numeros'). abatio el problema de waring en el sentido amplio. desde entonces tuvo poco mas que decir sobre el tema; pero la emergencia de las formas modulares de hilbert en la disertacion de un estudiante implica que su nombre esta mas unido a un area importante.  propuso una serie de conjeturas sobre la teoria de cuerpos de clases. los conceptos fueron muy influyentes, y su propia contribucion queda patente en los nombres del cuerpo de clase de hilbert y el simbolo de hilbert de la teoria local de cuerpos de clases. los resultados sobre estas conjeturas quedaron probados en su mayoria sobre 1930, tras el importante trabajo de teiji takagi que lo establecio como el primer matematico japones de nivel internacional.  hilbert no trabajo en las areas principales de la teoria analitica de numeros, pero su nombre quedo unido a la conjetura de hilbert-polya, por razones anecdoticas.  su paradoja del grand hotel, una meditacion sobre las extrañas propiedades del infinito, se usa a menudo en textos populares sobre numeros cardinales infinitos. tambien era miembro de una secta.  hilbert vivio para ver a los nazis purgar a la mayoria de miembros facultativos sobresalientes de la universidad de gottingen, en 1933.​ entre aquellos forzados a marcharse estuvieron hermann weyl, que habia ocupado la catedra de hilbert al retirarse en 1930, emmy noether y edmund landau. uno de los que hubo de dejar alemania fue paul bernays, colaborador de hilbert en logica matematica y coautor con el del importante libro grundlagen der mathematik (que acabo presentandose en dos volumenes, en 1934 y 1939). esta fue una secuela del libro de hilbert-ackermann fundamentos de logica teorica de 1928.  un año despues, asistio a un banquete y lo sentaron al lado del nuevo ministro de educacion, bernhard rust. rust le pregunto: «¿como va la matematica en gottingen ahora que ha sido liberada de la influencia judia?» a lo que hilbert contesto, «¿la matematica en gottingen? ya no queda nada de eso».​  para cuando hilbert murio en 1943, los nazis habian reestructurado casi por completo la universidad, ya que mucho del personal facultativo anterior era judio o estaba casado con judios. al funeral de hilbert asistio menos de una docena de personas, y solo dos de ellas eran colegas academicos.​  en su tumba, en gottingen, se puede leer su epitafio:  ironicamente, el dia antes de que hilbert pronunciase esta frase, kurt godel presentaba su tesis, que contenia el famoso teorema de incompletitud: hay cosas que sabemos que son ciertas, pero que no podemos probar.  ademas de numerosas entidades y teoremas matematicos que portan su apellido, la designacion de dos elementos astronomicos le rinde homenaje:  bibliografia primaria para la traduccion al ingles:  secundaria: ",
        "snippet": "David Hilbert (Königsberg, Prusia Oriental; 23 de enero de 1862-Gotinga, Alemania; 14 de febrero de 1943) fue un matemático alemán, reconocido como uno de los más influyentes del siglo XIX y principios del XX. Estableció su reputación como gran matemático y científico inventando y desarrollando un gran abanico de ideas, como la teoría de invariantes, la axiomatización de la geometría y la noción de espacio de Hilbert, uno de los fundamentos del análisis funcional. Hilbert y sus estudiantes proporcionaron partes significativas de la infraestructura matemática necesaria para la mecánica cuántica y la relatividad general. Fue uno de los fundadores de la teoría de la demostración, la lógica matemática y la distinción entre matemática y metamatemática. Adoptó y defendió vivamente la teoría de conjuntos y los números transfinitos de Georg Cantor. Un ejemplo famoso de su liderazgo mundial en la matemática es su presentación en 1900 de un conjunto de problemas abiertos que incidió en el curso de gran parte de la investigación matemática del siglo XX.",
        "enlaces_salientes": [
            "/wiki/David_Hilbert",
            "/wiki/David_Hilbert",
            "/wiki/David_Hilbert",
            "/wiki/23_de_enero",
            "/wiki/1862",
            "/wiki/K%C3%B6nigsberg",
            "/wiki/Prusia_Oriental",
            "/wiki/14_de_febrero",
            "/wiki/1943",
            "/wiki/Gotinga",
            "/wiki/Alemania_nazi",
            "/wiki/Alemania",
            "/wiki/Universidad_de_K%C3%B6nigsberg",
            "/wiki/Ferdinand_von_Lindemann",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Teorema_de_la_Base_de_Hilbert",
            "/wiki/Axiomas_de_Hilbert",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/Programa_de_Hilbert",
            "/wiki/Acci%C3%B3n_de_Einstein-Hilbert",
            "/wiki/Espacio_de_Hilbert",
            "/wiki/Universidad_de_K%C3%B6nigsberg",
            "/wiki/Universidad_de_G%C3%B6ttingen",
            "/wiki/Wilhelm_Ackermann",
            "/wiki/Richard_Courant",
            "/wiki/Max_Dehn",
            "/wiki/Hellmuth_Kneser",
            "/wiki/Emanuel_Lasker",
            "/wiki/Erhard_Schmidt",
            "/wiki/Hugo_Steinhaus",
            "/wiki/Teiji_Takagi",
            "/wiki/Hermann_Weyl",
            "/wiki/Ernst_Zermelo",
            "/wiki/Jos%C3%A9_Agust%C3%ADn_P%C3%A9rez_del_Pulgar",
            "/wiki/Wilhelm_Ackermann",
            "/wiki/Richard_Courant",
            "/wiki/Teorema_de_la_base_de_Hilbert",
            "/wiki/Academia_de_Ciencias_de_Gotinga",
            "/wiki/Academia_de_Ciencias_de_la_Uni%C3%B3n_Sovi%C3%A9tica",
            "/wiki/Real_Academia_de_las_Ciencias_de_Suecia",
            "/wiki/Academia_H%C3%BAngara_de_Ciencias",
            "/wiki/Academia_Nacional_de_los_Linces",
            "/wiki/Academia_de_Ciencias_de_Rusia",
            "/wiki/Academia_Prusiana_de_las_Ciencias",
            "/wiki/Real_Academia_de_Artes_y_Ciencias_de_los_Pa%C3%ADses_Bajos",
            "/wiki/Academia_de_Ciencias_de_Baviera",
            "/wiki/Academia_de_Ciencias_de_Tur%C3%ADn",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Royal_Society",
            "/wiki/Academia_Sajona_de_Ciencias_de_Leipzig",
            "/wiki/Academia_Alemana_de_las_Ciencias_Naturales_Leopoldina",
            "/wiki/Medalla_Lobachevski",
            "/wiki/Orden_B%C3%A1vara_de_Maximiliano_para_las_ciencias_y_las_artes",
            "/wiki/Premio_Bolyai",
            "/wiki/K%C3%B6nigsberg",
            "/wiki/Prusia_Oriental",
            "/wiki/23_de_enero",
            "/wiki/1862",
            "/wiki/Gotinga",
            "/wiki/Alemania",
            "/wiki/14_de_febrero",
            "/wiki/1943",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Alemania",
            "/wiki/Teor%C3%ADa_de_invariantes",
            "/wiki/Axiomas_de_Hilbert",
            "/wiki/Espacio_de_Hilbert",
            "/wiki/An%C3%A1lisis_funcional",
            "/wiki/Mec%C3%A1nica_cu%C3%A1ntica",
            "/wiki/Relatividad_general",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Metamatem%C3%A1tica",
            "/wiki/Georg_Cantor",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/K%C3%B6nigsberg",
            "/wiki/Prusia_Oriental",
            "/wiki/Kaliningrado",
            "/wiki/Rusia",
            "/wiki/Liceo_(instituci%C3%B3n)",
            "/wiki/Universidad_de_K%C3%B6nigsberg",
            "/wiki/Ferdinand_von_Lindemann",
            "/wiki/Forma_binaria",
            "/wiki/Hermann_Minkowski",
            "/wiki/Felix_Klein",
            "/wiki/Universidad_de_G%C3%B6ttingen",
            "/wiki/Paul_Gordan",
            "/wiki/Teorema",
            "/wiki/Teorema_de_la_Base_de_Hilbert",
            "/wiki/Forma_algebraica",
            "/wiki/Teorema_de_existencia",
            "/wiki/Mathematische_Annalen",
            "/wiki/Axiomas_de_Hilbert",
            "/wiki/1899",
            "/wiki/Geometr%C3%ADa_euclidiana",
            "/wiki/Axioma",
            "/wiki/Euclides",
            "/wiki/Sistema_formal",
            "/wiki/Punto_(geometr%C3%ADa)",
            "/wiki/Recta",
            "/wiki/Plano_(geometr%C3%ADa)",
            "/wiki/%C3%81ngulo",
            "/wiki/Geometr%C3%ADa_plana",
            "/wiki/Geometr%C3%ADa_espacial",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/Congreso_Internacional_de_Matem%C3%A1ticos",
            "/wiki/Par%C3%ADs",
            "/wiki/Geometr%C3%ADa_cl%C3%A1sica",
            "/wiki/Logicismo",
            "/wiki/Formalismo_matem%C3%A1tico",
            "/wiki/Giuseppe_Peano",
            "/wiki/Conjunto",
            "/wiki/Nicolas_Bourbaki",
            "/wiki/Formalismo_matem%C3%A1tico",
            "/wiki/Programa_de_Hilbert",
            "/wiki/1920",
            "/wiki/Metamatem%C3%A1tica",
            "/wiki/Programa_de_Hilbert",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Axioma",
            "/wiki/Consistencia_(l%C3%B3gica)",
            "/wiki/Ignorabimus",
            "/wiki/Emil_du_Bois-Reymond",
            "/wiki/Filosof%C3%ADa_de_la_matem%C3%A1tica",
            "/wiki/Nicolas_Bourbaki",
            "/wiki/Sistema_formal",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/1931",
            "/wiki/Teorema_de_la_incompletitud_de_G%C3%B6del",
            "/wiki/Teor%C3%ADa_de_la_demostraci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_computabilidad",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Inform%C3%A1tica_te%C3%B3rica",
            "/wiki/Alonzo_Church",
            "/wiki/Alan_Turing",
            "/wiki/Hermann_Weyl",
            "/wiki/Emanuel_Lasker",
            "/wiki/Ernst_Zermelo",
            "/wiki/Carl_Gustav_Hempel",
            "/wiki/John_von_Neumann",
            "/wiki/Emmy_Noether",
            "/wiki/Alonzo_Church",
            "/wiki/Espacio_eucl%C3%ADdeo",
            "/wiki/Espacio_de_Hilbert",
            "/wiki/F%C3%ADsica_matem%C3%A1tica",
            "/wiki/Stefan_Banach",
            "/wiki/Espacio_de_Banach",
            "/wiki/An%C3%A1lisis_funcional",
            "/wiki/Hermann_Minkowski",
            "/wiki/Teor%C3%ADa_cin%C3%A9tica",
            "/wiki/Radiaci%C3%B3n",
            "/wiki/Albert_Einstein",
            "/wiki/Teor%C3%ADa_general_de_la_relatividad",
            "/wiki/Ecuaci%C3%B3n_del_campo_de_Einstein",
            "/wiki/Acci%C3%B3n_de_Einstein-Hilbert",
            "/wiki/Formulaci%C3%B3n_matem%C3%A1tica_de_la_mec%C3%A1nica_cu%C3%A1ntica",
            "/wiki/Hermann_Weyl",
            "/wiki/John_von_Neumann",
            "/wiki/Werner_Heisenberg",
            "/wiki/Ecuaci%C3%B3n_de_Schr%C3%B6dinger",
            "/wiki/Erwin_Schr%C3%B6dinger",
            "/wiki/Espacio_de_Hilbert",
            "/wiki/Ecuaci%C3%B3n_integral",
            "/wiki/Richard_Courant",
            "/wiki/Teor%C3%ADa_algebraica_de_n%C3%BAmeros",
            "/wiki/Problema_de_Waring",
            "/wiki/Teor%C3%ADa_de_cuerpos_de_clases",
            "/wiki/Teiji_Takagi",
            "/wiki/Teor%C3%ADa_anal%C3%ADtica_de_n%C3%BAmeros",
            "/wiki/Hotel_infinito",
            "/wiki/N%C3%BAmero_cardinal",
            "/wiki/Nazismo",
            "/wiki/Universidad_de_G%C3%B6ttingen",
            "/wiki/1933",
            "/wiki/Hermann_Weyl",
            "/wiki/Emmy_Noether",
            "/wiki/Edmund_Landau",
            "/wiki/Paul_Bernays",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Wilhelm_Ackermann",
            "/wiki/Bernhard_Rust",
            "/wiki/1943",
            "/wiki/Idioma_alem%C3%A1n",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/Teorema_de_la_incompletitud_de_G%C3%B6del",
            "/wiki/Hilbert_(cr%C3%A1ter)",
            "/wiki/Asteroide",
            "/wiki/(12022)_Hilbert",
            "/wiki/Curva_de_Hilbert",
            "/wiki/Matriz_de_Hilbert",
            "/wiki/Espacio_de_Hilbert",
            "/wiki/Transformada_de_Hilbert",
            "/wiki/Hilbert_Nullstellensatz",
            "/wiki/Axiomas_de_Hilbert",
            "/wiki/Teorema_de_la_Base_de_Hilbert",
            "/wiki/Hotel_infinito",
            "/wiki/Entscheidungsproblem",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/Hermann_Weyl",
            "/wiki/Paul_Bernays",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/El_reto_de_Hilbert",
            "/wiki/Piergiorgio_Odifreddi",
            "/wiki/Geometr%C3%ADa_no_eucl%C3%ADdea",
            "/wiki/Kip_Thorne",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Scopus",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Academia_Sajona_de_Ciencias_de_Leipzig",
            "/wiki/Real_Academia_de_Artes_y_Ciencias_de_los_Pa%C3%ADses_Bajos",
            "/wiki/Deutsche_Akademie_der_Naturforscher_Leopoldina",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Proyecto_Gutenberg"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/John_von_Neumann",
        "titulo": "John von Neumann",
        "contenido": "john von neumann (registrado al nacer como neumann janos lajos; budapest, imperio austrohungaro, 28 de diciembre de 1903 – washington d. c., estados unidos, 8 de febrero de 1957) fue un matematico hungaro-estadounidense que realizo contribuciones fundamentales en fisica cuantica, analisis funcional, teoria de conjuntos, teoria de juegos, ciencias de la computacion, economia, analisis numerico, cibernetica, hidrodinamica, estadistica y muchos otros campos.​ se le considera uno de los matematicos mas importantes del siglo xx.​  neumann janos lajos nacio en budapest en 1903, cuando esta ciudad pertenecia al imperio austrohungaro. su padre, max neumann, era un banquero judio que se habia casado con margaret kann, hija de una familia adinerada de pest. el padre de john, max neumann, recibio el 20 de febrero de 1913 la nobleza hungara donada por el emperador francisco jose de austria-hungria. de esta manera, john, que en hungria ya utilizaba la forma germanizada de su nombre, solia presentarse como johann von neumann. fue el mayor de tres hermanos y a los diez años comenzo a estudiar en el colegio luterano de budapest. sus profesores se dieron cuenta pronto de su talento y recomendaron que recibiera clases particulares de matematicas, impartidas por profesores universitarios.​  john era un superdotado y gano el premio eotvos al mejor alumno del pais en matematicas y ciencia. luego, su enorme inteligencia se haria  legendaria. el futuro premio nobel de fisica eugene wigner fue compañero de colegio, una clase por encima de el. seria su amigo toda la vida y las conversaciones que mantuvo con von neumann en aquella epoca le disuadieron de dedicarse a las matematicas: «habiendo conocido a janos von neumann me di cuenta de la diferencia entre un matematico de primera fila y yo».​  en 1919, al termino de la primera guerra mundial, su familia abandono hungria durante la epoca revolucionaria que culmino con el gobierno comunista de bela kun. a su vuelta, en 1921, john fue admitido en la universidad de budapest donde acabaria doctorandose en matematicas en 1926. al mismo tiempo estudiaba en berlin, y recibio algunas clases de albert einstein, junto a otros compañeros hungaros como el mismo wigner, leo szilard y dennis gabor. ademas, se matriculo en la escuela politecnica federal de zurich, donde en 1925 obtuvo la licenciatura en ingenieria quimica y conocio a figuras como hermann weyl y george polya. finalmente, tambien asistia a los seminarios de david hilbert en gotinga, donde coincidio con robert oppenheimer, con quien volveria a encontrarse en princeton. a los 24 años se convirtio en privatdozent de matematicas en la universidad de berlin.​  es sumamente probable que ya en gotinga, la meca de los matematicos por aquel entonces, conociese a norbert wiener entre 1924 y 1926.  en 1929, la universidad de princeton ofrecio a von neumann y a wigner una invitacion para un semestre. acudio alli acompañado de su novia mariette koevesi, con la que se casaria ese mismo año y tendria en 1935 una hija, marina, que llegaria a ser una distinguida economista.​ durante los años siguientes alternaba sus estancias entre alemania y estados unidos, pero en 1933 la llegada de los nazis al poder hizo que los profesores judios fuesen progresivamente expulsados de sus puestos. von neumann se encontro con la facilidad de estar ya establecido en los estados unidos y de que el instituto de estudios avanzados de princeton comenzo a funcionar ese mismo año, y fue elegido como uno de los primeros profesores junto con albert einstein, oswald veblen, hermann weyl y james w. alexander.​  aunque llevaban una intensa vida social y su casa de princeton era lugar de encuentro habitual para fiestas sociales, su relacion matrimonial se fue deteriorando y, finalmente, acabo divorciandose de mariette en 1937. al año siguiente viajo a europa y daba conferencias e intercambiaba ideas con cientificos como niels bohr, con quien coincidio en copenhague. visito tambien a su familia en hungria y, antes de regresar a estados unidos, se caso con su amiga hungara klara dan.​  al año siguiente estallo la segunda guerra mundial y el gobierno estadounidense puso en marcha el famoso proyecto manhattan, al que von neumann se unio en 1943, junto con eugene wigner y leo szilard, tambien hungaros exiliados. su aportacion mas importante radico en el diseño del metodo de implosion, utilizado en alamogordo, la primera detonacion de una bomba atomica de la historia, y que luego volveria a usarse en la de nagasaki.​  su aporte al programa atomico estadounidense termino yendo mucho mas alla de las contribuciones cientificas.leslie groves, la maxima autoridad militar a cargo del proyecto manhattan, lo eligio como uno de los miembros del comite encargado de tomar decisiones estrategicas. se mostro a favor de construir la bomba de hidrogeno y los misiles balisticos intercontinentales capaces de ser lanzados sobre la union sovietica, y participo activamente en su diseño. la primera explosion de una bomba h se produjo en un atolon del oceano pacifico en 1952.​  von neumann tambien se vio afectado en la posguerra por el surgimiento de la persecucion macartista, a pesar de que era un decidido partidario de la disuasion nuclear. otros cientificos, como robert oppenheimer, mostraron posturas politicas opuestas, y en el ambiente que daba inicio a la guerra fria fueron llevados ante el comite de actividades antiamericanas. von neumann, adoptando una actitud radicalmente diferente a la de otros cientificos como edward teller, se atrevio a defender en publico la inocencia y lealtad de oppenheimer.​  en enero de 1955 von neumann fue ratificado por el senado de los estados unidos como uno de los cinco comisarios de la comision de energia atomica, el puesto mas alto al que un cientifico podia aspirar en el gobierno, lo que hizo que en la primavera se mudara a washington con su familia. al año siguiente, en 1956, recibio de manos del presidente dwight d. eisenhower la primera medalla fermi, a la vez que se le manifestaban los primeros sintomas de la enfermedad que rapidamente terminaria con su vida.​  era comun en la epoca subestimar los peligros de la radiacion, y von neumann compartia la misma confianza: permanecia en los alamos varios meses al año y acudia personalmente a los ensayos nucleares. finalmente contrajo un cancer de huesos que le fue diagnosticado en 1955 y que ya al año siguiente lo incapacito gravemente. algunas reuniones de alto secreto de la comision de la energia atomica tuvieron que celebrarse en la habitacion del hospital militar walter reed en el que habia sido internado. aunque de origen judio, von neumann nunca habia sido creyente y sorprendio a sus allegados pidiendo el consuelo de un sacerdote catolico, el padre strittmater. john von neumann murio el 8 de febrero de 1957.​  la axiomatizacion de las matematicas, de acuerdo con el modelo de los elementos de euclides, habia alcanzado nuevos niveles de rigor y envergadura a finales del siglo xix; particularmente en aritmetica (gracias a richard dedekind y giuseppe peano) y geometria (gracias a david hilbert). de cualquier manera, a comienzos del siglo xx, la teoria de conjuntos no habia sido formalizada. esta nueva rama de las matematicas habia sido creada por georg cantor y puesta en crisis por bertrand russell con el descubrimiento de su famosa paradoja sobre el conjunto de todos los conjuntos que no pertenecen a si mismos. la paradoja de russell consistia en la observacion de que si el conjunto x (de todos los conjuntos que no son miembros de si mismos) es un miembro de si mismo, entonces debe pertenecer al conjunto de los conjuntos que no pertenecen a si mismos y, por otra parte, si el conjunto x no pertenece a si mismo, entonces debe pertenecer al conjunto de los conjuntos que no pertenecen a si mismos y, por lo tanto, debe pertenecer a si mismo.  una de sus famosas aportaciones a la teoria de numeros fue la definicion de numero ordinal (teoria de conjuntos).  el problema de una axiomatizacion adecuada de la teoria de conjuntos fue implicitamente resuelto, cerca de 20 años despues, gracias a ernst zermelo y abraham fraenkel, por medio de una serie de principios que permitieron la construccion de todos los conjuntos utilizados en la practica actual de las matematicas, pero que explicitamente no excluia la posibilidad de la existencia de conjuntos que pertenecieran a si mismos. en su tesis doctoral de 1925, von neumann demostro como era posible excluir esta posibilidad en dos formas complementarias: el axioma de la fundacion y la nocion de clase.  el axioma de la fundacion establecia que cada conjunto puede ser construido de abajo hacia arriba, en una sucesion de pasos ordenada por medio de los principios de zermelo y fraenkel, de tal manera que, si un conjunto pertenece a otro, entonces, necesariamente, el primero debe ir antes del segundo en la sucesion. ccon esto se excluye la posibilidad de que un conjunto pertenezca a si mismo. con el objetivo de demostrar que la adicion de este nuevo axioma a los otros no implicaba contradicciones, von neumann introdujo un metodo de demostracion (llamado metodo de los modelos internos) que mas tarde se convertiria en un instrumento esencial de la teoria de conjuntos.  la segunda aproximacion al problema toma como base la nocion de clase y define un conjunto como una clase que pertenece a otras clases, mientras una clase de propiedad se define como una clase que no pertenece a otras clases. mientras en la aproximacion zermelo/fraenkel los axiomas impiden la construccion de un conjunto de todos los conjuntos que no pertenecen a si mismos, en la aproximacion de von neumann la clase de todos los conjuntos que no pertenecen a si mismos puede ser construida pero es una clase de propiedad y no un conjunto.  con esta contribucion de von neumann, el sistema axiomatico de la teoria de conjuntos se hizo completamente satisfactorio. la siguiente cuestion era si era o no definitivo y si no estaba sujeto a mejoras. la contundente respuesta negativa la dio kurt godel, cuando anuncio, en el historico congreso de konigsberg de septiembre de 1930, su famoso primer teorema de la incompletitud: los sistemas axiomaticos usuales son incompletos, en el sentido de que no pueden probar cada verdad que puede expresarse en su lenguaje. este resultado fue lo suficientemente innovador como para desconcertar a la mayoria de los matematicos de aquella epoca. pero von neumann, que habia participado en el congreso, confirmo su fama de pensador instantaneo y, en menos de un mes, estuvo en disposicion de comunicarle a godel una interesante consecuencia de su teorema: los sistemas axiomaticos usuales son incapaces de demostrar su propia consistencia. esta es, precisamente, la consecuencia que ha atraido la mayor atencion, aunque godel, que originalmente la consideraba como una simple curiosidad, tambien la habria derivado independientemente. por esta razon, el resultado se conoce como el segundo teorema de godel, sin mencion alguna a von neumann.  en el congreso internacional de matematicos de 1900, david hilbert presento su famosa lista de 23 problemas considerada central para el desarrollo de las matematicas del nuevo siglo. el sexto problema era la axiomatizacion de las teorias fisicas. entre las nuevas teorias fisicas del siglo, la unica pendiente de recibir tal tratamiento a finales de la decada de 1930 era la mecanica cuantica. de hecho, en ese momento, la mecanica cuantica se encontraba en una condicion de crisis de fundamentos, similar a la que paso la teoria de conjuntos a comienzos de siglo, enfrentando problemas tanto de naturaleza filosofica como tecnica. por otra parte, su aparente indeterminismo no habia sido reducido a una explicacion de forma determinista, como albert einstein creia que debia ser a fin de que la teoria se hiciera satisfactoria y completa. ademas, todavia existian dos formulaciones heuristicas distintas, pero equivalentes: la supuesta mecanica matricial de werner heisenberg y la mecanica ondulatoria de erwin schrodinger, pero todavia no habia una formulacion teorica unificada satisfactoria.  despues de haber completado la axiomatizacion de la teoria de conjuntos, von neumann empezo a enfrentarse a la axiomatizacion de la mecanica cuantica. inmediatamente, en 1926, comprendio que un sistema cuantico podria  considerarse como un punto en un llamado espacio de hilbert, analogo al espacio de fase 6n dimensional (n es el numero de particulas, 3 coordenadas generales y 3 momentos canonicos para cada una) de la mecanica clasica, pero con infinidad de dimensiones (correspondiente a la infinidad de estados posibles del sistema) en su lugar. entonces, las cantidades de la fisica tradicional (es decir, posicion y momento) podrian representarse como operadores lineales particulares operando en esos espacios. por consiguiente, la fisica de la mecanica cuantica se reducia a las matematicas de los operadores lineales hermitianos en los espacios de hilbert. por ejemplo, el famoso principio de incertidumbre de heisenberg, segun el cual la determinacion de la posicion de una particula impide determinar su momento y viceversa, se traslada a la no conmutatividad de los dos operadores correspondientes. esta nueva formulacion matematica incluia, como clases especiales, las formulaciones tanto de heisenberg como de schrodinger y culmino en el clasico de 1932 las fundamentaciones matematicas de la mecanica cuantica. los matematicos consideraron esta aproximacion como extremadamente elegante y satisfactoria. pero, los fisicos, en general, terminaron prefiriendo otra aproximacion diferente, formulada en 1930 por paul dirac y que se basaba en un extraño tipo de funcion (la llamada delta de dirac), severamente criticada por von neumann.  de cualquier forma, el tratamiento abstracto de von neumann tambien le permitio  confrontar el problema extremadamente profundo y fundamental del determinismo contra el no determinismo. en su libro, demostro un teorema segun el cual es imposible que la mecanica cuantica sea derivada por aproximacion estadistica de una teoria determinista del mismo tipo que la utilizada en mecanica clasica. esta demostracion contenia un error conceptual, pero ayudo a inaugurar una linea de investigaciones que, gracias al trabajo de john stuart bell en 1964 sobre el teorema de bell y los experimentos de alain aspect en 1982, finalmente demostraron que la fisica cuantica, en definitiva, requiere una nocion de la realidad sustancialmente diferente de la manejada en la fisica clasica.  en un trabajo complementario de 1936, von neumann demostro, junto con garret birkhoff, que la mecanica cuantica tambien requiere una logica sustancialmente diferente de la logica clasica. por ejemplo, la luz (los fotones) no puede pasar a traves de dos filtros sucesivos que esten polarizados perpendicularmente (por ejemplo, uno horizontal y el otro vertical). por eso, a fortiori, la luz no puede pasar si un tercer filtro, polarizado diagonalmente, se agrega a los otros dos, ya sea antes o despues de ellos en la sucesion. pero si el tercer filtro se coloca entre los otros dos, los fotones si pasaran. esta observacion experimental se traduce, en terminos logicos, como la no conmutatividad de la conjuncion, es decir:   ( a ∧ b ) = ( b ∧ a )  tambien se demostro que las leyes de distribucion de la logica clasica,   p ∨ ( q ∧ r ) = ( p ∨ q ) ∧ ( p ∨ r )  y   p ∧ ( q ∨ r ) = ( p ∧ q ) ∨ ( p ∧ r )  no son validas para la teoria cuantica. esto se debe a que una disyuncion cuantica, diferente al caso de la disyuncion clasica, puede ser verdadera incluso cuando ambos disyuntos son falsos y esto puede atribuirse, a su vez, al hecho de que es frecuente que ocurra, en mecanica cuantica, que un par de alternativas sean semanticamente determinadas, mientras cada uno de sus miembros son necesariamente indeterminados. esta ultima propiedad puede ilustrarse con un simple ejemplo. supongase que se esta tratando con particulas (como electrones) de espin (momento angular) semientero, por lo que solo hay dos posibles valores: positivo o negativo. entonces, el principio de indeterminacion establece que el espin, relativo a dos direcciones diferentes (por ejemplo, x e y) da como resultado un par de cantidades incompatibles. supongase que el estado φ de cierto electron verifica la proposicion «el espin del electron x es positivo». por el principio de indeterminacion, el valor del espin en la direccion y sera completamente indeterminado para φ. entonces, φ no puede verificar ni la proposicion «el espin en la direccion de y es positivo» ni la proposicion «el espin en la direccion de y es negativo». sin embargo, la disyuncion de la proposicion «el espin en la direccion y es positivo o negativo» debe ser verdadera para φ. en el caso de la distribucion es, por lo tanto, posible tener una situacion en la cual   a ∧ ( b ∨ c ) = a ∧ 1 = a ,  mientras   ( a ∧ b ) ∨ ( a ∧ c ) = 0 ∨ 0 = 0 .  hasta la decada de 1930, la economia parecia involucrar el uso de una gran cantidad de matematicas y numeros, pero casi todo era superficial o irrelevante. la economia se utilizaba, sobre todo, para proveer, inutilmente, formulaciones precisas y soluciones a problemas que de hecho eran intrinsecamente vagos. la economia se encontraba en un estado similar al de la fisica del siglo xii: esperaba todavia el desarrollo de un lenguaje apropiado a traves del cual expresarse y resolver sus problemas[cita requerida] . mientras la fisica, por supuesto, habia encontrado su lenguaje en el calculo infinitesimal, von neumann propuso el lenguaje de la teoria de juegos y la teoria del equilibrio general para la economia.  su primera contribucion significativa fue el teorema minimax de 1928. este teorema establece que en ciertos juegos de suma cero, que involucran informacion perfecta (esto es, cada jugador conoce de antemano la estrategia de su oponente y sus consecuencias), existe una estrategia que permite a ambos jugadores minimizar su maxima perdida (de ahi el nombre «minimax»). en particular, cuando se examina cada posible estrategia, un jugador debe considerar todas las respuestas posibles del jugador adversario y la perdida maxima que puede acarrear. el jugador juega, entonces, con la estrategia que da como resultado la minimizacion de su maxima perdida. tal estrategia se llama optima para ambos jugadores solo en caso de que sus minimaxes sean iguales (en valor absoluto) y contrarios (en signo). si el valor comun es cero, el juego se convierte en un sinsentido.  von neumann finalmente perfecciono y extendio el teorema minimax para incluir juegos que involucran informacion imperfecta y juegos de mas de dos jugadores. este trabajo culmino en el clasico de 1944 theory of games and economic behavior (teoria de juegos y comportamiento economico), escrito con oskar morgenstern.  la segunda contribucion importante de von neumann en esta area fue la solucion, en 1937, a un problema descrito por leon walras en 1874: la existencia de situaciones de equilibrio en modelos matematicos de desarrollo del mercado basado en oferta y demanda. primero reconocio que tal modelo tendria que expresarse por medio de inecuaciones y no de ecuaciones (como solia hacerse), y entonces encontro la solucion al problema de walras aplicando un teorema de punto fijo derivado del trabajo de luitzen brouwer. la importancia perdurable del trabajo en equilibrio general y la metodologia de los teoremas de punto fijo es resaltada por la concesion del premio nobel, en 1972, a kenneth arrow y, en 1983, a gerard debreu.  von neumann (junto con morgenstern, en su libro de 1944) fue el primero en emplear el metodo de prueba, utilizado en teoria de juegos, conocido como induccion hacia atras (backward induction).​  en 1937, habiendo obtenido recientemente su ciudadania estadounidense, von neumann empezo a interesarse en problemas de matematica aplicada. se convirtio rapidamente en uno de los mas grandes expertos en materia de explosivos y se comprometio con un gran numero de consultorias militares, principalmente para la marina de estados unidos. en 1942 desarrollo una teoria sobre el proceso de detonacion. un resultado notable en el campo de explosiones fue el descubrimiento de que las bombas de grandes dimensiones son mas devastadoras si se detonan antes de tocar el suelo, por la fuerza adicional causada por las ondas de detonacion (los medios mantuvieron, simplemente, que von neumann habia descubierto que es mejor perder un objetivo que acertarlo). lo cual era lo opuesto al empleo operacional de las bombas mas potentes utilizadas en ese momento, las bombas terremoto, que se incrustaban en el suelo antes de explotar. las mas famosas (o infames) aplicaciones de este descubrimiento ocurrieron el 6 y 9 de agosto de 1945, cuando dos proyectiles nucleares fueron detonados sobre hiroshima y nagasaki, a la altitud precisa, calculada por el mismo von neumann, con el objetivo de que produjeran el mayor daño posible.  von neumann se incorporo al proyecto manhattan y su principal contribucion fue el concepto y el diseño de los explosivos de contacto necesarios para comprimir el nucleo de plutonio de la primera detonacion nuclear de la historia, la prueba trinity, y de la bomba fat man lanzada sobre nagasaki.  desde un punto de vista politico, von neumann era un miembro del comite cuyo trabajo era seleccionar «objetivos» potenciales. la primera eleccion de von neumann, la ciudad de kioto, fue rechazada por el secretario de la guerra henry stimson.  despues de la guerra, robert oppenheimer habia hecho notar que los fisicos «habian conocido el pecado» como resultado del desarrollo de las primeras bombas atomicas. la respuesta de von neumann, algo cinica, fue que «algunas veces alguien confiesa un pecado con el fin de darse el credito por el». en cualquier caso, continuo imperturbable en su trabajo, y finalmente se convirtio, junto con edward teller, en uno de los mas convencidos defensores del proyecto de construccion de la bomba de hidrogeno. von neumann habia colaborado con el espia klaus fuchs en el desarrollo de la bomba de hidrogeno y los dos archivaron una patente secreta sobre «mejora en metodos y medios para la utilizacion de energia nuclear» en 1946, la cual esbozaba un esquema para el uso de la explosion de una bomba de fision que produjera la compresion de combustible de fusion necesaria para poder iniciar una reaccion termonuclear. aunque el metodo escogido para el diseño final de la bomba de hidrogeno fue el de teller y ulam, se reconocio posteriormente que fue un paso en la direccion correcta hacia el logro de este.  el trabajo de von neumann en la bomba de hidrogeno se encontraba tambien en el dominio de la computacion, donde el y stanislaw ulam desarrollaron simulaciones computacionales en las nuevas calculadoras digitales de von neumann para los computos hidrodinamicos necesarios. durante este tiempo contribuyo a desarrollar el metodo de montecarlo, el cual permitia la aproximacion de problemas muy complicados a traves del uso de numeros aleatorios. como utilizar listas de «verdaderos» numeros aleatorios era demasiado lento para el eniac, von neumann elaboro una forma tosca de generar numeros pseudoaleatorios, utilizando el metodo middle-square ('metodo del centro del cuadrado'). aunque se ha demostrado que este metodo no es fiable, von neumann era consciente de eso en aquel entonces: lo justifico por ser mas rapido, en terminos de tiempo computacional, que cualquier otro metodo a su disposicion en ese momento, y tambien hizo notar que cuando aquel fallaba lo hacia de manera muy obvia, no como otros metodos que podian ser sutilmente incorrectos.   en 1952 la primera bomba de hidrogeno, ivy mike, fue detonada en el atolon de enewetak.  von neumann le dio su nombre a la arquitectura de von neumann, utilizada en casi todos los computadores, por su publicacion del concepto; aunque muchos piensan que este nombramiento ignora la contribucion de j. presper eckert y john william mauchly, quienes contribuyeron al concepto durante su trabajo en eniac.​ virtualmente, cada computador personal, microcomputador, minicomputador y supercomputador es una maquina de von neumann. tambien creo el campo de los automatas celulares sin computadores, construyendo los primeros ejemplos de automatas autorreplicables con lapiz y papel. el concepto de constructor universal fue presentado en su trabajo postumo teoria de los automatas autorreproductivos. el termino «maquina de von neumann» se refiere alternativamente a las maquinas autorreplicativas. von neumann probo que el camino mas efectivo para las operaciones mineras a gran escala, como minar una luna entera o un cinturon de asteroides, es a traves del uso de maquinas autorreplicativas, para aprovechar el crecimiento exponencial de tales mecanismos.  ademas de su trabajo en arquitectura computacional, von neumann ofrecio una contribucion al estudio de algoritmos. donald knuth considera a von neumann el inventor, en 1945, del conocido algoritmo merge sort, en el cual la primera y segunda mitad de un array (vector) se clasifican recursivamente por separado y luego se fusionan juntas. otro trabajo notable de von neumman se publico en 1946 con el desarrollo del primer algoritmo generador de numeros pseudoaleatorios conocido como cuadrado medio​. a pesar de las debilidades del algoritmo, influyo a otros grandes investigadores y cientistas en este campo de estudio en la informatica.  tambien participo en la investigacion de problemas en el campo de la hidrodinamica numerica. junto con r. d. richtmyer desarrollo un algoritmo para definir la viscosidad artificial, que probo la esencia para el entendimiento de las ondas de choque. puede decirse que sin ese trabajo no seria posible entender mucho de astronautica y ni siquiera podrian haberse desarrollado los reactores y los motores espaciales. el problema era que cuando los computadores resuelven problemas hidro o aerodinamicos, buscan poner muchos puntos de rejilla (o malla, en ingles grid) computacionales en regiones con onda de choque de discontinuidad aguda. la viscosidad artificial era un truco matematico para suavizar levemente la transicion del choque sin sacrificar la fisica basica.  von neumann desarrollo una carrera academica «relampago» similar a la velocidad de su propio intelecto, y obtuvo a los 29 años una de las primeras cinco plazas docentes en el recien creado instituto de estudios avanzados de princeton (otra fue para albert einstein). el parecia obligado, entonces, a buscar otros campos de interes con el objetivo de satisfacer su ambiciosa personalidad, y lo encontro en su colaboracion con el complejo militar-industrial estadounidense. le consultaban con frecuencia la cia, el ejercito de los estados unidos, la corporacion rand, standard oil, ibm y otros.  durante una audiencia del comite del senado, una vez describio su ideologia politica como \"violentamente anticomunista y mucho mas militarista que la normal\". primero como presidente del conocido comite para misiles de von neumann y luego como miembro de la restringida comision de energia atomica, desde 1953 hasta su muerte en 1957 el era el cientifico con mayor poder politico en estados unidos. a traves de su comite, desarrollo varios escenarios de proliferacion nuclear, misiles submarinos e intercontinentales con cabezas atomicas y el muy controvertido equilibrio estrategico llamado destruccion mutua asegurada (destruccion mutuamente asegurada). en pocas palabras, era la mente diestra de los aspectos cientificos de la guerra fria que condiciono al mundo occidental por cuarenta años.  von neumann siempre vestia un traje de negocios gris de franela, conservador. tambien se sabe que para jugar al tenis iba vestido con su traje de negocios y que le gustaba organizar grandes fiestas en su casa de princeton, en ocasiones hasta dos veces por semana. a pesar de conducir muy mal, le gustaba hacerlo (con frecuencia lo hacia mientras leia un libro), y llego a ocasionar numerosas detenciones y accidentes. en uno de ellos le dijo a la policia: \"yo iba avanzando por el camino. los arboles de la derecha me estaban pasando de manera ordenada a 60 millas por hora. de repente uno de ellos se paro en mi camino\".  john poseia memoria eidetica: \"one of his remarkable abilities was his power of absolute recall. as far as i could tell, von neumann was able on once reading a book or article to quote it back verbatim; moreover, he could do it years later without hesitation\". en una ocasion, stanislaw ulam quiso poner a prueba la memoria de john y le pregunto si recordaba el principio de historia de dos ciudades, a lo que inmediatamente john, sin hacer pausa alguna, respondio recitando el capitulo uno sin parar hasta que ulam se lo pidio.​ ",
        "snippet": "John von Neumann (registrado al nacer como Neumann János Lajos; Budapest, Imperio austrohúngaro, 28 de diciembre de 1903 – Washington D. C., Estados Unidos, 8 de febrero de 1957) fue un matemático húngaro-estadounidense que realizó contribuciones fundamentales en física cuántica, análisis funcional, teoría de conjuntos, teoría de juegos, ciencias de la computación, economía, análisis numérico, cibernética, hidrodinámica, estadística y muchos otros campos.[1]​ Se le considera uno de los matemáticos más importantes del siglo XX.[2]​",
        "enlaces_salientes": [
            "/wiki/John_von_Neumann",
            "/wiki/John_von_Neumann",
            "/wiki/John_von_Neumann",
            "/wiki/Von_Neumann_(desambiguaci%C3%B3n)",
            "/wiki/28_de_diciembre",
            "/wiki/1903",
            "/wiki/Budapest",
            "/wiki/Imperio_austroh%C3%BAngaro",
            "/wiki/8_de_febrero",
            "/wiki/1957",
            "/wiki/Washington_D._C.",
            "/wiki/Estados_Unidos",
            "/wiki/C%C3%A1ncer_de_p%C3%A1ncreas",
            "/wiki/Austroh%C3%BAngara",
            "/wiki/Estadounidense",
            "/wiki/H%C3%BAngara",
            "/wiki/Hungr%C3%ADa",
            "/wiki/Juda%C3%ADsmo",
            "/wiki/Idioma_h%C3%BAngaro",
            "/wiki/Klara_Dan_von_Neumann",
            "/wiki/Universidad_E%C3%B6tv%C3%B6s_Lor%C3%A1nd",
            "/wiki/Escuela_Polit%C3%A9cnica_Federal_de_Z%C3%BArich",
            "/wiki/Universidad_de_Gotinga",
            "/wiki/Lip%C3%B3t_Fej%C3%A9r",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Qu%C3%ADmico",
            "/wiki/F%C3%ADsico",
            "/wiki/Inventor",
            "/wiki/Economista",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/An%C3%A1lisis_funcional",
            "/wiki/Teor%C3%ADa_de_operadores",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/F%C3%ADsica",
            "/wiki/Teor%C3%ADa_de_juegos",
            "/wiki/Aut%C3%B3mata_celular",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Bomba_at%C3%B3mica",
            "/wiki/Ciencias_de_la_informaci%C3%B3n_(tecnolog%C3%ADa)",
            "/wiki/F%C3%ADsica_cu%C3%A1ntica",
            "/wiki/An%C3%A1lisis_funcional",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Teor%C3%ADa_de_juegos",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Econom%C3%ADa",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Hidrodin%C3%A1mica",
            "/wiki/Estad%C3%ADstica",
            "/wiki/American_Mathematical_Society",
            "/wiki/Universidad_de_Hamburgo",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Instituto_de_Estudios_Avanzados_(Princeton)",
            "/wiki/Laboratorio_Nacional_de_Los_%C3%81lamos",
            "/wiki/Proyecto_de_Armas_Especiales_para_las_Fuerzas_Armadas",
            "/wiki/Comisi%C3%B3n_de_Energ%C3%ADa_At%C3%B3mica_de_los_Estados_Unidos",
            "/wiki/Vecindad_de_von_Neumann",
            "/wiki/Arquitectura_de_Von_Neumann",
            "/wiki/%C3%81lgebra_de_von_Neumann",
            "/wiki/Teor%C3%ADa_de_conjuntos_de_Von_Neumann-Bernays-G%C3%B6del",
            "/wiki/Conjetura_de_von_Neumann",
            "/wiki/Entrop%C3%ADa_de_von_Neumann",
            "/wiki/American_Philosophical_Society",
            "/wiki/Real_Academia_de_Artes_y_Ciencias_de_los_Pa%C3%ADses_Bajos",
            "/wiki/Academia_Nacional_de_los_Linces",
            "/wiki/London_Mathematical_Society",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Econometric_Society",
            "/wiki/Budapest",
            "/wiki/Imperio_austroh%C3%BAngaro",
            "/wiki/28_de_diciembre",
            "/wiki/1903",
            "/wiki/Washington_D._C.",
            "/wiki/Estados_Unidos",
            "/wiki/8_de_febrero",
            "/wiki/1957",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Hungr%C3%ADa",
            "/wiki/Estados_Unidos",
            "/wiki/F%C3%ADsica_cu%C3%A1ntica",
            "/wiki/An%C3%A1lisis_funcional",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Teor%C3%ADa_de_juegos",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Econom%C3%ADa",
            "/wiki/An%C3%A1lisis_num%C3%A9rico",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Hidrodin%C3%A1mica",
            "/wiki/Estad%C3%ADstica",
            "/wiki/Budapest",
            "/wiki/Imperio_austroh%C3%BAngaro",
            "/wiki/Pest",
            "/wiki/Hungr%C3%ADa",
            "/wiki/Eugene_Paul_Wigner",
            "/wiki/Primera_Guerra_Mundial",
            "/wiki/B%C3%A9la_Kun",
            "/wiki/Universidad_E%C3%B6tv%C3%B6s_Lor%C3%A1nd",
            "/wiki/Albert_Einstein",
            "/wiki/Le%C3%B3_Szil%C3%A1rd",
            "/wiki/Dennis_Gabor",
            "/wiki/Escuela_Polit%C3%A9cnica_Federal_de_Z%C3%BArich",
            "/wiki/Hermann_Weyl",
            "/wiki/George_P%C3%B3lya",
            "/wiki/David_Hilbert",
            "/wiki/Gotinga",
            "/wiki/Robert_Oppenheimer",
            "/wiki/Princeton_(Nueva_Jersey)",
            "/wiki/Profesor_asociado",
            "/wiki/Gotinga",
            "/wiki/Norbert_Wiener",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Nazismo",
            "/wiki/Institute_for_Advanced_Study",
            "/wiki/Oswald_Veblen",
            "/wiki/Hermann_Weyl",
            "/wiki/Niels_Bohr",
            "/wiki/Copenhague",
            "/wiki/Klara_Dan_von_Neumann",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Proyecto_Manhattan",
            "/wiki/Fabricaci%C3%B3n_de_armas_nucleares#Método_de_implosión",
            "/wiki/Alamogordo",
            "/wiki/Bomba_at%C3%B3mica",
            "/wiki/Nagasaki",
            "/wiki/Leslie_Groves",
            "/wiki/Misil_bal%C3%ADstico_intercontinental",
            "/wiki/Uni%C3%B3n_Sovi%C3%A9tica",
            "/wiki/Ivy_Mike",
            "/wiki/Enewetak",
            "/wiki/Oc%C3%A9ano_Pac%C3%ADfico",
            "/wiki/1952",
            "/wiki/Postguerra_de_la_Segunda_Guerra_Mundial",
            "/wiki/Macarthismo",
            "/wiki/Estrategia_de_las_armas_nucleares",
            "/wiki/Robert_Oppenheimer",
            "/wiki/Guerra_Fr%C3%ADa",
            "/wiki/Comit%C3%A9_de_Actividades_Antiamericanas",
            "/wiki/Edward_Teller",
            "/wiki/1955",
            "/wiki/Senado_de_los_Estados_Unidos",
            "/wiki/Comisi%C3%B3n_de_Energ%C3%ADa_At%C3%B3mica_de_Estados_Unidos",
            "/wiki/Washington_D._C.",
            "/wiki/1956",
            "/wiki/Dwight_D._Eisenhower",
            "/wiki/Premio_Enrico_Fermi",
            "/wiki/Envenenamiento_por_radiaci%C3%B3n",
            "/wiki/Laboratorio_Nacional_de_Los_%C3%81lamos",
            "/wiki/C%C3%A1ncer_de_huesos",
            "/wiki/Iglesia_cat%C3%B3lica",
            "/wiki/8_de_febrero",
            "/wiki/1957",
            "/wiki/Los_elementos",
            "/wiki/Euclides",
            "/wiki/Aritm%C3%A9tica",
            "/wiki/Richard_Dedekind",
            "/wiki/Giuseppe_Peano",
            "/wiki/Geometr%C3%ADa",
            "/wiki/David_Hilbert",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Georg_Cantor",
            "/wiki/Bertrand_Russell",
            "/wiki/Paradoja_de_Russell",
            "/wiki/Teor%C3%ADa_de_N%C3%BAmeros",
            "/wiki/N%C3%BAmero_ordinal_(teor%C3%ADa_de_conjuntos)",
            "/wiki/Ernst_Zermelo",
            "/wiki/Adolf_Fraenkel",
            "/wiki/Axiomas_de_Zermelo-Fraenkel",
            "/wiki/Axioma_de_regularidad",
            "/wiki/Kurt_G%C3%B6del",
            "/wiki/K%C3%B6nigsberg",
            "/wiki/Teoremas_de_incompletitud_de_G%C3%B6del",
            "/wiki/Congreso_Internacional_de_Matem%C3%A1ticos",
            "/wiki/David_Hilbert",
            "/wiki/Problemas_de_Hilbert",
            "/wiki/Sexto_problema_de_Hilbert",
            "/wiki/F%C3%ADsica",
            "/wiki/Mec%C3%A1nica_cu%C3%A1ntica",
            "/wiki/Albert_Einstein",
            "/wiki/Heur%C3%ADstica",
            "/wiki/Mec%C3%A1nica_matricial",
            "/wiki/Werner_Heisenberg",
            "/wiki/Mec%C3%A1nica_ondulatoria",
            "/wiki/Erwin_Schr%C3%B6dinger",
            "/wiki/Espacio_de_Hilbert",
            "/wiki/Operador_lineal",
            "/wiki/Principio_de_incertidumbre",
            "/wiki/Paul_Dirac",
            "/wiki/Delta_de_Dirac",
            "/wiki/Determinismo",
            "/wiki/John_S._Bell",
            "/wiki/Teorema_de_Bell",
            "/wiki/Alain_Aspect",
            "/wiki/F%C3%ADsica_cl%C3%A1sica",
            "/wiki/Garret_Birkhoff",
            "/wiki/Luz",
            "/wiki/Fot%C3%B3n",
            "/wiki/Conmutatividad",
            "/wiki/Esp%C3%ADn",
            "/wiki/Momento_angular",
            "/wiki/Principio_de_indeterminaci%C3%B3n",
            "/wiki/Electr%C3%B3n",
            "/wiki/D%C3%A9cada_de_1930",
            "/wiki/Econom%C3%ADa",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/Teor%C3%ADa_de_juegos",
            "/wiki/Teor%C3%ADa_del_equilibrio_general",
            "/wiki/Minimax",
            "/wiki/Informaci%C3%B3n_perfecta",
            "/wiki/Theory_of_Games_and_Economic_Behavior",
            "/wiki/Oskar_Morgenstern",
            "/wiki/L%C3%A9on_Walras",
            "/wiki/1874",
            "/wiki/Modelo_matem%C3%A1tico",
            "/wiki/Ley_de_la_oferta_y_la_demanda",
            "/wiki/Inecuaci%C3%B3n",
            "/wiki/Teorema_del_punto_fijo_de_Brouwer",
            "/wiki/Luitzen_Egbertus_Jan_Brouwer",
            "/wiki/Premio_Nobel",
            "/wiki/Kenneth_Arrow",
            "/wiki/Gerard_Debreu",
            "/wiki/Inducci%C3%B3n_hacia_atr%C3%A1s",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Explosivos",
            "/wiki/Armada_de_los_Estados_Unidos",
            "/wiki/Modelo_de_detonaci%C3%B3n_de_Zeldovich-von_Neumann-D%C3%B6ring",
            "/wiki/Bomba_terremoto",
            "/wiki/6_de_agosto",
            "/wiki/9_de_agosto",
            "/wiki/1945",
            "/wiki/Hiroshima",
            "/wiki/Nagasaki",
            "/wiki/Proyecto_Manhattan",
            "/wiki/Dise%C3%B1o_de_armas_nucleares",
            "/wiki/Plutonio",
            "/wiki/Prueba_Trinity",
            "/wiki/Fat_Man",
            "/wiki/Kioto",
            "/wiki/Secretario_de_la_Guerra_de_los_Estados_Unidos",
            "/wiki/Henry_Stimson",
            "/wiki/Robert_Oppenheimer",
            "/wiki/Edward_Teller",
            "/wiki/Bomba_de_hidr%C3%B3geno",
            "/wiki/Klaus_Fuchs",
            "/wiki/Patente",
            "/wiki/1946",
            "/wiki/Reacci%C3%B3n_termonuclear",
            "/wiki/Proceso_Teller-Ulam",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Stanislaw_Ulam",
            "/wiki/M%C3%A9todo_de_Montecarlo",
            "/wiki/N%C3%BAmero_aleatorio",
            "/wiki/ENIAC",
            "/wiki/N%C3%BAmero_pseudoaleatorio",
            "/wiki/1952",
            "/wiki/Ivy_Mike",
            "/wiki/Enewetak",
            "/wiki/Laboratorio_Nacional_Los_%C3%81lamos",
            "/wiki/Arquitectura_de_von_Neumann",
            "/wiki/Computadora_electr%C3%B3nica",
            "/wiki/J._Presper_Eckert",
            "/wiki/John_William_Mauchly",
            "/wiki/ENIAC",
            "/wiki/Microcomputador",
            "/wiki/Minicomputador",
            "/wiki/Supercomputador",
            "/wiki/M%C3%A1quina_de_von_Neumann",
            "/wiki/Aut%C3%B3mata_celular",
            "/wiki/Autorreplicaci%C3%B3n",
            "/wiki/M%C3%A1quina_de_von_Neumann",
            "/wiki/Sat%C3%A9lite_natural",
            "/wiki/Cintur%C3%B3n_de_asteroides",
            "/wiki/Crecimiento_exponencial",
            "/wiki/Algoritmos",
            "/wiki/Donald_Knuth",
            "/wiki/Merge_sort",
            "/wiki/Generador_de_n%C3%BAmeros_pseudoaleatorios",
            "/wiki/Hidrodin%C3%A1mica",
            "/wiki/Onda_de_choque",
            "/wiki/Astron%C3%A1utica",
            "/wiki/Motor_de_reacci%C3%B3n",
            "/wiki/Motor_espacial",
            "/wiki/Institute_for_Advanced_Study",
            "/wiki/Princeton_(Nueva_Jersey)",
            "/wiki/Albert_Einstein",
            "/wiki/Complejo_militar-industrial",
            "/wiki/CIA",
            "/wiki/Ej%C3%A9rcito_de_los_Estados_Unidos",
            "/wiki/Corporaci%C3%B3n_RAND",
            "/wiki/Standard_Oil",
            "/wiki/IBM",
            "/wiki/Anticomunista",
            "/wiki/Militarista",
            "/wiki/Comisi%C3%B3n_de_Energ%C3%ADa_At%C3%B3mica_de_los_Estados_Unidos",
            "/wiki/Proliferaci%C3%B3n_nuclear",
            "/wiki/Guerra_fr%C3%ADa",
            "/wiki/Stanislaw_Ulam",
            "/wiki/Historia_de_dos_ciudades_(novela)",
            "/wiki/Premio_de_Teor%C3%ADa_John_von_Neumann",
            "/wiki/Investigaci%C3%B3n_de_operaciones",
            "/wiki/Medalla_John_von_Neumann",
            "/wiki/IEEE",
            "/wiki/Society_for_Industrial_and_Applied_Mathematics",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Von_Neumann_(cr%C3%A1ter)",
            "/wiki/(22824)_von_Neumann",
            "/wiki/Medalla_Presidencial_de_la_Libertad",
            "/wiki/Dwight_Eisenhower",
            "/wiki/Ciencias_sociales",
            "/wiki/4_de_mayo",
            "/wiki/2005",
            "/wiki/Servicio_Postal_de_los_Estados_Unidos",
            "/wiki/Estampilla",
            "/wiki/Barbara_McClintock",
            "/wiki/Josiah_Willard_Gibbs",
            "/wiki/Richard_Feynman",
            "/wiki/ADIVAC",
            "/wiki/Arquitectura_de_von_Neumann",
            "/wiki/Arquitectura_de_computadores",
            "/wiki/Conjetura_de_von_Neumann",
            "/wiki/Lenguajes_de_programaci%C3%B3n_Von_Neumann",
            "/wiki/Alan_Turing",
            "/wiki/The_New_York_Times",
            "/wiki/OCLC",
            "/wiki/American_Mathematical_Society",
            "/wiki/ISBN",
            "/wiki/Herman_Goldstine",
            "/wiki/Princeton_University_Press",
            "/wiki/MIT_Press",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Jes%C3%BAs_Moster%C3%ADn",
            "/wiki/ISBN",
            "/wiki/Internet_Archive",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Library_of_Congress",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Real_Academia_de_Artes_y_Ciencias_de_los_Pa%C3%ADses_Bajos",
            "/wiki/Biografisch_Portaal",
            "/wiki/Open_Library",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Internet_Movie_Database"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Joseph-Marie_Jacquard",
        "titulo": "Joseph Marie Jacquard",
        "contenido": "joseph marie charles (lyon, 7 de julio de 1752 - oullins, 7 de agosto de 1834), conocido como joseph marie jacquard, fue un tejedor y comerciante frances, conocido por crear el primer telar programable con tarjetas perforadas (tambien invencion suya), el telar de jacquard.  el apellido de la familia de joseph marie charles era \"jacquard\". en la generacion de su abuelo, varias ramas de la familia charles vivian en el barrio de lyon, couzon-au-mont d'or. para distinguir las distintas ramas, la comunidad les dio distintos apodos, y esta recibio el de \"jacquard\". por lo tanto, el abuelo de joseph era bartolome charles (llamado) jacquard.​​  joseph marie charles jacquard nacio en una familia catolica conservadora el 7 de julio de 1752. fue uno de los nueve hijos de jean charles jacquard, un maestro tejedor de lyon, y su esposa, antoinette rive. sin embargo, solo jose y su hermana clemenceau (nacida el 7 de noviembre de 1747) sobrevivieron hasta la edad adulta. aunque su padre era un hombre de propiedad, joseph no recibio educacion formal y permanecio analfabeto hasta que tenia 13 años. finalmente fue instruido por su cuñado, jean-marie barrett, quien dirigia un negocio de impresion y venta de libros. barrett tambien presento a joseph a las sociedades y academicos.​ al principio, joseph ayudo a su padre a operar su telar, pero el trabajo resulto ser demasiado arduo, por lo que jacquard se coloco primero con un encuadernador y luego con un fabricante de impresoras.​  su madre murio en 1762, y cuando su padre murio en 1772, joseph heredo la casa, los telares y el taller de su padre, asi como un viñedo y una cantera en couzon-au-mont d'or. en 1778, enumero sus ocupaciones como maestro tejedor y comerciante de seda.​ la profesion de jacquard en este momento es problematica porque en 1780, la mayoria de los tejedores de seda no trabajaban de manera independiente, sino que trabajaban para los salarios de los comerciantes de seda, y jacquard no estaba registrado como un comerciante de seda en lyon.​  existe cierta confusion sobre la historia del inicio temprano en el trabajo de jacquard. el economista britanico sir john bowring conocio a jacquard, quien le conto a bowring que antes habia sido fabricante de sombreros de paja.​ eymard afirmo que antes de involucrarse en el tejido de la seda, jacquard era un tipografo​ (en el sentido de ser fabricante de tipos de letras individuales para imprentas), un soldado, un blanqueador de sombreros de paja y un quemador de cal (un fabricante de cal para mortero).​ barlow afirma que antes de casarse, jacquard habia trabajado para un encuadernador, un tipografo​ y un fabricante de cubiertos. despues de casarse, jacquard intento la fabricacion de cubiertos y la creacion de tejidos.​ sin embargo, barlow no cita ninguna fuente para esa informacion.  el 26 de julio de 1778, joseph se caso con claudine boichon. ella era una viuda de clase media de lyon que poseia propiedades y tenia una dote considerable. sin embargo, jose pronto se endeudo profundamente y fue llevado ante los tribunales. barlow afirma que despues de que el padre de jacquard muriera, jacquard comenzo un negocio de tejido de figuras, pero fallo y perdio toda su riqueza.​ para saldar sus deudas, se vio obligado a vender su herencia y apropiarse de la dote de su esposa. afortunadamente, su esposa mantuvo una casa en oullins (en el lado sur de lyon, a lo largo del rio rodano), donde residia la pareja. el 19 de abril de 1779, la pareja tuvo su unico hijo, jean marie.​ charles ballot declaro que despues de que se reprimiera la rebelion de lyon en 1793, jose y su hijo escaparon de la ciudad al unirse al ejercito revolucionario. lucharon juntos en la campaña del rin de 1795, sirviendo en el batallon de rodano y loira al mando del general jean charles pichegru. el hijo de jose fue asesinado a las afueras de heidelberg.  en 1800, joseph comenzo a inventar diversos dispositivos. invento un telar de pedal en 1800, un telar para tejer redes de pesca en 1803 y, a partir de 1804, el telar \"jacquard\", que tejeria seda estampada automaticamente. pero ninguno de estos primeros inventos funcionaron bien, por lo que no tuvieron exito.​  en 1801, jacquard exhibio su invencion en la exposicion de productos de la industria francesa en paris, donde fue galardonado con una medalla de bronce.​ en 1803 fue convocado a paris,y adscrito al conservatoire des arts et metiers. el telar fue declarado propiedad publica en 1805, y jacquard fue recompensado con una pension y una regalia en cada maquina. a pesar de ello, los tejedores de seda rechazaron ferozmente su invencion, quienes temian su introduccion debido al ahorro de mano de obra. de todas formas, sus ventajas garantizaron su adopcion general, y hacia 1812 habia 11.000 telares jacquard en uso en francia. este reclamo ha sido cuestionado: inicialmente se vendieron pocos telares jacquard debido a problemas con el mecanismo de la tarjeta perforada. solo despues de 1815, una vez que jean antoine breton resolvio los problemas con el mecanismo de la tarjeta perforada, aumentaron las ventas de telares.​​​  jacquard murio en oullins (rodano), el 7 de agosto de 1834.​ seis años despues, se le erigio una estatua en lyon, en el sitio donde se destruyo su telar de exhibicion en 1801.  en 1801 jacquard invento su famoso telar gobernado por un sistema de tarjetas perforadas, lo presento en una exhibicion industrial de lyon en 1805. la invencion se basaba en los instrumentos diseñados por basile bouchon (1725), jean-baptiste falcon (1728) y jacques vaucanson (1740), todos ellos de nacionalidad francesa. el control se realizaba mediante unas perforaciones en tarjetas o fichas de carton, que permitian el paso de las agujas que movian los hilos, antes del paso de la lanzadera. la secuencia de tarjetas formaba un bucle cerrado para permitir la repeticion del dibujo.​ este sistema permitia que incluso los usuarios mas inexpertos pudieran elaborar complejos diseños.  el telar en si no fue el revolucionario, lo importante y el gran invento fue el sistema de tarjetas perforadas, que permitian el movimiento independiente de los hilos a traves de unos ligamentos insertados en diferentes zonas del tejido. cada tarjeta perforada correspondia a una linea del diseño, la suma de todas las tarjetas es lo que creaba el patron. cada perforacion estaba conectada a un gancho (llamado bolus) que se podia colocar en dos posiciones, arriba o abajo. asi que dependiendo de la posicion del bolus, la montura hacia que la trama se desplazara en una de las dos direcciones, de esta manera la secuencia de subidas y bajadas del hilo creaba un patron sobre el tejido escogido. los ganchos se podian conectar con mas de un hilo, de esta manera se repetia el patron mas de una vez. su invento desperto mucho interes en francia, en el 1812 ya se habian vendido 11000 unidades en su pais y 1000 mas en el resto de europa.​  revoluciono radicalmente la industria textil, su sistema permitio que el trabajo de varios hombres lo hiciera solo uno. y esto, claramente, no agrado a todo el mundo. inicialmente sufrio el rechazo de los tejedores, incluso quemaron publicamente uno de sus telares. pero su protesta no sirvio para nada, la revolucion no se podia parar. declararon el telar automatico patrimonio nacional y jacquard recibio la medalla de la legion de honor y un acuerdo donde pactaron el pago de 50 francos al inventor por cada telar vendido.​  el metodo de su telar, se convirtio en el paradigma de la primera maquina computacional, desarrollada por charles babbage. tambien se empleo en multiples equipos y maquinarias, como los pianos mecanicos, conocidos como pianolas y posteriormente en los ordenadores de los años 40 a 60 como soporte para la entrada de datos y programas.​  jacquard murio en oullins, el 7 de agosto de 1834, donde trabajo como corregidor municipal. seis años despues, construyeron en lyon una estatua en su honor, exactamente en el lugar donde un grupo de obreros quemo un modelo de su telar automatico.​ ",
        "snippet": "Joseph Marie Charles (Lyon, 7 de julio de 1752 - Oullins, 7 de agosto de 1834), conocido como Joseph Marie Jacquard, fue un tejedor y comerciante francés, conocido por crear el primer telar programable con tarjetas perforadas (también invención suya), el telar de Jacquard.",
        "enlaces_salientes": [
            "/wiki/Joseph_Marie_Jacquard",
            "/wiki/Joseph_Marie_Jacquard",
            "/wiki/Joseph_Marie_Jacquard",
            "/wiki/Lyon",
            "/wiki/Lyonnais",
            "/wiki/Reino_de_Francia",
            "/wiki/7_de_agosto",
            "/wiki/1834",
            "/wiki/Oullins",
            "/wiki/Monarqu%C3%ADa_de_Julio",
            "/wiki/Francia",
            "/wiki/Inventor",
            "/wiki/Comerciante",
            "/wiki/Ingeniero",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Tarjeta_perforada",
            "/wiki/Caballero_de_la_Legi%C3%B3n_de_Honor",
            "/wiki/Lyon",
            "/wiki/Oullins",
            "/wiki/Francia",
            "/wiki/Tarjeta_perforada",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Lyon",
            "/wiki/Couzon-au-Mont-d%27Or",
            "/wiki/Empresa_dise%C3%B1adora_de_tipos",
            "/wiki/Oullins",
            "/wiki/R%C3%B3dano",
            "/wiki/Jean-Charles_Pichegru",
            "/wiki/Heidelberg",
            "/wiki/Par%C3%ADs",
            "/wiki/Tarjeta_perforada",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Legi%C3%B3n_de_Honor",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Charles_Babbage",
            "/wiki/Oullins",
            "/wiki/Merriam-Webster",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Union_List_of_Artist_Names",
            "/wiki/Deutsche_Biographie",
            "/wiki/Base_L%C3%A9onore",
            "/wiki/Open_Library",
            "/wiki/Rijksbureau_voor_Kunsthistorische_Documentatie",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Babbage",
        "titulo": "Charles Babbage",
        "contenido": "charles babbage fue un matematico y cientifico britanico.​ diseño y desarrollo una calculadora mecanica capaz de calcular tablas de funciones numericas por el metodo de diferencias. tambien diseño, (pero nunca construyo), la analitica para ejecutar programas de tabulacion o computacion; por estos inventos se le considera como una de las primeras personas en concebir la idea de lo que hoy llamariamos una computadora, por lo que se le considera como \"el padre de los ordenadores\".  en el museo de ciencias de londres se exhiben partes de sus mecanismos inconclusos. parte de su cerebro conservado en formol se exhibe en el royal college of surgeons of england. sitio en londres.​  hay un debate sobre la fecha y lugar de nacimiento de babbage. en primer lugar, segun dictionary of national biography seguramente nacio en el numero 48 de crosby row, walworth en londres, inglaterra.​ en relacion con su fecha de nacimiento, the times publico que babbage nacio el 26 de diciembre de 1792 pero un sobrino suyo afirmo que fue un año antes, 1791. el registro de la parroquia st. mary's en newington establece que babbage fue bautizado el 6 de enero de 1792, lo cual puede confirmar que hubiese nacido un año antes.​​​  babbage fue el cuarto hijo de betsy plumleigh teape y benjamin babbage (socio banquero del empresario william praed en fundar praed9s & co.)​  cuando babbage tenia 8 años fue enviado a una escuela de dia en alpington para recuperarse de una  peligrosa fiebre. durante un tiempo pudo atender a la escuela de enrique vi en totnes, pero su salud le obligo a seguir recibiendo clase de los tutores privados durante un tiempo.​  fue despues de esto cuando babbage comenzo a acudir a una academia en enfield (londres), donde las clases se impartian por el reverendo stephen freeman. la biblioteca de esta academia incentivo la pasion de babbage por las matematicas. antes de dejar esta academia estudio en dos escuelas privadas, la primera se impartia por un clerigo cerca de cambridge, a traves de la cual conocio al evangelico ingles charles simeon, pero no eran tutorias lo que charles necesitaba. la segunda escuela era un tutor de oxford, gracias al cual babbage adquirio el nivel suficiente para ser admitido en cambridge.​ fue entonces cuando le trajeron de vuelta a casa para estudiar en una escuela a la edad de 16 o 17.​  en octubre de 1810 babbage llego a trinity college (cambridge), habiendose formado de forma autodidacta en matematicas contemporaneas​ (a partir de las lecturas de robert woodhouse, joseph-louis lagrange y maria gaetana agnesi). consecuentemente se llevo una gran decepcion con la forma de impartir las matematicas de la universidad.  en 1812, junto con john herschel, george peacock y otros amigos, formaron la analytical society  paralelamente babbage fue miembro de otras asociaciones como the ghost club, asociacion de investigacion de fenomenos paranormales y the extractors club , centrado en la liberacion de los miembros del manicomio, en caso de que alguna vez sucediese.​  en ese mismo año babbage fue enviado a peterhouse, cambridge, donde se encontraba en la elite de las matematicas pero no se graduo con notas elevadas sino que recibio en cambio el titulo sin tener que examinarse en 1814. defendio una tesis que se considero \"blasfemia\" en la disputa publica, no obstante no se sabe si esto estuvo relacionado con el hecho de no llevar a cabo un examen.​  dada su reputacion, babbage consiguio progresar rapidamente. impartio clases de astronomia en el royal institution en 1815 y fue elegido miembro de la royal society en 1816.​ sin embargo, al presentarse a las oposiciones tras su graduacion no fue aceptado. en 1816 fue candidato para ser profesor en haileybury college, con cartas de recomendacion de james ivory y john playfair, pero fue  henry walter bates el que se llevo el puesto.​ junto con herschel visitaron paris y la sociedad de arcueil en 1819, conociendo en este viaje a los principales matematicos y fisicos franceses.​ ese mismo año aplico a la universidad de edimburgo recomendado por pierre-simon laplace, perdiendo de nuevo el puesto por william wallace, matematico y astronomo escoces.​​  babbage compro las tablas actuariales de george barrett, actuario britanico, el cual murio en 1821 dejando trabajos sin publicar y estudio el campo en 1836 en \"la vision comparativa de varias instituciones de seguros de vida\" (comparative view of the various institutions for the assurance of lives). el interes por este proyecto fue continuado por la idea de crear una compañia de seguros, promovida por francis baily debatida en 1824 pero nunca llevada a cabo. no obstante, babbage si llego a calcular las tablas actuariales para esa idea utilizando la mortalidad de la sociedad a partir del año 1792.​  el y edward ryan se casaron con las hermanas whitmore, babbage en el año 1814. se construyo una casa en marylebone, londres y formo una gran familia. durante todos estos años fue su padre quien mantenia sus proyectos siempre con cierta reticencia dada su precocidad a la hora de contraer matrimonio.​  en 1827 su padre murio, lo cual le permitio heredar alrededor de £100.000 de aquel entonces, convirtiendole en una persona independiente y rica.​ ese mismo año su mujer fallecio y babbage decidio emprender un viaje de un año de duracion. en ese viaje conocio a leopoldo ii de toscana en italia, programando un futuro encuentro en piedmont. en ese viaje recibio la noticia de que habia sido aceptado para la vacante de profesor en cambridge, puesto que le habia sido negado en tres ocasiones distintas.  babbage intento encontrar un metodo por el cual se pudieran hacer calculos automaticamente por una maquina, eliminando errores debidos a la fatiga o  aburrimiento que sufrian las personas encargadas de compilar las tablas matematicas de la epoca. esta idea la tuvo en 1812. tres factores parecieron haberlo motivado: una aversion al desorden, su conocimiento de tablas logaritmicas, y los trabajos de maquinas calculadoras realizadas por blaise pascal y gottfried leibniz. en 1822, en una carta dirigida a sir humphry davy en la aplicacion de maquinaria al calculo e impresion de tablas matematicas, discutio los principios de una maquina calculadora. ademas diseño un plano de computadoras.  entre 1833 y 1842 intento construir una maquina que fuese programable para hacer cualquier tipo de calculo, no solo los referentes al calculo de tablas logaritmicas o funciones polinomicas. esta fue la maquina analitica. el diseño se basaba en el telar de joseph marie jacquard, el cual usaba tarjetas perforadas para realizar diseños en el tejido. babbage adapto su diseño para conseguir calcular funciones analiticas. la maquina analitica tenia dispositivos de entrada basados en las tarjetas perforadas de jacquard, un procesador aritmetico, que calculaba numeros, una unidad de control que determinaba que tarea debia ser realizada, un mecanismo de salida y una memoria donde los numeros podian ser almacenados hasta ser procesados. se considera que la maquina analitica de babbage fue la primera computadora de la historia. en 1835 termino el diseño inicial completamente funcional. sin embargo, debido a problemas similares a los de la maquina diferencial, la maquina analitica nunca fue terminada por charles. en 1842, para obtener la financiacion necesaria para realizar su proyecto, babbage contacto con sir robert peel. peel lo rechazo, y ofrecio a babbage un titulo de caballero que fue rechazado por babbage. lady ada lovelace, matematica e hija de lord byron, se entero de los esfuerzos de babbage y se intereso en su maquina. promovio activamente la maquina analitica, y escribio varios programas para la maquina analitica. algunos historiadores afirman que esas instrucciones hacen de ada lovelace la primera programadora de computadoras de la historia.  charles babbage ha sido considerado por algunos como el padre de las computadoras modernas, pero sin duda tambien puede ser considerado el padre de las impresoras modernas. mas de 150 años despues de sus planos y un trabajo minucioso del museo de ciencias de londres, dieron como resultado la construccion de la maquina analitica. los planos del matematico y cientifico incluian un componente de impresion, el cual ha sido reconstruido por el museo y es funcional. esta impresora consta de 8000 piezas mecanicas y pesa aproximadamente 2,5 toneladas.  fue tan innovadora para su epoca y podemos apreciarlo hoy, que es capaz de imprimir automaticamente los resultados de un calculo y un usuario puede cambiar parametros como espacio entre lineas, elegir entre dos tipografias, numero de columnas y otros. su sofisticacion llega a tal punto que puede generar (fabricar) los moldes de las impresiones que podrian ser usados por las imprentas aun hoy en dia. esta impresora lamentablemente no lleva un nombre ya que babbage la incluyo en sus planos de la maquina analitica, pero basta con aludir a ella como la impresora de babbage para reconocer en este hombre un visionario.  babbage es recordado tambien por otros logros. la promocion del calculo infinitesimal es quizas la primera entre ellas. en 1812, babbage funda la sociedad analitica. la tarea primordial de esta sociedad, conducida por el estudiante robert woodhouse, era promover el calculo leibniziano, o calculo analitico, sobre el estilo de calculo newtoniano. el calculo de newton era torpe y aproximado, y era usado mas por razones politicas que practicas. la sociedad analitica incluia a sir john herschel y george peacock entre sus miembros. en los años 1815-1817 contribuyo en el «calculo de funciones» de las philosophical transactions -transacciones filosoficas-, y en 1816 fue hecho miembro de la royal academy  charles babbage tambien logro resultados notables en criptografia. rompio la cifra auto llave de vigenere,​ asi como la cifra mucho mas debil que se llama cifrado de vigenere hoy en dia. la cifra del auto llave fue llamada «la cifra indescifrable», aunque debido a la confusion popular muchos pensaron que la cifra apolialfabetica mas debil era indescifrable. el descubrimiento de babbage fue usado en campañas militares inglesas, y era considerado un secreto militar. como resultado, el merito por haber descifrado esta clave le fue otorgado a friedrich kasiski, quien descifro tambien este sistema criptografico algunos años despues.  publico la obra \"on the economy of machinery and manufactures\" (sobre la economia de la maquinaria y las manufacturas) (1832), sobre la organizacion y el diseño racional de la produccion industrial. el libro tuvo buenas ventas y tuvo incidencia en la investigacion operativa que por entonces era una incipiente disciplina. en ella describio lo que hoy dia se conoce como el principio de babbage ​, enfocado a lograr ventajas comerciales a partir de una mas cuidadosa division del trabajo. en sus propias palabras:  es decir, advirtio que los trabajadores cualificados suelen pasar parte de su tiempo realizando tareas que estan por debajo de sus valiosas competencias especificas. si estas tareas se dividen eficientemente entre varios trabajadores, los costos de la mano de obra pueden reducirse de forma notable asignando solo tareas de alta cualificacion a los trabajadores mejor pagados, y restringiendo otras tareas a los trabajadores con menor remuneracion. esto no mejoraria por si mismo la productividad de los trabajadores, pero si su rentabilidad.​  de 1828 a 1839 babbage fue profesor de matematicas en cambridge. escribio articulos en distintas revistas cientificas, y era miembro activo de la astronomical society —sociedad astronomica— en 1820 y de la statistical society —sociedad estadistica— en 1834. durante los ultimos años de su vida residio en londres, dedicandose a la construccion de maquinas capaces de la ejecucion de operaciones aritmeticas y calculos algebraicos.  propuso el sistema de franqueo postal que utilizamos hoy en dia. hasta entonces el coste de enviar una carta dependia de la distancia que tenia que viajar; babbage advirtio que el coste del trabajo requerido para calcular el precio de cada carta superaba el coste del franqueo de esta y propuso un unico coste para cada carta con independencia del sitio del pais al que era enviada.  fue el primero en señalar que la anchura del anillo de un arbol dependia de la meteorologia que habia hecho ese año, por lo que seria posible deducir climas pasados estudiando arboles antiguos.  invento el apartavacas, un aparato que se sujetaba a la parte delantera de las locomotoras de vapor para que las vacas se apartasen de las vias del ferrocarril.​  se intereso tambien por temas politicos y sociales e inicio una campaña para deshacerse de los organilleros y musicos callejeros de londres, aunque estos pasaron al contraataque y se organizaron en torno a su casa tocando lo mas alto que podian.  charles babbage fue un matematico y cientifico de la computacion britanico.​ diseño y desarrollo una calculadora mecanica capaz de calcular tablas de funciones numericas por el metodo de diferencias. nacimiento: 26 de diciembre de 1791, londres, reino unido fallecimiento: 18 de octubre de 1871, marylebone, londres, reino unido. hijos: charles whitmore babbage, dugald bromhead, mas .educacion: peterhouse (1812–1814), trinity college (1810–1812) padres: betsy plumleigh teape, benjamin babbage. premio: medalla de oro de la real sociedad astronomica (1824) ",
        "snippet": "Charles Babbage fue un matemático y cientifico britanico.[1]​ Diseñó y desarrolló una calculadora mecánica capaz de calcular tablas de funciones numéricas por el método de diferencias. También diseñó, (pero nunca construyó), la analítica para ejecutar programas de tabulación o computación; por estos inventos se le considera como una de las primeras personas en concebir la idea de lo que hoy llamaríamos una computadora, por lo que se le considera como \"El padre de los ordenadores\". En el Museo de Ciencias de Londres se exhiben partes de sus mecanismos inconclusos. Parte de su cerebro conservado en formol se exhibe en el Royal College of Surgeons of England. Sitio en Londres.[2]​",
        "enlaces_salientes": [
            "/wiki/Charles_Babbage",
            "/wiki/Charles_Babbage",
            "/wiki/Charles_Babbage",
            "/wiki/Londres",
            "/wiki/Reino_de_Gran_Breta%C3%B1a",
            "/wiki/Walworth",
            "/wiki/Reino_Unido",
            "/wiki/Marylebone",
            "/wiki/Insuficiencia_renal",
            "/wiki/Reino_Unido_de_Gran_Breta%C3%B1a_e_Irlanda",
            "/wiki/Cristianismo",
            "/wiki/Peterhouse",
            "/wiki/Trinity_College_(Cambridge)",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Inventor",
            "/wiki/Economista",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Ingeniero",
            "/wiki/Astr%C3%B3nomo",
            "/wiki/Escritor",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Filosof%C3%ADa_anal%C3%ADtica",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Profesor_Lucasiano",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Royal_Society",
            "/wiki/Academia_de_Ciencias_de_Baviera",
            "/wiki/Academia_H%C3%BAngara_de_Ciencias",
            "/wiki/Royal_Society_of_Edinburgh",
            "/wiki/Real_Sociedad_Astron%C3%B3mica",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Royal_Statistical_Society",
            "/wiki/Academia_de_Ciencias_de_Tur%C3%ADn",
            "/wiki/Miembro_de_la_Royal_Society",
            "/wiki/Medalla_de_oro_de_la_Real_Sociedad_Astron%C3%B3mica",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Cientifico",
            "/wiki/Britanico",
            "/wiki/Calculadora_mec%C3%A1nica",
            "/wiki/Tabulaci%C3%B3n",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Computadora",
            "/wiki/Museo_de_Ciencias_de_Londres",
            "/wiki/Formol",
            "/wiki/Londres",
            "/wiki/Dictionary_of_National_Biography",
            "/wiki/Walworth",
            "/wiki/Londres",
            "/wiki/Inglaterra",
            "/wiki/The_Times",
            "/wiki/St._Mary%27s",
            "/wiki/Alpington",
            "/wiki/Totnes",
            "/wiki/Enfield_(Londres)",
            "/wiki/Cambridge",
            "/wiki/Trinity_College_(Cambridge)",
            "/wiki/Robert_Woodhouse",
            "/wiki/Joseph-Louis_Lagrange",
            "/wiki/Maria_Gaetana_Agnesi",
            "/wiki/John_Herschel",
            "/wiki/George_Peacock",
            "/wiki/The_Ghost_Club",
            "/wiki/Peterhouse",
            "/wiki/Royal_Institution",
            "/wiki/Miembro_de_la_Royal_Society",
            "/wiki/John_Playfair",
            "/wiki/Henry_Walter_Bates",
            "/wiki/Sociedad_de_Arcueil",
            "/wiki/Universidad_de_Edimburgo",
            "/wiki/Pierre-Simon_Laplace",
            "/wiki/Francis_Baily",
            "/wiki/Marylebone",
            "/wiki/Londres",
            "/wiki/Leopoldo_II_de_Toscana",
            "/wiki/1812",
            "/wiki/Blaise_Pascal",
            "/wiki/Gottfried_Leibniz",
            "/wiki/1822",
            "/wiki/Humphry_Davy",
            "/wiki/Calculadora",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/1833",
            "/wiki/1842",
            "/wiki/Joseph_Marie_Jacquard",
            "/wiki/1835",
            "/wiki/Anal%C3%ADtica",
            "/wiki/1842",
            "/wiki/Robert_Peel",
            "/wiki/Ada_Lovelace",
            "/wiki/Lord_Byron",
            "/wiki/Computadora",
            "/wiki/Impresora",
            "/wiki/Museo_de_Ciencias_de_Londres",
            "/wiki/Impresora",
            "/wiki/C%C3%A1lculo",
            "/wiki/Usuario",
            "/wiki/Tipograf%C3%ADa",
            "/wiki/Imprenta",
            "/wiki/Impresora",
            "/wiki/C%C3%A1lculo_infinitesimal",
            "/wiki/1812",
            "/wiki/Robert_Woodhouse",
            "/wiki/John_Herschel",
            "/wiki/George_Peacock",
            "/wiki/1815",
            "/wiki/1817",
            "/wiki/1816",
            "/wiki/Royal_Academy",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Cifrado_de_Vigen%C3%A8re",
            "/wiki/Friedrich_Kasiski",
            "/wiki/1828",
            "/wiki/1839",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Real_Sociedad_Astron%C3%B3mica",
            "/wiki/1820",
            "/wiki/Royal_Statistical_Society",
            "/wiki/1834",
            "/wiki/Londres",
            "/wiki/Locomotora_de_vapor#Topes_y_apartavacas",
            "/wiki/Organillero",
            "/wiki/Londres",
            "/wiki/Babbage_(cr%C3%A1ter)",
            "/wiki/Asteroide",
            "/wiki/(11341)_Babbage",
            "/wiki/M%C3%A1quina_diferencial",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Ada_Lovelace",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Princeton_University_Press",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Biblioteca_Virtual_Miguel_de_Cervantes",
            "/wiki/Proyecto_Gutenberg"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Ada_Lovelace",
        "titulo": "Ada Lovelace",
        "contenido": "augusta ada king, condesa de lovelace (londres, 10 de diciembre de 1815-id., 27 de noviembre de 1852), registrada al nacer como augusta ada byron y conocida habitualmente como ada lovelace, fue una matematica y escritora britanica, celebre sobre todo por su trabajo acerca de la computadora mecanica de uso general de charles babbage, la denominada maquina analitica. fue la primera en reconocer que la maquina tenia aplicaciones mas alla del calculo puro y en haber publicado lo que se reconoce hoy como el primer algoritmo destinado a ser procesado por una maquina, por lo que se le considera como la primera programadora de ordenadores.​​​  lovelace fue la unica hija legitima del poeta lord byron y anna isabella noel byron. byron se separo de su esposa un mes despues del nacimiento de ada y dejo inglaterra para siempre cuatro meses despues. conmemoro la despedida en un poema que comienza: «¿es tu rostro como el de tu madre, mi bella hija? ¡ada! hija unica de mi casa y mi corazon».​ murio en la guerra de independencia de grecia cuando ada tenia ocho años.  dedujo y previo la capacidad de los ordenadores para ir mas alla de los simples calculos de numeros, mientras que otros, incluido el propio babbage, se centraron unicamente en estas capacidades.​  su posicion social y su educacion la llevaron a conocer a cientificos importantes como andrew crosse, sir david brewster, charles wheatstone, michael faraday y al novelista charles dickens, relaciones que aprovecho para llegar mas lejos en su educacion. entre estas relaciones se encuentra mary somerville, que fue su tutora durante un tiempo, ademas de amiga y estimulo intelectual.​ ada byron se referia a si misma como una cientifica poetisa y como analista (y metafisica).​​  a una edad temprana, su talento matematico la condujo a una relacion de amistad prolongada con el matematico ingles charles babbage, y concretamente con la obra de babbage sobre la maquina analitica.​ entre 1842 y 1843, tradujo un articulo del ingeniero militar italiano luigi menabrea sobre la maquina, que complemento con un amplio conjunto de notas propias, denominado simplemente notas. estas notas contienen lo que se considera como el primer programa de ordenador, esto es, un algoritmo codificado para que una maquina lo procese. las notas de lovelace son importantes en la historia de la computacion. otros historiadores rechazan esta perspectiva y señalan que las notas personales de babbage de los años 1836/1837 contienen los primeros programas para el motor.​ tambien desarrollo una vision de la capacidad de las computadoras para ir mas alla del mero calculo o el calculo de numeros, mientras que muchos otros, incluido el propio babbage, se centraron solo en esas capacidades. su mentalidad de 'ciencia poetica' la llevo a hacer preguntas sobre el motor analitico (como se muestra en sus notas) examinando como los individuos y la sociedad se relacionan con la tecnologia como una herramienta de colaboracion.  ada lovelace fue la unica hija legitima de anna isabella y del poeta lord byron,​ quien esperaba que su hijo fuera un niño y se sintio decepcionado cuando su esposa dio a luz a una niña. nacio el domingo 10 de diciembre de 1815. la niña lleva el nombre de la media hermana de byron, augusta leigh, y fue llamada ada por el propio byron. el 16 de enero de 1816, por orden de lord byron, lady byron se fue a la casa de sus padres en kirkby mallory (leicestershire) llevando a su hija de cinco semanas con ella. aunque la ley inglesa en ese momento otorgaba la custodia total de los hijos al padre en casos de separacion, lord byron no intento reclamar sus derechos parentales, pero solicito que su hermana lo mantuviera informado sobre el bienestar de ada. en abril de 1816 su padre abandono inglaterra huyendo de sus acreedores y del escandalo que se cernia sobre el por los rumores de incesto. meses mas tarde, annabella presento una demanda de separacion. durante los ocho años que lord byron estuvo fuera de su pais hasta su muerte escribia con frecuencia a augusta y preguntaba por la hija de ambos. a lovelace no se le mostro el retrato familiar de su padre hasta que cumplio 20 años.  lovelace no tuvo una relacion cercana con su madre. a menudo la dejaban al cuidado de su abuela materna judith, hon. lady milbanke, que la adoraba. sin embargo, debido a las actitudes sociales de la epoca, que favorecian al marido en cualquier separacion, con el bienestar de cualquier niño que actuara como mitigante, lady byron tuvo que presentarse como una madre amorosa para el resto de la sociedad. esto incluia escribir cartas de ansiedad a lady milbanke sobre el bienestar de su hija, con una nota de presentacion que decia que debia retener las cartas en caso de que tuviera que usarlas para mostrar preocupacion materna.  desde niña ada desperto el interes de una sociedad en la que se vivian continuos escandalos. su madre puso mucho empeño en protegerla, pero solo lo consiguio hasta cierto punto.  lady byron queria darle una educacion esmerada a su hija, muy parecida a la que ella misma habia recibido, pero mas exigente.​ ada no se podia relacionar con otros niños sin la previa aprobacion de su madre, por lo que la mayor parte de su infancia la paso sola o con adultos. su educacion empezo cuando era muy pequeña; a los cuatro años ya tenia preceptores e institutrices. a los ocho años (en 1824) la jornada normal de ada comenzaba con clase de musica a las 10:00 de la mañana, a las 11:15 tocaba lectura de frances, a las 11:30 clase de aritmetica, a las 13:30 hacia deberes, a las 15:15 musica otra vez y a las 16:30 finalizaba con ejercicios de frances. lady byron le impuso una disciplina estricta basada en un sistema de recompensas y castigos, y tambien buscando el estimulo intelectual con lecturas y relaciones con intelectuales. puso mucho empeño en que su hija aprendiera matematicas, disciplina que ella misma practicaba. en este contexto, ada conoce a la matematica y cientifica escocesa mary somerville, que durante un tiempo fue su tutora. somerville, en tanto que mujer cientifica, se convierte en un importante estimulo y gran influencia en su vida. ambas, alumna y tutora, comparten aficiones cientificas estableciendose entre ellas una gran complicidad.​  a medida que ada se iba haciendo mayor, su madre pasaba temporadas fuera de casa, en balnearios o en el campo.  tuvo mala salud, sufrio muchas de las infecciones infantiles y le dolia la cabeza frecuentemente. a los siete años contrajo una enfermedad grave, que la mantuvo postrada durante meses. a los catorce mantuvo reposo durante mas de un año debido al sarampion, lo cual hizo que dedicara largas horas al estudio y a la lectura.  cuando ada tenia 8 años se conocio la muerte de su padre en grecia, en abril de 1824. lady byron se intereso por estrechar lazos con su familia politica. el nuevo y sexto lord byron mantuvo una buena relacion con annabella; este tenia un hijo pequeño un año menor que ada. annabella indujo a ada a escribir una carta a su primo con la esperanza de unir de nuevo a la familia.​  en junio de 1826, ada, que entonces tenia diez años, viajo por primera vez fuera de inglaterra. partio con todo un grupo (en el que se incluia su madre) y el viaje duro 15 meses, durante los cuales ada disfruto de todo lo nuevo que veian sus ojos, de todo lo que escuchaba, descubria, etc. en el otoño de 1827 acabo su viaje y se instalaron directamente en bifrons, una mansion de campo muy alejada de la ciudad. en ese palacio no ocurria nada del interes de ada; ademas su madre estaba frecuentemente fuera de casa, asi que la niña se dedicaba a estudiar y a dejar volar su imaginacion. ese mismo año, ada empezo su formacion en matematicas. a los once años estaba obsesionada con la idea de volar; estaba decidida a inventar una maquina que le permitiera moverse por el aire. su primer paso, en febrero de 1828, fue construir alas. investigo diferentes materiales y tamaños. considero varios materiales para las alas: papel, seda de aceite, alambres y plumas. paso años estudiando la anatomia de las aves para determinar la proporcion correcta entre las alas y el cuerpo, y creando bocetos de su soñado proyecto. decidio escribir un libro, flyology, ilustrando, con placas, algunos de sus hallazgos. decidio que equipo necesitaria; por ejemplo, una brujula, para «atravesar el pais por el camino mas directo», para que pueda superar montañas, rios y valles. su ultimo paso fue integrar steam con el «arte de volar»\".  a principios de 1829 contrajo una enfermedad grave, posiblemente sarampion, que le causo paralisis en las piernas y la obligo a guardar cama hasta mediados de 1832. ese periodo la marco profundamente, pero siguio estudiando. el año de su recuperacion se mudo con su madre a fordhook manor, una mansion situada en ealing, una aldea a 12 km del centro de londres, muy popular entre la aristocracia londinense. durante este tiempo ada vivio su primer romance; se enamoro de un joven, hijo de john hamble, que la ayudaba con los estudios dos horas al dia. vivieron su historia de amor en secreto durante algun tiempo, pero, cuando lady byron se entero, prohibio al joven entrar en su casa y relacionarse con su hija.​  el año que cumplia dieciocho años, ada empezo a asistir a las fiestas de la alta sociedad londinense. en uno de sus primeros eventos conocio a charles babbage, la unica persona que compartiria su fascinacion por las cuestiones de mecanica. babbage tenia cuarenta y cuatro años en ese momento y era conocido, entre otras cosas, por el proyecto que tenia entre manos: una calculadora mecanica que funcionaba sin la ayuda de un humano, llamada la maquina diferencial.  en esos tiempos en inglaterra se hizo famoso un avanzado artilugio, el telar de seda de joseph marie jacquard, con el que ella estaba totalmente fascinada. le maravillaba la posibilidad de idear y construir maquinas, como la de jacquard, que permitieran al ser humano controlar procesos que anteriormente eran incontrolables o lo eran de una forma erratica.  ada y babbage se hicieron amigos. su relacion la estimulo intelectualmente; le ayudo a avanzar en sus especulaciones sobre el calculo hasta concebir una brillante idea: construir un telar de jacquard aplicado a los numeros, o en otras palabras: una computadora.  la maquina diferencial de babbage tenia todos los elementos que entusiasmaban a ada, y principalmente demostraba que un dia las maquinas harian posible volar. la amistad entre el cientifico y la joven duro toda su vida; se escribieron cartas hasta la muerte de ella.  en 1834 ada se relacionaba mucho con william king, al que lady byron habia encargado guiar a su hija moralmente; tambien se encargo de enseñarle matematicas. fue durante esas clases cuando ada se dio cuenta de que su pasion eran las matematicas. ya habia encontrado la disciplina a la que aplicar su extraordinaria inteligencia. el verano de ese año, ada y su madre recorrieron el norte de inglaterra, la zona industrial mas importante, visitando muchas fabricas, donde pudieron ver el telar de jacquard en funcionamiento. durante esa epoca, madre e hija se relacionaban mucho con mary somerville, la matematica mas famosa de su pais. otros conocidos incluyeron a los cientificos andrew crosse, sir david brewster , charles wheatstone, michael faraday y el autor charles dickens.  ada ya era una habitual de la corte victoriana y empezaba a asistir a diversos eventos en los que con frecuencia participaba en los bailes y encandilaba a muchos de sus asistentes, los cuales la describian como un ser encantador. sin embargo, john hobhouse, que habia sido amigo de su padre, fue una excepcion y la describio como «una joven estirada y demacrada pero con algun rasgo de su amigo, especialmente su boca». la descripcion fue hecha despues de su encuentro el 24 de febrero de 1834, en el que ada dejo claro a hobhouse que el no le gustaba, pero esta primera impresion no duro mucho tiempo y posteriormente se hicieron amigos.  en la primavera de 1835 ada conocio a william, lord king. el aristocrata era de una familia muy influyente desde el punto de vista politico, social, intelectual y religioso. poseia varias propiedades importantes y el titulo de lord tenia mas de un siglo de antiguedad, asi que lady byron aprobo su relacion. el 8 de julio de 1835 se casaron, convirtiendose ella en lady king. su residencia paso a ser una gran propiedad en ockham park (ockham, surrey), junto con otra en el fiordo de torridon y una mas en londres. paso su luna de miel en la mansion worthy, situada en asley combe (somerset), la cual habia sido construida en 1799 como un refugio de caza y que el propio king amplio con motivo de su luna de miel. posteriormente la casa se convertiria en su retiro de verano tras volver a ser ampliada.  el matrimonio tuvo tres hijos: byron, el heredero, nacido el 12 de mayo de 1836; anne isabella (llamada annabella, posteriormente lady anne blunt), nacida el 22 de septiembre de 1837; y ralph gordon, nacido el 2 de julio de 1839.  inmediatamente despues del nacimiento de annabella, lady king experimento «una dolorosa y prolongada enfermedad que tardo meses en curarse». entre 1843 y 1844 su madre le encargo a william benjamin carpenter la tarea de educar a los hijos de ada y de actuar como un «instructor moral» para su propia hija.  en 1837, william king paso de baron a vizconde de ockham y tomo otro titulo, el de conde de lovelace. a partir de ese momento, ada siempre firmaria como ada lovelace.  en sus primeros años de matrimonio ada fue muy feliz, pero la falta de ambicion de su marido acabo cansandola, por lo que se refugio de nuevo en las matematicas. decidio que necesitaba buscar un buen mentor que la guiara en su trabajo intelectual y en el verano de 1840 su madre le encontro uno: el famoso matematico y logico augustus de morgan. con su ayuda, ada progreso rapidamente, pero de morgan tuvo un problema como profesor. informo a lady byron de que su hija no se contentaba con aprender las lecciones como cualquier dama; sus preguntas iban mucho mas alla de lo que trataban en las clases y el no queria fomentar esa actitud. de morgan creia (como casi toda la sociedad en esos tiempos) que las mujeres no estaban hechas para estudiar los fundamentos de las matematicas ni de otras ciencias. las preguntas de ada, segun el, eran impropias de una mujer. en definitiva, le inquietaba que su alumna pensase como un hombre. pero lady byron y lord lovelace hicieron caso omiso de la advertencia del profesor y ella continuo con sus estudios.  durante este tiempo en el que se vio obligada a compaginar su faceta de esposa y madre, el intercambio epistolar con su antigua tutora y amiga, mary somerville, representan un gran desahogo para ada. en esta correspondencia lovelace hace participe a su amiga de su frustracion despues de la maternidad y de las dificultades para continuar con sus estudios.​  en 1841 la madre de ada les conto a su hija y a medora leigh que el padre de ambas era el propio lord byron, y el 27 de febrero ada le escribio a su madre: «no estoy ni siquiera sorprendida. de hecho, simplemente me ha confirmado aquello de lo que, por años, no tuve la mas minima duda, pero hubiera considerado impropio por mi parte el haberle insinuado de alguna manera lo que sospechaba». ada no culpo a su padre por la incestuosa relacion sino a augusta leigh: «me temo que ella es inherentemente mas malvada de lo que el fue nunca». esto no evito que la madre de ada intentara destruir la imagen que esta tenia de su padre, sino que la llevo a hacerlo con mayor intensidad. a pesar de lo que cambio su vida despues de casarse, ada y babbage mantuvieron su amistad; el los visitaba a ella y a su marido con frecuencia. en el otoño de 1840, babbage volvio de su estancia en italia preocupado por su proyecto; cada vez le parecia mas dificil llegar a construir el prototipo totalmente operativo de la maquina analitica (o diferencial). no tenia suficientes recursos para financiarla, pero era optimista porque un reconocido cientifico italiano iba a escribir un articulo sobre su proyecto.​  a lo largo de sus enfermedades, continuo su educacion. la obsesion de su madre de desarraigar cualquiera de las locuras de las que acuso a byron fue una de las razones por las que ada aprendio matematicas desde temprana edad. william frend, william king y mary somerville, la destacada investigadora y autora del siglo xix, la educaron en matematicas y ciencias. uno de sus tutores posteriores fue el matematico y logico augustus de morgan. a partir de 1832, cuando tenia diecisiete años, sus habilidades matematicas comenzaron a surgir, y su interes por las matematicas domino la mayor parte de su vida adulta. en una carta a lady byron, de morgan sugirio que la habilidad de su hija en matematicas podria llevarla a convertirse en «una investigadora matematica, quizas de eminencia de primer nivel».  lovelace a menudo cuestionaba suposiciones basicas integrando poesia y ciencia. mientras estudiaba calculo diferencial, le escribio a de morgan:  lovelace creia que la intuicion y la imaginacion eran criticas para la aplicacion efectiva de conceptos matematicos y cientificos. valoraba la metafisica tanto como las matematicas, y las veia como herramientas para explorar «los mundos invisibles que nos rodean».  en 1841, ada escribe a babbage una carta dejando claro que esta interesada en colaborar con el. a babbage le parecio bien la idea, asi ella empezo traduciendo el articulo del cientifico italiano, luigi federico menabrea. con la traduccion del texto ella tenia dos objetivos: dar a conocer el valioso trabajo de su amigo y cumplir su sueño de alcanzar una vida intelectual que la elevase por encima de las exigencias de la maternidad y el matrimonio.[cita requerida]  finalmente llamo a su trabajo notas, que consistia en su propio estudio sobre la maquina analitica, y como anexo, la traduccion del articulo del italiano. babbage la asesoro, pero ada fue enteramente la autora de ese trabajo.  ada dedica gran parte de su estudio a describir con un lenguaje muy tecnico como funcionaria la maquina analitica, pero tambien ofrece una serie de observaciones que dejan clara su aportacion teorica. ella distinguia con claridad entre datos y procesamiento; este pensamiento era revolucionario en su tiempo. ada aspiraba a crear la informatica, que ella llamaba la ciencia de las operaciones. se dio cuenta de las aplicaciones practicas de la maquina analitica y llego incluso a vislumbrar la posibilidad de digitalizar la musica. escribio en las notas: «supongamos, por ejemplo, que las relaciones fundamentales entre los sonidos, en el arte de la armonia, fueran susceptibles de tales expresiones y adaptaciones: la maquina podria componer piezas musicales todo lo largas y complejas que se quisiera». ada tenia una idea clara: la maquina analitica y el telar de jacquard vienen a hacer lo mismo. una frase clave donde se expresa esto es: «puede decirse que la primera teje dibujos algebraicos, del mismo modo que el telar de jacquard teje flores y hojas». ada expresa con claridad las tres funciones que podia cumplir el invento de babbage: procesar formulas matematicas expresadas con simbolos, hacer calculos numericos (su objetivo primordial) y dar resultados algebraicos en notacion literal.  babbage y ada concebian la maquina analitica de manera muy distinta. al primero no le interesaban demasiado sus consecuencias practicas. a ada, por el contrario, le obsesionaban las aplicaciones del invento. ella fue la primera en intuir lo que el invento de babbage significaba para el progreso tecnologico. entendio que la tecnologia utilizada en el telar de jacquard y en la maquina analitica podia aplicarse a todo proceso que implicara tratar datos: de este modo abria camino a una nueva ciencia, la de la computacion de la informacion.​  en 1840 charles babbage viajo a italia para explicar el concepto de la maquina analitica en la universidad de turin. entre la audiencia se encontraba el ingeniero militar y matematico luigi menabrea, quien publicara mas tarde las notas de la conferencia, en frances. a ada se le pidio que hiciera la traduccion de lo escrito por menabrea al ingles, y al hacerlo, añadio un apendice mas extenso que fue un articulo en si mismo, consistiendo en siete notas etiquetadas alfabeticamente de la a a la g. las notas de ada se publicaron en la revista scientific memoir en septiembre de 1843, con el titulo de «sketch of the analytical engine invented by charles babbage»,​ que firmo con sus iniciales a. a. l.  en estas notas, ada escribio:  este algoritmo para calcular los numeros de bernoulli, una serie de fracciones con diferentes aplicaciones en matematicas, se ha considerado por muchos como el primer programa/algoritmo de la historia. consecuentemente, muchos perfiles de la figura de ada lovelace lo celebran como la primera persona programadora de la historia. sin embargo, se ha mantenido durante años la controversia sobre el grado de participacion de babbage en la confeccion de las notas de lovelace. es una controversia complicada debido al hecho de que se ha tomado, en los ultimos años, la contribucion de ada como \"una cuestion de genero\"​ y a la atencion creciente de la promocion de las mujeres en ciencia, tecnologia, ingenieria y matematicas (stem).​  actualmente esta probado que fue babbage la primera persona que hizo lo que se entiende como un programa, ya que escribio algoritmos parecidos entre 6 y 7 años antes de la publicacion del articulo de lovelace en 1843. existen 24 de tales 'programas' y tienen caracteristicas identicas a los de la nota g de lovelace. la idea general de que ella escribio el primer programa de ordenador de la historia es solo un mito​ tratandose en realidad de un trabajo en equipo con babbage.​  en cambio, la aportacion de ada a la informatica fue incluso aun mas importante: con una vision mas amplia que la de babbage, dedujo y previo la capacidad de las maquinas para ir mas alla de los simples calculos de numeros. ada vio las aplicaciones practicas de la maquina, y creyo acertadamente que en el futuro podria incluso componer musica y hacer graficos:   fue la primera persona en darse cuenta de que los numeros almacenados dentro de la maquina analitica podian representar otras cosas mas alla de la magnitud de dichos numeros, es decir, el caracter simbolico de la representacion numerica interna de la maquina. tambien aporto una primera idea de lo que seria el software:   (las palabras en cursiva son de la propia ada).  actualmente se podria decir que ada lovelace fue la primera ingeniera del software,​ algo mas importante que ser programadora, pues ella estudio, desarrollo y creo la documentacion sobre un determinado sistema de procesamiento automatico.  desde un punto de vista moderno, como se entiende lo que significa ser un programador (el que usa un lenguaje intermedio para comunicarle a un ordenador que interprete y ejecute una serie de ordenes), el primero fue alan turing, al desarrollar su maquina de turing. ademas, existen grandes diferencias entre el desarrollo de babbage/lovelace con el de turing: mientras que la maquina analitica era una maquina de proposito especifico (el motor diferencial), la de turing era programable de uso general.​  babbage y ada desarrollaron la gran idea de separar operaciones y datos de la maquinaria, y que las operaciones se pudieran codificar en tarjetas que dirigieran el comportamiento de la maquinaria. pero no fueron mas alla. la propuesta de turing es la de una maquina universal (es decir, una maquina que garantice la ejecucion de cualquier funcion que pueda ser descrita en terminos de la propia maquina), y una representacion uniforme de los datos y de las operaciones, almacenados ambos en la propia maquina.​  en sus notas, lovelace enfatizo la diferencia entre el motor analitico y las maquinas de calculo previas, en particular su capacidad de ser programado para resolver problemas de cualquier complejidad. se dio cuenta de que el potencial del dispositivo se extendia mucho mas alla del mero procesamiento numerico intensivo (number crunching). en sus notas, ella escribio:  este analisis fue un desarrollo importante de las ideas previas sobre las capacidades de los dispositivos informaticos y anticipo las implicaciones de la informatica moderna cien años antes de que se realizaran. walter isaacson atribuye la idea de lovelace sobre la aplicacion de la informatica a cualquier proceso basado en simbolos logicos a una observacion sobre textiles: «cuando vio algunos telares mecanicos que usaban tarjetas perforadas para dirigir el tejido de hermosos diseños, le recordo como la maquina de babbage usaba tarjetas perforadas para hacer calculos».[cita requerida] esta vision es considerada importante por escritores como betty toole y benjamin woolley, asi como por el programador john graham-cumming, cuyo proyecto plan 28 tiene el objetivo de construir la primera maquina analitica completa. de acuerdo con el historiador de informatica y especialista en babbage doron swade:  aunque a lovelace se la conoce como la primera programadora informatica, algunos biografos e historiadores de la informatica afirman lo contrario.  allan g. bromley, en el articulo de 1990 difference and analytical engines:  bruce collier, quien mas tarde escribio una biografia de babbage, escribio en su tesis de doctorado de la universidad de harvard de 1970 que lovelace «hizo una contribucion considerable para publicitar la maquina analitica, pero no hay evidencia de que haya avanzado en el diseño o la teoria de ninguna manera».  eugene eric kim y betty alexandra toole consideran «incorrecto» considerar a lovelace como el primer programador de computadoras, ya que babbage escribio los programas iniciales para su motor analitico, aunque la mayoria nunca se publico. bromley observa varias docenas de programas de muestra preparados por babbage entre 1837 y 1840, todos sustancialmente anteriores a las notas de lovelace. dorothy k. stein considera que las notas de lovelace son «mas un reflejo de la incertidumbre matematica del autor, los propositos politicos del inventor y, sobre todo, del contexto social y cultural en el que se escribio, que un plan para una investigacion cientifica».  en su libro, idea makers, stephen wolfram defiende las contribuciones de lovelace. aunque reconoce que babbage escribio varios algoritmos ineditos para analytical engine antes de las notas de lovelace, wolfram argumenta que «no hay nada tan sofisticado —o tan limpio— como el calculo de ada de los numeros de bernoulli. babbage ciertamente ayudo y comento el trabajo de ada, pero ella era definitivamente la conductora de eso». wolfram luego sugiere que el logro principal de lovelace fue destilar de la correspondencia de babbage «una exposicion clara de la operacion abstracta de la maquina, algo que babbage nunca hizo».  doron swade, un especialista en historia de la informatica conocido por su trabajo en babbage, analizo cuatro afirmaciones sobre lovelace durante una conferencia sobre el motor analitico de babbage:  segun el, solo el cuarto reclamo tenia «alguna sustancia en absoluto». explico que ada era solo una «principiante prometedora» en lugar de genio en matematicas, que comenzo a estudiar conceptos basicos de las matematicas cinco años despues de que babbage concibio el motor analitico por lo que no pudo haber hecho contribuciones importantes, y que ella solo publico el primer programa de computadora en vez de realmente escribirlo. pero esta de acuerdo con que ada fue la unica persona que vio el potencial del motor analitico como una maquina capaz de expresar entidades distintas de las cantidades.  a finales de la decada de 1840, ada se volvio adicta a las carreras de caballos y junto con algunos de sus amigos intentaron crear un modelo matematico que les ayudara a ganar grandes apuestas. el intento fue un absoluto fracaso, generandole a ada miles de libras de deuda y provocando que uno de los miembros del grupo la chantajeara con informar a su marido, cosa que finalmente se vio forzada a confesarle. en la ultima epoca de su vida paso continuos apuros economicos.​  en el verano de 1852, la salud de ada empeoro mucho, llevaba años padeciendo agotamiento nervioso y debilidad general, pero no fue hasta ese año que aparecieron los primeros sintomas del cancer de utero. la enfermedad duro varios meses, durante los cuales su madre tomo el control respecto a sus citas medicas y personales. por influencia de su madre, decidio dejar de ser materialista y adopto ideas religiosas​ que la llevaron a arrepentirse de su vida anterior.​  finalmente, fallecio a los treinta y seis años el 27 de noviembre de 1852, acompañada de lady byron y de william.  fue enterrada, a peticion suya, junto a su padre, en la parroquia del pueblo de hucknall torkard, en nottinghamshire, cerca de la abadia de newstead.​  sugirio el uso de tarjetas perforadas como metodo de entrada de informacion e instrucciones a la maquina analitica.​ ademas introdujo una notacion para escribir programas, principalmente basada en el dominio que ada tenia sobre el texto de luigi menabrea de 1842 (que comento personalmente completandolo con anotaciones que son mas extensas que el texto mismo) sobre el funcionamiento del telar de jacquard asi como de la maquina analitica de babbage. es reseñable ademas su mencion sobre la existencia de ceros o estado neutro en las tarjetas perforadas siendo que las tarjetas representaban para la maquina de babbage numeros decimales y no binarios (8 perforaciones equivaldrian entonces a 8 unidades).  tambien introdujo la posibilidad de que la maquina analitica no fuera solo capaz de realizar calculos matematicos, sino tambien de, entre muchas otras cosas, «producir arte» y componer musica, literatura... de hecho, afirmaba que el invento seria capaz de realizar cualquier cosa que se le pidiera, siempre y cuando supieramos como ordenarselo.​  el lenguaje de programacion ada, creado por el departamento de defensa de los estados unidos, fue nombrado asi en homenaje a ada lovelace. el manual de referencia del lenguaje fue aprobado el 10 de diciembre de 1980, y al estandar de defensa de los estados unidos para el lenguaje mil-std-1815 se le dio el numero del año de su nacimiento.  en 1981, la asociacion de mujeres en informatica inauguro su premio ada lovelace.​​ desde 1998, la british computer society (bcs) ha otorgado la medalla lovelace​ y en 2008 inicio una competencia anual para mujeres estudiantes.​ bcswomen patrocina el coloquio lovelace, una conferencia anual para mujeres universitarias. ada college es una universidad de educacion superior en tottenham hale, londres, centrada en las habilidades digitales.​  desde 1998, la british computer society ha premiado con la lovelace medal (medalla lovelace) en su nombre​ y en 2008 iniciaron una competicion anual para mujeres estudiantes de la informatica.​ en reino unido, el bcswomen lovelace colloquium —conferencia anual para universitarias— tambien lleva su nombre, ada lovelace.​  el dia de ada lovelace (ada lovelace day) es un evento anual celebrado el segundo martes de octubre​ cuyo objetivo es el de elevar el perfil de las mujeres en la ciencia, tecnologia, ingenieria y matematicas (las areas stem). pretende visibilizar, dar reconocimiento y apoyo a las mujeres que trabajan en alguno de estos ambitos, asi como a sus descubrimientos e invenciones, introducir a las mujeres mas jovenes en el mundo de la ciencia y la tecnologia y crear nuevos referentes femeninos. esta jornada internacional, que se empezo a celebrar en 2009 gracias a suw charman-anderson, cuenta con la organizacion de conferencias, talleres, concursos... en todo el mundo. el evento mas representativo es el ada lovelace day live!, celebrado en londres.​ los eventos han incluido wikipedia editatones con el objetivo de mejorar la representacion de las mujeres en wikipedia en terminos de articulos y editores para reducir la no intencionada brecha de genero en wikipedia.[cita requerida]  la iniciativa ada es una organizacion sin animo de lucro dedicada a incrementar la participacion y dedicacion de las mujeres en la cultura libre y en los movimientos open source.​  el edificio b de la escuela politecnica superior de la uam, en la que se imparten los grados de ingenieria informatica y de ingenieria de tecnologias y servicios de telecomunicacion, recibe el nombre de edificio b - ada lovelace. asi mismo, en la universidad de zaragoza se encuentra el edificio ada byron, en el que se imparten las mismas titulaciones que en el de la uam.​  el centro de computadoras en el pueblo de porlock, cerca de donde vivia lovelace, lleva su nombre. ada lovelace house​ es un edificio propiedad del consejo en kirkby-in-ashfield, nottinghamshire, cerca de donde lovelace paso su infancia; el edificio, que anteriormente albergaba las oficinas locales del consejo de distrito, ahora ofrece espacio de oficinas de alta calidad para una serie de empresas locales de nueva creacion.​​  tambien es la inspiracion e influencia de la academia ada developers en seattle, washington. la academia es una organizacion sin fines de lucro que busca aumentar la diversidad en tecnologia mediante la capacitacion de mujeres, personas trans y no binarias para ser ingenieros de software.​  en la universidad de malaga se encuentra el edificio de investigacion ada byron, inaugurado en 2014 y dedicado a la tecnologia informatica.​ el 10 de noviembre de 2009 una de las calles del parque tecnologico de gijon, en asturias, paso a llamarse ada byron en su honor.​  en 2014, la universidad de deusto entrega por primera vez un reconocimiento llamado premio ada byron a la mujer tecnologa, en honor a la informatica. este es un galardon que se concede a las mujeres tecnologas para visibilizar la trayectoria de los personajes femeninos en este ambito. las premiadas son mujeres que tienen como referencias a mujeres cientificas y tecnologas, que lleven siglos aportando al mundo tal y como la que da nombre al premio, ada byron.​  el premio ada byron destaca por valorar el empoderamiento de las mujeres tecnologas y su efecto positivo en el desarrollo y crecimiento sostenible a nivel mundial.  en 2017 fue lanzada la criptomoneda ada de cardano en su homenaje.  en 2018, the new york times publico un obituario tardio para ada lovelace.​  el 27 de julio de 2018, el senador ron wyden presento, en el senado de los estados unidos, la designacion del 9 de octubre de 2018 como dia nacional de ada lovelace: «para honrar la vida y las contribuciones de ada lovelace como una mujer lider en ciencias y matematicas». la resolucion (s.res.592)​ fue considerada y acordada sin enmiendas y con un preambulo por consentimiento unanime.  en la universidad del rosario, en bogota, colombia, se encuentra la sala lovelace, en su honor, del programa de matematicas aplicadas y ciencias de la computacion. se trata de una sala de computacion moderna donde se ven cursos de programacion, algoritmos, estructuras de datos, entre otros.​  en el 197º aniversario de su nacimiento, google le dedico su google doodle.​​ el doodle muestra a lovelace trabajando en una formula entre imagenes que muestran la evolucion de los ordenadores.​  el poeta uruguayo eduardo galeano le dedico el capitulo «las edades de ada», en su libro espejosː una historia casi universal (2009), destacando su papel de pionera al ser la primera programadora de la historia.​  el bicentenario del nacimiento de ada lovelace se celebro con una serie de eventos, que incluyen ada lovelace day: celebrating the achievements of women in science, technology, engineering and maths.​  exposiciones especiales fueron exhibidas por el museo de ciencias de londres, inglaterra y la biblioteca weston (parte de la biblioteca bodleian) en oxford (inglaterra).  en el episodio «spyfall parte 2»' de la temporada 12 de la serie doctor who, «la doctor» se encuentra con la pionera en informatica ada lovelace.  se han localizado seis copias de la primera edicion de 1843 de sketch of the analytical engine con las notas de ada lovelace. tres se llevan a cabo en la universidad de harvard, uno en la universidad de oklahoma y uno en la academia de la fuerza aerea de los estados unidos. el 20 de julio de 2018, la sexta copia se vendio en una subasta a un comprador anonimo por £ 95,000. un facsimil digital de una de las copias en la biblioteca de la universidad de harvard esta disponible en linea. ",
        "snippet": "Augusta Ada King, condesa de Lovelace (Londres, 10 de diciembre de 1815-íd., 27 de noviembre de 1852), registrada al nacer como Augusta Ada Byron y conocida habitualmente como Ada Lovelace, fue una matemática y escritora británica, célebre sobre todo por su trabajo acerca de la computadora mecánica de uso general de Charles Babbage, la denominada máquina analítica. Fue la primera en reconocer que la máquina tenía aplicaciones más allá del cálculo puro y en haber publicado lo que se reconoce hoy como el primer algoritmo destinado a ser procesado por una máquina, por lo que se le considera como la primera programadora de ordenadores.[2]​[3]​[4]​",
        "enlaces_salientes": [
            "/wiki/Ada_Lovelace",
            "/wiki/Ada_Lovelace",
            "/wiki/Ada_Lovelace",
            "/wiki/Antoine_Claudet",
            "/wiki/Londres",
            "/wiki/Reino_Unido_de_Gran_Breta%C3%B1a_e_Irlanda",
            "/wiki/Marylebone",
            "/wiki/Reino_Unido",
            "/wiki/C%C3%A1ncer_uterino",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Lord_Byron",
            "/wiki/Anna_Isabella_Noel_Byron",
            "/wiki/Mary_Somerville",
            "/wiki/Augustus_De_Morgan",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Programador",
            "/wiki/Poeta",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Inventor",
            "/wiki/Traductor",
            "/wiki/Escritor",
            "/wiki/Ingeniero",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Londres",
            "/wiki/10_de_diciembre",
            "/wiki/1815",
            "/wiki/27_de_noviembre",
            "/wiki/1852",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Escritora",
            "/wiki/Computadora",
            "/wiki/Charles_Babbage",
            "/wiki/M%C3%A1quina_anal%C3%ADtica",
            "/wiki/Algoritmo",
            "/wiki/Programador",
            "/wiki/Ordenador",
            "/wiki/Lord_Byron",
            "/wiki/Anna_Isabella_Noel_Byron",
            "/wiki/Guerra_de_independencia_de_Grecia",
            "/wiki/David_Brewster",
            "/wiki/Charles_Wheatstone",
            "/wiki/Michael_Faraday",
            "/wiki/Charles_Dickens",
            "/wiki/Mary_Somerville",
            "/wiki/Luigi_Menabrea",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Alfred_d%27Orsay",
            "/wiki/Anna_Isabella_Noel_Byron",
            "/wiki/Lord_Byron",
            "/wiki/Leicestershire",
            "/wiki/Mary_Somerville",
            "/wiki/Balneario",
            "/wiki/Sarampi%C3%B3n",
            "/wiki/Flyology",
            "/wiki/Charles_Babbage",
            "/wiki/M%C3%A1quina_diferencial",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Mary_Somerville",
            "/wiki/David_Brewster",
            "/wiki/Charles_Wheatstone",
            "/wiki/Michael_Faraday",
            "/wiki/Charles_Dickens",
            "/wiki/Fiordo_de_Torridon",
            "/wiki/Luna_de_miel",
            "/wiki/William_Benjamin_Carpenter",
            "/wiki/Augustus_De_Morgan",
            "/wiki/Italia",
            "/wiki/Mary_Somerville",
            "/wiki/Augustus_De_Morgan",
            "/wiki/Metaf%C3%ADsica",
            "/wiki/Luigi_Federico_Menabrea",
            "/wiki/Scientific_Memoirs_by_Officers_of_the_Medical_and_Sanitary_Departments_of_the_Government_of_India",
            "/wiki/N%C3%BAmero_de_Bernoulli",
            "/wiki/CTIM",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Lenguaje_formal",
            "/wiki/Software",
            "/wiki/Ingenier%C3%ADa_de_software",
            "/wiki/Programador",
            "/wiki/Alan_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Materialismo",
            "/wiki/Nottinghamshire",
            "/wiki/Tarjetas_perforadas",
            "/wiki/Telar_de_Jacquard",
            "/wiki/Ada_(lenguaje_de_programaci%C3%B3n)",
            "/wiki/Departamento_de_Defensa_de_los_Estados_Unidos",
            "/wiki/Asociaci%C3%B3n_de_Mujeres_en_Computaci%C3%B3n",
            "/wiki/British_Computer_Society",
            "/wiki/British_Computer_Society",
            "/wiki/Medalla",
            "/wiki/STEM",
            "/wiki/Londres",
            "/wiki/Brecha_de_g%C3%A9nero_en_Wikipedia",
            "/wiki/Ada_Initiative",
            "/wiki/Escuela_Polit%C3%A9cnica_Superior_(Universidad_Aut%C3%B3noma_de_Madrid)",
            "/wiki/Universidad_Aut%C3%B3noma_de_Madrid",
            "/wiki/Universidad_de_Zaragoza",
            "/wiki/Porlock",
            "/wiki/Universidad_de_Deusto",
            "/wiki/Premio_Ada_Byron",
            "/wiki/Ada_(moneda_digital)",
            "/wiki/The_New_York_Times",
            "/wiki/Ron_Wyden",
            "/wiki/Senado_de_los_Estados_Unidos",
            "/wiki/Google",
            "/wiki/Google_Doodle",
            "/wiki/Eduardo_Galeano",
            "/wiki/Espejos_(libro)",
            "/wiki/Aniversario",
            "/wiki/Universidad_de_Oxford",
            "/wiki/Museo_de_Ciencias_de_Londres",
            "/wiki/Biblioteca_Bodleian",
            "/wiki/Oxford",
            "/wiki/Spyfall",
            "/wiki/Doctor_Who",
            "/wiki/ISBN",
            "/wiki/Mujeres_en_inform%C3%A1tica",
            "/wiki/Mujeres_en_campos_de_CTIM",
            "/wiki/Microsiervos_(blog)",
            "/wiki/ISSN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Semantic_Scholar",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Claude_Shannon",
        "titulo": "Claude Shannon",
        "contenido": "claude elwood shannon (30 de abril de 1916 - 24 de febrero de 2001) fue un matematico, ingeniero electrico y criptografo estadounidense recordado como «el padre de la teoria de la informacion».​​  shannon es reconocido por haber fundado el campo de la teoria de la informacion con la publicacion una teoria matematica de la comunicacion, que supuso un hito en 1948. es quizas igualmente conocido por haber sentado las bases de la teoria del diseño de circuitos digitales en 1937, con apenas 21 años de edad. mientras realizaba su maestria en el massachusetts institute of technology (mit), demostro en su tesis que las aplicaciones electronicas de algebra booleana podrian construir cualquier relacion logico-numerica.​ shannon contribuyo asimismo al campo del criptoanalisis para la defensa de estados unidos durante la segunda guerra mundial, con trabajos sobre el descifrado de codigos y la seguridad en las telecomunicaciones.  los primeros años de su vida los paso en gaylord, donde se graduo de la secundaria en 1932. desde joven, shannon mostro una clara inclinacion hacia las cosas mecanicas. resaltaba respecto a sus compañeros en las asignaturas de ciencias. su heroe de la niñez era edison, con quien luego descubrio que tenia un parentesco y a cuyas investigaciones se aproximo bastante.  en 1932 ingreso en la universidad de michigan, donde su hermana catherine se doctoro como matematica. en 1936 obtuvo los titulos de ingeniero electricista y matematico. su interes por la matematica y la ingenieria continuo durante toda su vida.  en 1936 acepto el puesto de asistente de investigacion en el departamento de ingenieria electrica en el instituto tecnologico de massachusetts (mit). su situacion le permitio continuar estudiando mientras trabajaba por horas para el departamento, donde trabajo en el computador analogico mas avanzado de esa era, el analizador diferencial de vannevar bush.  en ese momento surgio su interes hacia los circuitos de reles complejos. intentando simplificar centralitas telefonicas de reles, se dio cuenta de que estos podian usarse para hacer calculos. sumado esto a su gusto por la logica y el algebra booleana, pudo desarrollar esta idea durante el verano de 1937, que paso en los laboratorios bell en la ciudad de nueva york.  en su tesis doctoral en el mit​ demostro como el algebra booleana se podia utilizar en el analisis y la sintesis de la conmutacion y de los circuitos digitales. la tesis desperto un interes considerable cuando aparecio en 1938 en las publicaciones especializadas. en 1940 le fue concedido el premio alfred noble para ingenieros estadounidenses por parte de la sociedad estadounidense de ingenieros civiles de los estados unidos, otorgado cada año a una persona de no mas de treinta años. un cuarto de siglo mas tarde, herman goldstine, en su libro las computadoras desde pascal hasta von neumann, cito su tesis como una de las mas importantes de la historia que ayudo a cambiar el diseño de circuitos digitales.  durante el verano de 1938 realizo trabajos de investigacion en el mit y le fue concedida la beca bolles cuando trabajaba como ayudante de enseñanza mientras realizaba un doctorado en matematica. en 1940 estudio un master en ingenieria electrica y se doctoro en filosofia de la matematica.  shannon paso quince años en los laboratorios bell, una asociacion muy fructifera con muchos matematicos y cientificos de primera linea como harry nyquist, walter houser brattain, john bardeen y william bradford shockley, inventores del transistor; george stibitz, quien construyo computadoras basadas en reles; warren weaver, quien escribio una extensa y aclaradora introduccion a su obra una teoria matematica de la comunicacion y muchos otros mas.  durante este periodo shannon trabajo en muchas areas, y lo mas notable fue todo lo referente a la teoria de la informacion, que se publico en 1948 con el nombre de una teoria matematica de la comunicacion. en este trabajo se demostro que todas las fuentes de informacion (telegrafo electrico, telefono, radio, la gente que habla, las camaras de television, etcetera) pueden medirse, y que los canales de comunicacion tienen una unidad de medida similar, determinando la velocidad maxima de transferencia o capacidad de canal. demostro tambien que la informacion se puede transmitir sobre un canal si y solamente si la magnitud de la fuente no excede la capacidad de transmision del canal que la conduce, y sento las bases para la correccion de errores, supresion de ruidos y redundancia.  en el area de las computadoras y de la inteligencia artificial, publico en 1949 un trabajo que describia la programacion de una computadora para jugar al ajedrez, convirtiendose en la base de posteriores desarrollos.​​  en el campo de la biblioteconomia y la documentacion, el desarrollo booleano revoluciono las busquedas en catalogos de bibliotecas o en bases de datos de centros de documentacion.  a lo largo de su vida recibio numerosas condecoraciones y reconocimientos de universidades e instituciones de todo el mundo.  ante la pregunta de un periodista de si las maquinas podian pensar, replico: «¡naturalmente! ¡usted y yo somos maquinas y vaya si pensamos!».  shannon, claude elwood (1948). «a mathematical theory of communication». bell system technical journal 27 (379-423 and 623-656). shannon, claude elwood (1949). «communication theory of secrecy systems». bell system technical journal 28 (656-715). ",
        "snippet": "Claude Elwood Shannon (30 de abril de 1916 - 24 de febrero de 2001) fue un matemático, ingeniero eléctrico y criptógrafo estadounidense recordado como «el padre de la teoría de la información».[1]​[2]​",
        "enlaces_salientes": [
            "/wiki/Claude_Shannon",
            "/wiki/Claude_Shannon",
            "/wiki/Claude_Shannon",
            "/wiki/Petoskey",
            "/wiki/Estados_Unidos",
            "/wiki/Medford_(Massachusetts)",
            "/wiki/Gaylord_(M%C3%ADchigan)",
            "/wiki/Betty_Shannon",
            "/wiki/Universidad_de_M%C3%ADchigan",
            "/wiki/Ingenier%C3%ADa_el%C3%A9ctrica",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Instituto_de_Tecnolog%C3%ADa_de_Massachusetts",
            "/wiki/Vannevar_Bush",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Inventor",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Ingeniero",
            "/wiki/Genetista",
            "/wiki/Teor%C3%ADa_de_la_probabilidad",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Cibern%C3%A9tica",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/Instituto_de_Estudios_Avanzados_(Princeton)",
            "/wiki/Bell_Labs",
            "/wiki/Ivan_Sutherland",
            "/wiki/William_Daniel_Hillis",
            "/wiki/Una_teor%C3%ADa_matem%C3%A1tica_de_la_comunicaci%C3%B3n",
            "/wiki/Teorema_de_muestreo_de_Nyquist-Shannon",
            "/wiki/Primer_teorema_de_Shannon",
            "/wiki/Segundo_teorema_de_Shannon",
            "/wiki/Teorema_de_Shannon-Hartley",
            "/wiki/Entrop%C3%ADa_(informaci%C3%B3n)",
            "/wiki/%C3%8Dndice_de_Shannon",
            "/wiki/N%C3%BAmero_de_Shannon",
            "/wiki/Juego_de_cambio_de_Shannon",
            "/wiki/F%C3%B3rmula_de_Interpolaci%C3%B3n_de_Whittaker-Shannon",
            "/wiki/Teor%C3%ADa_de_la_comunicaci%C3%B3n_de_los_sistemas_secretos",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Academia_Alemana_de_las_Ciencias_Naturales_Leopoldina",
            "/wiki/Real_Academia_de_Artes_y_Ciencias_de_los_Pa%C3%ADses_Bajos",
            "/wiki/American_Philosophical_Society",
            "/wiki/Royal_Society",
            "/wiki/Ciclismo_de_competici%C3%B3n",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Electr%C3%B3nica",
            "/wiki/Cript%C3%B3grafo",
            "/wiki/Estados_Unidos_de_Am%C3%A9rica",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Una_teor%C3%ADa_matem%C3%A1tica_de_la_comunicaci%C3%B3n",
            "/wiki/Circuito_digital",
            "/wiki/Maestr%C3%ADa",
            "/wiki/Massachusetts_Institute_of_Technology",
            "/wiki/%C3%81lgebra_booleana",
            "/wiki/Criptoan%C3%A1lisis",
            "/wiki/Estados_Unidos",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Telecomunicaciones",
            "/wiki/Thomas_Alva_Edison",
            "/wiki/Universidad_de_M%C3%ADchigan",
            "/wiki/Ingenier%C3%ADa",
            "/wiki/Electricidad",
            "/wiki/Matem%C3%A1tica",
            "/wiki/Instituto_Tecnol%C3%B3gico_de_Massachusetts",
            "/wiki/Computador_anal%C3%B3gico",
            "/wiki/Analizador_diferencial",
            "/wiki/Vannevar_Bush",
            "/wiki/Rel%C3%A9",
            "/wiki/L%C3%B3gica",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/Laboratorios_Bell",
            "/wiki/Nueva_York",
            "/wiki/%C3%81lgebra_de_Boole",
            "/wiki/Circuito_de_conmutaci%C3%B3n",
            "/wiki/Circuito",
            "/wiki/Se%C3%B1al_digital",
            "/wiki/Sociedad_Estadounidense_de_Ingenieros_Civiles",
            "/wiki/Estados_Unidos",
            "/wiki/Herman_Goldstine",
            "/wiki/Blaise_Pascal",
            "/wiki/John_von_Neumann",
            "/wiki/Ingenier%C3%ADa_el%C3%A9ctrica",
            "/wiki/Filosof%C3%ADa_de_la_matem%C3%A1tica",
            "/wiki/Minivac_601",
            "/wiki/Harry_Nyquist",
            "/wiki/Walter_Houser_Brattain",
            "/wiki/John_Bardeen",
            "/wiki/William_Bradford_Shockley",
            "/wiki/Transistor",
            "/wiki/George_Stibitz",
            "/wiki/Rel%C3%A9s",
            "/wiki/Warren_Weaver",
            "/wiki/Una_teor%C3%ADa_matem%C3%A1tica_de_la_comunicaci%C3%B3n",
            "/wiki/Teor%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Tel%C3%A9grafo_el%C3%A9ctrico",
            "/wiki/Tel%C3%A9fono",
            "/wiki/Radio_(medio_de_comunicaci%C3%B3n)",
            "/wiki/Televisi%C3%B3n",
            "/wiki/Canal_de_comunicaciones",
            "/wiki/Capacidad_de_canal",
            "/wiki/Computadora_electr%C3%B3nica",
            "/wiki/Inteligencia_artificial",
            "/wiki/Ajedrez_por_computadora",
            "/wiki/Biblioteconom%C3%ADa",
            "/wiki/Documentaci%C3%B3n",
            "/wiki/Biblioteca",
            "/wiki/Bases_de_datos",
            "/wiki/Centro_de_documentaci%C3%B3n",
            "/wiki/A_mathematical_theory_of_communication",
            "/wiki/Communication_theory_of_secrecy_systems",
            "/wiki/Abraham_Lempel",
            "/wiki/Ajedrez_por_computadora",
            "/wiki/Minivac_601",
            "/wiki/Libreta_de_un_solo_uso",
            "/wiki/N%C3%BAmero_de_Shannon",
            "/wiki/Shannon_(unidad)",
            "/wiki/Teorema_de_Shannon-Hartley",
            "/wiki/Teorema_de_codificaci%C3%B3n_de_fuentes_de_Shannon",
            "/wiki/Segundo_teorema_de_Shannon",
            "/wiki/Biographical_Memoirs_of_Fellows_of_the_Royal_Society",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Scopus",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Deutsche_Biographie",
            "/wiki/Real_Academia_de_Artes_y_Ciencias_de_los_Pa%C3%ADses_Bajos",
            "/wiki/Deutsche_Akademie_der_Naturforscher_Leopoldina",
            "/wiki/Open_Library",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Howard_Aiken",
        "titulo": "Howard H. Aiken",
        "contenido": "howard h. aiken (hoboken, nueva jersey, 8 de marzo de 1900-san luis, misuri, 14 de marzo de 1973), fue un fisico estadounidense, pionero en el campo de la informatica y cientifico principal tras el proyecto que dio lugar a la serie de ordenadores mark.  fue hijo unico. al llegar a la adolescencia se mudo, con sus padres, a casa de sus abuelos maternos no tiene , en indianapolis.  estudio en la universidad de wisconsin-madison, y posteriormente obtuvo su doctorado en fisica en la universidad de harvard en 1939. durante este tiempo, encontro ecuaciones diferenciales que solo podia resolver numericamente. ideo un dispositivo electromecanico de computacion que podia hacer gran parte de ese trabajo por el. este ordenador fue originalmente llamado automatic sequence controlled calculator (ascc) y posteriormente renombrado harvard mark i. con la ayuda de grace hopper, y financiado por ibm, la maquina fue completada en 1944.  en 1947, aiken, completo su trabajo en el ordenador harvard mark ii. continuo su trabajo en el mark iii y en el harvard mark iv. el mark iii utilizo algunos componentes electronicos y el mark iv fue completamente electronico. el mark iii y el mark iv utilizaron memoria de tambor magnetico y el mark iv tambien tenia un nucleo de memoria magnetica.  aiken fue inspirado por la maquina diferencial de charles babbage.  de el, se supone que dijo, en 1947: \"solo seis ordenadores digitales electronicos serian necesarios para satisfacer las necesidades de computacion de todos los estados unidos\". la cita tambien es atribuida a thomas john watson, pero probablemente no fue dicha por ninguno de los dos.  howard aiken fue tambien oficial en la reserva de la marina estadounidense.  el 14 de marzo de 1973, aiken murio durante un viaje a san luis, misuri.   ",
        "snippet": "Howard H. Aiken (Hoboken, Nueva Jersey, 8 de marzo de 1900-San Luis, Misuri, 14 de marzo de 1973), fue un físico estadounidense, pionero en el campo de la informática y científico principal tras el proyecto que dio lugar a la serie de ordenadores Mark.",
        "enlaces_salientes": [
            "/wiki/Howard_H._Aiken",
            "/wiki/Howard_H._Aiken",
            "/wiki/Howard_H._Aiken",
            "/wiki/8_de_marzo",
            "/wiki/1900",
            "/wiki/Hoboken_(Nueva_Jersey)",
            "/wiki/Nueva_Jersey",
            "/wiki/Estados_Unidos",
            "/wiki/14_de_marzo",
            "/wiki/1973",
            "/wiki/San_Luis_(Missouri)",
            "/wiki/Misuri_(estado)",
            "/wiki/Estados_Unidos",
            "/wiki/M%C3%A9xico",
            "/wiki/Fort_Lauderdale",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Universidad_de_Wisconsin-Madison",
            "/wiki/Universidad_de_Harvard",
            "/wiki/Doctorado",
            "/wiki/Matem%C3%A1ticas_aplicadas",
            "/wiki/Computaci%C3%B3n_cient%C3%ADfica",
            "/wiki/Westinghouse_Electric",
            "/wiki/IBM",
            "/wiki/Armada_de_los_Estados_Unidos",
            "/wiki/Universidad_de_Harvard",
            "/wiki/Universidad_de_Miami",
            "/wiki/Gerrit_Blaauw",
            "/wiki/Kenneth_Iverson",
            "/wiki/Frederick_Brooks",
            "/wiki/Gerard_Salton",
            "/wiki/Harvard_Mark_I",
            "/wiki/Harvard_Mark_II",
            "/wiki/Harvard_Mark_III",
            "/wiki/Harvard_Mark_IV",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Asociaci%C3%B3n_Estadounidense_para_el_Avance_de_la_Ciencia",
            "/wiki/1964",
            "/wiki/Medalla_Edison_IEEE",
            "/wiki/1970",
            "/wiki/Harvard_Mark_I",
            "/wiki/Hoboken_(Nueva_Jersey)",
            "/wiki/Nueva_Jersey",
            "/wiki/8_de_marzo",
            "/wiki/1900",
            "/wiki/San_Luis_(Missouri)",
            "/wiki/Misuri",
            "/wiki/14_de_marzo",
            "/wiki/1973",
            "/wiki/Nacionalidad_estadounidense",
            "/wiki/Inform%C3%A1tica",
            "/wiki/Computadora",
            "/wiki/Harvard_Mark_I",
            "/wiki/Hijo_%C3%BAnico",
            "/wiki/Indian%C3%A1polis",
            "/wiki/Universidad_de_Wisconsin-Madison",
            "/wiki/Doctorado",
            "/wiki/F%C3%ADsica",
            "/wiki/Universidad_de_Harvard",
            "/wiki/1939",
            "/wiki/Ecuaciones_diferenciales",
            "/wiki/Electromec%C3%A1nica",
            "/wiki/Computaci%C3%B3n",
            "/wiki/Harvard_Mark_I",
            "/wiki/Grace_Hopper",
            "/wiki/IBM",
            "/wiki/1944",
            "/wiki/1947",
            "/wiki/Harvard_Mark_II",
            "/wiki/Harvard_Mark_III",
            "/wiki/Harvard_Mark_IV",
            "/wiki/Electr%C3%B3nica",
            "/wiki/Memoria_(inform%C3%A1tica)",
            "/wiki/Tambor_magn%C3%A9tico",
            "/wiki/M%C3%A1quina_Diferencial",
            "/wiki/Charles_Babbage",
            "/wiki/Thomas_John_Watson",
            "/wiki/Armada_de_los_Estados_Unidos",
            "/wiki/14_de_marzo",
            "/wiki/1973",
            "/wiki/San_Luis_(Misuri)",
            "/wiki/Misuri",
            "/wiki/1964",
            "/wiki/1970",
            "/wiki/Medalla_Edison_IEEE",
            "/wiki/IEEE",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Deutsche_Biographie",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Bibcode",
        "titulo": "Bibcode",
        "contenido": "el bibcode es un identificador usado por numerosas bases de datos astronomicas para citar referencias bibliograficas. el bibcode fue desarrollado para ser usado en el simbad y la base de datos de objetos extragalacticos nasa/ipac (ned), pero se usa mas ampliamente en el sistema de datos astrofisicos, tambien de la nasa.​​  el codigo tiene una longitud fija de 19 caracteres y tiene la forma:  donde yyyy son los cuatro digitos del año de publicacion de la referencia, jjjjj es un codigo que indica la publicacion de procedencia de la referencia, vvvv el numero de volumen, m la seccion de la publicacion, por ejemplo l indica la seccion de cartas, pppp indica la pagina de comienzo de la referencia y a es la primera letra del apellido del primer autor. se usan puntos para rellenar los campos no usados o para completar campos donde la longitud del codigo empleado sea mas corto que los espacios reservados a el. la alineacion se hace a la derecha para el codigo de publicacion y a la izquierda para el numero de volumen y de pagina.​​  ejemplos de codificacion: ",
        "snippet": "El bibcode es un identificador usado por numerosas bases de datos astronómicas para citar referencias bibliográficas. El bibcode fue desarrollado para ser usado en el SIMBAD y la Base de datos de objetos extragalácticos NASA/IPAC (NED), pero se usa más ampliamente en el Sistema de Datos Astrofísicos, también de la NASA.[1]​[2]​",
        "enlaces_salientes": [
            "/wiki/Bibcode",
            "/wiki/Bibcode",
            "/wiki/Bibcode",
            "/wiki/Base_de_datos",
            "/wiki/Astronom%C3%ADa",
            "/wiki/SIMBAD",
            "/wiki/NASA_Extragalactic_Database",
            "/wiki/Sistema_de_Datos_Astrof%C3%ADsicos",
            "/wiki/NASA",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Jean_van_Heijenoort",
        "titulo": "Jean van Heijenoort",
        "contenido": "jean louis maxime van heijenoort (pronunciacion en ingles: /væn_ˈhaɪən.ɔːrt/; pronunciacion en frances: /van ɛjɛnɔrt/; creil, francia el 23 de julio de 1912 - ciudad de mexico, mexico el 29 de marzo de 1986) fue un pionero en historia de la logica matematica. tambien fue secretario personal y guardaespaldas de leon trotski entre 1932 y 1939, y militante trotskista desde entonces hasta 1947.  nacio en el poblado frances de creil en el seno de una familia que atraveso penurias economicas, especialmente tras la muerte de su padre (un inmingrante neerlandes) ocurrida a sus dos años de edad. sin embargo esto no impidio que recibiese una buena educacion tradicional francesa, en la cual se destaco por sus escritos. mas tarde obtuvo la ciudadania estadounidense pero continuo visitando a su familia y amigos en francia dos veces por año desde 1958 hasta su muerte.  van heijenoort tuvo varios hijos con dos de sus cuatro esposas. mientras vivia con trotski en coyoacan, actualmente un barrio de la capital mexicana, su primera esposa lo dejo tras enfrentarse a la esposa de trotski. van heijenoort tambien fue por entonces uno de los amantes de frida kahlo, en la pelicula frida es interpretado por el actor felipe fulop. habiendose apartado de trotski por razones personales en 1939, van heijenoort era inocente de todas las circunstancias que llevaron a su asesinato en 1940. el propio matematico murio tambien asesinado, cuarenta y seis años despues, en ciudad de mexico, por su cuarta exesposa, a quien visitaba en ese momento. tras dispararle mortalmente, ella se suicido con otro tiro. ",
        "snippet": "Jean Louis Maxime van Heijenoort (pronunciación en inglés: /væn_ˈhaɪən.ɔːrt/; pronunciación en francés: /van ɛjɛnɔrt/; Creil, Francia el 23 de julio de 1912 - Ciudad de México, México el 29 de marzo de 1986) fue un pionero en historia de la lógica matemática. También fue secretario personal y guardaespaldas de León Trotski entre 1932 y 1939, y militante trotskista desde entonces hasta 1947.",
        "enlaces_salientes": [
            "/wiki/Jean_van_Heijenoort",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/Jean_van_Heijenoort",
            "/wiki/Creil",
            "/wiki/Francia",
            "/wiki/Ciudad_de_M%C3%A9xico",
            "/wiki/M%C3%A9xico",
            "/wiki/Homicidio",
            "/wiki/Estados_Unidos",
            "/wiki/Universidad_de_Nueva_York",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Cuarta_Internacional",
            "/wiki/Creil",
            "/wiki/Francia",
            "/wiki/Ciudad_de_M%C3%A9xico",
            "/wiki/M%C3%A9xico",
            "/wiki/L%C3%B3gica_matem%C3%A1tica",
            "/wiki/Guardaespaldas",
            "/wiki/Le%C3%B3n_Trotski",
            "/wiki/Trotskista",
            "/wiki/Francia",
            "/wiki/Creil",
            "/wiki/Pa%C3%ADses_Bajos",
            "/wiki/Naturalizaci%C3%B3n",
            "/wiki/Coyoac%C3%A1n",
            "/wiki/Frida_Kahlo",
            "/wiki/Frida_(pel%C3%ADcula)",
            "/wiki/Ciudad_de_M%C3%A9xico",
            "/wiki/Suicidio",
            "/wiki/Marxists_Internet_Archive",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Deutsche_Biographie"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Andrew_Hodges",
        "titulo": "Andrew Hodges",
        "contenido": "andrew hodges (nacido en londres, 1949) es un matematico, escritor y pionero del movimiento de liberacion gay de los años 70. durante las ultimas decadas (desde 1972) hodges ha centrado sus actividades de investigacion en el campo de la llamada teoria de twistores —la teoria matematica propuesta por roger penrose que trata de generar el espacio-tiempo a partir de la estructura de los rayos luminosos, o mas precisamente de las particulas que se desplazan a la velocidad de la luz. tal vez es mas conocido como autor de alan turing: the enigma, la biografia del extraordinario matematico britanico alan turing, uno de los fundadores del campo de la computacion y de la inteligencia artificial. el libro fue incluido el año 2002 por el diario the guardian​ en su lista de los 50 libros esenciales de todos los tiempos. asi mismo, es autor de otros libros de divulgacion cientifica. actualmente trabaja en el wadham college de la universidad de oxford. ",
        "snippet": "Andrew Hodges (nacido en Londres, 1949) es un matemático, escritor y pionero del movimiento de liberación gay de los años 70. Durante las últimas décadas (desde 1972) Hodges ha centrado sus actividades de investigación en el campo de la llamada teoría de twistores —la teoría matemática propuesta por Roger Penrose que trata de generar el espacio-tiempo a partir de la estructura de los rayos luminosos, o más precisamente de las partículas que se desplazan a la velocidad de la luz. Tal vez es más conocido como autor de Alan Turing: The Enigma, la biografía del extraordinario matemático británico Alan Turing, uno de los fundadores del campo de la computación y de la inteligencia artificial. El libro fue incluido el año 2002 por el diario The Guardian[1]​ en su lista de los 50 libros esenciales de todos los tiempos. Así mismo, es autor de otros libros de divulgación científica. Actualmente trabaja en el Wadham College de la Universidad de Oxford.",
        "enlaces_salientes": [
            "/wiki/Andrew_Hodges",
            "/wiki/Andrew_Hodges",
            "/wiki/Andrew_Hodges",
            "/wiki/Londres",
            "/wiki/Reino_Unido",
            "/wiki/Oxfordshire",
            "/wiki/Universidad_de_Londres",
            "/wiki/Roger_Penrose",
            "/wiki/Matem%C3%A1tico",
            "/wiki/F%C3%ADsico",
            "/wiki/Bi%C3%B3grafo",
            "/wiki/Universidad_de_Oxford",
            "/wiki/Londres",
            "/wiki/1949",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Escritor",
            "/wiki/Liberaci%C3%B3n_gay",
            "/wiki/Teor%C3%ADa_de_twistores",
            "/wiki/Roger_Penrose",
            "/wiki/Velocidad_de_la_luz",
            "/wiki/Alan_Turing",
            "/wiki/Universidad_de_Oxford",
            "/wiki/Alan_Turing",
            "/wiki/Teor%C3%ADa_de_twistores",
            "/wiki/Roger_Penrose",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Open_Library",
            "/wiki/Europeana"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Simon_and_Schuster",
        "titulo": "Simon & Schuster",
        "contenido": "simon & schuster, inc., una division de paramount global, es una editorial fundada en la ciudad de nueva york en 1924 por richard l. simon y m. lincoln (\"max\") schuster. publica cerca de 2000 titulos anualmente bajo 35 imprentas diferentes.  en 1924, richard simon tuvo la idea de publicar un libro de crucigramas, por lo que se unio a lincoln schuster y entre ambos reunieron 8 mil dolares para iniciar una pequeña editorial.​​ para llamar la atencion, el libro de crucigramas traia un lapiz de regalo.​ inesperadamente este libro se volvio sumamente popular en 1924.​  en 1939, con robert fair de graff, simon & schuster fundo la subsidiaria pocket books, primera editorial en rustica de estados unidos. a lo largo de lo que restaba del siglo xx, la empresa se convirtio en una de las principales editoriales de norteamerica.  en octubre de 2014, simon & schuster firmo un acuerdo con amazon.com para la distribucion de e-books o libros electronicos.​ ",
        "snippet": "Simon & Schuster, Inc., una división de Paramount Global, es una editorial fundada en la ciudad de Nueva York en 1924 por Richard L. Simon y M. Lincoln (\"Max\") Schuster. Publica cerca de 2000 títulos anualmente bajo 35 imprentas diferentes.",
        "enlaces_salientes": [
            "/wiki/Simon_%26_Schuster",
            "/wiki/Simon_%26_Schuster",
            "/wiki/Simon_%26_Schuster",
            "/wiki/Tipos_de_entidad_empresarial",
            "/wiki/Filial",
            "/wiki/Industria",
            "/wiki/Richard_L._Simon",
            "/wiki/M._Lincoln_Schuster",
            "/wiki/Sede_central",
            "/wiki/Nueva_York",
            "/wiki/Estados_Unidos",
            "/wiki/Bien_econ%C3%B3mico",
            "/wiki/Propiedad",
            "/wiki/Richard_L._Simon",
            "/wiki/M._Lincoln_Schuster",
            "/wiki/Empresa_matriz",
            "/wiki/Paramount_Global",
            "/wiki/Filial",
            "/wiki/Sitio_web",
            "/wiki/Paramount_Global",
            "/wiki/Nueva_York",
            "/wiki/Richard_L._Simon",
            "/wiki/M._Lincoln_Schuster",
            "/wiki/Pocket_Books",
            "/wiki/Amazon.com",
            "/wiki/Andrew_Solomon",
            "/wiki/Anna_Todd",
            "/wiki/Annie_Proulx",
            "/wiki/Audrey_Niffenegger",
            "/wiki/Becca_Fitzpatrick",
            "/wiki/Bob_Dylan",
            "/wiki/Bob_Woodward",
            "/wiki/Brad_Thor",
            "/wiki/Cassandra_Clare",
            "/wiki/Cornelius_Ryan",
            "/wiki/Dan_Brown",
            "/wiki/David_McCullough",
            "/wiki/Dick_Cheney",
            "/wiki/Donald_Trump",
            "/wiki/Doris_Kearns_Goodwin",
            "/wiki/Ernest_Hemingway",
            "/wiki/F._Scott_Fitzgerald",
            "/wiki/Frank_McCourt",
            "/wiki/Gillian_Anderson",
            "/wiki/Gilda_Radner",
            "/wiki/Glenn_Beck",
            "/wiki/Harold_Robbins",
            "/wiki/Hilary_Duff",
            "/wiki/Hillary_Clinton",
            "/wiki/Holly_Black",
            "/wiki/Hunter_S._Thompson",
            "/wiki/Jeannette_Walls",
            "/wiki/Jimmy_Carter",
            "/wiki/Jodi_Picoult",
            "/wiki/John_Irving",
            "/wiki/Kesha",
            "/wiki/Larry_McMurtry",
            "/wiki/Lauren_Weisberger",
            "/wiki/R._L._Stine",
            "/wiki/Sandra_Brown",
            "/wiki/Sloan_Wilson",
            "/wiki/Stephen_King",
            "/wiki/Sylvia_Nasar",
            "/wiki/Thomas_Wolfe",
            "/wiki/Ursula_K._Le_Guin",
            "/wiki/Vince_Flynn",
            "/wiki/Walter_Isaacson",
            "/wiki/ISBN",
            "/wiki/Wayback_Machine",
            "/wiki/Reuters",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Bibcode",
        "titulo": "Bibcode",
        "contenido": "el bibcode es un identificador usado por numerosas bases de datos astronomicas para citar referencias bibliograficas. el bibcode fue desarrollado para ser usado en el simbad y la base de datos de objetos extragalacticos nasa/ipac (ned), pero se usa mas ampliamente en el sistema de datos astrofisicos, tambien de la nasa.​​  el codigo tiene una longitud fija de 19 caracteres y tiene la forma:  donde yyyy son los cuatro digitos del año de publicacion de la referencia, jjjjj es un codigo que indica la publicacion de procedencia de la referencia, vvvv el numero de volumen, m la seccion de la publicacion, por ejemplo l indica la seccion de cartas, pppp indica la pagina de comienzo de la referencia y a es la primera letra del apellido del primer autor. se usan puntos para rellenar los campos no usados o para completar campos donde la longitud del codigo empleado sea mas corto que los espacios reservados a el. la alineacion se hace a la derecha para el codigo de publicacion y a la izquierda para el numero de volumen y de pagina.​​  ejemplos de codificacion: ",
        "snippet": "El bibcode es un identificador usado por numerosas bases de datos astronómicas para citar referencias bibliográficas. El bibcode fue desarrollado para ser usado en el SIMBAD y la Base de datos de objetos extragalácticos NASA/IPAC (NED), pero se usa más ampliamente en el Sistema de Datos Astrofísicos, también de la NASA.[1]​[2]​",
        "enlaces_salientes": [
            "/wiki/Bibcode",
            "/wiki/Bibcode",
            "/wiki/Bibcode",
            "/wiki/Base_de_datos",
            "/wiki/Astronom%C3%ADa",
            "/wiki/SIMBAD",
            "/wiki/NASA_Extragalactic_Database",
            "/wiki/Sistema_de_Datos_Astrof%C3%ADsicos",
            "/wiki/NASA",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Stephen_Kleene",
        "titulo": "Stephen Kleene",
        "contenido": "stephen cole kleene (hartford, connecticut; 5 de enero de 1909-madison, wisconsin; 25 de enero de 1994) fue un logico y matematico estadounidense. introdujo la operacion clausura de kleene, denotada por el simbolo v*.  kleene nacio en hartford, connecticut, estados unidos. recibio su titulo de artes en el amherts college en 1930. desde 1930 a 1935 fue un estudiante graduado y asistente investigador en la universidad de princeton, donde recibio su doctorado en matematicas en 1934, supervisado por alonzo church, por una tesis titulada una teoria de enteros positivos en logica formal. en 1935 ingreso en el departamento de matematicas uw-madison como instructor. se convirtio en asistente de profesor en 1937.  desde 1939 a 1940 fue un visitante escolar en princeton del institute for advanced study (instituto para estudio avanzado), donde fundo la teoria de las funciones recursivas, un area de interes que seria investigada por el durante toda su vida. en 1941 regreso a amherst como profesor asociado de matematicas.  durante la segunda guerra mundial, kleene fue capitan de corbeta en la armada de los estados unidos. ademas, fue instructor de navegacion en la us naval reserve’s midshipmen’s school en nueva york, y despues director de proyecto en la laboratorio de investigacion naval de los estados unidos en washington d. c.  en 1946 regreso a wisconsin, convirtiendose en profesor en 1948. ahi fue presidente de matematicas y ciencias computacionales en 1962 y 1963, y decano del colegio de letras y ciencias desde 1969 hasta 1974. en 1964 fue llamado el profesor de matematicas «cyrus c. macduffee». se retiro en 1979.  avido escalador de montañas, kleene tuvo fuerte interes en la naturaleza y el ambiente, y participo en muchas causas a favor de conservacion del medioambiente. condujo varias organizaciones profesionales, sirviendo como presidente de la association of symbolic logic (asociacion de logica simbolica) de 1956 a 1958. en 1961 fue presidente de la internacional union of the history an the philosophy of science. murio en madison, wisconsin. ",
        "snippet": "Stephen Cole Kleene (Hartford, Connecticut; 5 de enero de 1909-Madison, Wisconsin; 25 de enero de 1994) fue un lógico y matemático estadounidense. Introdujo la operación Clausura de Kleene, denotada por el símbolo V*.",
        "enlaces_salientes": [
            "/wiki/Stephen_Kleene",
            "/wiki/Stephen_Kleene",
            "/wiki/Stephen_Kleene",
            "/wiki/Hartford",
            "/wiki/Connecticut",
            "/wiki/Estados_Unidos",
            "/wiki/Madison_(Wisconsin)",
            "/wiki/Wisconsin",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Doctorado",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Amherst_College",
            "/wiki/Alonzo_Church",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Ciencia_computacional_te%C3%B3rica",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Universidad_de_Wisconsin-Madison",
            "/wiki/Armada_de_los_Estados_Unidos",
            "/wiki/Clausura_de_Kleene",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Grado_militar",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Beca_Guggenheim",
            "/wiki/Premio_Leroy_Steele",
            "/wiki/Medalla_Nacional_de_Ciencia_(Estados_Unidos)",
            "/wiki/Hartford",
            "/wiki/Connecticut",
            "/wiki/5_de_enero",
            "/wiki/1909",
            "/wiki/Madison_(Wisconsin)",
            "/wiki/Wisconsin",
            "/wiki/25_de_enero",
            "/wiki/1994",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Estados_Unidos",
            "/wiki/Clausura_de_Kleene",
            "/wiki/Amherst_College",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Institute_for_Advanced_Study",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Nueva_York",
            "/wiki/Laboratorio_de_Investigaci%C3%B3n_Naval_de_los_Estados_Unidos",
            "/wiki/Washington_D._C.",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Semantic_Scholar",
        "titulo": "Semantic Scholar",
        "contenido": "semantic scholar es un motor de busqueda respaldado por un sistema de inteligencia artificial dedicado a trabajar con publicaciones academicas. desarrollado en el allen institute for artificial intelligence, se lanzo al publico en noviembre de 2015.​ utiliza avances recientes en el procesamiento del lenguaje natural para proporcionar resumenes de articulos academicos.​  semantic scholar esta concebido para proporcionar resumenes en una sola frase de articulos cientificos. uno de sus objetivos era abordar el desafio de leer numerosos titulos y extensos resumenes en dispositivos moviles.​ tambien busca asegurar que los tres millones de articulos cientificos publicados anualmente lleguen a los lectores, ya que se estima que solo la mitad de esta literatura se lee alguna vez.​  la inteligencia artificial se utiliza para captar la esencia de un articulo mediante una tecnica \"abstractiva\".​ el proyecto se vale de una combinacion de aprendizaje automatico, procesamiento de lenguajes naturales y vision artificial para agregar un factor de analisis semantico a los metodos tradicionales de analisis de citas, pudiendo a su vez extraer figuras, entidades y aspectos relevantes de los articulos.​ en comparacion con google academico y pubmed, semantic scholar esta diseñado para destacar los articulos mas importantes e influyentes e identificar las conexiones entre ellos. a cada articulo alojado por semantic scholar se le asigna un identificador unico llamado semantic scholar corpus id (o s2cid para abreviar), como por ejemplo  en enero de 2018, tras un proyecto de 2017 que agrego articulos y resumenes de temas biomedicos, el corpus de semantic scholar incluia mas de 40 millones de articulos sobre ciencias de la computacion y biomedicina.​ en marzo de 2018, doug raymond, quien desarrollo las iniciativas de aprendizaje automatico para la plataforma amazon alexa, fue contratado para liderar el proyecto semantic scholar.​ en agosto de 2019, la cantidad de articulos incluidos habia aumentado a mas de 173 millones​ despues de la adicion de los registros de microsoft academic.​  en 2020, los usuarios de semantic scholar alcanzaron los siete millones al mes.​ ",
        "snippet": "Semantic Scholar es un motor de búsqueda respaldado por un sistema de inteligencia artificial dedicado a trabajar con publicaciones académicas. Desarrollado en el Allen Institute for Artificial Intelligence, se lanzó al público en noviembre de 2015.[1]​ Utiliza avances recientes en el procesamiento del lenguaje natural para proporcionar resúmenes de artículos académicos.[2]​",
        "enlaces_salientes": [
            "/wiki/Semantic_Scholar",
            "/wiki/Semantic_Scholar",
            "/wiki/Semantic_Scholar",
            "/wiki/Dominio_de_Internet",
            "/wiki/Sitio_web",
            "/wiki/Agregador",
            "/wiki/Instituto_Allen_para_la_Inteligencia_Artificial",
            "/wiki/Alexa_Internet",
            "/wiki/Motor_de_b%C3%BAsqueda",
            "/wiki/Inteligencia_artificial",
            "/wiki/Publicaci%C3%B3n_acad%C3%A9mica",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Procesamiento_de_lenguajes_naturales",
            "/wiki/Visi%C3%B3n_artificial",
            "/wiki/An%C3%A1lisis_de_citas",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/PubMed",
            "/wiki/Identificador",
            "/wiki/PubMed_Central",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Biomedicina",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Amazon_Alexa",
            "/wiki/Microsoft_Academic",
            "/wiki/An%C3%A1lisis_de_citas",
            "/wiki/%C3%8Dndice_de_citas",
            "/wiki/Cienciometr%C3%ADa",
            "/wiki/Science",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Stephen_Kleene",
        "titulo": "Stephen Kleene",
        "contenido": "stephen cole kleene (hartford, connecticut; 5 de enero de 1909-madison, wisconsin; 25 de enero de 1994) fue un logico y matematico estadounidense. introdujo la operacion clausura de kleene, denotada por el simbolo v*.  kleene nacio en hartford, connecticut, estados unidos. recibio su titulo de artes en el amherts college en 1930. desde 1930 a 1935 fue un estudiante graduado y asistente investigador en la universidad de princeton, donde recibio su doctorado en matematicas en 1934, supervisado por alonzo church, por una tesis titulada una teoria de enteros positivos en logica formal. en 1935 ingreso en el departamento de matematicas uw-madison como instructor. se convirtio en asistente de profesor en 1937.  desde 1939 a 1940 fue un visitante escolar en princeton del institute for advanced study (instituto para estudio avanzado), donde fundo la teoria de las funciones recursivas, un area de interes que seria investigada por el durante toda su vida. en 1941 regreso a amherst como profesor asociado de matematicas.  durante la segunda guerra mundial, kleene fue capitan de corbeta en la armada de los estados unidos. ademas, fue instructor de navegacion en la us naval reserve’s midshipmen’s school en nueva york, y despues director de proyecto en la laboratorio de investigacion naval de los estados unidos en washington d. c.  en 1946 regreso a wisconsin, convirtiendose en profesor en 1948. ahi fue presidente de matematicas y ciencias computacionales en 1962 y 1963, y decano del colegio de letras y ciencias desde 1969 hasta 1974. en 1964 fue llamado el profesor de matematicas «cyrus c. macduffee». se retiro en 1979.  avido escalador de montañas, kleene tuvo fuerte interes en la naturaleza y el ambiente, y participo en muchas causas a favor de conservacion del medioambiente. condujo varias organizaciones profesionales, sirviendo como presidente de la association of symbolic logic (asociacion de logica simbolica) de 1956 a 1958. en 1961 fue presidente de la internacional union of the history an the philosophy of science. murio en madison, wisconsin. ",
        "snippet": "Stephen Cole Kleene (Hartford, Connecticut; 5 de enero de 1909-Madison, Wisconsin; 25 de enero de 1994) fue un lógico y matemático estadounidense. Introdujo la operación Clausura de Kleene, denotada por el símbolo V*.",
        "enlaces_salientes": [
            "/wiki/Stephen_Kleene",
            "/wiki/Stephen_Kleene",
            "/wiki/Stephen_Kleene",
            "/wiki/Hartford",
            "/wiki/Connecticut",
            "/wiki/Estados_Unidos",
            "/wiki/Madison_(Wisconsin)",
            "/wiki/Wisconsin",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Doctorado",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Amherst_College",
            "/wiki/Alonzo_Church",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Fil%C3%B3sofo",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Ciencia_computacional_te%C3%B3rica",
            "/wiki/Teor%C3%ADa_de_la_computaci%C3%B3n",
            "/wiki/Universidad_de_Wisconsin-Madison",
            "/wiki/Armada_de_los_Estados_Unidos",
            "/wiki/Clausura_de_Kleene",
            "/wiki/C%C3%A1lculo_lambda",
            "/wiki/Grado_militar",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Beca_Guggenheim",
            "/wiki/Premio_Leroy_Steele",
            "/wiki/Medalla_Nacional_de_Ciencia_(Estados_Unidos)",
            "/wiki/Hartford",
            "/wiki/Connecticut",
            "/wiki/5_de_enero",
            "/wiki/1909",
            "/wiki/Madison_(Wisconsin)",
            "/wiki/Wisconsin",
            "/wiki/25_de_enero",
            "/wiki/1994",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Estados_Unidos",
            "/wiki/Clausura_de_Kleene",
            "/wiki/Amherst_College",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Institute_for_Advanced_Study",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Nueva_York",
            "/wiki/Laboratorio_de_Investigaci%C3%B3n_Naval_de_los_Estados_Unidos",
            "/wiki/Washington_D._C.",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/JSTOR",
        "titulo": "JSTOR",
        "contenido": "jstor (abreviatura en ingles de journal storage, «almacen de publicaciones periodicas») es un sistema de almacenamiento en linea de publicaciones academicas. fundada en 1995, jstor es una sociedad estadounidense con base en la ciudad de nueva york.  jstor fue concebida como la solucion a uno de los mayores problemas que deben enfrentar hoy las bibliotecas (especialmente las universitarias y las de investigacion) debido al creciente aumento de publicaciones academicas en la actualidad. william g. bowen, su fundador, fue presidente de la universidad de princeton desde el año 1972 al 1988.​ en general, a muchas bibliotecas se les hacia excesivamente costoso el mantener una interesante coleccion de publicaciones debido a cuestiones de espacio, por lo que encontraron en jstor una solucion viable a dicha cuestion, digitalizando muchos de sus titulos y almacenandolos en su base de datos en linea con la confianza en que estos permanecerian disponibles a largo plazo.  a partir del exito alcanzado con el proyecto inicial, bowen y kevin guthrie (quien seria mas tarde presidente de jstor) se interesaron en ampliar el numero de publicaciones participantes hasta la fecha. de esta manera se reunieron con representantes de la real sociedad de londres y, como resultado, se pacto la digitalizacion de sus principales articulos que se remiten a sus origenes en 1665. el trabajo de inclusion de dichos volumenes en la base de datos en linea fue finalizado en diciembre de 2000.​  hacia junio de 2007, la base de datos contaba con mas de 23 millones de paginas de texto.​ hacia julio de 2007, el material de jstor es provisto por 446 editores. cerca de 53 millones de busquedas de archivos fueron realizadas entre enero y julio de 2007.​  el acceso a jstor se encuentra autorizado a bibliotecas, universidades y editores de todo el mundo que han firmado un acuerdo con la institucion. estas, a su vez, facilitan el acceso de sus miembros a jstor de manera gratuita a traves de internet. tambien existe la posibilidad de suscribirse, mediante pago, de manera individual o privada.  el programador y activista de internet aaron swartz, que fue coautor de los rss y colaboro en la creacion de las licencias creative commons, fue acusado el 19 de julio de 2011 de descargar 4.8 millones de articulos y otros documentos de la base de datos de jstor, presuntamente con el fin de compartirlos a traves de sitios de descarga gratuita.​ poco antes de que se iniciara el juicio, aaron swartz aparecio muerto en su casa a la edad de 26 años. segun la investigacion del caso, se trataria de un suicidio debido al acoso por parte del deficiente sistema de justicia de estados unidos y del fiscal stephen heymann, el cual intento avanzar su carrera con el caso de aaron swartz.​   ",
        "snippet": "JSTOR (abreviatura en inglés de Journal STORage, «almacén de publicaciones periódicas») es un sistema de almacenamiento en línea de publicaciones académicas. Fundada en 1995, JSTOR es una sociedad estadounidense con base en la ciudad de Nueva York.",
        "enlaces_salientes": [
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/Dominio_de_Internet",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Biblioteca_digital",
            "/wiki/Sitio_web",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/1995",
            "/wiki/Alexa_Internet",
            "/wiki/Estadounidense",
            "/wiki/Nueva_York",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Royal_Society_de_Londres",
            "/wiki/Internet",
            "/wiki/Aaron_Swartz",
            "/wiki/RSS",
            "/wiki/Licencias_Creative_Commons",
            "/wiki/Wayback_Machine",
            "/wiki/Princeton_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/BIBSYS"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Donald_Knuth",
        "titulo": "Donald Knuth",
        "contenido": "donald ervin knuth (milwaukee, wisconsin; 10 de enero 1938) es un reconocido experto en ciencias de la computacion estadounidense y matematico, famoso por su fructifera investigacion dentro del analisis de algoritmos y compiladores.​  es profesor emerito de la universidad de stanford.​  knuth nacio en milwaukee, wisconsin, hijo de ervin henry knuth y louise marie bohning.​ describe su herencia como \"alemana luterana del medio oeste\".​: 66  su padre tenia una pequeña imprenta y enseñaba contabilidad.​ donald, estudiante del milwaukee lutheran high school, penso en formas ingeniosas de resolver problemas. por ejemplo, en octavo grado, participo en un concurso para encontrar el numero de palabras que las letras en \"ziegler's giant bar\"  (\"barra gigante de ziegler\") podian ser reordenadas; los jueces habian identificado 2.500 palabras de este tipo. con el tiempo ganado fuera de la escuela debido a un fingido dolor de estomago, y trabajando el problema en sentido contrario, knuth utilizo un diccionario no abreviado y determino si cada entrada del diccionario podia formarse utilizando las letras de la frase. usando este algoritmo, identifico mas de 4.500 palabras, ganando el concurso.​{rp|3} como premios, el colegio recibio un nuevo televisor y suficientes chocolatinas para que todos sus compañeros se las comieran.​  knuth recibio una beca en fisica en la case institute of technology (ahora parte de la case western reserve university) en cleveland, ohio, matriculandose en 1956.​ tambien se unio al capitulo beta nu de la fraternidad theta chi. mientras estudiaba fisica en case, knuth conocio el ibm 650, un primer ordenador comercial. despues de leer el manual del ordenador, knuth decidio reescribir el codigo ensamblador y compilador de la maquina utilizada en su escuela, porque creia que podia hacerlo mejor.​  en 1958, knuth creo un programa para ayudar al equipo de baloncesto de su colegio a ganar sus partidos.​ asigno \"valores\" a los jugadores para calibrar su probabilidad de obtener puntos, un enfoque novedoso del que posteriormente informaron newsweek y cbs evening news.​  knuth fue uno de los editores fundadores de la revista engineering and science review del instituto case, que gano un premio nacional como mejor revista tecnica en 1959.​​ luego cambio la fisica por las matematicas, y recibio dos titulos de case en 1960:​ su licenciatura en ciencias, y simultaneamente un master en ciencias por un premio especial de la facultad, que considero su trabajo excepcionalmente destacado.​​  en 1963, con el matematico marshall hall como asesor,​ se doctoro en matematicas en el california institute of technology.​  despues de recibir su doctorado, knuth se unio a la facultad de caltech como profesor asistente.​  acepto el encargo de escribir un libro sobre lenguaje de programacion informatico compilador. mientras trabajaba en este proyecto, knuth decidio que no podia tratar adecuadamente el tema sin desarrollar primero una teoria fundamental de la programacion de ordenadores, que se convirtio en el arte de la programacion de ordenadores. originalmente planeo publicarlo como un solo libro. a medida que knuth desarrollaba su esquema para el libro, llego a la conclusion de que necesitaba seis volumenes, y luego siete, para cubrir completamente el tema. publico el primer volumen en 1968.​  justo antes de publicar el primer volumen de the art of computer programming, knuth dejo caltech para aceptar un empleo en el division de investigacion de comunicaciones del instituto de analisis de defensa, situado entonces en el campus de la princeton university, que realizaba investigaciones matematicas en criptografia para apoyar a la national security agency.  en 1967, knuth asistio a una conferencia de la sociedad de matematica industrial y aplicada y alguien le pregunto a que se dedicaba. en aquella epoca, la informatica se dividia en analisis numerico, inteligencia artificial y lenguajes de programacion. basandose en su estudio y en el libro the art of computer programming, knuth decidio que la proxima vez que alguien le preguntara diria: \"analisis de algoritmos\".\"​  knuth dejo entonces su puesto para unirse a la facultad de la universidad de stanford en 1969,​ donde ahora es profesor emerito de ciencias de la computacion fletcher jones.​​  esta casado con jill carter knuth. tienen dos hijos.  ha sido galardonado con el premio fundacion bbva fronteras del conocimiento 2010 en la categoria de tecnologias de la informacion y la comunicacion.​  se le conoce principalmente por ser el autor de la obra the art of computer programming (el arte de programar computadoras), una de las mas respetadas referencias en el campo de las ciencias de la computacion. sento las bases y dio nombre al analisis de algoritmos, y ha realizado numerosos aportes a varias ramas teoricas de la informatica. es el creador de tex, del sistema de diseño de tipos metafont y del estilo de programacion conocido como programacion literaria (literate programming).​ knuth es conocido como el \"padre del analisis de algoritmos\".​  knuth es un programador conocido por su humor geek: ofrece una recompensa de 2,56 dolares a quien encuentre errores conceptuales o tipograficos en sus libros (la razon detras de la extraña cifra es que «256 centavos son 1 dolar hexadecimal»), y por otro lado ofrecia 3,16 por errores en 3:16 bible texts illuminated. enumero las distintas versiones de tex de manera que se aproximaran al numero π (3, 3.1, 3.14, etc.), al igual que los numeros de version de metafont se van aproximando a e. su cita mas celebre, al enviarle sus comentarios a un colega autor de un algoritmo, es: «cuidado con los errores en el codigo anterior; solo he demostrado que es correcto, no lo he probado».  knuth es el autor de 3:16 bible texts illuminated (1991, isbn 0-89579-252-4), libro en el que intenta examinar la biblia por un proceso de «muestreo estratificado aleatorio», es decir, un analisis del capitulo 3, versiculo 16 de cada libro. cada versiculo se acompaña de un renderizado en arte caligrafico, realizado por un grupo de caligrafos capitaneado por hermann zapf.    knuth es tambien el autor de numeros surrealistas,​ una novela matematica sobre la construccion de john conway de la teoria de conjuntos de un sistema alternativo de numeros. en lugar de limitarse a explicar el tema, el libro pretende mostrar el desarrollo de las matematicas. knuth queria que el libro preparara a los estudiantes para realizar una investigacion original y creativa.  en 1995, knuth escribio el prologo del libro a=b de marko petkovsek, herbert wilf y doron zeilberger.​ knuth tambien es un colaborador ocasional de rompecabezas linguisticos en word ways: the journal of recreational linguistics.​  knuth tambien ha profundizado en la matematica recreativa.  contribuyo con articulos al journal of recreational mathematics a partir de la decada de 1960, y fue reconocido como uno de los principales colaboradores en el libro de joseph madachy mathematics on vacation.​  knuth tambien ha aparecido en una serie de numberphile​ y videos de computerphile en youtube donde ha tratado temas desde la escritura de numeros surreales​ a por que no utiliza el correo electronico.​   ",
        "snippet": "Donald Ervin Knuth (Milwaukee, Wisconsin; 10 de enero 1938) es un reconocido experto en ciencias de la computación estadounidense y matemático, famoso por su fructífera investigación dentro del análisis de algoritmos y compiladores.[1]​",
        "enlaces_salientes": [
            "/wiki/Donald_Knuth",
            "/wiki/Donald_Knuth",
            "/wiki/Donald_Knuth",
            "/wiki/10_de_enero",
            "/wiki/1938",
            "/wiki/Milwaukee",
            "/wiki/Wisconsin",
            "/wiki/Estados_Unidos",
            "/wiki/Estados_Unidos",
            "/wiki/Luteranismo",
            "/wiki/Universidad_Case_de_la_Reserva_Occidental",
            "/wiki/Master_of_Science",
            "/wiki/Bachelor_of_Science",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Instituto_Tecnol%C3%B3gico_de_California",
            "/wiki/Philosophi%C3%A6_doctor",
            "/wiki/Marshall_Hall_(matem%C3%A1tico)",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Escritor",
            "/wiki/Programador",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Ingeniero",
            "/wiki/Acad%C3%A9mico_(ocupaci%C3%B3n)",
            "/wiki/Combinatoria",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Catedr%C3%A1tico_de_universidad",
            "/wiki/Universidad_Stanford",
            "/wiki/Burroughs_Corporation",
            "/wiki/Instituto_de_An%C3%A1lisis_de_la_Defensa",
            "/wiki/Michael_Fredman",
            "/wiki/Vaughan_Pratt",
            "/wiki/%C3%93rgano_(m%C3%BAsica)",
            "/wiki/TeX",
            "/wiki/METAFONT",
            "/wiki/The_Art_of_Computer_Programming",
            "/wiki/Computer_Modern",
            "/wiki/Programaci%C3%B3n_literaria",
            "/wiki/Academia_Noruega_de_Ciencias_y_Letras",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Academia_Nacional_de_Ingenier%C3%ADa_(Estados_Unidos)",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Institute_of_Electrical_and_Electronics_Engineers",
            "/wiki/Academia_de_Ciencias_de_Francia",
            "/wiki/Academia_de_Ciencias_de_Baviera",
            "/wiki/Royal_Society",
            "/wiki/Academia_de_Ciencias_de_Rusia",
            "/wiki/Sociedad_de_Matem%C3%A1ticas_Aplicadas_e_Industriales",
            "/wiki/British_Computer_Society",
            "/wiki/American_Philosophical_Society",
            "/wiki/American_Mathematical_Society",
            "/wiki/London_Mathematical_Society",
            "/wiki/Milwaukee",
            "/wiki/Wisconsin",
            "/wiki/10_de_enero",
            "/wiki/1938",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Matem%C3%A1tico",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Compilador",
            "/wiki/Profesor_Em%C3%A9rito",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Milwaukee",
            "/wiki/Wisconsin",
            "/wiki/Case_Western_Reserve_University",
            "/wiki/Case_Western_Reserve_University",
            "/wiki/Cleveland",
            "/wiki/IBM_650",
            "/wiki/Ordenador",
            "/wiki/Newsweek",
            "/wiki/CBS_Evening_News",
            "/wiki/Marshall_Hall_(matem%C3%A1tico)",
            "/wiki/California_Institute_of_Technology",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Compilador",
            "/wiki/Princeton_University",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/National_Security_Agency",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Premios_Fundaci%C3%B3n_BBVA_Fronteras_del_Conocimiento",
            "/wiki/Tecnolog%C3%ADas_de_la_informaci%C3%B3n_y_la_comunicaci%C3%B3n",
            "/wiki/The_Art_of_Computer_Programming",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Inform%C3%A1tica",
            "/wiki/TeX",
            "/wiki/METAFONT",
            "/wiki/Programaci%C3%B3n_literaria",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Programador",
            "/wiki/Geek",
            "/wiki/D%C3%B3lar",
            "/wiki/Hexadecimal",
            "/wiki/N%C3%BAmero_%CF%80",
            "/wiki/METAFONT",
            "/wiki/N%C3%BAmero_e",
            "/wiki/Algoritmo",
            "/wiki/1991",
            "/wiki/Biblia",
            "/wiki/Caligraf%C3%ADa",
            "/wiki/Hermann_Zapf",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/John_Horton_Conway",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Herbert_Wilf",
            "/wiki/Doron_Zeilberger",
            "/wiki/Matem%C3%A1tica_recreativa",
            "/wiki/YouTube",
            "/wiki/Premio_Knuth",
            "/wiki/Algoritmo_Knuth-Morris-Pratt",
            "/wiki/Notaci%C3%B3n_flecha_de_Knuth",
            "/wiki/Wayback_Machine",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Edward_Feigenbaum",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Quanta_Magazine",
            "/wiki/Stanford_University",
            "/wiki/Richard_M._Karp",
            "/wiki/Digital_object_identifier",
            "/wiki/Charles_Bachman",
            "/wiki/Premio_Turing",
            "/wiki/1974",
            "/wiki/Allen_Newell",
            "/wiki/Herbert_Alexander_Simon",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Scopus",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Royal_Society",
            "/wiki/Open_Library",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Pers%C3%A9e_(portal)"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Donald_Knuth",
        "titulo": "Donald Knuth",
        "contenido": "donald ervin knuth (milwaukee, wisconsin; 10 de enero 1938) es un reconocido experto en ciencias de la computacion estadounidense y matematico, famoso por su fructifera investigacion dentro del analisis de algoritmos y compiladores.​  es profesor emerito de la universidad de stanford.​  knuth nacio en milwaukee, wisconsin, hijo de ervin henry knuth y louise marie bohning.​ describe su herencia como \"alemana luterana del medio oeste\".​: 66  su padre tenia una pequeña imprenta y enseñaba contabilidad.​ donald, estudiante del milwaukee lutheran high school, penso en formas ingeniosas de resolver problemas. por ejemplo, en octavo grado, participo en un concurso para encontrar el numero de palabras que las letras en \"ziegler's giant bar\"  (\"barra gigante de ziegler\") podian ser reordenadas; los jueces habian identificado 2.500 palabras de este tipo. con el tiempo ganado fuera de la escuela debido a un fingido dolor de estomago, y trabajando el problema en sentido contrario, knuth utilizo un diccionario no abreviado y determino si cada entrada del diccionario podia formarse utilizando las letras de la frase. usando este algoritmo, identifico mas de 4.500 palabras, ganando el concurso.​{rp|3} como premios, el colegio recibio un nuevo televisor y suficientes chocolatinas para que todos sus compañeros se las comieran.​  knuth recibio una beca en fisica en la case institute of technology (ahora parte de la case western reserve university) en cleveland, ohio, matriculandose en 1956.​ tambien se unio al capitulo beta nu de la fraternidad theta chi. mientras estudiaba fisica en case, knuth conocio el ibm 650, un primer ordenador comercial. despues de leer el manual del ordenador, knuth decidio reescribir el codigo ensamblador y compilador de la maquina utilizada en su escuela, porque creia que podia hacerlo mejor.​  en 1958, knuth creo un programa para ayudar al equipo de baloncesto de su colegio a ganar sus partidos.​ asigno \"valores\" a los jugadores para calibrar su probabilidad de obtener puntos, un enfoque novedoso del que posteriormente informaron newsweek y cbs evening news.​  knuth fue uno de los editores fundadores de la revista engineering and science review del instituto case, que gano un premio nacional como mejor revista tecnica en 1959.​​ luego cambio la fisica por las matematicas, y recibio dos titulos de case en 1960:​ su licenciatura en ciencias, y simultaneamente un master en ciencias por un premio especial de la facultad, que considero su trabajo excepcionalmente destacado.​​  en 1963, con el matematico marshall hall como asesor,​ se doctoro en matematicas en el california institute of technology.​  despues de recibir su doctorado, knuth se unio a la facultad de caltech como profesor asistente.​  acepto el encargo de escribir un libro sobre lenguaje de programacion informatico compilador. mientras trabajaba en este proyecto, knuth decidio que no podia tratar adecuadamente el tema sin desarrollar primero una teoria fundamental de la programacion de ordenadores, que se convirtio en el arte de la programacion de ordenadores. originalmente planeo publicarlo como un solo libro. a medida que knuth desarrollaba su esquema para el libro, llego a la conclusion de que necesitaba seis volumenes, y luego siete, para cubrir completamente el tema. publico el primer volumen en 1968.​  justo antes de publicar el primer volumen de the art of computer programming, knuth dejo caltech para aceptar un empleo en el division de investigacion de comunicaciones del instituto de analisis de defensa, situado entonces en el campus de la princeton university, que realizaba investigaciones matematicas en criptografia para apoyar a la national security agency.  en 1967, knuth asistio a una conferencia de la sociedad de matematica industrial y aplicada y alguien le pregunto a que se dedicaba. en aquella epoca, la informatica se dividia en analisis numerico, inteligencia artificial y lenguajes de programacion. basandose en su estudio y en el libro the art of computer programming, knuth decidio que la proxima vez que alguien le preguntara diria: \"analisis de algoritmos\".\"​  knuth dejo entonces su puesto para unirse a la facultad de la universidad de stanford en 1969,​ donde ahora es profesor emerito de ciencias de la computacion fletcher jones.​​  esta casado con jill carter knuth. tienen dos hijos.  ha sido galardonado con el premio fundacion bbva fronteras del conocimiento 2010 en la categoria de tecnologias de la informacion y la comunicacion.​  se le conoce principalmente por ser el autor de la obra the art of computer programming (el arte de programar computadoras), una de las mas respetadas referencias en el campo de las ciencias de la computacion. sento las bases y dio nombre al analisis de algoritmos, y ha realizado numerosos aportes a varias ramas teoricas de la informatica. es el creador de tex, del sistema de diseño de tipos metafont y del estilo de programacion conocido como programacion literaria (literate programming).​ knuth es conocido como el \"padre del analisis de algoritmos\".​  knuth es un programador conocido por su humor geek: ofrece una recompensa de 2,56 dolares a quien encuentre errores conceptuales o tipograficos en sus libros (la razon detras de la extraña cifra es que «256 centavos son 1 dolar hexadecimal»), y por otro lado ofrecia 3,16 por errores en 3:16 bible texts illuminated. enumero las distintas versiones de tex de manera que se aproximaran al numero π (3, 3.1, 3.14, etc.), al igual que los numeros de version de metafont se van aproximando a e. su cita mas celebre, al enviarle sus comentarios a un colega autor de un algoritmo, es: «cuidado con los errores en el codigo anterior; solo he demostrado que es correcto, no lo he probado».  knuth es el autor de 3:16 bible texts illuminated (1991, isbn 0-89579-252-4), libro en el que intenta examinar la biblia por un proceso de «muestreo estratificado aleatorio», es decir, un analisis del capitulo 3, versiculo 16 de cada libro. cada versiculo se acompaña de un renderizado en arte caligrafico, realizado por un grupo de caligrafos capitaneado por hermann zapf.    knuth es tambien el autor de numeros surrealistas,​ una novela matematica sobre la construccion de john conway de la teoria de conjuntos de un sistema alternativo de numeros. en lugar de limitarse a explicar el tema, el libro pretende mostrar el desarrollo de las matematicas. knuth queria que el libro preparara a los estudiantes para realizar una investigacion original y creativa.  en 1995, knuth escribio el prologo del libro a=b de marko petkovsek, herbert wilf y doron zeilberger.​ knuth tambien es un colaborador ocasional de rompecabezas linguisticos en word ways: the journal of recreational linguistics.​  knuth tambien ha profundizado en la matematica recreativa.  contribuyo con articulos al journal of recreational mathematics a partir de la decada de 1960, y fue reconocido como uno de los principales colaboradores en el libro de joseph madachy mathematics on vacation.​  knuth tambien ha aparecido en una serie de numberphile​ y videos de computerphile en youtube donde ha tratado temas desde la escritura de numeros surreales​ a por que no utiliza el correo electronico.​   ",
        "snippet": "Donald Ervin Knuth (Milwaukee, Wisconsin; 10 de enero 1938) es un reconocido experto en ciencias de la computación estadounidense y matemático, famoso por su fructífera investigación dentro del análisis de algoritmos y compiladores.[1]​",
        "enlaces_salientes": [
            "/wiki/Donald_Knuth",
            "/wiki/Donald_Knuth",
            "/wiki/Donald_Knuth",
            "/wiki/10_de_enero",
            "/wiki/1938",
            "/wiki/Milwaukee",
            "/wiki/Wisconsin",
            "/wiki/Estados_Unidos",
            "/wiki/Estados_Unidos",
            "/wiki/Luteranismo",
            "/wiki/Universidad_Case_de_la_Reserva_Occidental",
            "/wiki/Master_of_Science",
            "/wiki/Bachelor_of_Science",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Instituto_Tecnol%C3%B3gico_de_California",
            "/wiki/Philosophi%C3%A6_doctor",
            "/wiki/Marshall_Hall_(matem%C3%A1tico)",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Inform%C3%A1tico_te%C3%B3rico",
            "/wiki/Escritor",
            "/wiki/Programador",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Ingeniero",
            "/wiki/Acad%C3%A9mico_(ocupaci%C3%B3n)",
            "/wiki/Combinatoria",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Catedr%C3%A1tico_de_universidad",
            "/wiki/Universidad_Stanford",
            "/wiki/Burroughs_Corporation",
            "/wiki/Instituto_de_An%C3%A1lisis_de_la_Defensa",
            "/wiki/Michael_Fredman",
            "/wiki/Vaughan_Pratt",
            "/wiki/%C3%93rgano_(m%C3%BAsica)",
            "/wiki/TeX",
            "/wiki/METAFONT",
            "/wiki/The_Art_of_Computer_Programming",
            "/wiki/Computer_Modern",
            "/wiki/Programaci%C3%B3n_literaria",
            "/wiki/Academia_Noruega_de_Ciencias_y_Letras",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Academia_Nacional_de_Ingenier%C3%ADa_(Estados_Unidos)",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Institute_of_Electrical_and_Electronics_Engineers",
            "/wiki/Academia_de_Ciencias_de_Francia",
            "/wiki/Academia_de_Ciencias_de_Baviera",
            "/wiki/Royal_Society",
            "/wiki/Academia_de_Ciencias_de_Rusia",
            "/wiki/Sociedad_de_Matem%C3%A1ticas_Aplicadas_e_Industriales",
            "/wiki/British_Computer_Society",
            "/wiki/American_Philosophical_Society",
            "/wiki/American_Mathematical_Society",
            "/wiki/London_Mathematical_Society",
            "/wiki/Milwaukee",
            "/wiki/Wisconsin",
            "/wiki/10_de_enero",
            "/wiki/1938",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Matem%C3%A1tico",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Compilador",
            "/wiki/Profesor_Em%C3%A9rito",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Milwaukee",
            "/wiki/Wisconsin",
            "/wiki/Case_Western_Reserve_University",
            "/wiki/Case_Western_Reserve_University",
            "/wiki/Cleveland",
            "/wiki/IBM_650",
            "/wiki/Ordenador",
            "/wiki/Newsweek",
            "/wiki/CBS_Evening_News",
            "/wiki/Marshall_Hall_(matem%C3%A1tico)",
            "/wiki/California_Institute_of_Technology",
            "/wiki/Lenguaje_de_programaci%C3%B3n",
            "/wiki/Compilador",
            "/wiki/Princeton_University",
            "/wiki/Criptograf%C3%ADa",
            "/wiki/National_Security_Agency",
            "/wiki/Universidad_de_Stanford",
            "/wiki/Premios_Fundaci%C3%B3n_BBVA_Fronteras_del_Conocimiento",
            "/wiki/Tecnolog%C3%ADas_de_la_informaci%C3%B3n_y_la_comunicaci%C3%B3n",
            "/wiki/The_Art_of_Computer_Programming",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Inform%C3%A1tica",
            "/wiki/TeX",
            "/wiki/METAFONT",
            "/wiki/Programaci%C3%B3n_literaria",
            "/wiki/An%C3%A1lisis_de_algoritmos",
            "/wiki/Programador",
            "/wiki/Geek",
            "/wiki/D%C3%B3lar",
            "/wiki/Hexadecimal",
            "/wiki/N%C3%BAmero_%CF%80",
            "/wiki/METAFONT",
            "/wiki/N%C3%BAmero_e",
            "/wiki/Algoritmo",
            "/wiki/1991",
            "/wiki/Biblia",
            "/wiki/Caligraf%C3%ADa",
            "/wiki/Hermann_Zapf",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/John_Horton_Conway",
            "/wiki/Teor%C3%ADa_de_conjuntos",
            "/wiki/Herbert_Wilf",
            "/wiki/Doron_Zeilberger",
            "/wiki/Matem%C3%A1tica_recreativa",
            "/wiki/YouTube",
            "/wiki/Premio_Knuth",
            "/wiki/Algoritmo_Knuth-Morris-Pratt",
            "/wiki/Notaci%C3%B3n_flecha_de_Knuth",
            "/wiki/Wayback_Machine",
            "/wiki/MacTutor_History_of_Mathematics_archive",
            "/wiki/Universidad_de_Saint_Andrews",
            "/wiki/Edward_Feigenbaum",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Association_for_Computing_Machinery",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Quanta_Magazine",
            "/wiki/Stanford_University",
            "/wiki/Richard_M._Karp",
            "/wiki/Digital_object_identifier",
            "/wiki/Charles_Bachman",
            "/wiki/Premio_Turing",
            "/wiki/1974",
            "/wiki/Allen_Newell",
            "/wiki/Herbert_Alexander_Simon",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Scopus",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Royal_Society",
            "/wiki/Open_Library",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Pers%C3%A9e_(portal)"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Semantic_Scholar",
        "titulo": "Semantic Scholar",
        "contenido": "semantic scholar es un motor de busqueda respaldado por un sistema de inteligencia artificial dedicado a trabajar con publicaciones academicas. desarrollado en el allen institute for artificial intelligence, se lanzo al publico en noviembre de 2015.​ utiliza avances recientes en el procesamiento del lenguaje natural para proporcionar resumenes de articulos academicos.​  semantic scholar esta concebido para proporcionar resumenes en una sola frase de articulos cientificos. uno de sus objetivos era abordar el desafio de leer numerosos titulos y extensos resumenes en dispositivos moviles.​ tambien busca asegurar que los tres millones de articulos cientificos publicados anualmente lleguen a los lectores, ya que se estima que solo la mitad de esta literatura se lee alguna vez.​  la inteligencia artificial se utiliza para captar la esencia de un articulo mediante una tecnica \"abstractiva\".​ el proyecto se vale de una combinacion de aprendizaje automatico, procesamiento de lenguajes naturales y vision artificial para agregar un factor de analisis semantico a los metodos tradicionales de analisis de citas, pudiendo a su vez extraer figuras, entidades y aspectos relevantes de los articulos.​ en comparacion con google academico y pubmed, semantic scholar esta diseñado para destacar los articulos mas importantes e influyentes e identificar las conexiones entre ellos. a cada articulo alojado por semantic scholar se le asigna un identificador unico llamado semantic scholar corpus id (o s2cid para abreviar), como por ejemplo  en enero de 2018, tras un proyecto de 2017 que agrego articulos y resumenes de temas biomedicos, el corpus de semantic scholar incluia mas de 40 millones de articulos sobre ciencias de la computacion y biomedicina.​ en marzo de 2018, doug raymond, quien desarrollo las iniciativas de aprendizaje automatico para la plataforma amazon alexa, fue contratado para liderar el proyecto semantic scholar.​ en agosto de 2019, la cantidad de articulos incluidos habia aumentado a mas de 173 millones​ despues de la adicion de los registros de microsoft academic.​  en 2020, los usuarios de semantic scholar alcanzaron los siete millones al mes.​ ",
        "snippet": "Semantic Scholar es un motor de búsqueda respaldado por un sistema de inteligencia artificial dedicado a trabajar con publicaciones académicas. Desarrollado en el Allen Institute for Artificial Intelligence, se lanzó al público en noviembre de 2015.[1]​ Utiliza avances recientes en el procesamiento del lenguaje natural para proporcionar resúmenes de artículos académicos.[2]​",
        "enlaces_salientes": [
            "/wiki/Semantic_Scholar",
            "/wiki/Semantic_Scholar",
            "/wiki/Semantic_Scholar",
            "/wiki/Dominio_de_Internet",
            "/wiki/Sitio_web",
            "/wiki/Agregador",
            "/wiki/Instituto_Allen_para_la_Inteligencia_Artificial",
            "/wiki/Alexa_Internet",
            "/wiki/Motor_de_b%C3%BAsqueda",
            "/wiki/Inteligencia_artificial",
            "/wiki/Publicaci%C3%B3n_acad%C3%A9mica",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Procesamiento_de_lenguajes_naturales",
            "/wiki/Visi%C3%B3n_artificial",
            "/wiki/An%C3%A1lisis_de_citas",
            "/wiki/Google_Acad%C3%A9mico",
            "/wiki/PubMed",
            "/wiki/Identificador",
            "/wiki/PubMed_Central",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Ciencias_de_la_computaci%C3%B3n",
            "/wiki/Biomedicina",
            "/wiki/Aprendizaje_autom%C3%A1tico",
            "/wiki/Amazon_Alexa",
            "/wiki/Microsoft_Academic",
            "/wiki/An%C3%A1lisis_de_citas",
            "/wiki/%C3%8Dndice_de_citas",
            "/wiki/Cienciometr%C3%ADa",
            "/wiki/Science",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/A.A._Markov",
        "titulo": "Andréi Márkov",
        "contenido": "andrei andreyevich markov (en ruso: андреи андреевич марков; riazan, 14 de junio de 1856 — san petersburgo, 20 de julio de 1922) fue un matematico ruso conocido por sus trabajos en la teoria de los numeros y la teoria de probabilidades.  markov nacio en riazan, imperio ruso. su madre nadezhda petrovna era hija de un trabajador del estado, y su padre andrei grigorievich markov, el hijo de un diacono, estudio en un seminario y obtuvo un puesto como clerigo.​ antes de los 10 años, su padre, un funcionario estatal, fue trasladado a san petersburgo donde andrei entro a estudiar en un instituto de la ciudad. desde el principio mostro cierto talento para las matematicas y cuando se graduo en 1874 ya conocia a varios matematicos de la universidad de san petersburgo, donde ingreso tras su graduacion. en la universidad fue discipulo de pafnuti chebyshov y tras realizar sus tesis de maestria y doctorado, en 1886 accedio como adjunto a la academia de ciencias de san petersburgo, a propuesta del propio chebyshov. diez años despues markov habia ganado el puesto de academico regular. desde 1880, tras defender su tesis de maestria, markov impartio clases en la universidad y, cuando el propio chebyshov dejo la universidad tres años despues, fue markov quien le sustituyo en los cursos de teoria de probabilidad. en 1905, tras 25 años de actividad academica, markov se retiro definitivamente de la universidad, aunque siguio impartiendo algunos cursos sobre la teoria de la probabilidad.  aparte de su perfil academico, andrei markov fue un convencido activista politico. se opuso a los privilegios de la nobleza zarista y llego a rechazar las condecoraciones del propio zar en protesta por algunas decisiones politicas relacionadas con la academia de ciencias. hasta tal punto llego su implicacion en la politica que llego a ser conocido con el sobrenombre de «el academico militante».  markov arrastro durante toda su vida problemas relacionados con una malformacion congenita en la rodilla que le llevaria varias veces al quirofano y que, con el tiempo, fue la causa de su muerte cuando el 20 de julio de 1922 una de las muchas operaciones a las que se sometio le produjo una infeccion generalizada de la que no pudo recuperarse.  aunque markov influyo sobre diversos campos de las matematicas, por ejemplo en sus trabajos sobre fracciones continuas, la historia le recordara principalmente por sus resultados relacionados con la teoria de la probabilidad. en 1887 completo la prueba que permitia generalizar el teorema central del limite y que ya habia avanzado chebyshov. pero su aportacion mas conocida es otra: su trabajo teorico en el campo de los procesos en los que estan involucrados componentes aleatorios (procesos estocasticos) darian fruto en un instrumento matematico que actualmente se conoce como cadena de markov: secuencias de valores de una variable aleatoria en las que el valor de la variable en el futuro depende del valor de la variable en el presente, pero es independiente de la historia de dicha variable. las cadenas de markov, hoy dia, se consideran una herramienta esencial en disciplinas como la economia, la ingenieria, la investigacion de operaciones y muchas otras.  ademas del uso de su apellido en terminologia matematica, se refiere a: ",
        "snippet": "Andréi Andréyevich Márkov (en ruso: Андре́й Андре́евич Ма́рков; Riazán, 14 de junio de 1856 — San Petersburgo, 20 de julio de 1922) fue un matemático ruso conocido por sus trabajos en la teoría de los números y la teoría de probabilidades.",
        "enlaces_salientes": [
            "/wiki/Andr%C3%A9i_M%C3%A1rkov",
            "/wiki/Andr%C3%A9i_M%C3%A1rkov",
            "/wiki/Andr%C3%A9i_M%C3%A1rkov",
            "/wiki/Calendario_juliano",
            "/wiki/Riaz%C3%A1n",
            "/wiki/Imperio_ruso",
            "/wiki/San_Petersburgo",
            "/wiki/Ate%C3%ADsmo",
            "/wiki/Universidad_Estatal_de_San_Petersburgo",
            "/wiki/Pafnuti_Chebyshov",
            "/wiki/Matem%C3%A1tico",
            "/wiki/Estad%C3%ADstico",
            "/wiki/Profesor_de_educaci%C3%B3n_superior",
            "/wiki/Teor%C3%ADa_de_la_probabilidad",
            "/wiki/An%C3%A1lisis_matem%C3%A1tico",
            "/wiki/Teor%C3%ADa_de_n%C3%BAmeros",
            "/wiki/Abram_Sam%C3%B3ilovich_Bezik%C3%B3vich",
            "/wiki/Aleksandr_Fridman",
            "/wiki/Jacob_Tamarkin",
            "/wiki/Gueorgui_Voron%C3%B3i",
            "/wiki/Iv%C3%A1n_Vinogr%C3%A1dov",
            "/wiki/Academia_de_Ciencias_de_Rusia",
            "/wiki/Idioma_ruso",
            "/wiki/14_de_junio",
            "/wiki/1856",
            "/wiki/20_de_julio",
            "/wiki/1922",
            "/wiki/Teor%C3%ADa_de_los_n%C3%BAmeros",
            "/wiki/Teor%C3%ADa_de_probabilidades",
            "/wiki/Riaz%C3%A1n",
            "/wiki/Imperio_ruso",
            "/wiki/San_Petersburgo",
            "/wiki/1874",
            "/wiki/Universidad_de_San_Petersburgo",
            "/wiki/Pafnuti_Chebyshov",
            "/wiki/1886",
            "/wiki/San_Petersburgo",
            "/wiki/1880",
            "/wiki/Teor%C3%ADa_de_probabilidad",
            "/wiki/1905",
            "/wiki/Zar",
            "/wiki/20_de_julio",
            "/wiki/1922",
            "/wiki/Fracci%C3%B3n_continua",
            "/wiki/1887",
            "/wiki/Teorema_central_del_l%C3%ADmite",
            "/wiki/Proceso_estoc%C3%A1stico",
            "/wiki/Cadena_de_M%C3%A1rkov",
            "/wiki/Cadena_de_M%C3%A1rkov",
            "/wiki/Markov_(cr%C3%A1ter)",
            "/wiki/Aleksandr_M%C3%A1rkov_(astr%C3%B3nomo)",
            "/wiki/Asteroide",
            "/wiki/(27514)_Markov",
            "/wiki/Desigualdad_de_M%C3%A1rkov",
            "/wiki/Modelo_oculto_de_M%C3%A1rkov",
            "/wiki/Proceso_de_decisi%C3%B3n_de_M%C3%A1rkov",
            "/wiki/Propiedad_de_M%C3%A1rkov",
            "/wiki/Teorema_de_Gauss-M%C3%A1rkov",
            "/wiki/OCLC",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Marvin_Minsky",
        "titulo": "Marvin Minsky",
        "contenido": "marvin lee minsky (nueva york, 9 de agosto de 1927-boston, 24 de enero de 2016)​ fue un cientifico estadounidense. es considerado uno de los padres de la inteligencia artificial. fue cofundador del laboratorio de inteligencia artificial del instituto de tecnologia de massachusetts (mit).  marvin lee minsky nacio en la ciudad de nueva york, en el seno de una familia judia. asistio a la escuela fieldston y a la escuela secundaria de ciencias del bronx. mas tarde asistio a la academia phillips en andover, massachusetts.  tras acabar la secundaria se unio a la marina de los estados unidos. tras dos años de servicio, entro en la universidad de princeton, donde se graduaria en 1950.  hasta su muerte, ocupo la plaza de profesor toshiba de los medios de comunicacion y las ciencias en el instituto de tecnologia de massachusetts (mit).  minsky contribuyo  al desarrollo de la descripcion grafica simbolica, geometria computacional, representacion del conocimiento, semantica computacional, percepcion mecanica, aprendizaje simbolico y conexionista. en 1951 creo snarc, el primer simulador de redes neuronales. fue el inventor de las patentes del casco de realidad virtual en 1963 y del microscopio confocal en 1957 (antecesor de los ampliamente utilizados y modernos microscopios confocales de barrido por laser).  escribio el libro \"perceptrones\" (con seymour papert), que se convirtio en el trabajo fundacional en el analisis de redes neuronales artificiales. su critica a ese campo​ ha sido indicada como responsable de la desaparicion virtual de la investigacion academica en redes neuronales artificiales durante los años 1970.​  minsky fue consejero en la pelicula 2001: una odisea del espacio y hay referencias a el tanto en la pelicula como en el libro. durante la filmacion minsky casi muere en un accidente.​  minsky tambien fue responsable de sugerir la trama de \"jurassic park\" a michael crichton durante un paseo por la playa de malibu. en ese punto los dinosaurios fueron concebidos como automatas. mas tarde crichton hizo uso de sus conocimientos en biomedicina y concibio los dinosaurios como clones.  minsky recibio el premio fundacion bbva fronteras del conocimiento 2013 en tecnologias de la informacion y la comunicacion. el jurado de dicho premio destaco sus trabajos sobre el aprendizaje de las maquinas, en sistemas que integran la robotica, el lenguaje, la percepcion y la planificacion ademas de la representacion del conocimiento basada en marcos (frames), han conformado el campo de la inteligencia artificial.  durante su carrera profesional le fueron concecidos varios premios y reconocimientos:​   ",
        "snippet": "Marvin Lee Minsky (Nueva York, 9 de agosto de 1927-Boston, 24 de enero de 2016)[1]​ fue un científico estadounidense. Es considerado uno de los padres de la inteligencia artificial. Fue cofundador del laboratorio de inteligencia artificial del Instituto de Tecnología de Massachusetts (MIT).",
        "enlaces_salientes": [
            "/wiki/Marvin_Minsky",
            "/wiki/Marvin_Minsky",
            "/wiki/Marvin_Minsky",
            "/wiki/9_de_agosto",
            "/wiki/1927",
            "/wiki/Nueva_York",
            "/wiki/24_de_enero",
            "/wiki/2016",
            "/wiki/Boston",
            "/wiki/Massachusetts",
            "/wiki/Hemorragia_cerebral",
            "/wiki/Ate%C3%ADsmo",
            "/wiki/Phillips_Academy",
            "/wiki/Harvard_College",
            "/wiki/Universidad_de_Harvard",
            "/wiki/Bachelor_of_Arts",
            "/wiki/Matem%C3%A1ticas",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Philosophi%C3%A6_doctor",
            "/wiki/Albert_W._Tucker",
            "/wiki/American_Association_for_Artificial_Intelligence",
            "/wiki/Instituto_de_Tecnolog%C3%ADa_de_Massachusetts",
            "/wiki/Manuel_Blum",
            "/wiki/Adolfo_Guzm%C3%A1n_Arenas",
            "/wiki/William_Daniel_Hillis",
            "/wiki/Piano",
            "/wiki/Sociedad_de_la_mente",
            "/wiki/Armada_de_los_Estados_Unidos",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Academia_Nacional_de_Ciencias_(Estados_Unidos)",
            "/wiki/Academia_Estadounidense_de_las_Artes_y_las_Ciencias",
            "/wiki/Academia_Nacional_de_Ingenier%C3%ADa_(Estados_Unidos)",
            "/wiki/League_for_Programming_Freedom",
            "/wiki/Premio_Turing",
            "/wiki/Premio_Jap%C3%B3n",
            "/wiki/Nueva_York",
            "/wiki/Boston",
            "/wiki/Nacionalidad_estadounidense",
            "/wiki/Inteligencia_artificial",
            "/wiki/Inteligencia_artificial",
            "/wiki/Phillips_Academy",
            "/wiki/Estados_Unidos",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Instituto_de_Tecnolog%C3%ADa_de_Massachusetts",
            "/wiki/Geometr%C3%ADa_computacional",
            "/wiki/Representaci%C3%B3n_del_conocimiento",
            "/wiki/Microscopio_confocal",
            "/wiki/Perceptr%C3%B3n",
            "/wiki/Seymour_Papert",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Red_neuronal_artificial",
            "/wiki/Michael_Crichton",
            "/wiki/Malib%C3%BA_(California)",
            "/wiki/Minicomputadora",
            "/wiki/Digital_Equipment_Corporation",
            "/wiki/Digital_Equipment_Corporation",
            "/wiki/PDP-1",
            "/wiki/California",
            "/wiki/Estados_Unidos",
            "/wiki/Videojuego",
            "/wiki/Spacewar!",
            "/wiki/Premios_Fundaci%C3%B3n_BBVA_Fronteras_del_Conocimiento",
            "/wiki/Tecnolog%C3%ADas_de_la_informaci%C3%B3n_y_la_comunicaci%C3%B3n",
            "/wiki/MIT_Press",
            "/wiki/Seymour_Papert",
            "/wiki/Universidad_de_Oreg%C3%B3n",
            "/wiki/Harry_Harrison",
            "/wiki/ISBN",
            "/wiki/Richard_Hamming",
            "/wiki/Premio_Turing",
            "/wiki/James_H._Wilkinson",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_del_Estado_Ruso",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/BIBSYS",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Deutsche_Biographie",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Internet_Movie_Database"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Emil_Post",
        "titulo": "Emil Leon Post",
        "contenido": "emil leon post (11 de febrero de 1897 en augustow - 21 de abril de 1954 en nueva york) fue un matematico estadounidense.  creo el sistema formal llamado maquina de post, el cual es equivalente a la maquina de turing. ",
        "snippet": "Emil Leon Post (11 de febrero de 1897 en Augustów - 21 de abril de 1954 en Nueva York) fue un matemático estadounidense.",
        "enlaces_salientes": [
            "/wiki/Emil_Leon_Post",
            "/wiki/Emil_Leon_Post",
            "/wiki/Emil_Leon_Post",
            "/wiki/11_de_febrero",
            "/wiki/1897",
            "/wiki/Polonia",
            "/wiki/21_de_abril",
            "/wiki/1954",
            "/wiki/Estados_Unidos",
            "/wiki/Nueva_York",
            "/wiki/Polonia",
            "/wiki/Estados_Unidos",
            "/wiki/Idioma_polaco",
            "/wiki/Universidad_de_Columbia",
            "/wiki/City_College_(Nueva_York)",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Universidad_Cornell",
            "/wiki/Problema_de_correspondencia_de_Post",
            "/wiki/11_de_febrero",
            "/wiki/1897",
            "/wiki/August%C3%B3w",
            "/wiki/21_de_abril",
            "/wiki/1954",
            "/wiki/Nueva_York",
            "/wiki/Estados_Unidos",
            "/wiki/Sistema_formal",
            "/wiki/M%C3%A1quina_de_Post",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Mathematics_Genealogy_Project",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Open_Library",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/JSTOR",
        "titulo": "JSTOR",
        "contenido": "jstor (abreviatura en ingles de journal storage, «almacen de publicaciones periodicas») es un sistema de almacenamiento en linea de publicaciones academicas. fundada en 1995, jstor es una sociedad estadounidense con base en la ciudad de nueva york.  jstor fue concebida como la solucion a uno de los mayores problemas que deben enfrentar hoy las bibliotecas (especialmente las universitarias y las de investigacion) debido al creciente aumento de publicaciones academicas en la actualidad. william g. bowen, su fundador, fue presidente de la universidad de princeton desde el año 1972 al 1988.​ en general, a muchas bibliotecas se les hacia excesivamente costoso el mantener una interesante coleccion de publicaciones debido a cuestiones de espacio, por lo que encontraron en jstor una solucion viable a dicha cuestion, digitalizando muchos de sus titulos y almacenandolos en su base de datos en linea con la confianza en que estos permanecerian disponibles a largo plazo.  a partir del exito alcanzado con el proyecto inicial, bowen y kevin guthrie (quien seria mas tarde presidente de jstor) se interesaron en ampliar el numero de publicaciones participantes hasta la fecha. de esta manera se reunieron con representantes de la real sociedad de londres y, como resultado, se pacto la digitalizacion de sus principales articulos que se remiten a sus origenes en 1665. el trabajo de inclusion de dichos volumenes en la base de datos en linea fue finalizado en diciembre de 2000.​  hacia junio de 2007, la base de datos contaba con mas de 23 millones de paginas de texto.​ hacia julio de 2007, el material de jstor es provisto por 446 editores. cerca de 53 millones de busquedas de archivos fueron realizadas entre enero y julio de 2007.​  el acceso a jstor se encuentra autorizado a bibliotecas, universidades y editores de todo el mundo que han firmado un acuerdo con la institucion. estas, a su vez, facilitan el acceso de sus miembros a jstor de manera gratuita a traves de internet. tambien existe la posibilidad de suscribirse, mediante pago, de manera individual o privada.  el programador y activista de internet aaron swartz, que fue coautor de los rss y colaboro en la creacion de las licencias creative commons, fue acusado el 19 de julio de 2011 de descargar 4.8 millones de articulos y otros documentos de la base de datos de jstor, presuntamente con el fin de compartirlos a traves de sitios de descarga gratuita.​ poco antes de que se iniciara el juicio, aaron swartz aparecio muerto en su casa a la edad de 26 años. segun la investigacion del caso, se trataria de un suicidio debido al acoso por parte del deficiente sistema de justicia de estados unidos y del fiscal stephen heymann, el cual intento avanzar su carrera con el caso de aaron swartz.​   ",
        "snippet": "JSTOR (abreviatura en inglés de Journal STORage, «almacén de publicaciones periódicas») es un sistema de almacenamiento en línea de publicaciones académicas. Fundada en 1995, JSTOR es una sociedad estadounidense con base en la ciudad de Nueva York.",
        "enlaces_salientes": [
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/Dominio_de_Internet",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Biblioteca_digital",
            "/wiki/Sitio_web",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/1995",
            "/wiki/Alexa_Internet",
            "/wiki/Estadounidense",
            "/wiki/Nueva_York",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Royal_Society_de_Londres",
            "/wiki/Internet",
            "/wiki/Aaron_Swartz",
            "/wiki/RSS",
            "/wiki/Licencias_Creative_Commons",
            "/wiki/Wayback_Machine",
            "/wiki/Princeton_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/BIBSYS"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/JSTOR",
        "titulo": "JSTOR",
        "contenido": "jstor (abreviatura en ingles de journal storage, «almacen de publicaciones periodicas») es un sistema de almacenamiento en linea de publicaciones academicas. fundada en 1995, jstor es una sociedad estadounidense con base en la ciudad de nueva york.  jstor fue concebida como la solucion a uno de los mayores problemas que deben enfrentar hoy las bibliotecas (especialmente las universitarias y las de investigacion) debido al creciente aumento de publicaciones academicas en la actualidad. william g. bowen, su fundador, fue presidente de la universidad de princeton desde el año 1972 al 1988.​ en general, a muchas bibliotecas se les hacia excesivamente costoso el mantener una interesante coleccion de publicaciones debido a cuestiones de espacio, por lo que encontraron en jstor una solucion viable a dicha cuestion, digitalizando muchos de sus titulos y almacenandolos en su base de datos en linea con la confianza en que estos permanecerian disponibles a largo plazo.  a partir del exito alcanzado con el proyecto inicial, bowen y kevin guthrie (quien seria mas tarde presidente de jstor) se interesaron en ampliar el numero de publicaciones participantes hasta la fecha. de esta manera se reunieron con representantes de la real sociedad de londres y, como resultado, se pacto la digitalizacion de sus principales articulos que se remiten a sus origenes en 1665. el trabajo de inclusion de dichos volumenes en la base de datos en linea fue finalizado en diciembre de 2000.​  hacia junio de 2007, la base de datos contaba con mas de 23 millones de paginas de texto.​ hacia julio de 2007, el material de jstor es provisto por 446 editores. cerca de 53 millones de busquedas de archivos fueron realizadas entre enero y julio de 2007.​  el acceso a jstor se encuentra autorizado a bibliotecas, universidades y editores de todo el mundo que han firmado un acuerdo con la institucion. estas, a su vez, facilitan el acceso de sus miembros a jstor de manera gratuita a traves de internet. tambien existe la posibilidad de suscribirse, mediante pago, de manera individual o privada.  el programador y activista de internet aaron swartz, que fue coautor de los rss y colaboro en la creacion de las licencias creative commons, fue acusado el 19 de julio de 2011 de descargar 4.8 millones de articulos y otros documentos de la base de datos de jstor, presuntamente con el fin de compartirlos a traves de sitios de descarga gratuita.​ poco antes de que se iniciara el juicio, aaron swartz aparecio muerto en su casa a la edad de 26 años. segun la investigacion del caso, se trataria de un suicidio debido al acoso por parte del deficiente sistema de justicia de estados unidos y del fiscal stephen heymann, el cual intento avanzar su carrera con el caso de aaron swartz.​   ",
        "snippet": "JSTOR (abreviatura en inglés de Journal STORage, «almacén de publicaciones periódicas») es un sistema de almacenamiento en línea de publicaciones académicas. Fundada en 1995, JSTOR es una sociedad estadounidense con base en la ciudad de Nueva York.",
        "enlaces_salientes": [
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/JSTOR",
            "/wiki/Dominio_de_Internet",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Biblioteca_digital",
            "/wiki/Sitio_web",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/1995",
            "/wiki/Alexa_Internet",
            "/wiki/Estadounidense",
            "/wiki/Nueva_York",
            "/wiki/Universidad_de_Princeton",
            "/wiki/Royal_Society_de_Londres",
            "/wiki/Internet",
            "/wiki/Aaron_Swartz",
            "/wiki/RSS",
            "/wiki/Licencias_Creative_Commons",
            "/wiki/Wayback_Machine",
            "/wiki/Princeton_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/BIBSYS"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/ISBN",
        "titulo": "ISBN",
        "contenido": "el isbn (por las siglas en ingles de international standard book number, en español «codigo internacional normalizado para libros»)​ es un identificador unico para libros.[nota 1]​ mediante este sistema, a cada libro se le asigna una cadena alfanumerica unica internacional que sirve para identificar datos basicos del objeto tales como titulo, editorial, tirada, extension, materia, pais, traductor, lengua original, etc. no debe confundirse con el issn (international standard serial number, en español «numero internacional normalizado de publicaciones periodicas»),​ que corresponde al de las publicaciones periodicas, como revistas y diarios.  fue creado en 1970 al adoptar el estandar internacional iso 2108,​ hasta la reforma que entro en vigor en 2007, cada edicion y variacion (excepto las reimpresiones) de un libro recibia un isbn compuesto por 10 digitos de longitud, y dividido en cuatro partes:  estas partes tienen distintas longitudes y, para mejorar su legibilidad (lectura humana), es conveniente, aunque no obligatorio, que se separen con espacios en blanco o con guiones. ademas, se utilizan prefijos para asegurarse de que dos codigos no puedan comenzar de la misma forma.  en caso de usarse, tiene que estar situado correctamente, el primer guion se colocaba despues del primer digito, el segundo guion era de ubicacion variable y el tercer guion despues del noveno, justo antes del digito de control.​  el codigo de pais era 0 o 1 para paises de habla inglesa, 2 para paises de habla francesa, 3 para paises de habla alemana, etc. el sistema original isbn carecia del codigo de pais, pero anteponiendo un 0 a un numero sbn de 9 digitos se creaba un isbn valido. el codigo de pais puede tener hasta 5 digitos de longitud; por ejemplo, el 99936 se usa para butan. se puede consultar la lista de isbn por paises.  el numero del editor es asignado por la agencia nacional del isbn, y el numero del articulo es elegido por el editor.  los editores reciben bloques de isbn mas grandes de los que se espera que necesiten; un editor pequeño puede recibir isbn que consistan en un digito para el idioma, siete digitos para el editor y un solo digito para los articulos individuales. una vez que termine ese bloque puede recibir otro, con un numero de editor diferente. por tanto, a veces diferentes numeros de editor corresponden en realidad al mismo.  el digito de control de un isbn de diez cifras se halla mediante un calculo basado en el modulo 11: se multiplica cada uno de los nueve primeros digitos por la posicion que ocupan en la secuencia numerica, es decir, el primero por 1, el segundo por dos y asi sucesivamente hasta el noveno que se multiplica por 9. luego se suman estas multiplicaciones y el resultado se divide entre 11. dicha division dejara un resto entre 0 y 10. si el resto esta entre 0 y 9, este mismo valor es el del digito de control. pero si el resto es 10, entonces se establece como digito de control la letra x.  debido a la escasez existente en ciertas categorias del isbn, la organizacion internacional de estandares adopto implantar un isbn de trece digitos desde el 1 de enero de 2007. esta actualizacion pone a la par el sistema del isbn con el sistema de codigos de barras ean.​ los isbn existentes se prefijan con «978» (y el digito de control sera recalculado); cuando se agoten los isbn «978», se introducira el prefijo 979. cabe señalar la poca probabilidad de que coincidan los numeros de identificacion del editor asignados en los isbn «978» y «979».  el digito de control de un isbn de trece cifras se calcula de un modo diferente al del isbn de 10 cifras, con un calculo basado en el modulo 10: multiplicando el primero de los 12 numeros iniciales por 1, el segundo por 3, el tercero por 1, el cuarto por 3, y asi sucesivamente hasta llegar al numero 12; el digito de control es el valor que se debe añadir a la suma de todos estos productos para hacerla divisible por 10 (por ejemplo si la suma es 97, el digito de control es 3, porque 97 + 3 = 100, que es divisible por 10; si la suma es 86, el digito de control sera 4; si suman 120, sera 0; y asi en cualquier otro caso).​  muchos editores, incluida la editorial barnes & noble, han optado por utilizar los isbn. pero muchos detallistas prefieren el estandar mas universal european article number (ean), puesto que este se aplica a todos los soportes y no solo a los libros.  bookland es el nombre informal del prefijo de codigo unico de pais (ucc) asignado en la decada de 1980 para los identificadores de numero de articulo europeo (ean) de los libros publicados, independientemente del pais de origen, por lo que el espacio de nombres ean puede mantener un sistema de numeracion paralela redundante. en otras palabras, bookland es un pais ficticio que existe unicamente en ean con el proposito de catalogar geograficamente los libros en el sistema de codificacion ean, que de otro modo tendria una clave geografica. ",
        "snippet": "El ISBN (por las siglas en inglés de International Standard Book Number, en español «código Internacional normalizado para libros»)[1]​ es un identificador único para libros.[Nota 1]​ Mediante este sistema, a cada libro se le asigna una cadena alfanumérica única internacional que sirve para identificar datos básicos del objeto tales como título, editorial, tirada, extensión, materia, país, traductor, lengua original, etc. No debe confundirse con el ISSN (International Standard Serial Number, en español «número internacional normalizado de publicaciones periódicas»),[2]​ que corresponde al de las publicaciones periódicas, como revistas y diarios.",
        "enlaces_salientes": [
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/European_Article_Number",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Libro",
            "/wiki/Identificador",
            "/wiki/Obra_literaria",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Tirada_(impresi%C3%B3n)",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Prensa_escrita",
            "/wiki/Prensa_escrita",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/C%C3%B3digo_prefijo",
            "/wiki/But%C3%A1n",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Cifra_(matem%C3%A1tica)",
            "/wiki/C%C3%B3digo_de_barras",
            "/wiki/European_Article_Number",
            "/wiki/D%C3%ADgito_de_control",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Barnes_%26_Noble",
            "/wiki/European_Article_Number",
            "/wiki/GS1",
            "/wiki/ASIN",
            "/wiki/Amazon",
            "/wiki/International_Standard_Music_Number",
            "/wiki/International_Standard_Audiovisual_Number",
            "/wiki/International_Standard_Serial_Number",
            "/wiki/Publicaci%C3%B3n_peri%C3%B3dica",
            "/wiki/Internet_Blog_Serial_Number",
            "/wiki/Blog",
            "/wiki/ASIN",
            "/wiki/European_Article_Number",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Proceedings_of_the_London_Mathematical_Society",
        "titulo": "Proceedings of the London Mathematical Society",
        "contenido": "proceedings of the london mathematical society es una  revista cientifica de revision por pares especializada en matematica.  fundada en 1865, es una de las doce publicaciones editadas por la london mathematical society. entre sus articulos mas relevantes, se encuentra «on computable numbers, with an application to entscheidungsproblem» de 1936, de alan turing, en donde describe por primera vez su famosa maquina.​  segun journal citation reports, en 2011 tuvo un factor de impacto de 1.324, en el puesto 17 de 288 revistas.​ ",
        "snippet": "Proceedings of the London Mathematical Society es una revista científica de revisión por pares especializada en matemática.",
        "enlaces_salientes": [
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Proceedings_of_the_London_Mathematical_Society",
            "/wiki/Reino_Unido",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/ISSN",
            "/wiki/Revista_cient%C3%ADfica",
            "/wiki/Revisi%C3%B3n_por_pares",
            "/wiki/Matem%C3%A1tica",
            "/wiki/London_Mathematical_Society",
            "/wiki/Alan_Turing",
            "/wiki/M%C3%A1quina_de_Turing",
            "/wiki/Journal_Citation_Reports",
            "/wiki/Factor_de_impacto",
            "/wiki/Wayback_Machine",
            "/wiki/Oxford_University_Press",
            "/wiki/Control_de_autoridades",
            "/wiki/ISSN",
            "/wiki/Dialnet"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Digital_object_identifier",
        "titulo": "Identificador de objeto digital",
        "contenido": "el identificador de objeto digital, conocido en ingles como digital object identifier y abreviado doi y doi, es un enlace permanente en forma de codigo alfanumerico que identifica de forma unica un contenido electronico. esta pieza especifica de contenido intelectual puede ser un articulo cientifico, una imagen, un libro, una cancion u otro, siempre que se trate de un objeto en el ambiente digital.​  una forma comun de emplear el sistema doi es dar a las publicaciones cientificas un numero especifico que cualquiera puede utilizar para localizar a traves de la red el citado articulo. a diferencia del sistema url, usado en las paginas web, el sistema doi no cambia con el paso del tiempo, aunque el articulo sea reubicado en una direccion distinta puesto que lleva la informacion incorporada en forma de metadatos.​  el funcionamiento del doi se debe a la colaboracion de tres tipos de organizaciones:  crossref es la mayor agencia de registro e inicio en enero de 2000. cuenta hasta ahora con 10800 miembros de mas de 114 paises diferentes y mas de 90 millones de elementos de contenido registrado; ademas, cuenta con diferentes herramientas para agilizar la busqueda de informacion cientifica. una de las herramientas que ofrece crossref es el crossref metadata search​ que permite obtener, con tan solo proporcionar el doi, los datos basicos de una publicacion como titulo, palabras clave, autores y resumen, entre otros. tambien se pueden obtener los metadatos en formato bibtex​ y ris, asi como la referencia bibliografica en formato apa, vancouver, chicago, mla, ieee y harvard.  un ejemplo del funcionamiento del doi es en brasil, donde la plataforma lattes del conselho nacional de desenvolvimento cientifico e tecnologico (consejo nacional de desarrollo cientifico y tecnologico, cnpq) utiliza el doi como una forma digital de la certificacion de la produccion de literatura grabada por los investigadores en sus c.v. lattes. cuando un programa navegador encuentra un numero doi, utiliza el prefijo para encontrar la base de datos del editor y asi tener acceso a la informacion sobre el libro o periodico, que puede incluir datos de catalogo, criticas y enlaces. ",
        "snippet": "El identificador de objeto digital, conocido en inglés como digital object identifier y abreviado DOI y DOI, es un enlace permanente en forma de código alfanumérico que identifica de forma única un contenido electrónico. Esta pieza específica de contenido intelectual puede ser un artículo científico, una imagen, un libro, una canción u otro, siempre que se trate de un objeto en el ambiente digital.[1]​",
        "enlaces_salientes": [
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/IBM_DCE",
            "/wiki/Science",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/United_States_Patent_and_Trademark_Office",
        "titulo": "Oficina de Patentes y Marcas Registradas de los Estados Unidos",
        "contenido": "la oficina de patentes y marcas registradas de los estados unidos (conocida en ingles como la united states patent and trademark office, con el acronimo pto o uspto) es una agencia en el departamento de comercio de estados unidos que expide patentes a los inventores y las empresas para sus inventos, y registro de marcas para la identificacion de productos y propiedades intelectuales.  la oficina esta basada en alexandria, virginia, desde 2006, cuando se traslado desde el barrio crystal city del condado de arlington en el mismo estado. las oficinas bajo patentes y el director general de informacion, que permanecieron a las afueras del extremo sur de crystal city, completaron el traslado a randolph square, un edificio flamante en shirlington village, el 27 de abril de 2009.  el director de la oficina es david j. kappos, quien fue juramentado el 13 de agosto de 2009​ despues de la confirmacion de su nombramiento por el senado de los estados unidos durante la administracion del presidente barack obama.​ sucedio a john j. doll, quien sirvio como el jefe de accion despues de la resignacion de jon w. dudas al final de la administracion de george w. bush.​  la oficina coopera con la oficina europea de patentes (oep) y la oficina japonesa de patentes (opj) como una de las \"oficinas trilaterales de patentes.\" la uspto es tambien una oficina receptora, una administracion encargada para busqueda internacional, y una autoridad para examen preliminar internacional de solicitudes internacionales para patentes presentadas en virtud del tratado de cooperacion en materia de patentes.  la base legal para el sistema de patentes de estados unidos es la seccion octava del articulo primero de la constitucion de los estados unidos, en la que los poderes del congreso se definen. afirma, en parte, que:  la mision de la oficina de patentes y marcas es promover el progreso industrial y tecnologico en los estados unidos y fortalecer la economia nacional mediante:  a partir del 30 de septiembre de 2009, la oficina tuvo 9.716 empleados, casi todos basados en su sede en alexandria, que consiste en un complejo integrado por cinco edificios. 6.242 de estos empleados fueron examinadores de patentes (casi todos asignados para examinar las patentes utilitarias), y 388 fueron abogados para el examen de marcas.​  los examinadores de patentes son generalmente cientificos e ingenieros quienes no necesariamente tienen titulos de la ley, mientras que todos los examinadores de marcas deben ser abogados con licencia. todos los examinadores trabajan bajo un sistema de produccion que se basa estrictamente en \"cuentas.\"​ para todas las aplicaciones, \"cuentas\" se ganan por la composicion, presentacion, y envio de una accion de la primera oficina en cuanto al fondo, y en el tiempo de eliminacion de una aplicacion.  el comisario de patentes supervisa tres organismos principales, encabezados por el comisionado adjunto para operaciones de patentes (en la actualidad [¿cuando?] peggy focarino), el comisionado adjunto de politica de examen de patentes (en la actualidad [¿cuando?] andrew hirshfeld como adjunto interino), y el comisario de recursos de patentes y planificacion (que en la actualidad [¿cuando?] es vacante).​ las operaciones de patentes de la oficina se dividen en nueve centros tecnologicos diferentes que hacen frente a diversas artes.​  las decisiones de los examinadores de patentes pueden ser apeladas a la junta de apelaciones e interferencias de patentes, un organismo de derecho administrativo de la oficina de patentes y marcas. las decisiones de la junta de apelaciones pueden ser apeladas mas alla ante la corte de apelaciones de estados unidos para el circuito federal, o una accion civil puede ser demandada ante el comisionado de patentes en el tribunal de distrito de estados unidos para el distrito de columbia. la corte suprema de los estados unidos puede finalmente decidir sobre un caso de patentes. asimismo, las decisiones de los examinadores de marcas pueden ser apeladas a la junta de sala y apelacion de marcas, con las apelaciones posteriores dirigidas al circuito federal, o una accion civil tambien puede ser llevado.  en años recientes, la oficina de patentes y marcas ha sufrido retrasos crecientes entre el momento de solicitud de un patente y su momento de emision. para hacer frente a sus desafios con cargas de trabajo, la oficina ha emprendido un programa agresivo para contratacion y reclutamiento. la oficina contrato a 1.193 nuevos examinadores de patentes en el año fiscal de 2006,​ 1.215 nuevos examinadores en el año fiscal de 2007,​ y 1.211 en el año fiscal de 2008.​ la oficina espero continuar la contratacion de examinadores de patentes a un ritmo de aproximadamente 1.200 por año hasta el año 2012; sin embargo, debido a una desaceleracion en las presentaciones de aplicaciones nuevas desde el inicio de la crisis economica de 2008-2011,​ y las proyecciones de disminuciones sustanciales en las cuotas de mantenimiento en los proximos años,​ la agencia impuso una congelacion en sus contrataciones a principios de marzo de 2009.​  en 2006, la oficina de patentes y marcas instituyo un nuevo programa de entrenamiento para los examinadores de patentes, que fue nombrado la \"academia de entrenamiento para los examinadores de patentes\" (\"patent training academy\" en ingles). es un programa de ocho meses diseñado para enseñar a nuevos examinadores de patentes los fundamentos de las leyes, practicas, y examinaciones de patentes en un ambiente de estilo universitario.​ debido a la crisis presupuestaria inminente de la oficina, se habia rumoreado que el academia se cerraria a finales de 2009.​ focarino, entonces la poseedora del titulo \"comisionado interino de patentes,\" nego el cierre de la academia en una entrevista en mayo de 2009, afirmando que seria reducido, porque la meta de contratacion de nuevos examinadores en el año fiscal de 2009 se redujo a 600.​ en ultima instancia, 588 nuevos examinadores de patentes fueron contratados en el año fiscal de 2009.​  durante muchos años, el congreso \"desvio\" un 10% de los honorarios recogidos en la tesoreria general de los estados unidos por la oficina de patentes y marcas. en efecto, esto llevo dinero recaudado desde el sistema de patentes para el presupuesto general. esta desviacion de cuotas ha sido generalmente opuesto por los practicantes de patentes (por ejemplo, abogados de patentes y los agentes de patentes), los inventores, y la propia oficina,​ asi como el exjuez federal paul r. michel.​ estos interesados prefirieron utilizar los fondos para mejorar la oficina de patentes y el sistema de patentes, como por la aplicacion del plan estrategico del siglo 21 por parte de la oficina.​ los ultimos seis presupuestos anuales del gobierno de george w. bush no desviaron los cargos de la oficina, y el primer presupuesto de la administracion de barack obama continua con esta practica; sin embargo, las partes interesadas continuan presionando para permanentemente acabar la desviacion de cuotas.​  la oficina examina las solicitudes para registros de marcas. si se aprueba, las marcas estan registradas ya sea en el registro principal o en el registro de consulta, dependiendo en si la marca cumple con los criterios de distincion apropiada. sin embargo, esta funcion esta disminuyendo en popularidad, porque las solicitantes de marcas estan moviendo a registros mas baratos y sencillos.​​  la oficina de patentes y marcas solo permite ciertas personas calificadas a ejercer ante la oficina. practica incluye la presentacion de solicitudes para patentes en nombre de los inventores, el seguimiento de solicitudes para patentes en nombre de los inventores, y la participacion en los recursos administrativos y otras actuaciones ante los examinadores y juntas de la oficina. la oficina establece sus propios estandares para quien puede practicar y requiere que cualquier persona que practica debe registra. un agente de patentes es una persona que ha aprobado el examen de registro (la \"barra de la patente\"), pero no ha aprobado ningun examen de la barra del estado para convertirse en un abogado con licencia; un abogado de patentes es una persona quien ha pasado tanto una barra de estado como la barra de patentes, y esta en buena posicion como abogado.​ un agente de patentes solo puede actuar en una capacidad representativa en materias de patentes presentadas a la oficina de patentes y marcas, y no puede representar un titular de patente o un solicitante en un tribunal de justicia. para ser elegible para tomar el examen de revalida de patentes, un candidato debe poseer un grado de \"ingenieria o fisica, o el equivalente de un tal grado.\"​  los estados unidos le permite a cualquier ciudadano de cualquier pais el derecho de sentarse en la barra de patente (si tiene la experiencia tecnica necesaria).​ solo canada tiene un acuerdo de reciprocidad con los estados unidos que le confiere derechos similares a un agente de patentes.​  un inventor sin representacion puede presentar una solicitud de patente y lo procesar en su nombre propio (pro se). si parece a un examinador de patentes que un inventor presentando una solicitud de pro se no esta familiarizado con los procedimientos adecuados de la oficina de patentes, el examinador puede sugerir que la parte que presenta obtiene la representacion de una patente por un abogado o agente registrado.​ el examinador de patentes no puede recomendar a un abogado o un agente especifico, pero la oficina de patentes tiene una lista de los registrados.​  mientras el inventor de una invencion relativamente facil de describir puede ser capaz de producir una especificacion adecuada y planos detallados, una complejidad queda en lo que se reclama, ya sea en el lenguaje particular de la reclamacion de una solicitud de utilidad, o en la forma en la que los dibujos se presentan en una solicitud de diseño. tambien hay habilidades requeridas en la busqueda de la tecnica que se utiliza para apoyar la aplicacion y para evitar que se solicita una patente para algo que puede ser patentable. un examinador de patentes hara esfuerzos especiales para ayudar a los inventores pro si entender el proceso, pero la falta de entender adecuadamente o responder a una accion de oficina de la oficina de patentes y marcas puede poner en peligro los derechos del inventor, y puede llevar al abandono de la solicitud.  la oficina de patentes y marcas aceptara solicitudes de patentes presentadas en forma electronica. inventores o sus agentes/abogados pueden presentar solicitudes como documentos pdf de adobe. la pagina web de presentacion de solicitudes es https://web.archive.org/web/20100527094021/https://sportal.uspto.gov/secure/portal/efs-unregistered. las tasas de presentacion se pueden pagar con tarjeta de credito o por una \"cuenta de deposito\" de la oficina.  la oficina tambien proporciona, en su sitio web, copias electronicas libres de patentes y solicitudes como documentos graficos del formato tiff.   ",
        "snippet": "La Oficina de Patentes y Marcas Registradas de los Estados Unidos (conocida en inglés como la United States Patent and Trademark Office, con el acrónimo PTO o USPTO) es una agencia en el Departamento de Comercio de Estados Unidos que expide patentes a los inventores y las empresas para sus inventos, y registro de marcas para la identificación de productos y propiedades intelectuales.",
        "enlaces_salientes": [
            "/wiki/Oficina_de_Patentes_y_Marcas_Registradas_de_los_Estados_Unidos",
            "/wiki/Oficina_de_Patentes_y_Marcas_Registradas_de_los_Estados_Unidos",
            "/wiki/Oficina_de_Patentes_y_Marcas_Registradas_de_los_Estados_Unidos",
            "/wiki/Estados_Unidos",
            "/wiki/Organizaci%C3%B3n",
            "/wiki/Base_de_datos",
            "/wiki/Alexandria_(Virginia)",
            "/wiki/Virginia",
            "/wiki/Estados_Unidos",
            "/wiki/Departamento_de_Comercio_de_los_Estados_Unidos",
            "/wiki/4_de_julio",
            "/wiki/1836",
            "/wiki/Alexandria_(Virginia)",
            "/wiki/Virginia",
            "/wiki/Relieve_(arte)",
            "/wiki/Acr%C3%B3nimo",
            "/wiki/Departamento_de_Comercio_de_Estados_Unidos",
            "/wiki/Patente",
            "/wiki/Invento",
            "/wiki/Marca_(registro)",
            "/wiki/Propiedad_intelectual",
            "/wiki/Alexandria_(Virginia)",
            "/wiki/Virginia",
            "/wiki/2006",
            "/wiki/Condado_de_Arlington",
            "/wiki/27_de_abril",
            "/wiki/2009",
            "/wiki/13_de_agosto",
            "/wiki/2009",
            "/wiki/Senado_de_los_Estados_Unidos",
            "/wiki/Presidente_de_los_Estados_Unidos",
            "/wiki/Barack_Obama",
            "/wiki/George_W._Bush",
            "/wiki/Oficina_Europea_de_Patentes",
            "/wiki/Tratado_de_cooperaci%C3%B3n_en_materia_de_patentes",
            "/wiki/Constituci%C3%B3n_de_los_Estados_Unidos",
            "/wiki/Secretario_de_Comercio_de_Estados_Unidos",
            "/wiki/Presidente_de_los_Estados_Unidos",
            "/wiki/Derecho_de_autor",
            "/wiki/Propiedad_intelectual",
            "/wiki/30_de_septiembre",
            "/wiki/2009",
            "/wiki/Corte_Suprema_de_los_Estados_Unidos",
            "/wiki/2006",
            "/wiki/2007",
            "/wiki/2008",
            "/wiki/2012",
            "/wiki/Crisis_econ%C3%B3mica_de_2008-2011",
            "/wiki/2009",
            "/wiki/2006",
            "/wiki/George_W._Bush",
            "/wiki/Barack_Obama",
            "/wiki/Potasa",
            "/wiki/Carbonato_de_potasio",
            "/wiki/George_Washington",
            "/wiki/1790",
            "/wiki/1836",
            "/wiki/2008",
            "/wiki/Marca_(registro)",
            "/wiki/PDF",
            "/wiki/TIFF",
            "/wiki/Google_Patents",
            "/wiki/Instituto_Mexicano_de_la_Propiedad_Industrial",
            "/wiki/Oficina_Europea_de_Patentes",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/BIBSYS",
            "/wiki/Open_Library",
            "/wiki/Proyecto_Gutenberg"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Wikcionario",
        "titulo": "Wikcionario",
        "contenido": "el wikcionario (contraccion de wiki y diccionario; en ingles, wiktionary)​ es un proyecto de diccionario libre de la fundacion wikimedia, que contiene definiciones, traducciones, etimologias, sinonimos y pronunciaciones de palabras en multiples idiomas. esta basado en la tecnologia wiki, en particular mediante la utilizacion del software mediawiki, y su contenido esta protegido por las licencias libres gfdl y cc by-sa.  el primer wikcionario fue la version en ingles, creada por brion vibber el 12 de diciembre de 2002, a la cual le siguieron poco despues las versiones en frances y en polaco. el 1 de mayo de 2004, tim starling inicializo los sitios web donde se alojarian los respectivos wikcionarios de cada idioma que tuviese una correspondiente wikipedia, resultando en 143 nuevos wikcionarios en total, incluido el español.​​ el numero de versiones llego a 163 idiomas en enero de 2023.​  dentro de wikipedia, la liga para vincular una palabra directamente al wikcionario es :wikt:. por ejemplo, para enviar al lector a la definicion del termino \"diccionario\", se escribe: [[:wikt:diccionario]].  wiktionary se puso en linea el 12 de diciembre de 2002. el 28 de marzo de 2004 se subieron otros idiomas, y comenzaron a crearse wikcionarios en frances y polaco. desde entonces se han empezado a usar wikcionarios en muchos otros idiomas. el wikcionario se alojo en un nombre de dominio temporal hasta el 1 de mayo de 2004, cuando cambio al nombre de dominio actual.  al igual que otros proyectos que utilizan la tecnologia wiki, el uso de bots para automatizar tareas esta permitido en wikcionario, aunque en ocasiones ha presentado problemas. uno de los bots, autorizados denominado \"thirdpersbot\", fue responsable de la adicion de numerosas acepciones para conjugaciones de verbos en tercera persona, muchas de las cuales no habrian recibido su propia entrada en los diccionarios estandares. por ejemplo, este bot definio \"smoulders\" como la \"forma del presente simple en tercera persona singular de smolder\". de las 1.269.938 definiciones que el wiktionary ingles proporciona para 996.450 palabras inglesas distintas, 478.068 acepciones son definiciones de este tipo, es decir, que presentan una variacion en la conjugacion en lugar de un lema completamente unico. aun asi, incluso quitando estas definiciones \"redundantes\", la cobertura del vocabulario ingles es significativamente mayor que la de los principales diccionarios monolingues de papel.  el wikcionario en ingles no depende tanto de los bots comparado con otras ediciones. en el otro extremo se tiene por ejemplo a las versiones en frances y vietnamita del wikcionario, que mediante el uso de bots importaron grandes secciones del proyecto de diccionario vietnamita libre (fvdp, por sus siglas en ingles), un proyecto que proporciona diccionarios bilingues de contenido gratuito desde y hacia el idioma vietnamita. ",
        "snippet": "El Wikcionario (contracción de wiki y diccionario; en inglés, Wiktionary)[1]​ es un proyecto de diccionario libre de la Fundación Wikimedia, que contiene definiciones, traducciones, etimologías, sinónimos y pronunciaciones de palabras en múltiples idiomas. Está basado en la tecnología wiki, en particular mediante la utilización del software MediaWiki, y su contenido está protegido por las licencias libres GFDL y CC BY-SA.",
        "enlaces_salientes": [
            "/wiki/Wikcionario",
            "/wiki/Wikcionario",
            "/wiki/Wikcionario",
            "/wiki/Dominio_de_Internet",
            "/wiki/Diccionario",
            "/wiki/Estados_Unidos",
            "/wiki/MediaWiki",
            "/wiki/Desarrollador_de_software",
            "/wiki/Jimmy_Wales",
            "/wiki/Fundaci%C3%B3n_Wikimedia",
            "/wiki/Fundaci%C3%B3n_Wikimedia",
            "/wiki/Alexa_Internet",
            "/wiki/Diccionario",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Contenido_libre",
            "/wiki/Fundaci%C3%B3n_Wikimedia",
            "/wiki/Definiciones",
            "/wiki/Traducciones",
            "/wiki/Etimolog%C3%ADas",
            "/wiki/Sinonimia_(sem%C3%A1ntica)",
            "/wiki/Pronunciaci%C3%B3n",
            "/wiki/MediaWiki",
            "/wiki/Licencia_de_documentaci%C3%B3n_libre_de_GNU",
            "/wiki/Licencias_Creative_Commons",
            "/wiki/Idioma_franc%C3%A9s",
            "/wiki/Idioma_polaco",
            "/wiki/Idioma_franc%C3%A9s",
            "/wiki/Idioma_polaco",
            "/wiki/Nombre_de_dominio",
            "/wiki/Lema_(ling%C3%BC%C3%ADstica)",
            "/wiki/Idioma_franc%C3%A9s",
            "/wiki/Idioma_vietnamita",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_malgache",
            "/wiki/Idioma_malgache",
            "/wiki/Idioma_franc%C3%A9s",
            "/wiki/Idioma_franc%C3%A9s",
            "/wiki/Idioma_serbocroata",
            "/wiki/Idioma_serbocroata",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Idioma_chino",
            "/wiki/Idioma_chino",
            "/wiki/Idioma_lituano",
            "/wiki/Idioma_lituano",
            "/wiki/Idioma_ruso",
            "/wiki/Idioma_ruso",
            "/wiki/Idioma_polaco",
            "/wiki/Idioma_polaco",
            "/wiki/Idioma_griego",
            "/wiki/Idioma_griego",
            "/wiki/Lingua_Libre",
            "/wiki/Meta-Wiki",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Control_de_autoridades",
        "titulo": "Control de autoridades",
        "contenido": "el control de autoridades, en biblioteconomia y en ciencia de la informacion, es un proceso para organizar y mantener informacion bibliografica, por ejemplo en el catalogo de una biblioteca. cumple dos funciones importantes: primero, que se puedan agregar materiales logicamente reunidos, aunque estos se presenten de forma diferente; y segundo, que se pueda distinguir entre nombres semejantes o incluso identicos.  el control de autoridades es el conjunto de procesos que crean, unifican y actualizan los puntos de acceso, de los catalogos automatizados y muestra asimismo las relaciones entre los distintos puntos, de una forma normalizada. su meta es facilitar la busqueda, identificacion y recuperacion de los documentos almacenados, evitando confusiones y ahorrando tiempo al usuario. para asegurar que las obras de una determinada entidad corporativa o personal sean recuperadas siempre que se realice una busqueda, se debera determinar el encabezamiento y establecer la forma autorizada de este, siguiendo tambien las convenciones y recomendaciones internacionales.  por otra parte, rocio acosta cita a schmierer y define el control de autoridades como la operacion que consiste en la determinacion de los puntos de acceso y en el registro de las decisiones que se han tomado para su eleccion, y comprende tres actividades:  el control de autoridades nos permite realizar el catalogo de la biblioteca, ayudandonos como recurso a recuperar registros bibliograficos tanto a profesionales de la informacion como a los usuarios, para ello, los profesionales de la informacion, necesitan establecer una serie de tareas principales:  se deben tener en cuenta varios aspectos a la hora de realizar un control de autoridades:  en principio los ficheros de autoridades los deben crear las bibliotecas, pero es importante el papel de las bibliotecas universitarias y locales para la informacion sobre autoridades locales y regionales. estos centros utilizan un sistema mixto basado en establecer sus propias autoridades cuando no estan en otros ficheros de autoridad de mas alto nivel. una vez que un centro ha tomado la decision de aplicar el control de autoridades a sus registros, hay unas operaciones a realizar: ",
        "snippet": "El control de autoridades, en biblioteconomía y en ciencia de la información, es un proceso para organizar y mantener información bibliográfica, por ejemplo en el catálogo de una biblioteca. Cumple dos funciones importantes: primero, que se puedan agregar materiales lógicamente reunidos, aunque estos se presenten de forma diferente; y segundo, que se pueda distinguir entre nombres semejantes o incluso idénticos.",
        "enlaces_salientes": [
            "/wiki/Control_de_autoridades",
            "/wiki/Control_de_autoridades",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteconom%C3%ADa",
            "/wiki/Tesauro",
            "/wiki/Ontolog%C3%ADa_(inform%C3%A1tica)",
            "/wiki/Art_%26_Architecture_Thesaurus"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
        "titulo": "Biblioteca Nacional de España",
        "contenido": "recoletos: paseo de recoletos 20-22. 28071 madrid;  la biblioteca nacional de españa (bne) es un organismo autonomo​ encargado del deposito del patrimonio bibliografico y documental de españa. dedicada a reunir, catalogar y conservar fondos bibliograficos, custodia alrededor de treinta millones de publicaciones producidas en territorio nacional desde comienzos del siglo xviii: libros, revistas, mapas, grabados, dibujos, partituras y folletos.  la biblioteca nacional difunde este patrimonio bibliografico a traves de su catalogo y de la elaboracion de la bibliografia española y desarrolla servicios al publico que van desde las salas de consulta y los servicios a distancia a traves su pagina web,​ a los servicios de informacion bibliografica especializada y el prestamo interbibliotecario. el acceso a las colecciones digitales de la biblioteca se realiza a traves de la biblioteca digital hispanica.​a traves del museo de la biblioteca se divulgan las colecciones, el funcionamiento y la historia de la biblioteca nacional. ademas desarrolla un programa de actos culturales.​  su sede principal se situa en el paseo de recoletos, en el llamado palacio de biblioteca y museos nacionales, un edificio que comparte con el museo arqueologico nacional. ademas, tiene una segunda sede en alcala de henares.  el 29 de diciembre de 1711, el rey felipe v aprobo el plan que le presentan su confesor pedro robinet y melchor de macanaz para crear una real biblioteca. la creacion de esta fue un elemento dinamizador de la cultura española dieciochesca, con la mision de «renovar la erudicion historica y sacar al aire las verdaderas raices de la nacion y de la monarquia españolas».​ pronto se comenzo la construccion de su sede en el pasadizo que unia el real alcazar de madrid con el convento de la encarnacion.​  la real biblioteca se abrio al publico el dia 1 de marzo de 1712. el 2 de enero de 1716, felipe v firmo el real decreto fundacional, que aclaraba el caracter publico de la biblioteca, abierta a «todos los estudiosos» y establecia las normas fundamentales para su funcionamiento.​  cuando la biblioteca abrio sus puertas, sus fondos estaban compuestos de materiales provenientes de las colecciones privadas de los monarcas de españa, felipe iv y felipe v, el cual mando traer mas de 6000 volumenes de francia.​ : 33  los primeros ejemplares que se incorporaron a la coleccion fueron confiscados a los austracistas, que perdieron la guerra de sucesion, como el arzobispo de valencia antoni folch de cardona,​ el marques de mondejar y el duque de uceda.​: 33  a esta coleccion se añadieron algunas bibliotecas privadas de nobles como el conde de aguilar y el duque de medinaceli.​ en 1715, la real biblioteca contaba ya con 28 242 libros impresos, 1282 manuscritos y 20 000 medallas.​  el precedente del deposito legal, establecido en 1716, permitio que la biblioteca ampliara sus colecciones de forma considerable. a esto se sumo el efecto de la real orden del 11 de mayo de 1750, por la cual la real biblioteca adquirio el derecho de tantear las tasas de librerias puestas a la venta, con la oportunidad de seleccionar entre las relaciones de libros que se le presentaban aquellas obras que no existian entre sus fondos.​: 3  en 1738 se publica la primera obra fruto del trabajo de la biblioteca bajo el titulo de bibliotheca universal de la polygraphia española, realizada por cristobal rodriguez. esta obra, apoyada en su preparacion por el bibliotecario mayor juan de ferreras, fue la primera de una serie de obras de paleografia española.​  durante los tiempos de juan de ferreras, tambien se empezaron a elaborar indices o catalogos para el publico. el bibliotecario juan de iriarte, en especial, se encargo de esta tarea, elaborando el regia matritensis bibliotheca geographica et chronologica en 1729, el primer catalogo de la biblioteca, y posteriormente el regia matritensis bibliotheca mathematica (catalogo de matematicas) y regiae bibliothecae matritensis codices graeci (catalogo de manuscritos griegos).​: 502  la real orden de 19 de junio de 1761, redactada por el bibliotecario mayor juan de santander y aprobada por el rey carlos iii, modifico la original de 1716, creando la imprenta real que vinculaba «la labor editorial de la biblioteca a los mas destacados impresores, encuadernadores y grabadores de la epoca». el bibliotecario mayor pasa a ser director de la biblioteca real y los bibliotecarios pasan a ser considerados criados de la casa real, con sus correspondientes privilegios.​: 4  durante esta epoca (1760-1778) la biblioteca conto con un taller de fundicion de tipos dirigido por geronimo gil, que fue el nucleo original del taller de tipos de la imprenta real.  durante el trascurso del siglo xix, la biblioteca cambio varias veces de sede, primero en 1809, cuando, durante el reinado de jose bonaparte, se traslado al convento de los trinitarios calzados en la calle de atocha. en 1819, de nuevo hubo de cambiar de sede al palacio donde celebraba sus sesiones el consejo del almirantazgo real debido a las reclamaciones realizadas por los trinitarios calzados tras la vuelta de fernando vii, y en 1826 se produjo un tercer traslado a la antigua casa del marques de alcañices, en la actual calle de arrieta, lugar donde residio durante casi todo el siglo.​: 4  el terreno donde se ubica actualmente la biblioteca nacional es el mismo en el cual se ubicaba el antiguo convento de copacabana o gran convento de recoletos de madrid. dicho convento pertenecia a los religiosos de la orden de agustinos recoletos y, tras la desamortizacion de 1835, fue vendido y destruido.  las colecciones de la biblioteca tambien se vieron afectadas por los hechos del siglo xix. primero, la desamortizacion española condujo a que muchas obras procedentes de instituciones religiosas suprimidas se depositaran en la biblioteca. en efecto, en 1837 se crean las comisiones cientificas y artisticas provinciales para seleccionar las obras que, procedentes de los conventos suprimidos, debian depositarse en las bibliotecas y museos, o ser subastadas. por esta via se depositaran en la biblioteca nacional unos 70 000 volumenes procedentes de los conventos madrileños afectados por la desamortizacion.​: 5  pasan tambien a la biblioteca gran parte de los fondos de la biblioteca de las cortes, fundada por las cortes de cadiz en 1814, y suprimida en 1838.​: 214  por ultimo, en 1869 manuel ruiz zorrilla dispuso la incautacion de los archivos, bibliotecas y colecciones de arte en poder de catedrales, cabildos, monasterios y ordenes militares, en la llamada desamortizacion cultural, medio por el cual ingresaron en la biblioteca nacional obras muy valiosas procedentes de las catedrales de avila y toledo.  mediante el decreto del 28 de noviembre de 1836, la biblioteca real pasa a denominarse biblioteca nacional y a depender del ministerio de la gobernacion de la peninsula.​ un año mas tarde, en 1837, antonia gutierrez bueno se convierte en la primera mujer a la que se permitio el acceso para consultas​. en 1857, se aprueba el primer reglamento de la biblioteca nacional, en el que se establece la convocatoria, concesion, y posterior publicacion de las obras ganadoras de los premios bibliograficos que anualmente convocaria la biblioteca nacional.​: 5 ​ estos premios hicieron que la biblioteca se convirtiera “en la principal impulsora de trabajos bibliograficos en españa”, promoviendo el interes de bibliotecarios y bibliografos. en 1858, se crea el cuerpo facultativo de archiveros, bibliotecarios y arqueologos, el cual es liderado por el director de la nacional.​  en 1876, la biblioteca contaba ya con 300 000 libros, 200 000 folletos impresos y mas de 30 000 manuscritos.​ a pesar de las varias mudanzas, la biblioteca nacional seguia creciendo y sus necesidades sobrepasaban la capacidad de las sedes que hasta entonces habia ocupado. en 1857 se pidio la realizacion de un proyecto para una nueva sede, y en 1864 se escogio finalmente la obra del arquitecto francisco jareño alarcon.​  el 21 de abril de 1866 la reina isabel ii coloco la primera piedra del palacio de archivos, bibliotecas y museos, situado en el paseo de recoletos. por razones economicas las obras procedieron con mucha lentitud, y hubo muchas modificaciones al proyecto original.​ en 1884, antonio ruiz de salces sustituyo a jareño en la direccion de las obras de construccion del nuevo edificio de la biblioteca nacional. en 1892 se finalizo la construccion del edificio y el 16 de marzo de 1896 se abrio al publico la biblioteca nacional en su nueva sede.​: 7  el siglo xx empezo para la biblioteca con la aprobacion del “reglamento de las bibliotecas publicas del estado” por el real decreto del 18 de octubre de 1901. mediante esta ley, que derogo a la anterior de 1857, la biblioteca nacional paso a ser la cabecera de las bibliotecas españolas.​: 208  durante este tiempo fue director de la biblioteca nacional el erudito español marcelino menendez pelayo, el cual promovio la creacion de catalogos especializados, como lo fueron el catalogo de los manuscritos arabes existentes en la biblioteca nacional de madrid (francisco guillen robles 1899), en 1901 el catalogo de los retratos de personajes españoles de 1901 y en 1906 el catalogo de la coleccion de dibujos originales de la biblioteca nacional, ambos de angel m. barcia. tambien se le dio un impulso nuevo a la revista de archivos, bibliotecas, y museos, que fue un instrumento importante para el desarrollo del campo de la biblioteconomia en españa.​  en 1930, el ministro de instruccion publica y bellas artes, elias tormo, crea el patronato de la biblioteca nacional, organo que se ocupara de elegir a miguel artigas como director de la biblioteca. durante la segunda republica española, artigas y el patronato lanzan un proceso de restauracion y ampliacion del edificio y de reformas de los servicios bibliotecarios.​ entre estas, destaca la reorganizacion del salon de lectura, la creacion de la sala general, abierta al publico e inaugurada por el presidente alcala zamora,​: 7  y la ampliacion de los horarios.​  durante la guerra civil española, el director de la biblioteca nacional fue tomas navarro tomas, elegido poco antes de empezar la guerra civil hasta su finalizacion. en este periodo tambien se cerraron sus puertas y sus fondos mas preciosos fueron evacuados a las torres de serranos, en valencia y despues al extranjero, a ginebra, en suiza. para salvar de la destruccion los fondos de centros religiosos, palacios o casas particulares, se trasladaron a la biblioteca alrededor de 500 000 volumenes mediante la junta de incautacion y proteccion del patrimonio artistico.​: 8  muchos de estos fondos provenian de prestigiosas bibliotecas privadas y algunos no pudieron ser devueltos despues de la guerra.​ el edificio de la biblioteca nacional tambien fue victima de varios bombardeos durante la guerra, aunque no causaron daño a los fondos que se albergaban dentro.​  despues de la guerra, se eligio nuevamente como director a miguel artigas y en 1939 se introduce el sistema decimal para la catalogacion de fondos en las bibliotecas publicas españolas.​: 8  en los años posteriores a la guerra, se celebran varias exposiciones destacadas, entre ellas dos dedicadas a miguel de cervantes y otra bajo el titulo un milenio del libro español en 1952.​ en 1953 se inaugura la nueva sede del archivo historico nacional, que antes compartia edificio con la biblioteca y el museo arqueologico nacional.  aunque hubo varias reformas de la organizacion y la gestion de la biblioteca durante la decada de 1950, la mas importante fue el decreto organico del 8 de marzo de 1957 y su correspondiente reglamento, publicado el 20 de diciembre del mismo año. el nuevo reglamento reestructuro los servicios de la biblioteca, dispuso que el director tuviera que ser un miembro del cuerpo facultativo y redujo las funciones del patronato.​ en 1957 tambien se promulga un nuevo decreto de deposito legal que logra, finalmente, que los impresores cumplan con el mismo.​  a pesar de las reformas, aun habia muchas labores bibliotecarias de caracter nacional que la biblioteca no desempeñaba. por ejemplo, en 1970 se creo el instituto bibliografico hispanico, que incluia el servicio nacional de informacion documental y bibliografica, el deposito legal, y la comision nacional de planificacion y coordinacion bibliografica.​: 9  la hemeroteca nacional, fundada en 1941, reunia tambien una importante coleccion de prensa española. en 1978, las colecciones de la biblioteca albergaban alrededor de cinco millones de piezas y tenia alrededor de 412 000 lectores anuales.​  en 1982 se llevo a cabo el primer estudio de viabilidad para automatizacion de la biblioteca,​: 9  que se concretaria en la adopcion del sistema sabina, una version especial del software español sabini.​ por real decreto, en 1985 se integran en la biblioteca nacional el instituto bibliografico hispanico, la hemeroteca nacional, y el centro del tesoro documental y bibliografico.​: 208  en 1985, la bne es declarada \"la institucion bibliotecaria superior del estado y la cabecera del sistema español de bibliotecas.\"​ a finales de la decada de 1980 se inician las obras para crear un segundo deposito en alcala de henares (inaugurado en el año 1993) y arranca el sistema de automatizacion ariadna, que empieza a funcionar en 1991.​: 9  en 1991, por real decreto (r.d. 1581/1991 de 31 de octubre), se aprueba el estatuto de la biblioteca nacional como organismo autonomo, y se inicia una fase de ampliacion para la biblioteca.​: 209  se abren nuevos servicios como el de informacion genealogica y heraldica, informacion general, y documentacion bibliotecaria. en 1995 se inaugura el museo del libro​ y se continua con el plan de automatizacion. en 1996 la bne inaugura su propio sitio web en internet.  el 11 de noviembre de 2009 entra en vigor el nuevo estatuto de la biblioteca nacional de españa aprobado por real decreto 1638/2009, de 30 de octubre. uno de los principales cambios es la denominacion oficial del organismo, que pasa a ser biblioteca nacional de españa, para una mejor identificacion \"en los foros y organizaciones internacionales\".​  el nuevo estatuto preve que la biblioteca garantice la representacion de las comunidades autonomas y de las universidades en su patronato. para ello se incorporan como vocales natos el vicepresidente segundo de la conferencia sectorial de cultura y el presidente de la conferencia de rectores de las universidades españolas. se modifica ademas el procedimiento para nombrar al director general, que sera designado por real decreto, acordado en consejo de ministros a propuesta del ministro de cultura, previa consulta al real patronato y \"atendiendo a criterios de competencia profesional y experiencia (…) en el area de bibliotecas y gestion cultural\".​  el 5 de mayo de 2010, el consejo de ministros de españa decidio que el cargo que encabeza a la biblioteca nacional pierda su condicion de direccion general en la estructura jerarquica administrativa del gobierno español, convirtiendose en una subdireccion general, tras lo cual, milagros del corral, la directora, presento su dimision.​ la sucedio en el cargo la presidenta de la federacion española de sociedades de archivistica, biblioteconomia, documentacion y museistica (fesabid), gloria perez-salmeron.  entre los proyectos de la biblioteca nacional durante este periodo destacan varios. en el 2007, se inauguro el nuevo museo de la biblioteca nacional, que sustituyo al antiguo museo del libro y amplio su oferta cultural y educativa.​ en 2008 se presento la biblioteca digital hispanica, portal desde el que se accede a los recursos digitalizados por la biblioteca.​ tambien la biblioteca empezo a participar en redes sociales, abrio su pagina en facebook en el 2008 y despues se han ido añadiendo perfiles en otras plataformas web 2.0 como twitter, youtube, slideshare, flickr y wordpress.  en 2009, la biblioteca nacional inicio un proyecto en colaboracion con internet archive, con el objetivo de \"recolectar, archivar, y preservar el dominio.es.\"​ en octubre de 2010, la bne inauguro el \"quijote interactivo\", una version digitalizada e interactiva de la obra de cervantes, que incluye contenidos que ayudan a contextualizar la lectura, como un mapa con las aventuras del quijote y apartados sobre la vida en el siglo xvii.​  en el ambito internacional, la biblioteca colabora en la base de datos dialnet, enlazando autores coincidentes en ambas bases de datos.​ su participacion en un proyecto de investigacion con el grupo de ingenieria ontologica (ontology engineering group) de la universidad politecnica de madrid ha dado como fruto la creacion del portal​ con una parte importante de los registros de la bne convertidos a rdf y disponibles en abierto.​  en las asociaciones profesionales ifla y oclc, la bne esta presente en importantes grupos de trabajo; forma parte del virtual authority file (viaf)​ desde sus inicios y es tambien importante su presencia en las entidades normalizadoras como la organizacion internacional de normalizacion o en su correlato nacional asociacion española de normalizacion y certificacion. asimismo, la biblioteca nacional de españa esta presente en eurig, un organismo creado para promover los intereses profesionales comunes de los usuarios y potenciales usuarios de rda (resource description and access) en europa.​  la biblioteca ha participado ademas en el proyecto impact,​ que analiza el reconocimiento de caracteres de las obras manuscritas, y tambien el proyecto arrow,​ que persigue realizar una base de datos europea sobre las llamadas obras huerfanas, obras de las cuales no se conoce quien detenta los derechos de propiedad intelectual. tambien se trabaja en la catalogacion de cantorales de los siglos xvi-xix, en colaboracion con la fundacion general de la universidad de alcala.​  el 15 de noviembre de 2010 la biblioteca nacional de españa presenta su catalogo bibliografico de la coleccion de incunables, un volumen doble, cuyo autor es julian martin abad, jefe del servicio de manuscritos e incunables de la bne y que recopila 2297 ediciones y 3158 ejemplares.​  el 13 de diciembre de 2011, los reyes de españa inauguraron la exposicion biblioteca nacional de españa: 300 años haciendo historia, acto con el que se iniciaron los actos conmemorativos de la celebracion del tricentenario de su fundacion.​  la biblioteca depende directamente del ministerio de cultura o equivalente y del director general de la misma, que cuentan con un real patronato a quien la ley le atribuye las facultades de «organo superior consultivo» y que tiene como estructura estable un consejo de direccion, una direccion tecnica y una gerencia.  presidentes  segun sus estatutos, forman parte del patrimonio del organismo autonomo biblioteca nacional, las sedes del paseo de recoletos (madrid), de alcala de henares y de la hemeroteca nacional.​ desde 2010 se añade la sede electronica de la biblioteca nacional de españa.​  el deposito legal puede definirse como la exigencia, impuesta por ley, de depositar en una o varias agencias especificas, ejemplares de publicaciones de todo tipo, reproducidas en cualquier soporte, para la distribucion publica, alquiler o venta.​ tiene como objetivo garantizar la conservacion y el acceso del patrimonio cultural de un pais a los investigadores de hoy y del futuro.  el 26 de julio de 1716 felipe v resolvio que se debia entregar una copia de «todas las impresiones nuevas que se hicieran en mis dominios» a su real biblioteca de madrid.​ este privilegio, antecedente del deposito legal moderno, lo ostentaba la real biblioteca de san lorenzo de el escorial, para aragon y castilla, desde el 12 de enero de 1619.​  pese a todos los intentos realizados a traves de los diversos periodos historicos, el deposito legal se incumplio sistematicamente hasta la promulgacion del real decreto de 23 de diciembre de 1957.​ este reglamento establecio un sistema administrativo que posibilito que sus objetivos se cumplieran. por otra parte estipulaba que los impresores eran los responsables del deposito legal. la tipologia de los materiales sujetos a deposito legal era realmente amplia, desde materiales impresos, hasta grabaciones sonoras, mapas geograficos, peliculas, y postales.​  este decreto, aunque derogado salvo en lo relativo a las funciones, se mantuvo practicamente intacto en su contenido en la orden del 30 de octubre de 1971,​ y en la de 20 de febrero de 1973,​ por la que se modifican algunos articulos del reglamento del instituto bibliografico hispanico.  la configuracion de españa como estado autonomico, con las transferencias de la gestion del deposito legal a las comunidades autonomas y los cambios en el mundo de la edicion, junto a la aparicion de nuevas tecnologias, hacian imprescindible la promulgacion de una nueva ley.​ la ley 23/2011, de 29 de julio, de deposito legal establece los siguientes cambios:  el numero de deposito legal esta compuesto de las siglas dl, el numero de constitucion del deposito y el año de constitucion expresado con cuatro cifras. todas las partes iran separadas del resto por un espacio, salvo el año, que ira precedido por un guion. al finalizar cada ejercicio, se cerrara la numeracion, que se iniciara de nuevo al comenzar el año. las unicas salvedades corresponden a los numeros obtenidos en asturias, donde dl puede ser sustituido por dll (depositu llegal),​ y navarra, donde puede sustituirse por lg (lege gordailua).​  tras la entrada en vigor de la ley 23/2011,​ tan solo ocho comunidades autonomas han adaptado su normativa a la misma: andalucia, aragon,​ asturias, castilla-la mancha, ceuta,​ cataluña,​ extremadura y navarra.  el contenido de todas ellas no difiere en lo esencial, aunque existen diferencias en los siguientes apartados:  las unicas que hacen referencia expresa son andalucia​ y extremadura,​ que determinan diez dias habiles a contar desde la presentacion de la solicitud, y, castilla-la mancha​ y navarra que establecen quince dias.  obligatoriamente, antes de su distribucion o venta, y, salvo aragon, en el plazo de dos meses desde la obtencion del numero de deposito.  en relacion con los libros, folletos, recursos multimedia en el que uno de los soportes sea en papel, publicaciones seriadas, colecciones por fasciculos, partituras, mapas, planos, atlas y similares, el numero de ejemplares a depositar sera de cuatro, dos para la comunidad y dos para la bne.  para el resto de documentos, segun lo indicado en la siguiente tabla:  esta regulado mediante r.d. 635/2015,​ de 10 de julio, y se entiende de aquellas publicaciones sin soporte fisico tangible.  este tipo de deposito legal es aplicable a los sitios web y sus publicaciones, siempre que contengan patrimonio bibliografico, visual, sonoro, audiovisual o digital de las culturas de españa.  las principales diferencias frente a la regulacion del deposito legal de las publicaciones tangibles son:  departamento de referencia  departamento de referencia  area de coordinacion de colecciones  departamento de patrimonio bibliografico  departamento de bellas artes y cartografia  departamento de musica y audiovisuales  departamento de referencia  departamento de referencia  departamento de referencia  la coleccion de la biblioteca nacional de españa es el reflejo de la sociedad española a lo largo de sus tres siglos de historia, de los gustos y la cultura del pais. su antiguedad, y esta representatividad de los avatares historicos, la convierten en una de las mas relevantes del mundo, integrada por autenticos tesoros, tanto por sus caracteristicas literarias y artisticas como por su importancia historica y bibliografica. este patrimonio se ha conservado y ha llegado a nosotros gracias al entusiasmo y el trabajo de un gran numero de personas de muy diversa condicion, desde bibliofilos y bibliotecarios a simples ciudadanos, quienes con su aportacion personal o sus conocimientos han contribuido al desarrollo de una biblioteca excepcional.  al fondo inicial se van sumando otras obras mediante diversos modos de adquisicion e incremento. a las ya mencionadas incautaciones de los nobles partidarios del contendiente austriaco en la guerra de sucesion, como las del duque de uceda, el marques de mondejar, etc., se unen las permutas de fondos con los conventos de santo tomas de avila y el convento de san vicente de plasencia, asi como las donaciones testamentarias hechas por miembros de las instituciones eclesiasticas y la nobleza, frecuentes como metodo para ganarse los favores de los reyes.  pero fue en los siglos xviii y xix cuando la biblioteca nacional de españa se afianza como la institucion bibliotecaria central mas estable del pais, y esto produjo el incremento de su coleccion, tanto por la incorporacion de las bibliotecas de los grandes eruditos, literatos, bibliofilos y politicos de la epoca mediante compra o donacion,​ como por las diversas desamortizaciones de los fondos eclesiasticos realizadas a lo largo del siglo xix. estas constituyeron una importante via de ingreso de fondos en la biblioteca nacional de españa, con colecciones procedentes de conventos, monasterios y ordenes militares, instituciones que fueron durante años productoras y conservadoras de un gran patrimonio cultural. en la desamortizacion de 1869, llamada desamortizacion cultural y promulgada por manuel ruiz zorrilla, la bne recibe varios de los fondos de las catedrales de toledo y avila.​  la siguiente tabla muestra las colecciones mas importantes adquiridas a los largo de los años, por compra, donacion o legado testamentario, las mas extensamente representadas en el catalogo de la bne en la actualidad:  por ultimo, hay que destacar la importancia que adquiere desde 1716 la legislacion que se ha ido promulgando a lo largo de su historia, como la ley de imprenta y de propiedad intelectual (1847 y 1875, respectivamente), el decreto de 1938, que incluye la proteccion de los inventos modernos de las artes graficas y los procesos de reproduccion,​ la ley de 1939 de recuperacion y devolucion, promulgada tras la guerra civil, por la que ingresaron en la biblioteca nacional de españa los libros no reclamados por sus propietarios. entre los hitos legislativos hay que señalar el decreto de 1957 del deposito legal,​ que consiguio hacer realmente efectivo el cumplimiento de dicho deposito, aumentando de manera radical el flujo de recepcion de todo tipo de materiales.  todas estas disposiciones van diseñando el actual flujo de acceso de fondos a la biblioteca nacional de españa, que se realiza por tres vias principales, el mencionado deposito legal, la compra y el canje o donativo.  en la actualidad, la biblioteca nacional de españa cuenta con unos fondos no exhaustivamente cuantificados, pero que se aproximan a los 28 millones de ejemplares. entre ellos destacan la coleccion de manuscritos, que abarca obras desde el s. ix d. c. hasta un total de 23 000 obras, y la de incunables, 2298 ediciones incunables representadas por 3159 ejemplares, incluidos dos libros xilograficos.  es en los impresos antiguos en los que es mas dificil de establecer un volumen exacto, en el catalogo automatizado hay en este momento 145 150 titulos, pero se estima que existe un porcentaje muy alto descrito solo en los catalogos manuales. entre las colecciones destacables estan las de barbieri, gayangos, gomez imaz, graiño, usoz o rico y sinobas.​ una coleccion especialmente relevantes es la coleccion de cervantes y la de cervantes-sedo.​  otro gran conjunto de materiales son los pertenecientes al departamento de bellas artes y cartografia, constituidos por grabados (mas de 100 000 estampas sueltas y otros 600 000 grabados incluidos en libros),​ dibujos, fotografias​ y mapas (a destacar la coleccion mendoza y la de tomas lopez e hijos)​ o las colecciones de ephemera o exlibris.  las obras custodiadas en el departamento de musica y audiovisuales​ comprenden partituras impresas y manuscritas (179 228), grabaciones sonoras en todo tipo de formatos (discos de pizarra, cilindros de cera, vinilos y casetes, 323 699 titulos en el catalogo automatizado) y videos (2000, beta, vhs, dvd y blu-ray, en el catalogo hay actualmente 98 487 titulos).  la coleccion de prensa y revistas de la biblioteca nacional tiene una gran importancia para la investigacion sociologica e historica, e incluye actualmente 157 682 titulos;​ la mayor parte de la prensa y las revistas historicas estan disponibles en la hemeroteca digital. esta coleccion y su incremento anual ocasiona un gran problema de espacio, junto con la coleccion de libros modernos, que en la actualidad cuenta con 2 713 606 y que crece a un ritmo de 100 000 volumenes anuales.​  en 2020 un acuerdo entre el ministerio de cultura (que reformo la legislacion para el caso), la asociacion española de videojuegos (aevi), la asociacion de usuarios de informatica clasica (auic) y la asociacion española de empresas productoras y desarrolladoras de videojuegos y software de entretenimiento (dev) permite depositar en la institucion todos los videojuegos desarrollados en españa​  los primeros catalogos de la real biblioteca publica son catalogos manuscritos y encuadernados, como las ya mencionadas obras de juan de iriarte. la enorme cantidad de catalogos impresos ha venido siendo recogidos en la guia de catalogos impresos de la biblioteca nacional, que en su 3.ª edicion de 2006 recoge un total de 514 catalogos impresos en monografias o en publicaciones seriadas; estos catalogos recogen todo tipo de colecciones: impresos, manuscritos, mapas, etcetera.​  tienen gran importancia los tradicionales catalogos en fichas por autor, titulo, materia o cdu, mantenidos y actualizados laboriosamente a lo largo de los siglos a partir de un catalogo interno «madre», el llamado indice general. en el año 1956 se comenzo a redactar el llamado catalogo diccionario, que mezclaba en una unica secuencia de muy prolijos criterios de ordenacion, autores, titulos y materias. asimismo las distintas salas mantienen sus propios catalogos especializados de las distintas colecciones, que en muchos casos son un recurso unico.  a partir del año 1994, la biblioteca nacional dispone de un opac (online public access catalog), es decir, de un catalogo de acceso en linea, basado en el sistema sirtex, que gestionaba la base de datos ariadna. en 1996, ariadna entra en la web, como la mayoria de los grandes catalogos y poco despues se hace accesible tambien el catalogo de autoridades. en la actualidad el catalogo automatizado de la biblioteca nacional cuenta con alrededor de cuatro millones de obras de todo tipo de materiales, 8 millones de volumenes​ y alrededor de 500 000 autoridades completas.​  en 1953, se publica por primera vez el inventario general de manuscritos de la biblioteca nacional, que recoge los codices de la seccion de manuscritos de la biblioteca. el inventario consta hasta el momento de quince volumenes y recoge 11 000 titulos de los mas de 23 000​ que se conservan hoy en la biblioteca. se puede acceder a la mayoria de los manuscritos desde el catalogo automatizado.  ademas, la biblioteca nacional gestiona tambien el catalogo colectivo de publicaciones periodicas o ccpp,​ que ofrece informacion sobre las colecciones de prensa y revistas que conservan las principales bibliotecas españolas. contiene informacion sobre alrededor de 88 000 titulos de seriadas y de los ejemplares de estas, unos 369 000 distribuidos por alrededor de 1100​ bibliotecas españolas. el directorio de bibliotecas y hemerotecas españolas o dibi recoge datos sobre mas de 10 400 bibliotecas y sirve de apoyo a la localizacion de ejemplares del ccpp.  la biblioteca digital hispanica (bdh) es el portal de la bne a traves del cual se pueden consultar de forma libre y gratuita las obras digitalizadas por la biblioteca. los materiales disponibles incluyen libros impresos entre los siglos xv y xix, manuscritos, dibujos, grabados, folletos, carteles, fotografias, mapas, atlas y grabaciones sonoras.​ ademas, con la colaboracion del departamento de musica y audiovisuales, se ha llevado a cabo una digitalizacion masiva de partituras.​  a traves de la bdh y gracias al protocolo oai-pmh, la biblioteca nacional de españa participa en europeana, el proyecto de la comision europea para crear una biblioteca digital europea, y en hispana, el recolector de recursos digitales del ministerio de educacion, cultura y deporte.  tambien se ha incorporado un conjunto de obras seleccionadas a la biblioteca digital mundial (world digital library) de la unesco.​  desde la bdh se accede ademas a la aplicacion de hemeroteca digital, que permite la consulta de alrededor de 900 publicaciones de prensa. la hemeroteca, creada en marzo de 2007, da acceso a la coleccion digital de prensa historica española que alberga la biblioteca. el objetivo es ofrecer acceso a las cabeceras mas importantes de la epoca para facilitar su estudio e investigacion. en la hemeroteca (al igual que en toda la bdh) es posible buscar en el texto completo de los documentos gracias al reconocimiento optico de caracteres (ocr).​  es una plataforma digital que se encuentra dentro de la biblioteca nacional de españa. con ella se busca el trabajo colaborativo, establecer comunidad entre sus participantes a traves de proyectos.  consta de proyectos abiertos donde cualquier persona puede participar a traves de tareas para favorecer el enriquecimiento de la biblioteca nacional.  su lema es: «mucha gente pequeña en lugares pequeños, haciendo cosas pequeñas, pueden cambiar el mundo» (eduardo galeano).  en el siglo xix el novelista armando palacio valdes hizo una critica demoledora del pesimo servicio que ofrecia la biblioteca nacional en su articulo \"la biblioteca nacional\", incorporado a su libro aguas fuertes. novelas y cuadros (madrid: establecimiento tipografico de ricardo fe, 1884). por otra parte, no se llevaba un control riguroso de la procedencia de muchas de las donaciones y fondos, lo que permitia en general un gran latrocinio no ya por parte del publico, sino de los bibliotecarios, con frecuencia asediados y sobornados por los coleccionistas.  en el siglo xx, a pesar de la ley de deposito legal, la biblioteca nacional se convierte, en palabras del especialista jesus cuadrado en «el coladero mas grande para desaparecer los productos de la cultura popular», desde tebeos a cromos, pasando por fotonovelas, novelas de genero, pegatinas, calcomanias, recortables, dioramas o carteles, los cuales eran sustraidos por bedeles y archiveros.​ ademas, fue robado un codice de leonardo da vinci, entre otros manuscritos, libros y mapas valiosisimos.  con la llegada de la democracia, la situacion no mejoro, ya que no se consideraba prioritario conservar, mantener, reponer o catalogar la denominada cultura popular. de esta manera, «mas de la mitad de la mitad de la mitad de todos los tebeos (apaisados o verticales, es lo mismo) han desaparecido; solo estan, cuando estan, las fichas, y no todas».​ lo mismo puede decirse de los cromos o las fotonovelas sobrevivientes, que se encontraban arrumbadas de mala manera.​ debido a esta situacion, diversos estudiosos de estos sectores convertirian en una constante su reclamacion de un centro de documentacion de la historieta y la cultura popular​ que evitase la «irreparable perdida de nuestra memoria grafica».​ todavia hoy, la biblioteca nacional adolece de la ausencia de colecciones enteras de tebeos.​  en agosto de 2012 organizo, sin embargo, la exposicion el rastro del comic, en la que se repasaron 155 años de viñetas, de las que la institucion conserva actualmente 9600 titulos.​ ",
        "snippet": "Recoletos: paseo de Recoletos 20-22. 28071 Madrid;",
        "enlaces_salientes": [
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Coordenadas_geogr%C3%A1ficas",
            "/wiki/Espa%C3%B1a",
            "/wiki/Biblioteca_nacional",
            "/wiki/Paseo_de_Recoletos",
            "/wiki/Madrid",
            "/wiki/Alcal%C3%A1_de_Henares",
            "/wiki/Madrid",
            "/wiki/Madrid",
            "/wiki/Ana_Santos_Aramburo",
            "/wiki/Ministerio_de_Cultura_y_Deporte",
            "/wiki/Sede_de_la_Biblioteca_Nacional_de_Espa%C3%B1a_en_Alcal%C3%A1_de_Henares",
            "/wiki/Euro",
            "/wiki/Organismo_aut%C3%B3nomo_de_Espa%C3%B1a",
            "/wiki/Espa%C3%B1a",
            "/wiki/Biblioteca_Digital_Hisp%C3%A1nica",
            "/wiki/Paseo_de_Recoletos",
            "/wiki/Palacio_de_Biblioteca_y_Museos_Nacionales",
            "/wiki/Museo_Arqueol%C3%B3gico_Nacional_de_Espa%C3%B1a",
            "/wiki/Sede_de_la_Biblioteca_Nacional_de_Espa%C3%B1a_en_Alcal%C3%A1_de_Henares",
            "/wiki/Alcal%C3%A1_de_Henares",
            "/wiki/Madrid",
            "/wiki/Felipe_V_de_Espa%C3%B1a",
            "/wiki/Pedro_Robinet",
            "/wiki/Melchor_de_Macanaz",
            "/wiki/Real_Alc%C3%A1zar_de_Madrid",
            "/wiki/Real_Monasterio_de_la_Encarnaci%C3%B3n",
            "/wiki/Felipe_IV_de_Espa%C3%B1a",
            "/wiki/Austriacistas",
            "/wiki/Guerra_de_sucesi%C3%B3n_espa%C3%B1ola",
            "/wiki/Antoni_Folch_de_Cardona",
            "/wiki/Gaspar_Ib%C3%A1%C3%B1ez_de_Segovia",
            "/wiki/Conde_de_Aguilar",
            "/wiki/Duque_de_Medinaceli",
            "/wiki/Crist%C3%B3bal_Rodr%C3%ADguez_(archivero)",
            "/wiki/Juan_Ferreras",
            "/wiki/Juan_de_Iriarte",
            "/wiki/Juan_de_Santander",
            "/wiki/Carlos_III_de_Espa%C3%B1a",
            "/wiki/Jer%C3%B3nimo_Antonio_Gil",
            "/wiki/Jos%C3%A9_Bonaparte",
            "/wiki/Convento_de_la_Trinidad_Calzada_(Madrid)",
            "/wiki/Orden_Trinitaria",
            "/wiki/Calle_de_Atocha",
            "/wiki/Fernando_VII_de_Espa%C3%B1a",
            "/wiki/Marquesado_de_Alca%C3%B1ices",
            "/wiki/Convento_de_Copacabana",
            "/wiki/Orden_de_Agustinos_Recoletos",
            "/wiki/San_Isidoro_de_Sevilla",
            "/wiki/Jos%C3%A9_Alcoverro",
            "/wiki/Desamortizaci%C3%B3n_espa%C3%B1ola",
            "/wiki/Cortes_de_C%C3%A1diz",
            "/wiki/Manuel_Ruiz_Zorrilla",
            "/wiki/Catedral_de_%C3%81vila",
            "/wiki/Catedral_de_Toledo",
            "/wiki/Ministerio_de_la_Gobernaci%C3%B3n_de_Espa%C3%B1a",
            "/wiki/Antonia_Guti%C3%A9rrez_Bueno",
            "/wiki/Francisco_Jare%C3%B1o",
            "/wiki/Isabel_II_de_Espa%C3%B1a",
            "/wiki/Palacio_de_Biblioteca_y_Museos_Nacionales",
            "/wiki/Paseo_de_Recoletos",
            "/wiki/Antonio_Ruiz_de_Salces",
            "/wiki/La_Ilustraci%C3%B3n_Art%C3%ADstica",
            "/wiki/Marcelino_Men%C3%A9ndez_Pelayo",
            "/wiki/Francisco_Guill%C3%A9n_Robles",
            "/wiki/El%C3%ADas_Tormo",
            "/wiki/Miguel_Artigas",
            "/wiki/Segunda_Rep%C3%BAblica_Espa%C3%B1ola",
            "/wiki/Alcal%C3%A1_Zamora",
            "/wiki/Guerra_civil_espa%C3%B1ola",
            "/wiki/Torres_de_Serranos",
            "/wiki/Valencia",
            "/wiki/Junta_de_Incautaci%C3%B3n_y_Protecci%C3%B3n_del_Patrimonio_Art%C3%ADstico",
            "/wiki/Archivo_Hist%C3%B3rico_Nacional",
            "/wiki/Museo_Arqueol%C3%B3gico_Nacional_(Espa%C3%B1a)",
            "/wiki/Consejo_de_Ministros_de_Espa%C3%B1a",
            "/wiki/Gobierno_espa%C3%B1ol",
            "/wiki/Milagros_del_Corral",
            "/wiki/Gloria_P%C3%A9rez-Salmer%C3%B3n",
            "/wiki/Biblioteca_Digital_Hisp%C3%A1nica",
            "/wiki/Facebook",
            "/wiki/Web_2.0",
            "/wiki/Twitter",
            "/wiki/YouTube",
            "/wiki/Slideshare",
            "/wiki/Flickr",
            "/wiki/Wordpress",
            "/wiki/Internet_Archive",
            "/wiki/Cervantes",
            "/wiki/Dialnet",
            "/wiki/Universidad_Polit%C3%A9cnica_de_Madrid",
            "/wiki/Resource_Description_Framework",
            "/wiki/IFLA",
            "/wiki/OCLC",
            "/wiki/VIAF",
            "/wiki/Organizaci%C3%B3n_Internacional_de_Normalizaci%C3%B3n",
            "/wiki/Asociaci%C3%B3n_Espa%C3%B1ola_de_Normalizaci%C3%B3n_y_Certificaci%C3%B3n",
            "/wiki/Universidad_de_Alcal%C3%A1",
            "/wiki/Ministerio_de_Cultura_(Espa%C3%B1a)",
            "/wiki/Sede_de_la_Biblioteca_Nacional_de_Espa%C3%B1a_en_Alcal%C3%A1_de_Henares",
            "/wiki/Sede_de_la_Biblioteca_Nacional_de_Espa%C3%B1a_en_Alcal%C3%A1_de_Henares",
            "/wiki/Felipe_V_de_Espa%C3%B1a",
            "/wiki/Real_Biblioteca_de_San_Lorenzo_de_El_Escorial",
            "/wiki/Arag%C3%B3n",
            "/wiki/Castilla",
            "/wiki/Estado_regional",
            "/wiki/Comunidades_aut%C3%B3nomas",
            "/wiki/Andaluc%C3%ADa",
            "/wiki/Arag%C3%B3n",
            "/wiki/Asturias",
            "/wiki/Castilla-La_Mancha",
            "/wiki/Ceuta",
            "/wiki/Catalu%C3%B1a",
            "/wiki/Extremadura",
            "/wiki/Navarra",
            "/wiki/Exlibris",
            "/wiki/Alfonso_X_el_Sabio",
            "/wiki/Jos%C3%A9_Alcoverro",
            "/wiki/Episodios_nacionales",
            "/wiki/Benito_P%C3%A9rez_Gald%C3%B3s",
            "/wiki/Espa%C3%B1a",
            "/wiki/Cris%C3%B3stomo_Mart%C3%ADnez",
            "/wiki/Orden_militar",
            "/wiki/Cayetano_Alberto_de_la_Barrera",
            "/wiki/Agust%C3%ADn_Dur%C3%A1n",
            "/wiki/Francisco_Asenjo_Barbieri",
            "/wiki/Manuel_Castellano",
            "/wiki/Com%C3%ADn_Colomer",
            "/wiki/Duque_de_Osuna",
            "/wiki/Pascual_de_Gayangos",
            "/wiki/Francisco_de_Paula_de_Borb%C3%B3n",
            "/wiki/Jos%C3%A9_Madrazo",
            "/wiki/Josef_de_Mendoza_y_R%C3%ADos",
            "/wiki/Pi_y_Margall",
            "/wiki/Tom%C3%A1s_Garc%C3%ADa_Figueras",
            "/wiki/Juan_Mar%C3%ADa_Guelbenzu",
            "/wiki/Juan_Eugenio_Hartzenbusch",
            "/wiki/Ram%C3%B3n_de_Garciasol",
            "/wiki/Valent%C3%ADn_Carderera",
            "/wiki/Jer%C3%B3nimo_de_Ayanz_y_Beaumont",
            "/wiki/Incunable",
            "/wiki/Manuel_Rico_Sinobas",
            "/wiki/Ephemera",
            "/wiki/Exlibris",
            "/wiki/Asociaci%C3%B3n_Espa%C3%B1ola_de_Videojuegos",
            "/wiki/Videojuego",
            "/wiki/Juan_de_Iriarte",
            "/wiki/OPAC",
            "/wiki/Biblioteca_Digital_Hisp%C3%A1nica",
            "/wiki/Biblioteca_Digital_Hisp%C3%A1nica",
            "/wiki/OAI-PMH",
            "/wiki/Europeana",
            "/wiki/Hispana_(biblioteca_digital)",
            "/wiki/Ministerio_de_Educaci%C3%B3n,_Cultura_y_Deporte",
            "/wiki/Biblioteca_Digital_Mundial",
            "/wiki/UNESCO",
            "/wiki/Hemeroteca_Digital_de_la_Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Reconocimiento_%C3%B3ptico_de_caracteres",
            "/wiki/Armando_Palacio_Vald%C3%A9s",
            "/wiki/Jes%C3%BAs_Cuadrado",
            "/wiki/Cultura_popular",
            "/wiki/Tebeo",
            "/wiki/Cromo",
            "/wiki/Fotonovela",
            "/wiki/Pegatina",
            "/wiki/Calcoman%C3%ADa",
            "/wiki/Recortable",
            "/wiki/Diorama",
            "/wiki/Cartel",
            "/wiki/Leonardo_da_Vinci",
            "/wiki/Tebeo",
            "/wiki/Asociaci%C3%B3n_de_Estados_Iberoamericanos_para_el_Desarrollo_de_las_Bibliotecas_Nacionales_de_Iberoam%C3%A9rica",
            "/wiki/Biblioteca_digital",
            "/wiki/C%C3%B3dices_Madrid_I-II",
            "/wiki/The_European_Library",
            "/wiki/Premio_Nacional_de_Bibliograf%C3%ADa",
            "/wiki/El_Pa%C3%ADs",
            "/wiki/Ministerio_de_Hacienda_y_Funci%C3%B3n_P%C3%BAblica",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISSN",
            "/wiki/Internet_Archive",
            "/wiki/Internet_Archive",
            "/wiki/Estricnina",
            "/wiki/Hustler",
            "/wiki/Makoki_(revista)",
            "/wiki/La_Vanguardia",
            "/wiki/Manuel_Carri%C3%B3n_G%C3%BAtiez",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISSN",
            "/wiki/ISBN",
            "/wiki/OCLC",
            "/wiki/ISBN",
            "/wiki/Tom%C3%A1s_Navarro_Tom%C3%A1s",
            "/wiki/ISBN",
            "/wiki/Pedro_Manuel_C%C3%A1tedra",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Union_List_of_Artist_Names",
            "/wiki/Dialnet"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Biblioteca_Nacional_de_Francia",
        "titulo": "Biblioteca Nacional de Francia",
        "contenido": "la biblioteca nacional de francia (en frances: bibliotheque nationale de france, abr. bnf) es la biblioteca mas importante de francia y una de las mas antiguas del mundo. esta situada principalmente en paris.​ sus actividades se reparten entre diferentes ubicaciones, siendo la principal la sede francois mitterrand en el xiii distrito de paris, en la orilla sur del rio sena. dispone de millones de volumenes, y almacena otros recursos a traves de otros departamentos como su biblioteca digital, gallica.  un decreto del año 1537, que sigue aun en vigor, exige que la bnf guarde un ejemplar de todas las obras publicadas en el pais. actualmente, alberga en total mas de 13 000 000 (trece millones) de libros y 350 000 volumenes encuadernados de manuscritos, ademas de colecciones de mapas, monedas, documentos, estampas y registros sonoros. cuenta con catorce departamentos y numerosas colecciones principalmente conservadas en sus cuatro sedes parisinas, incluyendo el departamento de monedas, medallas y antiguedades, heredero del cabinet des medailles. el conjunto de las colecciones representa alrededor de 4 000 000 000 (cuatro mil millones) de documentos impresos y especializados.  sus fondos resultaron de la union de diversas colecciones. la biblioteca del rey (bibliotheque du roi), fundada en 1368 por el rey carlos v (1364-1380) con unos 1200 manuscritos en el palacio real de louvre. despues de su reinado, los manuscritos junto a otras obras de arte se dispersaron a otros lugares pero luis xi (1423-1483) volvio a crear otra biblioteca real. en 1544, francisco i de francia traslado la biblioteca que contaba con 917 manuscritos, y la biblioteca de los duques de orleans en su residencia real de fontainebleau. desde el 28 de diciembre de 1537, mediante la ordonnance de montpellier,​ el castillo de blois donde se encontraba ahora la biblioteca, empezo a recibir una copia de cada publicacion que se ponia a la venta en el pais. esta obligacion, llamada deposito legal, es una etapa fundamental por su importancia y vigencia a lo largo de su existencia. la biblioteca se traslado a la capital, paris, entre 1567 y 1593 por carlos ix (1550-1574).  el primer catalogo de sus existencias se compilo y publico en 1622. bajo el nombre de biblioteca real (bibliotheque royal), en 1666 fueron instaladas por luis xiv (1643-1715) en la calle vivienne. se abrio al publico por primera vez en 1692.  en 1721, la biblioteca se traslado al palacio mazarin en la rue de richelieu y se sometio a sucesivas expansiones a partir de entonces. en plena revolucion francesa, paso a llamarse biblioteca nacional (bibliotheque nationale) en 1795, y se beneficio con las confiscaciones revolucionarias de las colecciones de libros que poseia la iglesia catolica en francia y mas tarde con las adquisiciones de napoleon. se estimo unos 300 000 volumenes antes de la revolucion y, en 1818, se habian duplicado.  durante el siglo xix, el administrador y bibliotecario leopold victor delisle organizo la extensa y valiosa coleccion de manuscritos de la biblioteca. en 1926, la bibliotheque nationale entro a formar parte de un grupo de otras bibliotecas parisinas que, a finales del siglo xx, incluia la biblioteca del arsenal y las bibliotecas de la opera de paris y del conservatorio nacional de musica. con la continua expansion de las colecciones, el antiguo complejo de edificios en la rue de richelieu ya no podia acomodar mas libros.  una nueva biblioteca diseñada se completo a lo largo del rio sena en 1995 y se abrio al año siguiente. estas nuevas estructuras albergan todos los libros, publicaciones periodicas y revistas de la bnf, con un total de mas de doce millones de libros impresos.  la biblioteca nacional de francia (bnf) antes de su sede principal, sufre de varias mudanzas y se instala en 1720 en la calle richelieu de paris. nombrada como biblioteca nacional primero, y posteriormente como imperial en el curso de los cambios de regimenes que conoce francia a partir de la revolucion, se instala en los edificios construidos por henri labrouste en 1868.  la evolucion de la bnf esta marcada por varias mudanzas de colecciones, de las cuales, la ultima fue la mas importante. acompañada por reformas y una ampliacion de las superficies utilizadas, con nuevas construcciones, anexiones de edificios preexistentes, y por otra parte almacenamientos en profundidad (en la calle richelieu) o en altura (en tolbiac). en varios siglos, la biblioteca encontro varias evoluciones tecnicas, que las tuvo en cuenta, a veces con retraso. estas evoluciones se reflejaron en la entrada de documentos mas variados. diferentes tecnicas tambien han sido puestas en ejecucion en la constitucion de catalogos cada vez mas complejos (catalogos manuscritos e impresos, ficheros y, desde 1987, catalogos informatizados).  el 14 de julio de 1988, francois mitterrand, aconsejado particularmente por jacques attali, anuncia en la tradicional entrevista televisada en la radio television francesa por el dia nacional, «el diseño y la construccion de la mayor y mas moderna biblioteca del mundo».​  la ubicacion escogida esta en el nuevo barrio de tolbiac, en el xiii distrito de paris, en una de las orillas del rio sena, entonces un terreno abandonado y propuesto para ayudar a la renovacion urbana de la ciudad. el proyecto arquitectonico de dominique perrault es atrevido. simbolizando unos libros abiertos, son cuatro rascacielos de vidrio y acero de 80 metros de altura, 22 pisos, en forma de «l». cada torre lleva un nombre: de los tiempos, de las leyes, de los numeros y torre de las letras. los edificios estan agrupados alrededor de un cuadrado abierto en el centro, que es un jardin de 12 000 m² (metros cuadrados) cerrado al publico. bajo este nivel hay ademas dos niveles, de los que el mas bajo es una calle interior destinada a la circulacion de vehiculos (en particular los propios vehiculos internos de la bnf y los que vienen para entregar nuevo material al deposito legal). el conjunto de las superficies construidas representa 2 900 000 m² y ocupa una superficie de 7,5 hectareas en una explanada de 60 000 m².  la nueva biblioteca nacional francesa abrio al publico el 20 de diciembre de 1996 y, despues de la mudanza de la sede mayor de las colecciones de la calle richelieu, acoge tambien en una sala especial a los investigadores desde octubre de 1998.  en el siglo xix, henri labrouste recibio dos directrices muy claras a la hora de diseñar la sala de lectura que llevaria su nombre. en primer lugar, los lectores debian consultar los documentos escogidos, que les eran traidos por los trabajadores del almacen, siempre bajo la atenta vigilancia de los conservadores. en segundo lugar, solo se podria utilizar luz natural en el espacio. teniendo eso siempre en cuenta, el arquitecto doto a la sala de nueve cupulas de las que dependia la difusion de la luz de manera uniforme, apoyadas sobre arcos de hierro que, a su vez, descansaban sobre 16 columnas de 30 centimetros de diametro y 10 metros de altura. la ligereza hecha edificio.​  fue la obra maestra de labrouste, empezada en 1868 y terminada diez años mas tarde, ya muerto su autor. esta sala de lectura esta formada por unas finas columnas de fundicion de nueve metros de altura que soportan una vidriera. las cupulas, en forma de cascara de huevo, contribuyen a dar sensacion de ligereza al conjunto. junto a esta sala se hizo un espectacular deposito, concebido para 900 000 libros. todo el edificio es de estructura metalica y la cubierta de cristal. esta biblioteca ha sido calificada como una de las obras mas bellas del siglo xix.​  la construccion de la sede richelieu comenzo en el siglo xvii, por lo que existia un desfase entre las instalaciones y las necesidades que se espera satisfaga un establecimiento asi en la actualidad. su antiguedad, la obsolescencia en aspectos tecnicos y de seguridad, el deficit en las condiciones para atender al publico, trabajar y conservar las colecciones motivaron su remodelacion.  la bnf es un establecimiento publico bajo tutela del ministerio de cultura. como biblioteca nacional, tiene por mision constituir colecciones, particularmente en el marco del deposito legal, velar por su conservacion y darlas a conocer al publico. produce un catalogo de referencia, coopera con otros establecimientos al nivel nacional e internacional y participa en programas de busqueda.  la zona superior de la sede de tolbiac es accesible a toda persona de dieciseis o mas años de edad, a condicion de pagar una cuota de entrada, o sea para un acceso puntual, o sea en forma de abono anual. la planta baja con jardin, asi como las salas de lectura de otras ubicaciones son utilizables solo despues de acreditacion mediante justificacion de la busqueda, y mediante pago (carta de quince dias o carta anual). ciertas personas pueden ser exoneradas y pagar una tarifa reducida, particularmente los estudiantes.  la bnf, ademas de asegurarse una copia de todo libro puesto a la venta en el pais, tambien recoge otros tipos de producciones en colaboracion con el instituto nacional de los medios audiovisuales y el centro nacional de la cinematografia. es a ella quien recoge mas documentos a este titulo y la mayoria de las entradas proviene del deposito legal. hay que anotar que si la bnf es depositaria de los libros y otros impresos, el deposito legal de las historietas esta en el centro nacional de la historieta y de la imagen (cnbdi) en angulema.  la bnf tiene una tradicion larga de exposiciones centradas sobre sus colecciones, pero a menudo completadas por aportaciones exteriores. desde la constitucion del nuevo establecimiento publico, reforzo su actividad de acogida de manifestaciones cientificas, tales como coloquios, conferencias, o mas raramente proyecciones y conciertos. tambien es una editorial. principalmente publica catalogos de sus colecciones, catalogos de exposiciones y documentos ineditos. algunas de sus producciones aparecen en coedicion con editores privados.  la bnf tiene tambien en sus misiones la cooperacion con otras bibliotecas francesas. anudo asi relaciones privilegiadas con otras bibliotecas destinadas «polos asociados» de la bnf. estos polos asociados son de dos tipos:  los polos regionales del deposito legal impresor, en cada region de provincia y exotica, reciben los libros depositados por los impresores.  los polos de division documental, en total de 47 (25 en isla de francia, 22 en las provincias). se comprometen, con la ayuda de este, en adquirir y conservar colecciones complementarias de las de la bnf, en un campo determinado. a menudo, varias bibliotecas de la misma ciudad forman juntos un polo de division documental.  la bnf tambien mantiene relaciones con otras bibliotecas e instituciones en el extranjero. la mas conocida es la participacion en la «biblioteca europea», la biblioteca virtual organizada conjuntamente por varias bibliotecas europeas, esencialmente con otras bibliotecas nacionales. esta reagrupacion dio origen a la iniciativa para una «biblioteca digital europea», un proyecto que asocia a la inmensa mayoria de las bibliotecas nacionales del continente.  la bnf aporta tambien su apoyo a bibliotecas de otros paises, en particular de africa francofona y de america del sur. participa por ultimo en la ifla. en el seno de esta federacion, la bnf participa en los grupos de trabajo sobre las normas de catalogar y esta encargada mas especialmente de coordinar el programa pac preservacion y conservacion, dedicado a la conservacion y a la salvaguardia de los documentos antiguos o fragiles.  la biblioteca nacional francesa es administrada por un consejo de administracion que comprende a representantes de los ministerios de tutela, miembros que representan el mundo de la busqueda, de los representantes del personal y de dos representantes de los usuarios al consejo de administracion le presta asistencia un consejo cientifico que tiene un papel consultivo.  el presidente de la bnf, nombrado por decreto por tres años, mandato renovable una vez, dirige el establecimiento, tiene asistencia de un director general y por directores generales adjuntos. actualmente, laurence engel es presidente de la bnf. los servicios de la bnf son repartidos en tres direcciones y cuatro delegaciones.  las delegaciones que directamente dependen del director general son las siguientes: ",
        "snippet": "La Biblioteca Nacional de Francia (en francés: Bibliothèque nationale de France, abr. BnF) es la biblioteca más importante de Francia y una de las más antiguas del mundo. Está situada principalmente en París.[1]​ Sus actividades se reparten entre diferentes ubicaciones, siendo la principal la sede François Mitterrand en el XIII distrito de París, en la orilla sur del río Sena. Dispone de millones de volúmenes, y almacena otros recursos a través de otros departamentos como su biblioteca digital, Gallica.",
        "enlaces_salientes": [
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Coordenadas_geogr%C3%A1ficas",
            "/wiki/Francia",
            "/wiki/Biblioteca_p%C3%BAblica",
            "/wiki/Idioma_franc%C3%A9s",
            "/wiki/Abreviatura",
            "/wiki/Biblioteca",
            "/wiki/Francia",
            "/wiki/Par%C3%ADs",
            "/wiki/Fran%C3%A7ois_Mitterrand",
            "/wiki/XIII_Distrito_de_Par%C3%ADs",
            "/wiki/R%C3%ADo_Sena",
            "/wiki/Gallica",
            "/wiki/Cabinet_des_M%C3%A9dailles",
            "/wiki/Carlos_V_de_Francia",
            "/wiki/Museo_del_Louvre",
            "/wiki/Luis_XI_de_Francia",
            "/wiki/Francisco_I_de_Francia",
            "/wiki/Ducado_de_Orleans",
            "/wiki/Fontainebleau",
            "/wiki/Castillo_de_Blois",
            "/wiki/Carlos_IX_de_Francia",
            "/wiki/Luis_XIV_de_Francia",
            "/wiki/Revoluci%C3%B3n_francesa",
            "/wiki/Iglesia_cat%C3%B3lica_en_Francia",
            "/wiki/Napole%C3%B3n_Bonaparte",
            "/wiki/1926",
            "/wiki/Biblioteca_del_Arsenal",
            "/wiki/%C3%93pera_de_Par%C3%ADs",
            "/wiki/Conservatorio_de_Par%C3%ADs",
            "/wiki/Henri_Labrouste",
            "/wiki/Fran%C3%A7ois_Mitterrand",
            "/wiki/Jacques_Attali",
            "/wiki/D%C3%ADa_Nacional_de_Francia",
            "/wiki/Dominique_Perrault",
            "/wiki/Rascacielos",
            "/wiki/Vidrio",
            "/wiki/Acero",
            "/wiki/Henri_Labrouste",
            "/wiki/Henri_Labrouste",
            "/wiki/Ministerio_de_Cultura_(Francia)",
            "/wiki/Angulema",
            "/wiki/The_European_Library",
            "/wiki/Federaci%C3%B3n_Internacional_de_Asociaciones_de_Bibliotecarios_y_Bibliotecas",
            "/wiki/Avi%C3%B1%C3%B3n",
            "/wiki/Bussy-Saint-Georges",
            "/wiki/Sabl%C3%A9-sur-Sarthe",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_de_Catalu%C3%B1a",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Union_List_of_Artist_Names",
            "/wiki/BIBSYS",
            "/wiki/Istituto_Centrale_per_il_Catalogo_Unico",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Gemeinsame_Normdatei",
        "titulo": "Gemeinsame Normdatei",
        "contenido": "el gemeinsame normdatei (gnd; en ingles: integrated authority file) es un indice estandarizado de control de autoridades para datos de personas, instituciones, congresos, datos geograficos, descriptores y palabras clave, asi como titulos de obras, al servicio principalmente de la catalogacion de literatura en bibliotecas y crecientemente tambien para la categorizacion en archivos, museos, proyectos y aplicaciones web. se mantiene en cooperacion entre la biblioteca nacional de alemania, todas las asociaciones de bibliotecas de paises germanoparlantes (el osterreichischer bibliothekenverbund de austria, la biblioteca nacional de suiza), la base de datos de periodicos y revistas (zeitschriftendatenbank) y muchas otras instituciones. los datos normalizados facilitan la catalogacion, ofrecen entradas univocas para las busquedas y posibilitan la interconexion en red de distintos recursos informativos.  la gnd surgio el 19 de abril de 2012, en reemplazo de los datos normalizados que hasta esa fecha se manejaban de manera separada en los siguientes indices separados:  a partir de julio de 2014, los datos normalizados se acopian y registran en concordancia con las reglas de la rda (resource description and access), que es la norma que se utiliza, entre otras, en la biblioteca del congreso de estados unidos.​ ",
        "snippet": "El Gemeinsame Normdatei (GND; en inglés: Integrated Authority File) es un índice estandarizado de control de autoridades para datos de personas, instituciones, congresos, datos geográficos, descriptores y palabras clave, así como títulos de obras, al servicio principalmente de la catalogación de literatura en bibliotecas y crecientemente también para la categorización en archivos, museos, proyectos y aplicaciones web. Se mantiene en cooperación entre la Biblioteca Nacional de Alemania, todas las asociaciones de bibliotecas de países germanoparlantes (el Österreichischer Bibliothekenverbund de Austria, la Biblioteca Nacional de Suiza), la Base de Datos de Periódicos y Revistas (Zeitschriftendatenbank) y muchas otras instituciones. Los datos normalizados facilitan la catalogación, ofrecen entradas unívocas para las búsquedas y posibilitan la interconexión en red de distintos recursos informativos.",
        "enlaces_salientes": [
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Alemania",
            "/wiki/Fr%C3%A1ncfort_del_Meno",
            "/wiki/Conjunto_de_datos",
            "/wiki/Cat%C3%A1logo_en_l%C3%ADnea",
            "/wiki/Base_de_datos",
            "/wiki/19_de_abril",
            "/wiki/2012",
            "/wiki/2012",
            "/wiki/Biblioteca_Nacional_de_Alemania",
            "/wiki/Biblioteca_Nacional_de_Alemania",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Control_de_autoridades",
            "/wiki/Biblioteca_Nacional_de_Alemania",
            "/wiki/Austria",
            "/wiki/Biblioteca_Nacional_de_Suiza",
            "/wiki/Resource_Description_and_Access",
            "/wiki/Biblioteca_del_Congreso_de_Estados_Unidos",
            "/wiki/ISSN",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Library_of_Congress_Control_Number",
        "titulo": "Library of Congress Control Number",
        "contenido": "el library of congress control number (en castellano, ‘numero de control de la biblioteca del congreso’), abreviado lccn, es un sistema basado en numeros de serie para numerar los registros de catalogo de la biblioteca del congreso de estados unidos. este sistema de numeracion ha estado en uso desde 1898. no tiene relacion alguna con los contenidos de los libros, y no debe confundirse con la clasificacion de la biblioteca del congreso (lcc).  el acronimo lccn aludia originalmente a library of congress card number (‘numero de tarjeta de la biblioteca del congreso’), ya que la biblioteca del congreso preparaba tarjetas de informacion bibliografica para su catalogo y vendia conjuntos duplicados de las tarjetas a otras bibliotecas para usarlos en sus catalogos. esta costumbre se conocia como catalogacion centralizada. a cada conjunto de tarjetas se daba un numero de serie para facilitar su identificacion. como la mayoria de la informacion bibliografica se crea, almacena y comparte actualmente de forma digital, sigue existiendo la necesidad de identificar univocamente cada registro, realizando aun el lccn esta funcion.  en su forma mas elemental el numero incluye un año y un numero de serie. al año tiene dos digitos desde 1898 a 2000, y cuatro digitos a partir de 2001. los tres años ambiguos se distinguen por la longitud del numero de serie. hay tambien algunas peculiaridades con los numeros que empiezan por un «7» debido a un experimento fallido llevado a cabo entre 1969 y 1972.  los numeros de serie tienen seis digitos y deben incluir ceros a la izquierda. el guion que a menudo separa el año y el numero de serie es opcional. mas recientemente, la biblioteca del congreso ha indicado a los editores que no lo incluyan.  los bibliotecarios de todo el mundo usan este identificador univoco en el proceso de catalogar la mayoria de los libros que han sido publicados en los estados unidos. esto les ayuda a corregir los datos de catalogacion (conocidos como registro de catalogo), que la biblioteca del congreso y terceros ponen a disposicion en la web y por otros medios. ",
        "snippet": "El Library of Congress Control Number (en castellano, ‘número de control de la Biblioteca del Congreso’), abreviado LCCN, es un sistema basado en números de serie para numerar los registros de catálogo de la Biblioteca del Congreso de Estados Unidos. Este sistema de numeración ha estado en uso desde 1898. No tiene relación alguna con los contenidos de los libros, y no debe confundirse con la Clasificación de la Biblioteca del Congreso (LCC).",
        "enlaces_salientes": [
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/N%C3%BAmero_de_serie",
            "/wiki/Biblioteca_del_Congreso_de_Estados_Unidos",
            "/wiki/1898",
            "/wiki/Clasificaci%C3%B3n_de_la_Biblioteca_del_Congreso",
            "/wiki/Guion_(signo_ortogr%C3%A1fico)",
            "/wiki/Bibliotecario",
            "/wiki/Identificador",
            "/wiki/World_Wide_Web",
            "/wiki/CODEN",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Biblioteca_Nacional_de_la_Dieta",
        "titulo": "Biblioteca Nacional de la Dieta",
        "contenido": "la biblioteca nacional de la dieta (en japones: 国立国会図書館, kokuritsu kokkai toshokan) esta al servicio de la investigacion y la administracion de la dieta de japon y del pueblo japones. es la unica biblioteca de japon que recoge y conserva todas las publicaciones editadas en el pais. la base para su creacion es el articulo 130 de la ley de la dieta y el articulo 1 de la ley de la biblioteca nacional de la dieta.​  la biblioteca de la dieta nacional es un organo del gobierno nacional perteneciente a la dieta, el organo legislativo de japon, y es una biblioteca parlamentaria cuyo objetivo principal es ayudar a la dieta en sus actividades legislativas. al mismo tiempo, como unica biblioteca nacional de japon, tambien presta servicios a los poderes administrativo y judicial y al pueblo japones. es miembro del fichero internacional virtual de autoridades.  sus instalaciones comprenden una biblioteca central y bibliotecas sucursales, tal como se define en el articulo 3 de la ley de la biblioteca nacional de la dieta. la biblioteca central esta formada por la biblioteca principal de tokio (nagata-cho, chiyoda-ku, tokio) y la kansai-kan (seikadai, seika-cho, souraku-gun, kioto), con la biblioteca filial de la dieta nacional anexa a la biblioteca principal de tokio.  ademas de la biblioteca internacional de literatura infantil (parque ueno, taito-ku, tokio), hay una biblioteca sucursal en el poder judicial (la biblioteca del tribunal supremo), y una biblioteca sucursal en cada departamento administrativo en vi  en 1968, año de su vigesimo, se construyo la sede principal conocida como tokyo main library.​ cuenta con dos instalaciones principales en tokio y en kioto, ademas de otras pequeñas sucursales.  la biblioteca nacional de la dieta es la sucesora de tres bibliotecas independientes: la biblioteca de la camara de los pares , la biblioteca de la camara de representantes , ambas establecidas con la creacion de la dieta imperial de japon en 1890; y la biblioteca imperial,​ que se establecio en 1872 bajo la jurisdiccion del ministerio de educacion.​  el poder de la dieta en el japon de la preguerra era limitado, y su necesidad de informacion era «correspondientemente pequeña». las bibliotecas originales de la dieta «nunca desarrollaron las colecciones ni los servicios que podrian haberlas convertido en complementos vitales de una actividad legislativa genuinamente responsable». hasta la derrota de japon, ademas, el ejecutivo habia controlado todos los documentos politicos, privando al pueblo y a la dieta del acceso a informacion vital. las fuerzas de ocupacion estadounidenses bajo el mando del general douglas macarthur consideraron que la reforma del sistema de bibliotecas de la dieta era una parte importante de la democratizacion de japon despues de su derrota en la segunda guerra mundial.​​  en 1946, cada casa de la dieta formo su propio comite permanente de la biblioteca nacional de la dieta. hani goro , un historiador marxista que habia sido encarcelado durante la guerra por crimenes de pensamiento y habia sido elegido miembro de la camara de consejeros (el sucesor de la abolida casa de los pares) despues de la guerra, encabezo los esfuerzos de reforma. hani concibio el nuevo organismo como «tanto una “ciudadela de soberania popular”» como el medio para realizar una «revolucion pacifica». los oficiales de ocupacion responsables de supervisar las reformas de las bibliotecas informaron que, aunque la ocupacion fue un catalizador para el cambio, la iniciativa local preexistio a la ocupacion y las reformas exitosas se debieron a japoneses dedicados como hani.​  la biblioteca nacional de la dieta se inauguro en junio de 1948 en la actual casa de invitados del estado (antiguo palacio independiente de akasaka) con una coleccion inicial de 100 000 volumenes. el primer bibliotecario de la biblioteca de la dieta fue el politico tokujiro kanamori. el filosofo masakazu nakai fue el primer subdirectorio.​ en 1949, la bnd se fusiono con la biblioteca nacional (anteriormente llamada biblioteca imperial) y se convirtio en la unica biblioteca nacional de japon. en este momento, la coleccion gano un millon de volumenes adicionales que anteriormente se encontraban en la antigua biblioteca nacional de ueno.​  en 1961, el bnd abrio en su ubicacion actual  en nagatacho, adyacente a la dieta nacional. en 1986, se completo el anexo de la bnd para dar cabida a un total combinado de 12 000 000 (doce millones) de libros y publicaciones periodicas. la kansai-kan (la biblioteca de kansai ), que se inauguro en octubre de 2002 en la ciudad de las ciencias de kansai ( ciudad seika condado de soraku, prefectura de kioto), tiene una coleccion de 6 000 000 (seis millones) de articulos. en mayo de 2002, la bnd abrio una nueva sucursal, la biblioteca internacional de literatura infantil, en el antiguo edificio de la biblioteca imperial de ueno. esta rama contiene unos 400 000 articulos de literatura infantil de todo el mundo.  aunque el mandato original de la bnd era ser una biblioteca de investigacion para la dieta nacional, el publico en general es el mayor consumidor de los servicios de la biblioteca. en el año fiscal que finalizo en marzo de 2004, por ejemplo, la biblioteca informo mas de 250 000 consultas de referencia; por el contrario, registro solo 32 000 solicitudes de investigacion de la dieta nacional.  en respuesta a la pandemia del coronavirus (covid-19), el bnd suspendio los servicios bibliotecarios al publico el 5 de marzo de 2020.​ la bnd reabrio al publico el 11 de junio de 2020 con un maximo de 200 visitantes por dia segun un sorteo estilo loteria, en el que los posibles visitantes deben registrarse de antemano para tener la oportunidad de ser seleccionados.​  como biblioteca nacional de japon, la biblioteca recopila copias de todas las publicaciones publicadas en japon. dado que la bnd sirve como biblioteca de investigacion para los miembros del parlamento, su personal y el publico, tambien tiene colecciones extensas de publicaciones en idiomas extranjeros sobre una amplia gama de temas.​  al igual que las instituciones relacionadas internacionalmente, la bnd tiene un derecho de deposito legal que diferencia claramente entre instituciones estatales y editoriales privadas. lo asombroso aqui es la alta obligacion tributaria para las publicaciones oficiales: treinta copias para las autoridades estatales, cinco copias para las prefecturas y ciudades y tres impuestos obligatorios para los municipios.  las editoriales privadas deben presentar en un plazo de treinta dias, con reembolso del 50 % de los costos y gastos de transporte. la literatura en cuestion se recibe principalmente a traves de dos grandes librerias.  a finales de marzo de 2002, la bnd celebro contar entre otras cosas con: 7 914 460 libros y 167 115 revistas, la mayor parte de las cuales estan escritas en japones. por supuesto, el espectro de medios recopilados es mucho mas diverso, desde publicaciones electronicas hasta braille.  la catalogacion se realiza por separado segun el tipo de medio (publicaciones periodicas, materiales que no son libros, libros) y sigue los criterios de las normas de catalogacion de nippon (ncr).​ los datos obtenidos (japan marc) se registran semanalmente en la bibliografia nacional de japon (nihon zenkoku shoshi). un derivado es el japan biblio disc (j-bisc), en el que la asociacion de bibliotecas de japon pone a disposicion los datos procesados. ademas, las revistas han sido indexadas desde 1985, registradas en una base de datos (mayo de 2004 - 15 158 zs) y accesibles a traves del sitio web de bnd (tambien en ingles). desde julio de 2011, la biblioteca nacional de japon tambien ha estado ofreciendo un archivo de autoridad con el titulo web bnd authorities, que incluye nombres personales y palabras clave.​  el inventario fue clasificado por primera vez por la clasificacion decimal nippon (ndc) , una mezcla de clasificacion decimal dewey (ddc) y clasificacion expansiva (ec), para medios japoneses y la ddc para medios occidentales.​ desde entonces, se ha utilizado una clasificacion separada completada en 1968 con el nombre national diet library classification (bndc) para la inclusion sistematica en la biblioteca y para su representacion en la bibliografia nacional. el bndc es alfanumerico (por ejemplo, matematicas: ma95, x = algebra; x = representacion numerica de la muestra) y tambien lo utilizan algunas bibliotecas universitarias.​  la presencia en internet de la bnd forma una interfaz de servicios para usuarios nacionales y extranjeros, estos ultimos, por ejemplo, a traves de prestamos interbibliotecarios y servicios de entrega y copia de documentos, acceso al creciente catalogo central y, por ejemplo, libros digitalizados del periodo meji debido a la participacion cada vez mayor de bibliotecas individuales, para las cuales se aplican condiciones especiales, por ejemplo, los derechos de autor caducados (desafortunadamente, el acceso, como la literatura digitalizada, esta en japones). el opac en particular es popular entre los usuarios debido a sus numerosas posibilidades de influir en la busqueda.  seria extremadamente dificil enumerar todas las tareas y actividades del bnd que se pueden utilizar a partir de los 18 años: coordinacion del sistema bibliotecario, cooperacion con bibliotecas extranjeras, evaluacion tecnica, capacitacion adicional del personal bibliotecario, servicios de informacion para parlamentarios y los ciudadanos pueden dar una idea aproximada de las tareas.  la biblioteca nacional de la dieta es una institucion nacional independiente que pertenece a la dieta, que es el legislador de japon, y es operado de forma independiente bajo la supervision del altavoz de la camara de representantes y el presidente de la camara de consejeros, asi como la permanente comite de la camara de representantes. el director general de la dieta nacional, que gobierna la administracion de la biblioteca, es designado por los presidentes de ambas camaras despues de consultar con los comites directivos de ambas camaras y con la aprobacion de la dieta.​  la organizacion consta de una biblioteca central y una biblioteca sucursal en virtud de la ley de bibliotecas dieteticas nacionales. ademas, se establecera el comite de coordinacion y enlace de la biblioteca nacional de dieta. la biblioteca central tiene el edificio principal de tokio en la ciudad de nagata, tokio y el edificio de kansai en la ciudad de seika, prefectura de kioto (ciudad de la ciencia de kansai) se comparten y almacenan diversos materiales. ademas, las casas del parlamento en el interior, adjunto al centro de la biblioteca de la rama de la dieta hay.​  las sucursales de las bibliotecas incluyen la biblioteca internacional de literatura infantil y las bibliotecas de los departamentos administrativo y judicial. de ellas, la biblioteca internacional de literatura infantil esta destinada principalmente a lectores menores de 18 años entre las publicaciones del japon recopiladas en la biblioteca nacional de la dieta por el sistema de deposito legal y las publicaciones fuera de japon mediante la compra y el intercambio internacional. comparte la preservacion y dotacion de la biblioteca, y su caracter es practicamente cercano al de la sucursal de la biblioteca central.  los departamentos administrativo y judicial, es decir, las bibliotecas ubicadas en cada ministerio y la corte suprema, seran tratados en detalle en la seccion de servicios para la administracion y el poder judicial. de esta manera, la biblioteca nacional de la dieta, que es la unica biblioteca central en japon, y cada biblioteca se coloca en una red integrada. estas bibliotecas son creadas por cada ministerio y tribunal, pero al mismo tiempo, como biblioteca filial de la biblioteca nacional de la dieta, se encuentran en una posicion especial como parte de la organizacion de la biblioteca nacional de la dieta junto con la biblioteca central.  la biblioteca central, que esta dividida en dos instalaciones, tokio y kansai, cuenta con alrededor de 900 empleados y se subdivide en departamentos para cada negocio, pero solo uno de ellos es especial segun la ley de bibliotecas dieteticas nacionales. hay una «oficina de investigacion y examen legislativo» como departamento.​ ademas del servicio de biblioteca a la dieta, la oficina de investigacion y examen legislativo respondio a las solicitudes de la dieta, centradas en investigadores especialistas que son asignados como servicios especiales para realizar investigaciones avanzadas en los campos requeridos por los comites permanentes de las camaras de representantes estamos realizando trabajos de investigacion.  como biblioteca nacional de japon, la bnd recopila copias de todas las publicaciones publicadas en japon. ademas, debido a que el bnd sirve como una biblioteca de investigacion para los miembros de la dieta, su personal y el publico en general, mantiene una extensa coleccion de materiales publicados en idiomas extranjeros sobre una amplia gama de temas.​  en los ultimos años, la biblioteca nacional de la dieta ha creado un sitio web detallado tanto en japones  sus bases de datos en linea consisten en el catalogo de acceso publico en linea de la biblioteca nacional de la dieta (ndl-opac), las colecciones digitales de la biblioteca nacional de la dieta y las actas de la dieta imperial y la dieta nacional.  ademas de sus servicios bibliotecarios, la organizacion tambien participa en actividades normativas en areas relacionadas con las normas bibliograficas y de busqueda y recuperacion. las areas de trabajo incluyen la descripcion de metadatos dublin core de la biblioteca nacional de la dieta (dc-ndl); ",
        "snippet": "La Biblioteca Nacional de la Dieta (en japonés: 国立国会図書館, Kokuritsu Kokkai Toshokan) está al servicio de la investigación y la administración de la Dieta de Japón y del pueblo japonés. Es la única biblioteca de Japón que recoge y conserva todas las publicaciones editadas en el país. La base para su creación es el artículo 130 de la Ley de la Dieta y el artículo 1 de la Ley de la Biblioteca Nacional de la Dieta.[1]​",
        "enlaces_salientes": [
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Coordenadas_geogr%C3%A1ficas",
            "/wiki/Jap%C3%B3n",
            "/wiki/Jap%C3%B3n",
            "/wiki/Biblioteca_p%C3%BAblica",
            "/wiki/Dieta_de_Jap%C3%B3n",
            "/wiki/Biblioteca_legislativa",
            "/wiki/Jap%C3%B3n",
            "/wiki/Tokio",
            "/wiki/Kioto",
            "/wiki/Literatura_infantil",
            "/wiki/Parque_Ueno",
            "/wiki/Tokio",
            "/wiki/Kioto",
            "/wiki/C%C3%A1mara_de_los_Pares_(Jap%C3%B3n)",
            "/wiki/C%C3%A1mara_de_Representantes_de_Jap%C3%B3n",
            "/wiki/Dieta_Imperial",
            "/wiki/Douglas_MacArthur",
            "/wiki/Segunda_Guerra_Mundial",
            "/wiki/Prefectura_de_Kioto",
            "/wiki/A%C3%B1o_fiscal",
            "/wiki/Braille_(lectura)",
            "/wiki/Seika",
            "/wiki/Control_de_autoridades",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Biblioteca_Nacional_de_Espa%C3%B1a",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Australia",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/CiNii",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Union_List_of_Artist_Names",
            "/wiki/BIBSYS",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Internet_Movie_Database"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
        "titulo": "Biblioteca Nacional de la República Checa",
        "contenido": "la  biblioteca nacional de la republica checa (en checo: narodni knihovna ceske republiky) ubicada en praga es la biblioteca principal y la mas importante de la republica checa. depende del ministerio de cultura y es la mas antigua de las bibliotecas checas. con un acervo de unos siete millones y medio de volumenes y documentos que se incremantan anualmente en cerca de 90 mil nuevos titulos, es tambien la biblioteca mas grande del pais.​ engloba tambien una seccion autonoma, la biblioteca eslava, consistente en una vasta coleccion de volumenes de ciencias politicas, historicos y filologicos eslavos, asi como tambien obras literarias.​ la biblioteca esta alojada en el clementinum, en el nucleo historico de la ciudad de praga.  junto a la universidad carolina de praga que mantenia varias bibliotecas tematicas o parciales, en el siglo xiii surgio la escuela  studium generale en el casco antiguo de la ciudad de praga, en el monasterio dominicano. esta escuela, en conjunto con su biblioteca, se fusiono en el siglo xiv con la universidad. en el año 1556 un grupo de religiosos jesuitas construyo sobre los restos del monasterio  un internado, al que llamaron clementinum. en 1622 la administracion de la  universidad carolina paso a manos de los jesuitas y todas las bibliotecas parciales se unificaron y alojaron en el clementinum.  tras la supresion de la compañia de jesus en 1773, la universidad paso a ser una institucion estatal y su biblioteca fue declarada por maria teresa i de austria como „biblioteca publica universitaria imperial real\" (\"offentlichen k. k. universitatsbibliothek“) lo que en 1887 tambien se reflejo en el nombre en checo (c.k. verejna a univerzitni knihovna). incluso despues de la division en 1882 en una universidad checa y una alemana, la biblioteca se mantuvo como una institucion conjunta al servicio de ambas universidades.  despues de 1918 el control estatal de la biblioteca paso a manos de la nueva checoslovaquia. en 1924 se fundo la slovanska knihovna (biblioteca eslava), que en 1929 tambien se alojo en el clementinum y continua siendo un area autonoma de la biblioteca nacional.  en 1935 hubo un cambio de nombre y la biblioteca paso a llamarse narodni a univerzitni knihovna (biblioteca nacional y universitaria), simultaneamente se promilgo la ley que la designa biblioteca depositaria de ejemplares de toda publicacion que obligatoriamente deben enviarse para su conservacion. en 1939, tras la  ocupacion alemana de checoslovaquia, se cerraron las universidades checas y la biblioteca se mantuvo en funcionamiento hasta 1941 bajo la denominacion zemska a univerzitni knihovna. en 1958 otras bibliotecas de praga se unificaron en la gran biblioteca statni knihovna csr (biblioteca estatal de checoslovaquia). finalmente, en 1990 recibio su nombre actual narodni knihovna (biblioteca nacional).​  el acervo de la biblioteca esta en los registros del catalogo electronico y puede ser consultado.​  en septiembre de 2005 la biblioteca fue la primera en recibir el premio memoria del mundo de la unesco/jikji,  creado en 2004. se le otorgo como una manera de «recompensar su contribucion a la conservacion y accesibilidad del patrimonio documental».​  la belleza del edificio barroco que aloja la biblioteca contrasta de manera casi dramatica con su funcionalidad. por un lado, el espacio disponible es limitado, sobre todo si se considera que de cada obra impresa, independientemente de su relevancia, dos ejemplares deben depositarse por ley en la biblioteca. por otra parte, las salas que otrora sirvieron de dormitorio de los monjes del monasterio, no brindan el espacio y las condiciones adecuadas para las necesidades practicas y funcionales de una sala de lectura y las plantas ubicadas en el subterraneo o en la planta baja, son dificilmente aislables de la humedad. todas estas consideraciones, pero principalmente las de espacio, llevaron a la idea de construir un edificio nuevo para la biblioteca. la construccion fue aprobada por el parlamento para iniciarse en 2006, pero diversas controversias sobre el lugar escogido para su emplazamiento y sobre el proceso de concurso de proyectos hizo que esta idea no llegara a concretarse.​  sin embargo, la necesidades espaciales se hicieron tan urgentes en el clementinum que en 2009 se opto por construir un edificio nuevo, no para trasladar la biblioteca completa, sino para que funcionara como repositorio de colecciones y como lugar de trabajo para bibliotecarios catalogadores, digitalizadores e indexadores del material nuevo que dia a dia incrementa el acervo. el edificio estuvo terminado en 2012, con una capacidad para 10 millones de libros. con el objetivo de hacer mas claro al publico la dimension de la mudanza, el director subrogante de la biblioteca explicaba a la prensa en 2014 que los libros trasladados durante el año 2013 desde el clementinum  al edificio ubicado en la calle sodomkova  del barrio praguense de hostivar, si fuesen puestos uno tras otro, ocuparian 35 kilometros.​ el objetivo que se cumplio fue resolver los problemas de espacio para guardar los libros, pero originalmente la idea no era esa, sino levantar una biblioteca completamente nueva. ante el fracaso de estos planes en 2008, las autoridades a cargo de la biblioteca se decidieron por la construccion de este deposito central.​  despues de esta gran mudanza, se generaron mejores condiciones para algunas secciones de la biblioteca en el clementinum, donde pueden ofrecer ahora un mejor servicio al lector. se trasladaron al nuevo repositorio no solo los libros, sino tambien una parte del personal de la biblioteca, principalmente para realizar trabajos de catalogacion y digitalizacion.​ ",
        "snippet": "La Biblioteca Nacional de la República Checa (en checo: Národní knihovna České republiky) ubicada en Praga es la biblioteca principal y la más importante de la República Checa. Depende del Ministerio de Cultura y es la más antigua de las bibliotecas checas. Con un acervo de unos siete millones y medio de volúmenes y documentos que se incremantan anualmente en cerca de 90 mil nuevos títulos, es también la biblioteca más grande del país.[1]​ Engloba también una sección autónoma, la Biblioteca Eslava, consistente en una vasta colección de volúmenes de ciencias políticas, históricos y filológicos eslavos, así como también obras literarias.[1]​ La biblioteca esta alojada en el Clementinum, en el núcleo histórico de la ciudad de Praga.",
        "enlaces_salientes": [
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Coordenadas_geogr%C3%A1ficas",
            "/wiki/Idioma_checo",
            "/wiki/Praga",
            "/wiki/Rep%C3%BAblica_Checa",
            "/wiki/Clementinum",
            "/wiki/Universidad_Carolina",
            "/wiki/Supresi%C3%B3n_de_la_Compa%C3%B1%C3%ADa_de_Jes%C3%BAs",
            "/wiki/Mar%C3%ADa_Teresa_I_de_Austria",
            "/wiki/Checoslovaquia",
            "/wiki/Ocupaci%C3%B3n_alemana_de_Checoslovaquia",
            "/wiki/Unesco",
            "/wiki/Jikji",
            "/wiki/Clementinum",
            "/wiki/Barroco",
            "/wiki/Biblioteca_t%C3%A9cnica_nacional_de_Praga",
            "/wiki/Clementinum",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/N%C3%BAmero_de_Identificaci%C3%B3n_Fiscal_a_efectos_del_IVA_(NIF-IVA)"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Biblioteca_Nacional_de_Israel",
        "titulo": "Biblioteca Nacional de Israel",
        "contenido": "la blibioteca nacional de israel ( en hebreo: הספרייה הלאומית) antes conocida como biblioteca nacional judia y universitaria segun sus siglas en ingles jnul (en hebreo: בית הספרים הלאומי והאוניברסיטאי), es la biblioteca nacional de israel. esta biblioteca alberga mas de 5 millones de libros y esta ubicada en el campus de givat ram de la universidad hebrea de jerusalen.  la biblioteca nacional posee una de las mayores colecciones de obras en hebreo y judaicas del mundo y alli se encuentran manuscritos, libros y piezas de artesania raras o unicas.​  la primera biblioteca publica que sirvio a la comunidad judia en palestina fue la b'nai b'rith, fundada en jerusalen en 1892. esta biblioteca se ubicaba en una calle homonima, cercana a la zona de la mision rusa en jerusalen.​ diez años despues fue reubicada en la calle etiopia.​ en 1920, cuando se planeaba la creacion de la universidad hebrea, la coleccion de la biblioteca b'nai brith se convirtio en la base para la biblioteca universitaria. los libros se trasladaron al monte scopus donde la universidad abriria cinco años despues.​  en 2007 fue oficialmente reconocida como la biblioteca nacional del estado de israel tras la aprobacion de la ley de bibliotecas nacionales.​ esta ley, que entro en funcionamiento el 23 de julio de 2008 cambio el nombre de la biblioteca al actual y la convirtio en dependiente de la universidad para despues pasar a ser una empresa de interes comunitario poseida conjuntamente por el gobierno de israel (50%), la universidad hebrea (25%) y otras organizaciones.  la mision de la biblioteca nacional de israel es asegurar todo el material publicado en israel en cualquier lengua. pretende albergar todas las publicaciones que traten de israel, la tierra de israel, el judaismo y el pueblo judio publicados en cualquier idioma, en cualquier pais del mundo. tambien pretende acumular todo el material publicado en hebreo o en cualquier lengua hablada en la diaspora como el yiddish o el ladino. por ley, dos copias de cualquier elemento publicado en israel deben ser depositadas en la biblioteca. desde 2001, con la reforma de la ley, tambien se incluyen entre los materiales que deben depositarse en la biblioteca grabaciones de audio, video y material no impreso.​ algunos de los fondos unicos de la biblioteca como el manuscrito del siglo xiv nuremberg mahzor fueron escaneados en 2007 y estan disponibles en internet.  entre los materiales raros de la biblioteca se encuentran manuscritos de isaac newton que tratan sobre temas teologicos.​ y documentos personales de cientos de figuras relevantes judias.  sala de lectura central de la 'national library' de israel.  la ventana obra de mordejai ardon en la recepcion.  el segundo edificio en el campus de monte scopus - 1929.  el primer edificio en el centro de jerusalen - 1912. ",
        "snippet": "La Blibioteca Nacional de Israel ( en hebreo: הספרייה הלאומית) antes conocida como Biblioteca Nacional Judía y Universitaria según sus siglas en inglés JNUL (en hebreo: בית הספרים הלאומי והאוניברסיטאי), es la Biblioteca Nacional de Israel. Esta biblioteca alberga más de 5 millones de libros y está ubicada en el campus de Givat Ram de la Universidad Hebrea de Jerusalén.",
        "enlaces_salientes": [
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Coordenadas_geogr%C3%A1ficas",
            "/wiki/Israel",
            "/wiki/Israel",
            "/wiki/Jerusal%C3%A9n",
            "/wiki/Biblioteca_publica",
            "/wiki/1892",
            "/wiki/Universidad_Hebrea_de_Jerusal%C3%A9n",
            "/wiki/Israel",
            "/wiki/Biblioteca_Nacional",
            "/wiki/Israel",
            "/wiki/Universidad_Hebrea_de_Jerusal%C3%A9n",
            "/wiki/Juda%C3%ADsmo",
            "/wiki/B%27nai_B%27rith",
            "/wiki/Jerusal%C3%A9n",
            "/wiki/Monte_Scopus",
            "/wiki/Gobierno_de_Israel",
            "/wiki/Universidad_Hebrea_de_Jerusal%C3%A9n",
            "/wiki/Tierra_de_Israel",
            "/wiki/Juda%C3%ADsmo",
            "/wiki/Pueblo_jud%C3%ADo",
            "/wiki/Idioma_hebreo",
            "/wiki/Di%C3%A1spora",
            "/wiki/Yiddish",
            "/wiki/Idioma_judeoespa%C3%B1ol",
            "/wiki/Isaac_Newton",
            "/wiki/Israel",
            "/wiki/Mordejai_Ard%C3%B3n",
            "/wiki/Monte_Scopus",
            "/wiki/Haaretz",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/International_Standard_Name_Identifier",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Art_%26_Architecture_Thesaurus",
        "titulo": "Art & Architecture Thesaurus",
        "contenido": "art & architecture thesaurus (tesauro de arte y arquitectura, abreviado como aat) es un vocabulario controlado que se utiliza para describir elementos y conceptos de arte, arquitectura, conservacion, arqueologia y cultura material desarrollado por el instituto de investigacion getty.​ cuenta con terminos, descripciones, citas bibliograficas y otra informacion relacionada con las bellas artes, la arquitectura y las artes decorativas.​  el aat es utilizado, entre otros, por museos, bibliotecas de arte, archivos, catalogadores e investigadores de historia del arte.​ se compone de terminos preferidos seleccionados y las relaciones de equivalencia, jerarquicas y asociativas.de esos terminos.​ cumple con las normas iso y niso, incluidas las normas iso 2788, iso 25964 y ansi/niso z39.19.​  en marzo de 2023, contiene alrededor de 74 045 registros y 488 911 terminos.​ ",
        "snippet": "Art & Architecture Thesaurus (Tesauro de Arte y Arquitectura, abreviado como AAT) es un vocabulario controlado que se utiliza para describir elementos y conceptos de arte, arquitectura, conservación, arqueología y cultura material desarrollado por el Instituto de investigación Getty.[1]​ Cuenta con términos, descripciones, citas bibliográficas y otra información relacionada con las bellas artes, la arquitectura y las artes decorativas.[2]​",
        "enlaces_salientes": [
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Art_%26_Architecture_Thesaurus",
            "/wiki/Lenguaje_de_indizaci%C3%B3n",
            "/wiki/J._Paul_Getty_Trust",
            "/wiki/ISSN",
            "/wiki/Control_de_autoridades"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Enciclopedia_Brit%C3%A1nica",
        "titulo": "Enciclopedia Británica",
        "contenido": "la enciclopedia britanica (en latin: encyclopædia britannica) es una enciclopedia en ingles de conocimiento general, editada por encyclopædia britannica, inc., una empresa privada. los articulos de la britannica estan dirigidos a lectores adultos, y estan escritos por un conjunto de 100 editores a tiempo completo y cerca de 4000 contribuyentes expertos,[cita requerida] que han incluido 110 ganadores del premio nobel y cinco presidentes de los estados unidos. estos articulos son considerados generalmente precisos, fiables y bien redactados. es ampliamente reconocida como la enciclopedia mas erudita de todas las editadas en ingles.​​  la britannica es la enciclopedia en ingles mas antigua todavia en edicion (aunque ya no se edite en papel).​ su primera edicion data entre 1768 y 1771, en edimburgo, escocia, y rapidamente obtuvo gran popularidad y tamaño, contando en su tercera edicion en 1801 con 21 volumenes.​​ su gran crecimiento ayudo a reclutar eminentes contribuyentes, por lo que la novena (1875-1889) y undecima edicion (1911) fueron consideradas como las mas famosas por su erudicion y estilo literario.​ empezando con la undecima edicion, la britannica gradualmente ha ido resumiendo y simplificando sus articulos para ampliar su mercado en norteamerica.​ en 1933, se convirtio en la primera enciclopedia en adoptar una politica de «revisiones continuas», en la cual la enciclopedia es continuamente reimpresa y cada articulo es actualizado con un programa regular.​  el 13 de marzo de 2012, los editores de la enciclopedia britanica anunciaron que dejaba de imprimirse en papel y que se centrarian en la edicion web, que debuto en 1994.​  la actual edicion, la decimoquinta, tiene una estructura de tres partes unicas: una micropædia de 12 volumenes de articulos cortos (que generalmente contienen menos de 750 palabras), macropædia de 17 volumenes de articulos largos (que contienen entre 2 y 310 paginas) y una propædia de un unico volumen que proporciona un esquema jerarquico del conocimiento humano. la micropædia esta pensada para una busqueda rapida de hechos, y es una guia para la macropædia; a los lectores se les recomienda estudiar el esquema de la propædia para entender el contexto de una materia y encontrar otros articulos mas detallados.​  el tamaño de la britannica, a grandes rasgos, ha permanecido constante en los ultimos setenta años, con cerca de 40 000 000 (cuarenta millones) de palabras en 500 000 (quinientos mil) temas.​ aunque la publicacion se realiza en estados unidos desde 1901, la enciclopedia ha mantenido su tradicional ortografia britanica al escribir, por ejemplo, labour («trabajo») en lugar del termino estadounidense labor.​  en el transcurso de su historia, la britannica ha tenido dificultades para cosechar beneficios economicos, un problema comun entre muchas enciclopedias.​ algunos articulos de ediciones pasadas han sido criticados por inexactitud, parcialidad, o por haber sido redactados por contribuyentes no suficientemente cualificados.​ asi mismo, la precision de algunas partes de la edicion vigente ha sido cuestionada;​ sin embargo, esas criticas han sido rechazadas por la administracion de la enciclopedia.  la britannica ha cambiado de manos en numerosas ocasiones; entre los anteriores propietarios se encuentran la editorial escocesa a & c black, horace everett hooper, sears roebuck and company y william benton. el actual propietario de la empresa encyclopaedia britannica, inc. es jacqui safra, un millonario y actor suizo. los recientes avances en la tecnologia de la informacion y el auge de enciclopedias electronicas, tales como microsoft encarta (actualmente no se edita) e internet, han reducido la demanda de enciclopedias impresas.​ para seguir siendo competitivos, encyclopædia britannica, inc., ha hecho enfasis en la reputacion de la britannica, reducido su precio y los costes de produccion, y desarrollado versiones electronicas en cd-rom, dvd y en la web. desde principios de los años treinta, la empresa tambien ha promovido trabajos derivados como obras de referencia.​  producto de la ilustracion escocesa, la britannica fue publicada inicialmente en edimburgo por adam y charles black. a diferencia de la l'encyclopedie (enciclopedia francesa), la britannica era una publicacion extremadamente conservadora. las ediciones posteriores se dedicaron generalmente al monarca de turno. para la octava y novena ediciones, su publicacion se traslado de escocia a londres y se asocio con el periodico the times en los años 1870. en la undecima edicion la publicacion se asocio con la universidad de cambridge. la marca comercial y derechos de publicacion fueron vendidos despues de su undecima edicion a sears roebuck and company y se traslado a chicago (estados unidos), donde permanece. su editor actual es encyclopædia britannica inc.  hacia el año 2004, la britannica poseia 75 000 articulos con mas de 44 000 000 (cuarenta y cuatro millones) de palabras. cuenta con una plantilla de 19 editores y la colaboracion de 4000 expertos. se publica en papel (en 32 volumenes, con un costo de 1400 us dolares), aparece en internet (con breves resumenes de articulos visibles sin cargo y los textos completos disponibles por un precio de 10 dolares mensuales o 60 dolares anuales), y esta disponible en cd-rom o dvd-rom (por 50 dolares). actualmente, la 11.ª edicion de la encyclopædia britannica, de 1911, se encuentra en dominio publico.[cita requerida]  la britannica se ha publicado en 15 ediciones oficiales, con varios volumenes complementarios desde la 3.ª y 5.ª edicion (vease el cuadro mas abajo). para ser exactos, la 10.ª edicion es solo un complemento de la 9.ª edicion, al igual que la 12.ª y 13.ª edicion se complementan con la 11.ª edicion. la 15.ª edicion se sometio a una masiva reorganizacion en 1985, pero la version actualizada es todavia conocida como la 15.ª edicion.  a lo largo de su historia, la britanica ha tenido dos objetivos: ser un excelente libro de referencia y proporcionar material didactico para aquellos que desean estudiar.​ en 1974, la 15.ª edicion adopto un tercer objetivo: el de sistematizar todos los conocimientos humanos.​ la historia de britannica se puede dividir en cinco grandes eras, marcadas por grandes cambios en la gestion o reorganizacion de la enciclopedia.  en la primera era (1.ª-6.ª edicion, 1768-1826), la britannica fue administrada por sus fundadores originales, colin macfarquhar y andrew bell, y, por algunas de sus amistades tales como thomas bonar, george gleig y archibald constable. la britannica fue publicada por primera vez entre 1768 y 1771 en edimburgo como la encyclopædia britannica, o, un diccionario de artes y ciencias, compilado en un nuevo plan. fue vista como una reaccion y una provocacion a la encyclopedie francesa de denis diderot (publicada entre 1751-1766), que a su vez se habia inspirado en la inglesa cyclopaedia (diccionario universal de las artes y las ciencias). britannica fue principalmente una empresa escocesa, simbolizada por un cardo como logo, emblema floral de escocia. el fundador de la enciclopedia fue uno de los mas famosos representantes de la ilustracion escocesa.​ en esta era, britannica paso de ser un conjunto de tres volumenes (1.ª edicion) elaborado por un joven editor william smellie​ a 20 volumenes escritos por numerosas personalidades. aunque varias otras enciclopedias, como rees's cyclopaedia y la encyclopaedia metropolitana de coleridge, compitieron con la britannica, estos competidores se fueron a la quiebra o dejaron de publicar debido a desacuerdos entre sus editores. al final de esta era, la britannica habia creado una red de colaboradores ilustres, principalmente a traves de amistades personales con los editores, en particular, constable y gleig.  durante la segunda era (7.ª-9.ª ediciones, 1827-1901), la britannica fue administrada por la editorial de edimburgo, a & c black. aunque algunos colaboradores fueron reclutados por amistad personal con los redactores jefe, mas notablemente macvey napier, otros fueron a la britannica por su creciente reputacion. a menudo los colaboradores venian de otros paises e incluian a las mas respetadas autoridades del mundo en sus respectivos campos. un indice general fue incluido por primera vez en la 7.ª edicion, una practica mantenida hasta 1974. el primer redactor jefe ingles fue thomas spencer baynes, quien superviso la produccion de la famosa 9.ª edicion; comunmente llamada scholar's edition \"(edicion erudita)\" por ser la edicion de la britannica mas dirigida al publico estudiantil.​​ sin embargo, a finales del siglo xix, la 9.ª edicion estaba desactualizada y la britannica confrontaba serios problemas economicos.  en la tercera era (10.ª-14.ª ediciones, 1901-1973), la britannica estuvo bajo administracion de empresarios estadounidenses, quienes introdujeron una agresiva estrategia de expansion, sirviendose del marketing y de ventas por correo, para de esa forma intentar incrementar las ganancias y la rentabilidad del producto. tambien simplificaron los articulos de la britannica, disminuyendo su contenido pero volviendola mas comprensible al publico en general. la 10.ª edicion fue producida rapidamente como un suplemento a la 9.ª, pero la edicion que es reconocida por su excelencia es la 11.ª; su propietario horace hooper, destino un enorme esfuerzo para perfeccionar tal edicion.​ cuando hooper y la britannica cayeron en dificultades financieras, la britannica paso a manos de sears roebuck durante 18 años (1920-1923, 1928-1943). en 1932, el vicepresidente de la cadena sears, elkan harrison powell, asumio la presidencia de la britannica; en 1936, empezo una politica de revision continua (todavia practicada en la actualidad), en donde cada articulo es revisado y actualizado al menos dos veces cada decada. esta estrategia contrasta con la practica anterior, donde los articulos no cambiaban hasta que fuera producida una nueva edicion, aproximadamente cada 25 años; incluso habia articulos que se copiaban sin cambios desde ediciones previas.​ powell desarrollo agresivamente proyectos educacionales para mejorar la reputacion de la britannica en estados unidos. en 1943, la presidencia paso a william benton, quien administro la britannica hasta su muerte en 1973. benton tambien creo la fundacion benton, la cual estuvo al mando de la britannica hasta 1996. en 1968 la britannica celebro su bicentenario.  en la cuarta era (15.ª edicion, 1974-1994), la britannica introdujo su 15.ª edicion, la cual fue reorganizada en tres partes: la micropædia, la macropædia y la propædia. bajo la influencia de mortimer adler (miembro del comite de redaccion de la encyclopædia britannica desde 1949, y su jefe desde 1974, asi como director de planeacion editorial de la decimoquinta edicion de la britannica desde 1965),​ la britannica empezo a buscar ser no solamente una referencia y herramienta educacional, sino tambien a sistematizar todo el conocimiento humano. la ausencia de un indice separado y la agrupacion de articulos en dos enciclopedias paralelas (la micro- y macropædia) provoco una tormenta de criticas a la 15.ª edicion inicial.​​  en respuesta, la 15.ª edicion fue completamente reorganizada e indexada para un relanzamiento en 1985. esta segunda version de la 15.ª edicion continua siendo publicada y revisada; la ultima version es la de 2010. el titulo oficial de la 15.ª edicion es new encyclopædia britannica (\"la nueva encyclopædia britannica\"), aunque tambien ha sido llamada britannica 3.​  en la quinta era (1994-presente), se inicio el desarrollo de versiones digitales de la britannica las cuales son distribuidas a traves de discos opticos y a traves de internet. en 1996, la britannica fue comprada a la fundacion benton por jacqui safra, a un precio mucho menor al estimado, debido a las dificultades economicas de la compañia. la encyclopædia britannica, inc. se dividio en 1999. una parte retuvo el nombre de la compañia y siguio desarrollando la version tradicional (impresa); la otra parte, britannica.com inc., desarrollo las versiones digitales. desde 2001, estas dos compañias han compartido un solo director ejecutivo, que originalmente fue ilan yeshua, quien ha continuado la estrategia de powell para el crecimiento de la britannica introduciendo nuevos productos bajo la marca britannica. en marzo de 2012 anuncio el fin de la edicion de papel quedando solo la edicion digital.​  la britannica fue dedicada al monarca de gran bretaña reinante desde 1788 hasta 1901 y luego, debido a su venta a una sociedad norteamericana, al monarca britanico y al presidente de los estados unidos. consecuentemente, la decimoprimera edicion es «dedicada con permiso a su majestad jorge v, rey de gran bretaña e irlanda y los dominios britanicos de ultramar, emperador de india, y a william howard taft, presidente de los estados unidos de america». el orden de las dos dedicaciones ha ido cambiando junto con el poder relativo entre el presidente de los estados unidos y el monarca de gran bretaña, y con las ventas de \"britannica\" en estos paises; la version de 1954 de la decimocuarta edicion es dedicada con permiso a los jefes de estado de los dos pueblos de lengua inglesa, dwight david eisenhower, presidente de los estados unidos de america, y su majestad, reina isabel segunda.​ continuando con la tradicion, la version 2007 de la decimoquinta edicion es «dedicada con permiso al actual presidente de los estados unidos de america, george w. bush, y a su majestad reina isabel segunda».  desde la tercera edicion, la britannica ha recibido una reputacion de excelencia.​​​ varias ediciones, desde la tercera a la novena, fueron copiadas y vendidas sin autorizacion en los estados unidos​ dando comienzo a la dobson's encyclopædia (la cual consistia practicamente en una copia de la tercera edicion de la enciclopedia “britannica”, con un estilo mas patriotico, adaptado para lectores americanos).​ para el lanzamiento de la decimocuarta edicion, la revista time honro a la britannica llamandola \"patriarca de la biblioteca\".​ en un anuncio relacionado, el naturalista william beebe era citado diciendo que la britannica estaba mas alla de la comparacion porque no hay competidor.​ se pueden encontrar varias referencias a la britannica a lo largo de la literatura inglesa, la mas notable en una de las historias de sherlock holmes favoritas de arthur conan doyle, \"la liga de los pelirrojos\". esta historia fue destacada por el lord mayor de londres, gilbert inglefield, durante el bicentenario de la britannica.  la britannica tiene la reputacion de resumir todo el conocimiento humano. para expandir su educacion, muchos se han dedicado a leer la britannica por completo, empleando entre tres y veintidos años para lograrlo.​ cuando fat'h ali se convirtio en el shah de persia en 1797, le regalaron un set completo de la tercera edicion de la britannica, la cual leyo completamente en tres años; tras esta hazaña, extendio su titulo de realeza agregandole \"el mas formidable señor y maestro de la encyclopædia britannica\".​ el escritor george bernard shaw afirmo haber leido completamente la novena edicion-exceptuando los articulos cientificos​-, richard evelyn byrd tomo a la britannica como material de lectura para su estadia de cinco meses en el polo sur en 1934, mientras philip beaver la leyo durante una expedicion marina. mas recientemente, a.j. jacobs, un editor de la revista esquire, leyo por completo la version 2002 de la decimoquinta edicion, describiendo sus experiencias en el bien acogido libro de 2004 the know-it-all: one man's humble quest to become the smartest person in the world. solo se sabe de dos personas que hayan leido dos ediciones independientes: el autor c. s. forester​ y amos urban shirk, un empresario estadounidense, quien leyo la decimoprimera y decimocuarta edicion, dedicando tres horas por noche durante cuatro años y medio para leer la decimoprimera.​ probablemente varios redactores jefe de la britannica han leido sus ediciones completamente, como william smellie (1.ª edicion), william robertson smith (9.ª edicion), y walter yust (14.ª edicion).  la britannica continua siendo galardonada en la actualidad. la britannica online gano el premio codie por \"el mejor servicio de informacion on-line al consumidor\";​ este premio es otorgado por la software and information industry association en reconocimiento a los mejores productos dentro de la categoria de software. en 2006 la britannica fue nuevamente finalista.​ igualmente la edicion cd/dvd-rom de la britannica recibio en 2004 el \"distinguished achievement award de la association of educational publishers\",​ y el premio codie en 2000, 2001 y 2002.​​  como enciclopedia general, la britannica busca describir el rango mas amplio de temas posible. los temas son escogidos para su referencia en la propædia outline of knowledge (‘esquema del conocimiento’).​ el porcentaje de articulos dedicados a los principales temas esta distribuido asi (macropædia):  un estudio complementario determino que en la micropædia los articulos de geografia suponian el 25 % de los articulos, ciencia el 18 %, ciencias sociales el 17 %, biografias el 17 %, y todas las demas humanidades el 25 % restante.​ en 1992, un revisor juzgo que el \"alcance, la profundidad, y la catolicidad de la cobertura de la britannica es insuperable por cualquier otra enciclopedia.\"​  la britannica no detalla los temas similares de forma equivalente; por ejemplo, el budismo y la mayor parte de las demas religiones estan conjugadas en un solo articulo de la macropædia, cuando existen 14 articulos dedicados al cristianismo, que componen cerca de la mitad de los articulos sobre religion.​ la britannica recoge 50.479 biografias, de las cuales 5.999 son de mujeres; un 11,87% de las biografias son de ciudadanos britanicos y un 25,51% estadounidenses​. sin embargo, la britannica ha sido elogiada como la menos parcial de las enciclopedias comercializadas en occidente​ y elogiada por sus biografias sobre mujeres importantes de todas las epocas.​  la britannica tambien ha recibido criticas, especialmente cuando sus ediciones iban quedando desactualizadas. debido a los costes economicos a la hora de producir una edicion completamente nueva de la britannica,​ sus editores generalmente demoran la actualizacion el mayor tiempo posible, siempre y cuando sea economicamente viable (usualmente veinticinco años).​ a pesar de la politica de revision continua, la decimocuarta edicion se habia vuelto muy desactualizada en treinta y cinco años (1929-1964). cuando el fisico estadounidense harvey einbinder detallo sus faltas en su libro de 1964, the myth of the britannica,​ la enciclopedia decidio lanzar la decimoquinta edicion, la cual requirio de diez años de trabajo. es dificil mantener a la britannica actualizada; un critico reciente escribio, “no es dificil encontrar articulos desactualizados o que necesitan revision”, resaltando que los articulos mas largos de la macropædia probablemente estan mas desactualizados que los mas cortos de la micropædia.​ la informacion en la micropædia es a veces inconsistente con respecto a los articulos de la macropædia, debido a la falta de actualizacion en alguno de los dos.​​ las bibliografias de los articulos de la macropædia han sido criticados por estar mas desactualizados que los articulos mismos.​​​  diferentes autoridades que van desde virginia woolf hasta profesores academicos criticaron la 11.ª edicion de la britanica por tener opiniones burguesas y arcaicas sobre el arte, la literatura y las ciencias sociales.​ por ejemplo, se la recrimino no tratar el trabajo de sigmund freud. un profesor contemporaneo de la universidad cornell, edward b. titchener, escribio en 1912, \"la nueva britannica no reproduce la atmosfera psicologica de su dia y generacion [..] a pesar del halo de autoridad y de los controles del personal, la mayor parte de los articulos secundarios de psicologia general no esta adaptados a los requisitos del lector inteligente.\"​  a la britannica se la critica ocasionalmente por las decisiones tomadas por sus editores. debido a su tamaño aproximadamente constante, la enciclopedia ha necesitado reducir o eliminar alguno de sus temas para acomodar otros, tomando algunas decisiones controvertidas. la version inicial de la decimoquinta edicion (1974-1985) fue reprochada por haber reducido drasticamente o eliminado su cobertura de literatura infantil, condecoraciones militares, y al poeta frances joachim du bellay; tambien se denunciaron otros errores editoriales, como la inconsistente ordenacion de las biografias japonesas.​ la eliminacion del indice fue condenada, como lo fue la division aparentemente arbitraria de articulos entre la micropædia y la macropædia.​​ resumiendo, un critico llamo a la decimoprimera edicion inicial como un fallo con matices… a la que le importa mas jugar con su formato que preservar la informacion.​ mas recientemente, los revisores de la american library association se sorprendieron al encontrar que la mayoria de los articulos de educacion fueron eliminados de la macropædia de 1992, junto con el articulo sobre psicologia.​  algunos contribuyentes de la britannica se equivocan ocasionalmente, o no son cientificos. un caso notorio en los primeros años de la britannica fue el rechazo de la teoria de la gravitacion universal de newton por parte de george gleig, el redactor jefe de la 3.ª edicion (1788-1797), quien escribio que la gravedad era causada por el elemento fuego.​ sin embargo, la britannica, ha defendido el acercamiento cientifico a temas emotivos, como hizo william robertson smith en sus articulos sobre religiones en la novena edicion, particularmente afirmando que la biblia no era historicamente exacta (1875).​  los criticos han acusado a ediciones pasadas de la britannica de presentar racismo y sexismo. la decimoprimera edicion de 1911 describe al ku klux klan como protector de la raza blanca y con un papel restablecedor del orden en el sur de estados unidos tras la guerra civil estadounidense, citando la necesidad de controlar a la raza negra, para impedir cualquier mezcla de razas y la frecuente ocurrencia de violaciones por parte de hombres negros a mujeres blancas.​​ de igual manera, el articulo sobre «civilizacion» argumenta a favor de la eugenesia, comenzando con que es irracional propagar los niveles bajos de inteligencia, incrementar las filas de los pobres, discapacitados y criminales… que hoy constituyen un obstaculo tan amenazador al progreso racial.​ la decimoprimera edicion no tiene biografia de marie curie, a pesar de que ella gano el premio nobel de fisica en 1903 y el premio nobel de quimica en 1911 (el mismo año de la publicacion), aunque se la menciona brevemente en la biografia de su esposo pierre curie.​  en 1912 el matematico louis charles karpinski critico a la edicion de 1911 por sus inexactitudes en sus articulos sobre historia de la matematica, ninguno de los cuales habia sido escrito por especialistas en la materia.​ en 1917, el critico willard huntington wright publico un libro, misinforming a nation (\"desinformando a una nacion\"),​ que resaltaba las inexactitudes y el sesgo ingles de la decimoprimera edicion, particularmente de los articulos de humanidades. muchas de las criticas de wright fueron arregladas en ediciones posteriores de la britannica. sin embargo, su libro fue denunciado como polemico por sus contemporaneos; por ejemplo, el new york times escribio \"rencor y poca templanza... impregna el libro\", mientras el new republic opino: \"es desafortunado para el proposito rencoroso del sr. wright que procediera con un espiritu acientifico y dando tan poca justificacion objetiva de sus criticas.\"​ otro critico, el editor ingles y exsacerdote joseph mccabe alego, en su libro lies and fallacies of the encyclopaedia britannica (‘mentiras y falacias de la encyclopaedia britannica’, 1947) que luego de la 11.ª edicion la britannica fue censurada bajo presion de la iglesia catolica.​  la britannica siempre ha reconocido que los errores son inevitables en una enciclopedia. hablando de su 3.ª edicion (1788-1797), su redactor jefe george gleig escribio la perfeccion parece ser incompatible con la naturaleza de los trabajos construidos bajo tal plan, y que abarca tal variedad de temas. mas recientemente (en marzo de 2006), la britannica escribio no queremos dar a entender que britannica este libre de errores; nunca hemos hecho tal afirmacion.  desde 1985, britannica esta estructurada en cuatro partes: la micropædia, la macropædia, la propædia y un indice en dos volumenes. los articulos propiamente dichos se encuentran en la micro y la macropædia, abarcando 12 y 17 volumenes respectivamente, teniendo cada uno de los volumenes alrededor de mil paginas. la macropædia de la edicion de 2007 desarrolla 699 articulos en profundidad, extendiendose cada uno de ellos entre 2 y 310 paginas, junto con las referencias y el nombre de los colaboradores. en cambio, la micropædia consta de aproximadamente 65 000 articulos, la inmensa mayoria (sobre el 97 %) con menos de 750 palabras, y no contienen ni referencias ni el nombre de los colaboradores.​ los articulos de la micropædia tienen como funcion ser utilizados para una rapida comprobacion de hechos y para la ayuda en la busqueda de mas informacion a traves de la macropædia. los articulos de la macropædia se suponen fidedignos y un almacen de informacion no cubierta en ningun otro sitio.​ el articulo mas extenso (310 paginas) es el de estados unidos, y resulto de la union de cada uno de los articulos de los diferentes estados.  los contenidos y la informacion de la britannica se puede encontrar siguiendo las referencias cruzadas existentes tanto en la micropædia como en la macropædia; sin embargo, estas son escasas, habiendo como promedio solo una por pagina.​ de ahi que a los lectores de la enciclopedia se les recomiende consultar en su lugar el indice alfabetico o la propædia, que organiza la enciclopedia britannica por temas.​  el nucleo de la propædia es su «esquema del conocimiento» que pretende dar un marco logico de todo el conocimiento humano.​ como consecuencia, este «esquema» es consultado por los editores de britannica para decidir que articulos deben ser incluidos en la enciclopedia.​ el esquema tiene tambien la intencion de ser una guia de estudio, poner los temas en una perspectiva adecuada y sugerir un listado de articulos para aquellas personas que deseen estudiar un tema en profundidad.​ sin embargo, las bibliotecas afirman que se usa poco, y hay incluso criticos que han recomendado su exclusion de la enciclopedia.​ la propædia tambien contiene transparencias a color de la anatomia humana y numerosos apendices enumerando a los miembros del personal, asesores y colaboradores de las tres partes de la enciclopedia.  juntas, la micropædia y la macropædia contienen hasta 40 000 000 (cuarenta millones) de palabras y 24 000 imagenes.​ el indice en dos volumenes tiene 2350 paginas listando los 228 274 temas cubiertos por la britannica y las 474 675 subentradas bajo esos temas.​  la enciclopedia normalmente utiliza ingles britanico en lugar de ingles estadounidense.​ por ejemplo, usa colour y no color (\"color\" en castellano), centre y no center (\"centro\" en castellano) y encyclopaedia pero no encyclopedia (\"enciclopedia\" en castellano); sin embargo, en algunas ocasiones no es asi, como por ejemplo en defense en lugar de defence (\"defensa\" en castellano).​ a pesar de todo ello, en las entradas se proporcionan referencias a los deletreos alternativos comunes de la palabra, del tipo «color: see colour».  desde 1936, los articulos de la encyclopædia britannica se revisan regularmente, siendo como minimo el 10 % del total de ellos revisado cada año.​​ de acuerdo con la pagina web de britannica en 2007, el 46 % de sus articulos habian sido revisados en los ultimos tres años;​ sin embargo, de acuerdo con otra pagina web sobre la misma enciclopedia solo lo habian sido el 35 %.​  el orden alfabetico de los articulos contenidos en la enciclopedia sigue reglas estrictas.​ se ignoran tanto signos diacriticos como letras no existentes en el alfabeto ingles, las entradas numericas se ordenan como si el numero estuviese escrito (la entrada «1812, war of» habria que buscarla como si buscasemos «eighteen-twelve, war of»). los articulos con nombre identico estan ordenados primero si hacen mencion a personas, luego a lugares y por ultimo a cosas. los gobernantes con mismo nombre estan organizados primero alfabeticamente por pais y luego por cronologia. asi, charles iii of france (carlos iii de francia), va antes que charles i of england (carlos i de inglaterra), ya que este ultimo esta listado como rey de reino unido e irlanda, great britain and ireland en ingles, que es alfabeticamente posterior a france, (‘francia’ en español). de la misma manera, los lugares que comparten denominacion estan organizados alfabeticamente por pais y sucesivamente por divisiones territoriales cada vez menores.  existen numerosas versiones abreviadas de la enciclopedia britannica. la mas importante de todas ellas es la britannica concise encyclopædia que consta de un solo volumen y contiene 28 000 articulos cortos condensando los 32 volumenes de la encyclopædia britannica original.​  compton's by britannica, publicada por primera vez en 2007, parte de la antigua compton's encyclopedia cuyos derechos de publicacion fueron adquiridos en esa fecha por encyclopædia britannica, y esta dirigida a adolescentes de entre 10 y 17 años, y consta de 26 volumenes y 11 000 paginas.​  una enciclopedia para niños, children's britannica, fue publicada por la oficina de londres en 1960, su editor fue john armitage y estaba dedicada al principe de gales, que por aquel entonces contaba con 12 años de edad. los colaboradores fueron en su gran mayoria britanicos y los asesores editoriales fueron \"el director, personal y estudiantes de la escuela de primaria william austin, en luton, bedfordshire\".​  tambien existen my first britannica orientada a edades entre 6 y 12 años y britannica discovery library para entre 3 y 6 (publicada entre 1974 y 1991).​  desde 1938, la empresa encyclopædia britannica, inc. publica anualmente un libro con los hechos mas destacados del año anterior. ademas, son accesibles en internet las publicaciones desde la edicion de 1994. la compañia tambien publica numerosos trabajos especializados tales como shakespeare: the essential guide to the life and works of the bard (wiley, 2006).  la editorial carenzo (chile), ha lanzado una version promocional de la britannica concise encyclopædia en castellano para america latina. esta edicion esta autorizada por encyclopædia britannica inc. (estando basada en su menor pero tambien notable enciclopedia hispanica), y segun la misma editorial cumple con los mismos estandares de calidad que la edicion inglesa de la enciclopedia britanica, ya que esta edicion en español habria sido revisada por los mismos editores de la edicion en ingles de la enciclopedia britanica.[cita requerida]  esta coleccion promocional consta de 20 tomos, con alrededor de 24 000 entradas y 4800 fotografias, caracteristicas similares a la britannica concise encyclopædia. en chile esta coleccion es ofrecida junto al periodico el mercurio. otro tanto ocurre en el peru, donde se oferta una edicion semejante junto con el diario el comercio. en paraguay esta edicion promocional es distribuida con el diario la nacion.[cita requerida]  britannica ultimate reference suite 2006 dvd contiene mas de 55 000 000 (cincuenta y cinco millones) de palabras y algo mas de 100 000 articulos.​ esto incluye 73 645 articulos de la britannica clasica, mientras que el resto fue obtenido de la britannica student encyclopædia, la britannica elementary encyclopædia y la britannica book of the year (1993-2004), ademas de unos pocos articulos \"clasicos\" de ediciones anteriores de la enciclopedia. el dvd contiene tambien un abanico de contenidos complementarios como mapas, videos, cortes de audio, animaciones y enlaces web. tambien incluye herramientas de estudio, diccionario y entradas del tesauro del merriam-webster.  encyclopædia britannica online es una pagina web con mas de 120 000 articulos actualizados regularmente.​ tiene articulos diarios, actualizaciones y enlaces al periodico en linea the new york times y a la pagina web de la bbc. existen subscripciones semanales, mensuales y anuales.​ ademas, tambien hay disponibles suscripciones especiales que se ofrecen a escuelas, institutos y bibliotecas. este tipo de subscripciones institucionales suponen una parte importante del negocio de la enciclopedia. aproximadamente el 60 % de los ingresos de la enciclopedia provienen de operaciones en la pagina web de las cuales el 15 % son de suscripciones a la propia pagina web.​  los articulos son accesibles en internet gratuitamente pero este acceso gratuito unicamente permite visualizar las primeras lineas de cada articulo. a principios de 2007, britannica empezo a hacer que los articulos fuesen completamente accesibles si estaban enlazados desde alguna otra pagina web​ debido a que este tipo de enlaces externos mejoran la posicion del articulo en los motores de busqueda de internet.  el 3 de junio de 2008, se anuncio una iniciativa que permitia y facilitaba la colaboracion entre expertos en los temas a tratar y expertos en temas en linea para desarrollar el contenido de britannica en su pagina web, todo ello bajo un control por parte del personal de la enciclopedia.​​ se reconoceria a los autores de las contribuciones​ pero su publicacion da una licencia perpetua e irrevocable a encyclopædia britannica, inc. sobre esas contribuciones​ el 22 de enero de 2009, el presidente de britannica, jorge cauz, anuncio que la compañia aceptaria ediciones y añadidos en su enciclopedia en linea por parte del publico en general aunque como condicion se exige un registro con nombre real y la direccion del contribuyente. todas las ediciones y aportaciones son revisadas y tienen que ser aprobadas por el personal profesional de la compañia.​ este tipo de contribuciones, las de los usuarios no academicos, se encontraran en una seccion aparte del contenido aportado por los expertos contratados por britannica,​ de la misma manera que seran clasificadas las contribuciones por partes de expertos ajenos a la empresa.​ los articulos creados e iniciados por usuarios, despues de ser revisados y aprobados, tambien seran solo accesibles en una seccion especial de la web, separada de los articulos generados por los profesionales contratados para ello.​​ el material oficial de britannica llevara un sello en el que diga britannica checked para diferenciarlo del material aportado por los usuarios de la web.​ a pesar de todas las aportaciones de contenido que pudiera haber por este medio, la edicion impresa de la enciclopedia no se vera afectada.​  el 13 de marzo de 2012, la enciclopedia anuncio en su pagina web que dejaba de editarse en papel, tras 244 años.​ la edicion de 2010 fue la ultima impresa, de la que se han vendido unicamente 8000 ejemplares en todo el mundo.​ en adelante se centraran en la edicion web de la enciclopedia.  la version impresa de 2007 cuenta con 4411 colaboradores, muchos de ellos eminencias en sus respectivos campos, como por ejemplo el premio nobel de economia milton friedman, el astronomo carl sagan y el cirujano michael debakey.​ aproximadamente, un cuarto del total de colaboradores han fallecido en la actualidad, mientras que otro cuarto estan retirados o son emeritos.  la mayoria (aproximadamente el 98 %) contribuyen a un unico articulo; sin embargo, en esta edicion de 2007, 64 lo hacen en tres, 23 en cuatro de ellos, 10 aportan en cinco articulos y 8 en mas de cinco. cabe destacar una colaboradora especialmente prolifica, la doctora christine sutton, de la universidad de oxford, que aporta en 24 articulos relacionados con fisica de particulas.  dale hoiberg, un sinologista, es vicepresidente senior y redactor jefe de britannica.​ entre sus predecesores como redactor jefe se encuentran hugh chisholm (1902-1924), james louis garvin (1926-1932), franklin henry hooper (1932-1938),​ walter yust (1938-1960), harry ashmore (1960-1963), warren e. preece (1964-1968, 1969-1975), sir william haley (1968-1969), philip w. goetz (1979-1991),​ y robert mchenry (1992-1997).​ anita wolff y theodore pappas son los actuales segundo editor y editor ejecutivo respectivamente.​ algunos editores ejecutivos anteriores fueron john v. dodge (1950-1964) y philip w. goetz.  la enciclopedia mantiene una plantilla editorial de cinco editores senior y nueve editores asociados, supervisados por dale hoiberg y otras cuatro personas. el personal editorial tambien ayuda en la construccion de articulos en la micropædia y en algunas secciones de la macropædia.​  britannica tiene un consejo editorial de consulta, en el cual estan incluidos 12 distinguidas eminencias:​​  en enero de 1996, la britannica perteneciente a la benton foundation fue comprada por el multimillonario financiero suizo jacqui safra,​ quien se desempeña como actual presidente de la junta. en 1997, don yannias, asociado desde hace mucho tiempo y asesor de inversiones de safra, se convirtio en ceo de la encyclopædia britannica, inc.​ una nueva compañia, britannica.com inc. se separo en 1999 para desarrollar la version digital de la britannica; yannias asumio el papel de ceo de la nueva compañia, mientras que la encyclopædia britannica, inc. permanecio vacante durante dos años. la permanencia de yannia en britannica.com inc. fue marcada por errores, muchos despidos y perdidas financieras.​ en 2001, yannias fue reemplazado por ilan yeshua, que reunio a los dirigentes de las dos compañias.​ yannias mas tarde regreso a la gestion de inversiones, pero permanece en la junta de directores de britannica.  en 2003, el exconsultor de gestion jorge cauz fue nombrado presidente de la encyclopædia britannica, inc. cauz es el ejecutivo principal e informa directamente a la junta de directores de britannica. cauz ha estado buscando alianzas con otras empresas y ampliar la marca britannica a los nuevos productos educativos y de referencia, continuando con la estrategia iniciada por el ex director general elkan harrison powell en la decada de 1930.​  bajo la propiedad de safra, la compañia ha experimentado dificultades financieras, y ha respondido al reducir el precio de sus productos y la aplicacion de drasticos recortes de costos. segun un informe de 2003 en el new york post la administracion de britannica ha eliminado los empleados 401(k) y fomentado el uso de imagenes de forma gratuita. estos cambios han tenido efectos negativos, como colaboradores independientes que han esperado hasta seis meses para los controles y el personal de britannica ha pasado años sin aumentos salariales.​  encyclopædia britannica, inc. ahora es dueño de marcas registradas sobre las palabras britannica, encyclopædia britanica, macropædia, micropædia y propædia, asi como en su logotipo cardo. ha ejercido sus derechos de marca tan recientemente como en 2005.​  como la britannica es una enciclopedia en general, no busca competir con las enciclopedias especializadas, tales como la enciclopedia de las matematicas o el diccionario de la edad media, que puede dedicar mucho mas espacio para sus temas elegidos. en sus primeros años, el principal competidor de la britannica fue la enciclopedia general de ephraim chambers y, poco despues, la enciclopedia de rees y la enciclopedia metropolitana de coleridge. en el siglo xx, los competidores exitosos incluyen enciclopedia collier, la enciclopedia americana, y la world book encyclopedia. sin embargo, a partir de la 9.ª edicion, la britannica fue ampliamente considerada poseedora de la mayor autoridad en general de cualquier enciclopedia de idioma ingles,​ sobre todo debido a su amplia cobertura y autores eminentes. la version impresa de la britannica es significativamente mas cara que sus competidores.​​  desde principios de 1990, la britannica se ha enfrentado a nuevos retos de las fuentes de informacion digital. la internet, facilitado por el desarrollo de motores de busqueda, se ha convertido en una fuente comun de informacion para muchas personas, y ofrece facil acceso a fuentes confiables y opiniones de expertos, en parte gracias a iniciativas como google libros, el lanzamiento del material educativo de la mit y pubmed central de la biblioteca nacional de medicina.​​ en general, internet tiende a proporcionar una cobertura mas actualizada que la prensa escrita, debido a la facilidad con que puede conseguirse material en internet actualizado.​ en los campos rapidamente cambiantes, como la ciencia, la tecnologia, la politica, la cultura y la historia moderna, la britannica ha luchado para mantenerse al dia, un primer problema analizado de forma sistematica por su exeditor walter yust.​ a pesar de que la britannica se encuentra disponible tanto en formato multimedia como en internet, su supremacia esta siendo desafiada por otras enciclopedias en linea, como wikipedia.  la enciclopedia britanica ha sido comparada con enciclopedias de impresion, tanto cualitativa como cuantitativamente.​​​ una comparacion muy conocida es la de kenneth kister, quien hizo una comparacion cualitativa y cuantitativa de la enciclopedia britanica, con dos enciclopedias comparables, la enciclopedia collier y la enciclopedia americana.​ para el analisis cuantitativo, diez articulos fueron seleccionados al azar (la circuncision, charles drew, galileo, philip glass, enfermedades del corazon, inteligencia, oso panda, el acoso sexual, sudario de turin y uzbekistan) y las calificaciones en letras de la a, d o f se otorgaron en cuatro categorias: cobertura, precision, claridad y novedad. en las cuatro categorias y para las tres enciclopedias, los cuatro grados promedio se redujo entre b- y b+, principalmente porque ninguna de las enciclopedias publico un articulo sobre el acoso sexual en 1994. en la categoria de precision, la britannica recibio una \"d\" y siete \"a\"s, la enciclopedia americana recibio ocho \"a\"s, y collier recibio una \"d\" y siete \"a\"s, por lo que la britannica recibio una puntuacion media de 92 % de precision, la americana 95 % y collier 92 %. la britannica de 1994 fue criticada por publicar una historia sobre charles drew enardecedora, que desde hace mucho tiempo habia sido desacreditada. en la categoria de la puntualidad, la britannica obtuvo un promedio de un 86 %; la americana, un 90 %; y collier, 85 %. despues de una comparacion cualitativa mas profunda de las tres enciclopedias, kister recomienda la enciclopedia collier como la enciclopedia superior, sobre todo en la fuerza de su excelente redaccion, presentacion equilibrada y de facil navegacion.  la collier no se halla en forma impresa desde 1998. la enciclopedia americana fue publicada por ultima vez en 2006. la britannica fue publicada por ultima vez en 2010.  el competidor mas notable de la britannica entre enciclopedias digitales en cd / dvd-rom era encarta,​ ahora suspendido, una enciclopedia moderna, multimedia que incorpora tres enciclopedias de impresion: funk & wagnalls, collier y el new merit scholar. encarta fue la mas vendida de las enciclopedias multimedia, basado en las ventas totales en estados unidos desde enero de 2000 a febrero de 2006.​ ambos ocuparon la misma gama de precios, con la 2007 encyclopædia britannica ultimate cd o dvd costando us$50​ y la microsoft encarta premium 2007 dvd us$45.​ la enciclopedia britanica contiene 100 000 articulos y el diccionario merriam-webster y sinonimos (solamente en estados unidos), y ofrece ediciones de primaria y secundaria.​ encarta contiene 62 000 articulos, un navegador visual facil de usar, herramientas de mapas interactivos, matematicas, lenguaje y las tareas escolares, un diccionario de estados unidos y el reino unido, y una edicion de la juventud.​ como encarta, la enciclopedia britanica ha sido criticada por su sesgo hacia los estados unidos; en el reino unido los articulos se actualizan con menos frecuencia, los mapas de los estados unidos son mas detalladas que las de otros paises, y carece de un diccionario del reino unido.​ al igual que la enciclopedia britanica, encarta estaba disponible en linea por suscripcion, aunque algunos contenidos se podia acceder de forma gratuita.​  entre las alternativas en linea a la britannica esta wikipedia, una enciclopedia web con contenido libre. una diferencia clave entre las dos enciclopedias se encuentra en la autoria de los articulos. los 699 articulos macropædia son generalmente escritos por colaboradores que estan identificados, y los cerca de 65 000 articulos micropædia son el trabajo de la redaccion y consultores externos que tambien estan identificados. por lo tanto, un articulo de britannica o bien tiene una autoria conocida, o bien un conjunto de posibles autores (el equipo editorial). con la excepcion de la redaccion, la mayoria de los colaboradores de la enciclopedia britanica son expertos en su campo (algunos son premiados con el nobel).​ por el contrario, los articulos de wikipedia son escritos por una comunidad de editores con diferentes niveles de experiencia: la mayoria de los editores no pretenden ninguna experiencia particular, de los que lo hacen, muchos son anonimos y no tienen credenciales verificables.​ otra diferencia es el ritmo del cambio del articulo: la enciclopedia britanica publicado en forma impresa se actualiza cada pocos años, mientras que los articulos de wikipedia es probable que se actualicen con frecuencia. robert mchenry, redactor de la enciclopedia britanica, dijo que wikipedia no puede aspirar a competir con esta en precision.​  el 14 de diciembre de 2005, en un estudio, la revista nature escogio los articulos de ambos lugares en una amplia gama de temas y los envio a lo que califico de «relevante» a expertos en la materia para su revision. los expertos comparan los articulos —uno de cada sitio en un determinado tema— al lado del otro, pero no dijeron que articulo provino de que sitio. nature devolvio 42 comentarios utiles de su ambito de expertos.  al final, la revista encontro solamente ocho errores graves, como equivocos en general de los conceptos vitales, en los articulos. de ellos, cuatro vinieron de cada sitio. ellos, sin embargo, descubrieron una serie de errores facticos, omisiones o declaraciones engañosas. en total, wikipedia tenia 162 problemas, mientras que en britannica habia 123.  el promedio es de 2.92 errores por articulo de britannica y 3.86 en wikipedia.​​ en su detallada refutacion de 20 paginas, encyclopædia britannica, inc. caracteriza el estudio publicado en la revista nature como deficiente y engañoso y pidio una \"pronta\" retraccion. señalo que dos de los articulos en el estudio fueron tomadas de un anuario de britannica, y no de la enciclopedia, y otros dos fueron de la enciclopedia de compton (llamado la enciclopedia britannica student en el sitio web de la compañia). la replica llego a mencionar que algunos de los articulos presentados a los encuestados eran combinaciones de varios articulos, y otros articulos que no eran mas que fragmentos, pero fueron sancionados por omision de hechos. la compañia tambien señalo que varios hechos clasificados como errores de nature eran pequeñas variaciones de ortografia, y que varios de sus supuestos errores fueron materia de interpretacion. nature defendio su historia y se nego a retractarse, indicando que, como se compara a wikipedia con la version web de la britannica, que utiliza cualquier material relevante disponible en sitio web de la enciclopedia britanica.​  entrevistado en febrero de 2009, el director gerente de britannica, dijo:  1suplemento de la cuarta, quinta y sexta ediciones de la encyclopaedia britannica. con disertaciones preliminares sobre la historia de las ciencias.  2 desde la 8.ª a la 14.ª edicion se incluia un volumen de indice separado.  3 la 9.ª edicion presentaba articulos de personas notables de la epoca, como james maxwell hablando de la electricidad y el magnetismo, y william thomson (que luego seria lord kelvin) hablando del calor.  4 la 10.ª edicion incluia un volumen de mapas y un volumen de indice que cubria la 9.ª y 10.ª edicion: constituyendo los nuevos volumenes, en combinacion con los volumenes existentes de la 9.ª ed., la 10.ª ed. … y suministrando tambien una nueva, distinta, e independiente biblioteca de referencia que trata de los eventos y desarrollos recientes  5 vols. 30-32 … constituyendo los nuevos volumenes, en combinacion con los veintinueve volumenes de la undecima edicion, la decimosegunda edicion  6 este suplemento sustituyo al suplemento anterior: constituyendo los tres nuevos volumenes suplementarios, con los volumenes de la ultima edicion estandar, la decimotercera edicion.  7 esta edicion fue la primera que se mantuvo actualizada por revision continua (normalmente anual).  8 la 15.ª edicion (presentada como \"britannica 3\") se publico en tres partes: una micropædia de diez volumenes (que contenia articulos cortos y servia de indice), una macropædia de 19 volumenes, y la propædia. se reorganizo en 1985 para tener 12 y 17 volumenes en la micro- y macropædia.  9 en 1985, el sistema se modifico añadiendo un indice de dos volumenes por separado; los articulos de la macropædia se consolidaron en menos articulos, mas grandes (por ejemplo, los articulos de los 50 estados de estados unidos, anteriormente separados, se incluyeron en el articulo \"estados unidos de america\"), con algunos articulos de mediana longitud trasladados a la micropædia.  la primera edicion en cd-rom se lanzo en 1994. en ese momento se ofrecio tambien una version en linea mediante suscripcion. en 1999 se ofrecio esta ultima gratis y no aparecieron versiones impresas. este experimento termino en 2001, y se lanzo una nueva version impresa.  la barsa, fundada en brasil en 1949, hoy pertenece al grupo español planeta. aunque su contenido sea oriundo de la matriz original, la marca acabo adquiriendo una identidad propia, al punto de tornarse la mas importante enciclopedia lusofona. fue editada en el pais sobre los auspicios de la encyclopaedia britannica de brasil publicacoes ltda. en la decada de 1970, bajo la direccion del inmortal de la abl, antonio houaiss, lanzo la enciclopedia mirador internacional​  algunos productos tuvieron corta existencia debido a la evolucion tecnologica, como fue el caso de la videopedia. dentro de los principales productos de barsa estan:​  compuesta de tres medios distintos, la enciclopedia posee actualizaciones semanales por internet, a traves de su sitio. posee un “consejo academico” del cual forman parte catorce universidades.​  posee mas de 122 000 entradas, de las cuales 500 son desarrolladas para concentrar las informaciones tematicas, ilustrada con mas de 10 000 fotografias, 900 dibujos, 500 mapas y 300 tablas.​  la barsa society posee diversos lanzamientos en varios medios. son productos como libros de derecho, enciclopedia multimedia del cuerpo humano (en 6 cd-rom), traductores etc.​  la barsa esta presente en varios paises de idioma español, como argentina, chile, españa, mexico y venezuela y tambien en portugal.​ ",
        "snippet": "La Enciclopedia Británica (en latín: Encyclopædia Britannica) es una enciclopedia en inglés de conocimiento general, editada por Encyclopædia Britannica, Inc., una empresa privada. Los artículos de la Britannica están dirigidos a lectores adultos, y están escritos por un conjunto de 100 editores a tiempo completo y cerca de 4000 contribuyentes expertos,[cita requerida] que han incluido 110 ganadores del Premio Nobel y cinco presidentes de los Estados Unidos. Estos artículos son considerados generalmente precisos, fiables y bien redactados. Es ampliamente reconocida como la enciclopedia más erudita de todas las editadas en inglés.[1]​[2]​",
        "enlaces_salientes": [
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Referencia",
            "/wiki/Enciclopedia",
            "/wiki/Ingl%C3%A9s_brit%C3%A1nico",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/Reino_Unido",
            "/wiki/Estados_Unidos",
            "/wiki/Lat%C3%ADn",
            "/wiki/Enciclopedia",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/Empresa_privada",
            "/wiki/Edici%C3%B3n_de_libros",
            "/wiki/Premio_Nobel",
            "/wiki/Presidente_de_los_Estados_Unidos",
            "/wiki/Edimburgo",
            "/wiki/Escocia",
            "/wiki/Encyclop%C3%A6dia_Britannica_(edici%C3%B3n_de_1911)",
            "/wiki/Norteam%C3%A9rica",
            "/wiki/Microp%C3%A6dia",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/Prop%C3%A6dia",
            "/wiki/Jerarqu%C3%ADa",
            "/wiki/Estados_Unidos",
            "/wiki/Esfera_armilar",
            "/wiki/Horace_Everett_Hooper",
            "/wiki/Sears_Roebuck_and_Company",
            "/wiki/William_Benton",
            "/wiki/Jacqui_Safra",
            "/wiki/Suiza",
            "/wiki/Tecnolog%C3%ADa_de_la_informaci%C3%B3n",
            "/wiki/Microsoft_Encarta",
            "/wiki/CD-ROM",
            "/wiki/DVD",
            "/wiki/World_Wide_Web",
            "/wiki/Serie_derivada",
            "/wiki/Ilustraci%C3%B3n_escocesa",
            "/wiki/Edimburgo",
            "/wiki/Adam_Black",
            "/wiki/L%27Encyclop%C3%A9die",
            "/wiki/Francia",
            "/wiki/Monarca",
            "/wiki/Escocia",
            "/wiki/Londres",
            "/wiki/The_Times",
            "/wiki/Universidad_de_Cambridge",
            "/wiki/Marca_comercial",
            "/wiki/Sears_Roebuck_and_Company",
            "/wiki/Chicago",
            "/wiki/Estados_Unidos",
            "/wiki/D%C3%B3lar_estadounidense",
            "/wiki/Internet",
            "/wiki/CD-ROM",
            "/wiki/DVD-ROM",
            "/wiki/Encyclop%C3%A6dia_Britannica_(edici%C3%B3n_de_1911)",
            "/wiki/Dominio_p%C3%BAblico",
            "/wiki/Encyclop%C3%A6dia_Britannica_(edici%C3%B3n_de_1911)",
            "/wiki/Encyclop%C3%A6dia_Britannica_(edici%C3%B3n_de_1911)",
            "/wiki/Andrew_Bell",
            "/wiki/Edimburgo",
            "/wiki/Encyclop%C3%A9die",
            "/wiki/Denis_Diderot",
            "/wiki/Cyclopaedia",
            "/wiki/Cardo",
            "/wiki/Ilustraci%C3%B3n_escocesa",
            "/wiki/Rees%27s_Cyclopaedia",
            "/wiki/Samuel_Taylor_Coleridge",
            "/wiki/Siglo_XIX",
            "/wiki/Egipto",
            "/wiki/Thomas_Young",
            "/wiki/Jerogl%C3%ADficos_egipcios",
            "/wiki/Piedra_de_Rosetta",
            "/wiki/Edimburgo",
            "/wiki/Redactor_jefe",
            "/wiki/Estados_Unidos",
            "/wiki/Mercadotecnia",
            "/wiki/Horace_Everett_Hooper",
            "/wiki/Sears_Roebuck_and_Company",
            "/wiki/William_Benton",
            "/wiki/Estados_Unidos",
            "/wiki/National_Geographic",
            "/wiki/Microp%C3%A6dia",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/Prop%C3%A6dia",
            "/wiki/Mortimer_Adler",
            "/wiki/Redactor_jefe",
            "/wiki/Disco_%C3%B3ptico",
            "/wiki/Jacqui_Safra",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/Director_ejecutivo",
            "/wiki/Corona_brit%C3%A1nica",
            "/wiki/Presidente_de_los_Estados_Unidos",
            "/wiki/Jorge_V_del_Reino_Unido",
            "/wiki/William_Howard_Taft",
            "/wiki/Dwight_D._Eisenhower",
            "/wiki/Isabel_II_del_Reino_Unido",
            "/wiki/George_W._Bush",
            "/wiki/Isabel_II_del_Reino_Unido",
            "/wiki/Grabado",
            "/wiki/Time_(revista)",
            "/wiki/William_Beebe",
            "/wiki/Sherlock_Holmes",
            "/wiki/Arthur_Conan_Doyle",
            "/wiki/Las_aventuras_de_Sherlock_Holmes",
            "/wiki/Monarqu%C3%ADa_en_Ir%C3%A1n",
            "/wiki/George_Bernard_Shaw",
            "/wiki/Richard_Evelyn_Byrd",
            "/wiki/Polo_Sur",
            "/wiki/Esquire",
            "/wiki/C._S._Forester",
            "/wiki/Redactor_jefe",
            "/wiki/Software_and_Information_Industry_Association",
            "/wiki/Software",
            "/wiki/Prop%C3%A6dia",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/Microp%C3%A6dia",
            "/wiki/Budismo",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/Cristianismo",
            "/wiki/Virginia_Woolf",
            "/wiki/Burgues%C3%ADa",
            "/wiki/Arte",
            "/wiki/Literatura",
            "/wiki/Ciencias_sociales",
            "/wiki/Sigmund_Freud",
            "/wiki/Universidad_Cornell",
            "/wiki/Edward_B._Titchener",
            "/wiki/Literatura_infantil",
            "/wiki/Joachim_du_Bellay",
            "/wiki/Jap%C3%B3n",
            "/wiki/Microp%C3%A6dia",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/American_Library_Association",
            "/wiki/Psicolog%C3%ADa",
            "/wiki/Ley_de_gravitaci%C3%B3n_universal",
            "/wiki/Redactor_jefe",
            "/wiki/Gravedad",
            "/wiki/Elementos_de_la_antig%C3%BCedad",
            "/wiki/William_Robertson_Smith",
            "/wiki/Biblia",
            "/wiki/Ku_Klux_Klan",
            "/wiki/Raza_cauc%C3%A1sica",
            "/wiki/Estados_Confederados_de_Am%C3%A9rica",
            "/wiki/Guerra_civil_estadounidense",
            "/wiki/Eugenesia",
            "/wiki/Marie_Curie",
            "/wiki/Premio_Nobel_de_F%C3%ADsica",
            "/wiki/Premio_Nobel_de_Qu%C3%ADmica",
            "/wiki/Pierre_Curie",
            "/wiki/Encyclop%C3%A6dia_Britannica_(edici%C3%B3n_de_1911)",
            "/wiki/Historia_de_la_matem%C3%A1tica",
            "/wiki/Willard_Huntington_Wright",
            "/wiki/New_York_Times",
            "/wiki/New_Republic",
            "/wiki/Joseph_McCabe",
            "/wiki/Iglesia_cat%C3%B3lica",
            "/wiki/Redactor_jefe",
            "/wiki/Microp%C3%A6dia",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/Prop%C3%A6dia",
            "/wiki/Estados_Unidos",
            "/wiki/Organizaci%C3%B3n_territorial_de_los_Estados_Unidos",
            "/wiki/Ingl%C3%A9s_brit%C3%A1nico",
            "/wiki/Ingl%C3%A9s_estadounidense",
            "/wiki/Signo_diacr%C3%ADtico",
            "/wiki/Carlos_III_de_Francia",
            "/wiki/Carlos_I_de_Inglaterra",
            "/wiki/Carlos_de_Gales",
            "/wiki/Luton",
            "/wiki/Bedfordshire",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/Chile",
            "/wiki/Am%C3%A9rica_Latina",
            "/wiki/Encyclop%C3%A6dia_Britannica_Inc.",
            "/wiki/El_Mercurio",
            "/wiki/Per%C3%BA",
            "/wiki/El_Comercio_(Per%C3%BA)",
            "/wiki/Paraguay",
            "/wiki/Ernest_Rutherford",
            "/wiki/DVD",
            "/wiki/Hiperenlace",
            "/wiki/Tesauro",
            "/wiki/Merriam-Webster",
            "/wiki/P%C3%A1gina_web",
            "/wiki/En_l%C3%ADnea",
            "/wiki/The_New_York_Times",
            "/wiki/British_Broadcasting_Corporation",
            "/wiki/En_l%C3%ADnea",
            "/wiki/Presidente",
            "/wiki/Acad%C3%A9mico",
            "/wiki/Premio_Nobel_de_Econom%C3%ADa",
            "/wiki/Milton_Friedman",
            "/wiki/Astr%C3%B3nomo",
            "/wiki/Carl_Sagan",
            "/wiki/Cirujano",
            "/wiki/Michael_DeBakey",
            "/wiki/Em%C3%A9rito",
            "/wiki/Universidad_de_Oxford",
            "/wiki/F%C3%ADsica_de_part%C3%ADculas",
            "/wiki/Sinolog%C3%ADa",
            "/wiki/Redactor_jefe",
            "/wiki/Redactor_jefe",
            "/wiki/Robert_McHenry",
            "/wiki/Microp%C3%A6dia",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/Nicholas_George_Carr",
            "/wiki/Wendy_Doniger",
            "/wiki/Council_on_Foreign_Relations",
            "/wiki/Premio_Nobel_de_F%C3%ADsica",
            "/wiki/Murray_Gell-Mann",
            "/wiki/Carnegie_Corporation",
            "/wiki/Vartan_Gregorian",
            "/wiki/Thomas_Nagel",
            "/wiki/Donald_Norman",
            "/wiki/Don_Michael_Randel",
            "/wiki/Royal_Society_of_Edinburgh",
            "/wiki/Universidad_de_St._Andrews",
            "/wiki/Escocia",
            "/wiki/Benton_Foundation",
            "/wiki/Jacqui_Safra",
            "/wiki/Don_Yannias",
            "/wiki/Director_ejecutivo",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/New_York_Post",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/Marcas_registradas",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/Microp%C3%A6dia",
            "/wiki/Cardo",
            "/wiki/Ephraim_Chambers",
            "/wiki/Abraham_Rees",
            "/wiki/Samuel_Taylor_Coleridge",
            "/wiki/Enciclopedia_Collier",
            "/wiki/Enciclopedia_Americana",
            "/wiki/World_Book_Encyclopedia",
            "/wiki/Enciclopedia",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Fuente_documental",
            "/wiki/Internet",
            "/wiki/Google_Libros",
            "/wiki/MIT",
            "/wiki/PubMed_Central",
            "/wiki/Biblioteca_Nacional_de_Medicina",
            "/wiki/Internet",
            "/wiki/Ciencia",
            "/wiki/Tecnolog%C3%ADa",
            "/wiki/Pol%C3%ADtica",
            "/wiki/Cultura",
            "/wiki/Historia_moderna",
            "/wiki/Cualidad",
            "/wiki/Cantidad",
            "/wiki/Enciclopedia_Collier",
            "/wiki/Enciclopedia_Americana",
            "/wiki/Circuncisi%C3%B3n",
            "/wiki/Charles_Drew",
            "/wiki/Galileo",
            "/wiki/Philip_Glass",
            "/wiki/Cardiopat%C3%ADa",
            "/wiki/Inteligencia",
            "/wiki/Oso_panda",
            "/wiki/Acoso_sexual",
            "/wiki/Sudario_de_Tur%C3%ADn",
            "/wiki/Uzbekist%C3%A1n",
            "/wiki/Precisi%C3%B3n",
            "/wiki/Charles_Drew",
            "/wiki/Encarta",
            "/wiki/Enciclopedia_Collier",
            "/wiki/Estados_Unidos",
            "/wiki/D%C3%B3lar_estadounidense",
            "/wiki/Reino_Unido",
            "/wiki/Contenido_libre",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/Microp%C3%A6dia",
            "/wiki/Premio_Nobel",
            "/wiki/Anonimato",
            "/wiki/Robert_McHenry",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/Historia_de_la_Encyclop%C3%A6dia_Britannica",
            "/wiki/James_Tytler",
            "/wiki/Libra_esterlina",
            "/wiki/S%C3%ADmbolos_qu%C3%ADmicos",
            "/wiki/Monarca",
            "/wiki/Copyright",
            "/wiki/Andrew_Bell",
            "/wiki/Humphry_Davy",
            "/wiki/Sir_Walter_Scott",
            "/wiki/Malthus",
            "/wiki/Adam_Black",
            "/wiki/David_Brewster",
            "/wiki/Thomas_de_Quincey",
            "/wiki/William_Thomson",
            "/wiki/Londres",
            "/wiki/Nueva_York",
            "/wiki/Horace_Everett_Hooper",
            "/wiki/Sears_Roebuck_and_Company",
            "/wiki/Primera_Guerra_Mundial",
            "/wiki/Microp%C3%A6dia",
            "/wiki/Macrop%C3%A6dia",
            "/wiki/Prop%C3%A6dia",
            "/wiki/Robert_McHenry",
            "/wiki/James_Clerk_Maxwell",
            "/wiki/William_Thomson",
            "/wiki/Grupo_Planeta",
            "/wiki/Enciclopedia",
            "/wiki/Lusofonia",
            "/wiki/Medio_de_comunicaci%C3%B3n_de_masas",
            "/wiki/Internet",
            "/wiki/Sitio_web",
            "/wiki/Entrada",
            "/wiki/Fotograf%C3%ADa",
            "/wiki/Dibujo",
            "/wiki/Mapa",
            "/wiki/Educaci%C3%B3n_primaria",
            "/wiki/Educaci%C3%B3n_secundaria",
            "/wiki/%C3%89tica",
            "/wiki/Idioma",
            "/wiki/Sin%C3%B3nimo",
            "/wiki/Ant%C3%B3nimo",
            "/wiki/Derecho",
            "/wiki/Cuerpo_humano",
            "/wiki/Traducci%C3%B3n",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Argentina",
            "/wiki/Chile",
            "/wiki/Espa%C3%B1a",
            "/wiki/M%C3%A9xico",
            "/wiki/Venezuela",
            "/wiki/Portugal",
            "/wiki/Enciclopedia",
            "/wiki/Enciclopedias_en_ingl%C3%A9s",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/ISBN",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Mortimer_Adler",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Edward_B._Titchener",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/S._S._Van_Dine",
            "/wiki/Joseph_McCabe",
            "/wiki/Encyclop%C3%A6dia_Britannica,_Inc.",
            "/wiki/Internet_Archive",
            "/wiki/Wayback_Machine",
            "/wiki/Internet_Archive",
            "/wiki/Bibcode",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Internet_Archive",
            "/wiki/Nature_(journal)",
            "/wiki/Identificador_de_objeto_digital",
            "/wiki/Bibcode",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/ISBN",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Wayback_Machine",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_la_Dieta",
            "/wiki/Biblioteca_Nacional_de_la_Rep%C3%BAblica_Checa",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/%C3%8Dndice_Internacional_de_Nombres_de_las_Plantas"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Enciclopedia_Treccani",
        "titulo": "Enciclopedia Treccani",
        "contenido": "enciclopedia treccani es el nombre con el que se conoce comunmente a la enciclopedia italiana de las ciencias, las letras y las artes (abreviada tambien en enciclopedia italiana). la primera edicion, que empezo a publicarse en 1929, y los ocho apendices posteriores de la enciclopedia, fueron preparados por el istituto dell'enciclopedia italiana, fundado en roma el 18 febrero de 1925 por giovanni treccani y giovanni gentile.  la enciclopedia treccani ha sido probablemente el mayor proyecto italiano de investigacion cultural.​  el libro encyclopaedias: their history throughout the ages la situaba en el podio de las enciclopedias mas importantes del siglo xx, junto a la xi edicion de la encyclopædia britanica y la enciclopedia universal ilustrada europeo-americana (enciclopedia espasa-calpe).​  hasta su aparicion, italia no habia tenido una gran enciclopedia universal, sino solo adaptaciones de obras extranjeras.​ en 1924, ferdinando martini y bonaldo stringher, amigos del empresario textil giovanni treccani (1877-1961), conociendo su actividad de mecenazgo, le propusieron la publicacion de una gran enciclopedia italiana.​  treccani se intereso vivamente en el proyecto y penso en una iniciativa aun mas grande. el acta constitutiva de la institucion que debia encargarse de la inmensa obra de organizacion y de publicacion se firmo en roma el 18 febrero de 1925. junto con el fundador, que era tambien el presidente, formaban parte del proyecto: el filosofo giovanni gentile en calidad de director cientifico, el editor calogero tumminelli como director editorial, el cientifico gian alberto blanc, el iusromanista pietro bonfante, el mariscal luigi cadorna, el ministro alberto de stefani, el historiador gaetano de sanctis, el economista luigi einaudi, el pintor vittorio grassi, el medico ettore marchiafava, el jurisconsulto silvio longhi, el ya citado ferdinando martini, el periodista ugo ojetti, el historiador francesco salata, el politico vittorio scialoja, el economista angelo sraffa, el almirante paolo thaon di revel, y el presidente del senado tommaso tittoni. el reconocido filosofo del lenguaje antonino pagliaro fue nombrado redactor jefe de la obra. una gran parte de ellos se adhirio en 1925 al manifiesto de los intelectuales fascistas.  sin embargo, el filosofo giovanni gentile, su primer director cientifico, fue el animador de la primera edicion de la enciclopedia italiana en 1925, y a el se deben en gran parte el nivel cultural y la amplitud de la vision de la obra. invito de hecho a colaborar en la nueva empresa a 3266 investigadores de diversa orientacion, ya que \"en la obra se debia involucrar a la mejor cultura nacional, incluidos muchos investigadores judios o abiertamente antifascistas, que obtuvieron a menudo en este trabajo su unico medio de vida». giovanni gentile logro ademas mantener una notable autonomia en la redaccion de la obra frente a las interferencias del regimen fascista.  entre 1925 y 1928 se desarrollo la fase preparatoria, que incluyo la formacion del comite tecnico (compuesto por los directores de las 48 secciones) y la redaccion de un diccionario. los temas seleccionados dieron lugar a 60.000 voces principales y 240.000 secundarias. el importante puesto de redactor jefe, tras las diferencias surgidas entre antonino pagliaro y gentile, fue ocupado desde 1929 por bruno migliorini y, posteriormente, por umberto bosco.  la primera edicion, formada por 35 volumenes de texto y uno de indices, se publico entre 1929 y 1937. cada volumen contaba aproximadamente con mil paginas y obtuvo un exito rotundo.  «el nivel era optimo: en las voces resultantes, se puede de hecho encontrar 'un correcto, y a menudo optimo, punto de partida para cualquier investigacion (...), ya se trate de investigaciones sobre temas de caracter general, ya se trate de investigaciones centradas en autores concretos. confiadas a especialistas, contienen en general un tratamiento claro y preciso de los temas (...), con una bibliografia esencial. algunas de estas voces (por ejemplo, romanticismo, renacimiento, dante) son verdaderos modelos de precision y complitud y tienen un valor cientifico que va mas alla del meramente divulgativo».​  entre 1935 y 1943 se publicaron tambien varias voces de la enciclopedia en fasciculos separados; el primero de estos incluye la voz \"fascismo\", que aparece firmada por benito mussolini (aunque fue redactada en realidad por el propio giovanni gentile) y por gioacchino volpe.​  progresivamente se fue planteando, y aun se plantea, el problema de las actualizaciones.  en 1938 se publico el volumen del primer apendice, al que siguieron otros ocho mas despues de la guerra.  aparentemente, y de forma similar a otras grandes obras de la misma editorial, la idea inicial parecia ser la de publicar un nuevo volumen de actualizacion cada año.  esto solo ocurrio, sin embargo, con el primer apendice, mientras que en los siguientes se aprecia una tendencia a ampliarse tanto en el numero de volumenes como en el arco temporal de referencia: el segundo apendice aparecio en dos volumenes referidos a diez años, la tercera en dos volumenes para doce años, la cuarta en tres volumenes para dieciocho años, la quinta en cinco volumenes para catorce años.  el \"quinto apendice\" (1979-1992) fue redactado en la forma tradicional, con la actualizacion de algunas voces o con la introduccion de nuevas.  posteriormente, a raiz del nacimiento y el desarrollo de internet y de la crisis de las grandes obras enciclopedicas, las actualizaciones, que se publicaban inevitablemente varios años despues del periodo al cual se referian, perdieron en buena parte su caracter peculiar para convertirse en publicaciones de caracter heterogeneo. parecia que la casa editora no supiera bien que hacer, dividida entre la idea de concluir la obra y cristalizarla en sentido historico, al no poder mantener el ritmo ni la capacidad de actualizar y conectar las informaciones de las nuevas tecnologias, y la de continuar publicando otros volumenes buscando nuevos desarrollos.​  no llego a haber, de hecho, un \"sexto apendice\" sino el \"apendice 2000\", publicado en 2000, que se componia de dos volumenes de actualizacion de voces en sentido estricto y otros dos volumenes mas de indices de toda la obra aparecida hasta entonces, dos volumenes de ensayos sobre temas diversos y dos volumenes de fotografias, tituladas \"herencia del siglo xx\".  el \"septimo apendice\", publicado en 2006 y 2009, se titulo \"siglo xxi\" y estaba formado por dos volumenes que incluian extractos de otras obras de la casa editorial publicados tambien como tercer suplemento del viejo diccionario enciclopedico italiano, por tres volumenes de actualizacion y por un dvd.  el \"octavo apendice\", publicado en 2012 y 2013, consta de dos volumenes de actualizaciones y seis volumenes, titulados \"la contribucion italiana a la historia del pensamiento\", dedicados al derecho, la economia, la filosofia, las ciencias, la historia y la politica, y la tecnica.  el \"noveno apendice\" en dos volumenes aparecio con fecha de 2015 y supone una actualizacion efectiva a dicha fecha.  globalmente, por lo tanto, en la version que parece definitiva, la enciclopedia se compone de 72 volumenes, con varias decenas de miles de paginas. las voces de la obra aparecen normalmente firmadas con las iniciales de los autores.  la enciclopedia italiana habria representado, durante el ventenio fascista, un ejemplo emblematico del compromiso entre el regimen y la elite cultural italiana de la epoca.​​  en 1996 nacio el sitio treccani.it, que se convirtio poco a poco en una verdadera enciclopedia en linea consultable gratuitamente. a partir del 2014 el portal supero los cien millones de visitas.​  el 30 de mayo de 2009 se oficializo un acuerdo alcanzado entre el ministro para la administracion publica y la innovacion, renato brunetta y el istituto della enciclopedia italiana.​ el acuerdo preve la presencia en dos sitios del ministerio de algunos materiales disponibles con licencia creativa commons.​​ ademas, esta previsto un enlace entre el portal scuola de treccani y el portal innovascuola del ministerio, mientras este ultimo hospedara un motor de busqueda desde el cual acceder al vocabulario y a las voces enciclopedicas presentes en el sitio de la enciclopedia treccani.​​ ",
        "snippet": "Enciclopedia Treccani es el nombre con el que se conoce comúnmente a la Enciclopedia Italiana de las ciencias, las letras y las artes (abreviada también en Enciclopedia Italiana). La primera edición, que empezó a publicarse en 1929, y los ocho apéndices posteriores de la enciclopedia, fueron preparados por el Istituto dell'Enciclopedia Italiana, fundado en Roma el 18 febrero de 1925 por Giovanni Treccani y Giovanni Gentile.",
        "enlaces_salientes": [
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Enciclopedia_Treccani",
            "/wiki/Istituto_dell%27Enciclopedia_Italiana",
            "/wiki/Enciclopedia",
            "/wiki/Idioma_italiano",
            "/wiki/1929",
            "/wiki/Instituto_de_la_Enciclopedia_Italiana",
            "/wiki/Italia",
            "/wiki/1929",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Roma",
            "/wiki/1929",
            "/wiki/Giovanni_Treccani",
            "/wiki/Giovanni_Gentile",
            "/wiki/Encyclop%C3%A6dia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_universal_ilustrada_europeo-americana",
            "/wiki/Enciclopedia",
            "/wiki/Giovanni_Treccani",
            "/wiki/Mecenazgo",
            "/wiki/Roma",
            "/wiki/Giovanni_Gentile",
            "/wiki/Derecho_romano",
            "/wiki/Mariscal_de_Italia",
            "/wiki/Luigi_Cadorna",
            "/wiki/Ministro",
            "/wiki/Gaetano_De_Sanctis",
            "/wiki/Luigi_Einaudi",
            "/wiki/Periodista",
            "/wiki/Ugo_Ojetti",
            "/wiki/Historiograf%C3%ADa",
            "/wiki/Francesco_Salata",
            "/wiki/Economista",
            "/wiki/Almirante",
            "/wiki/Manifesto_degli_intellettuali_fascisti",
            "/wiki/Giovanni_Gentile",
            "/wiki/Jud%C3%ADos",
            "/wiki/Antifascismo",
            "/wiki/Italia_fascista",
            "/wiki/Diccionario",
            "/wiki/Redactor_jefe",
            "/wiki/Libro",
            "/wiki/Romanticismo",
            "/wiki/Renacimiento",
            "/wiki/Dante_Alighieri",
            "/wiki/La_doctrina_del_fascismo",
            "/wiki/Benito_Mussolini",
            "/wiki/Giovanni_Gentile",
            "/wiki/Adenda",
            "/wiki/Autor",
            "/wiki/Fascismo",
            "/wiki/%C3%89lite",
            "/wiki/Italia_fascista",
            "/wiki/Istituto_della_Enciclopedia_Italiana",
            "/wiki/Licencias_Creative_Commons",
            "/wiki/Giovanni_Treccani",
            "/wiki/Giovanni_Gentile",
            "/wiki/Meyers_Konversations-Lexikon",
            "/wiki/Enciclopedia_Brockhaus",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Enciclopedia_Cat%C3%B3lica",
            "/wiki/Enciclopedia_Espasa",
            "/wiki/Amedeo_Benedetti",
            "/wiki/Tur%C3%ADn",
            "/wiki/D%C3%BCsseldorf",
            "/wiki/La_Repubblica",
            "/wiki/Gruppo_Editoriale_L%27Espresso",
            "/wiki/ISSN",
            "/wiki/Internet_Archive",
            "/wiki/Internet_Archive",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Internet_Archive",
            "/wiki/Internet_Archive",
            "/wiki/Wayback_Machine",
            "/wiki/Wayback_Machine",
            "/wiki/Mil%C3%A1n",
            "/wiki/Roma",
            "/wiki/Amedeo_Benedetti",
            "/wiki/Rai_Radio_3",
            "/wiki/Enciclopedia_Brit%C3%A1nica",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/Biblioteca_Nacional_de_Francia",
            "/wiki/Gemeinsame_Normdatei",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel",
            "/wiki/Syst%C3%A8me_universitaire_de_documentation",
            "/wiki/Enciclopedia_Brit%C3%A1nica"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Medical_Subject_Headings",
        "titulo": "Medical Subject Headings",
        "contenido": "el termino encabezados de temas medicos (en ingles, mesh, acronimo de medical subject headings) tambien conocido como terminos mesh, es un vocabulario terminologico controlado para publicaciones de articulos y libros de ciencia, creado por la biblioteca nacional de medicina de estados unidos (en ingles nlm).​  el mesh puede consultarse y descargarse gratuitamente en internet (pubmed). la version impresa anual se dejo de publicar en 2007. originalmente en ingles, mesh se tradujo a numerosos idiomas lo que permitio la recuperacion de documentos en otras lenguas diferentes del ingles.  el objetivo principal de mesh es proporcionar una terminologia jerarquicamente organizada para la indexacion y catalogacion de informacion biomedica, como medline /  pubmed y otras bases de datos de nlm.​  la version 2008 del mesh contenia un total de 24 767 titulos de material, tambien conocidos como descriptores, la mayor parte de los cuales se acompañaban por una breve descripcion o definicion, enlaces a los descriptores relacionados, y una lista de sinonimos o terminos muy similares (conocidos con el nombre de «terminos de entrada»).  este diccionario de sinonimos se creo en la decada de 1960 y comprende alrededor de 4000 terminos, como la evolucion de los encabezamientos de materia impresos en los separadores utilizados en los gabinetes de tarjetas de la biblioteca. en 2021, el numero de descriptores casi alcanzo los 30,000. el tesauro mesh esta organizado en una estructura jerarquica, con terminos que describen conceptos mas amplios en la parte superior de la estructura de arbol, con terminos mesh descendientes que describen conceptos mas especificos (es decir, mas especificos).​  los descriptores o encabezamientos de materia se organizan de manera jerarquica. un descriptor dado puede aparecer en varios lugares en el arbol jerarquico. las ubicaciones del arbol llevan etiquetas de manera sistematica, conocidas como «numero de arboles» y, por consiguiente, un descriptor puede llevar varios numeros de arbol. por ejemplo, tras el grafico de la derecha, c significa «enfermedades de c06 enfermedades del sistema digestivo», y para c06.301 «neoplasias del sistema digestivo»; c04 para las «neoplasias», para c04.588 «neoplasias por sitio», y c04.588.274 segundo arbol para «neoplasias del sistema digestivo». como se observa en el grafico, el termino «neoplasias» aparece en cuatro lugares en la jerarquia y, por lo tanto, lleva cuatro numeros diferentes de arboles. el numero de arboles de un descriptor dado esta sujeto a los constantes cambios en la actualizacion del mesh. cada descriptor tambien lleva un numero de identificacion alfanumerico unico, que no varia. ",
        "snippet": "El término Encabezados de Temas Médicos (en inglés, MeSH, acrónimo de Medical Subject Headings) también conocido como términos MESH, es un vocabulario terminológico controlado para publicaciones de artículos y libros de ciencia, creado por la Biblioteca Nacional de Medicina de Estados Unidos (en inglés NLM).[1]​",
        "enlaces_salientes": [
            "/wiki/Medical_Subject_Headings",
            "/wiki/Medical_Subject_Headings",
            "/wiki/Medical_Subject_Headings",
            "/wiki/Dominio_de_Internet",
            "/wiki/Estados_Unidos",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Acr%C3%B3nimo",
            "/wiki/Terminolog%C3%ADa",
            "/wiki/Art%C3%ADculo_cient%C3%ADfico",
            "/wiki/Biblioteca_Nacional_de_Medicina_de_Estados_Unidos",
            "/wiki/PubMed",
            "/wiki/Indexaci%C3%B3n",
            "/wiki/MEDLINE",
            "/wiki/Descriptor",
            "/wiki/Descripci%C3%B3n",
            "/wiki/Definici%C3%B3n",
            "/wiki/Sin%C3%B3nimo",
            "/wiki/Terminolog%C3%ADa",
            "/wiki/Encabezamientos_de_materia",
            "/wiki/CIE-10",
            "/wiki/Clasificaci%C3%B3n_internacional_de_los_trastornos_del_sue%C3%B1o",
            "/wiki/Encabezamientos_de_materia",
            "/wiki/PubMed_Central",
            "/wiki/PubMed_Identifier",
            "/wiki/Digital_object_identifier",
            "/wiki/Control_de_autoridades",
            "/wiki/Fichero_de_Autoridades_Virtual_Internacional",
            "/wiki/Library_of_Congress_Control_Number",
            "/wiki/Biblioteca_Nacional_de_Israel"
        ]
    },
    {
        "url": "https://es.wikipedia.org/wiki/Descriptores_en_Ciencias_de_la_Salud",
        "titulo": "Descriptores en Ciencias de la Salud",
        "contenido": "el vocabulario estructurado y cuatrilingue decs - descriptores en ciencias de la salud - fue creado por bireme - centro latinoamericano y del caribe de informacion en ciencias de la salud en 1986 para uso en la indizacion de articulos de revistas cientificas, libros, anales de congresos, informes tecnicos y otros tipos de materiales, asi como para usarse en la busqueda y recuperacion de asuntos de la literatura cientifica en las bases de datos lilacs, medline y otras. en la bvs, biblioteca virtual en salud, el decs es la herramienta que permite la navegacion entre registros y fuentes de informacion a traves de conceptos controlados y organizados en portugues, español, ingles y frances.  se desarrollo a partir del mesh - medical subject headings de la nlm - u.s. national library of medicine - con objeto de permitir el uso de terminologia comun para busqueda en los idiomas de las americas, proporcionando un medio consistente y unico para la recuperacion de informacion independientemente del idioma. ademas de los terminos medicos originales del mesh se desarrollaron las areas especificas de ciencia y salud (2005), homeopatia (1991), salud publica (1986) y vigilancia sanitaria (2005).  los conceptos que componen el decs se organizan en una estructura jerarquica permitiendo la ejecucion de busquedas en terminos mas amplios o mas especificos o todos los terminos que pertenezcan a una misma estructura jerarquica.  tiene como finalidad principal servir como un lenguaje unico para indexacion (o indizacion) y recuperacion de informacion entre los componentes del sistema latinoamericano y de caribe de informacion en ciencias de la salud,​ coordinado por bireme y que abarca 37 paises en america latina y en caribe, permitiendo un dialogo uniforme entre cerca de 600 bibliotecas.  participa en el proyecto de desarrollo de terminologia unica y red semantica en salud, umls - unified medical language system de la nlm con la responsabilidad de la actualizacion anual y envio de los terminos del mesh en portugues y español.​​ ",
        "snippet": "El vocabulario estructurado y cuatrilingüe DeCS - Descriptores en Ciencias de la Salud - fue creado por BIREME - Centro Latinoamericano y del Caribe de Información en Ciencias de la Salud en 1986 para uso en la indización de artículos de revistas científicas, libros, anales de congresos, informes técnicos y otros tipos de materiales, así como para usarse en la búsqueda y recuperación de asuntos de la literatura científica en las bases de datos LILACS, MEDLINE y otras. En la BVS, Biblioteca Virtual en Salud, el DeCS es la herramienta que permite la navegación entre registros y fuentes de información a través de conceptos controlados y organizados en portugués, español, inglés y francés.",
        "enlaces_salientes": [
            "/wiki/Descriptores_en_Ciencias_de_la_Salud",
            "/wiki/Descriptores_en_Ciencias_de_la_Salud",
            "/wiki/Descriptores_en_Ciencias_de_la_Salud",
            "/wiki/Vocabulario",
            "/wiki/Centro_Latinoamericano_y_del_Caribe_de_Informaci%C3%B3n_en_Ciencias_de_la_Salud",
            "/wiki/%C3%8Dndice_(base_de_datos)",
            "/wiki/LILACS",
            "/wiki/Medline",
            "/wiki/Registro_(base_de_datos)",
            "/wiki/Concepto",
            "/wiki/Idioma_portugu%C3%A9s",
            "/wiki/Idioma_espa%C3%B1ol",
            "/wiki/Idioma_ingl%C3%A9s",
            "/wiki/Idioma_franc%C3%A9s",
            "/wiki/MeSH",
            "/wiki/Medical_Subject_Headings",
            "/wiki/NLM",
            "/wiki/National_Library_of_Medicine",
            "/wiki/Terminolog%C3%ADa",
            "/wiki/Recuperaci%C3%B3n_de_informaci%C3%B3n",
            "/wiki/Ciencia",
            "/wiki/Salud",
            "/wiki/2005",
            "/wiki/Homeopat%C3%ADa",
            "/wiki/1991",
            "/wiki/Salud_P%C3%BAblica",
            "/wiki/1986",
            "/wiki/2005",
            "/wiki/Indexaci%C3%B3n",
            "/wiki/Recuperaci%C3%B3n_de_informaci%C3%B3n",
            "/wiki/Latinoam%C3%A9rica",
            "/wiki/Mar_Caribe",
            "/wiki/Red_sem%C3%A1ntica",
            "/wiki/Base_de_datos",
            "/wiki/Ling%C3%BC%C3%ADstica",
            "/wiki/Tesauro",
            "/wiki/Control_de_autoridades"
        ]
    }
]